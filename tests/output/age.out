Evaluating KNeighborsClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.388211382114 | 0.0467711274247 |  {'n_neighbors': 3} |        5        |
|  0.417010401722 |  0.054203794565 |  {'n_neighbors': 5} |        4        |
|  0.441146580583 | 0.0417891791478 | {'n_neighbors': 11} |        3        |
|  0.471602004623 | 0.0323550589291 | {'n_neighbors': 21} |        2        |
|  0.483818730744 | 0.0161783184573 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.48      1.00      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.23      0.47      0.31        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+------------------+---------------------+-----------------+
| test_mean_score |  test_std_score  |        params       | test_rank_score |
+-----------------+------------------+---------------------+-----------------+
|  0.323586179039 | 0.0392349326937  |  {'n_neighbors': 3} |        2        |
|  0.35851935775  | 0.0976656224836  |  {'n_neighbors': 5} |        1        |
|  0.293093740494 | 0.0504804923258  | {'n_neighbors': 11} |        3        |
|  0.291765719762 | 0.0816858435966  | {'n_neighbors': 21} |        4        |
|  0.239348463828 | 0.00691999439749 | {'n_neighbors': 31} |        5        |
+-----------------+------------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.18      0.21      0.19        14
          1       0.53      0.70      0.60        27
          2       0.67      0.18      0.29        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.42      0.42      0.39        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.373983739837 | 0.0450209744425 |  {'n_neighbors': 3} |        5        |
|  0.40662601626  |  0.072207165797 |  {'n_neighbors': 5} |        4        |
|  0.444959349593 | 0.0491815206613 | {'n_neighbors': 11} |        3        |
|  0.46772696477  |  0.032138173794 | {'n_neighbors': 21} |        2        |
|  0.475565718157 |   0.0191168956  | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.48      1.00      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.23      0.47      0.31        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.359756097561 | 0.0656043430796 |  {'n_neighbors': 3} |        5        |
|  0.382321221171 |  0.063857173319 |  {'n_neighbors': 5} |        4        |
|  0.402413099386 | 0.0361584527064 | {'n_neighbors': 11} |        3        |
|  0.465467894475 |  0.034022140311 | {'n_neighbors': 21} |        2        |
|  0.475609756098 | 0.0222889339594 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.47      0.32        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.324757660155 | 0.0637807481297 |  {'n_neighbors': 3} |        1        |
|  0.321760102878 | 0.0623227039693 |  {'n_neighbors': 5} |        2        |
|  0.313143540243 | 0.0631451102029 | {'n_neighbors': 11} |        3        |
|  0.265774244223 | 0.0531341336704 | {'n_neighbors': 21} |        5        |
|  0.277987099015 | 0.0931178508623 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.42      0.57      0.48        14
          1       0.61      0.70      0.66        27
          2       0.14      0.09      0.11        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.42      0.49      0.45        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.367886178862 | 0.0368405067926 |  {'n_neighbors': 3} |        5        |
|  0.39018583043  | 0.0483972278733 |  {'n_neighbors': 5} |        4        |
|  0.43476836873  | 0.0358652997003 | {'n_neighbors': 11} |        3        |
|  0.461299153808 | 0.0284653717753 | {'n_neighbors': 21} |        2        |
|  0.471525634644 | 0.0157673436319 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.47      0.32        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.400406504065 |  0.035328133299 |  {'n_neighbors': 3} |        5        |
|  0.404471544715 | 0.0342204414313 |  {'n_neighbors': 5} |        4        |
|  0.453294376694 | 0.0403383439964 | {'n_neighbors': 11} |        3        |
|  0.469512195122 | 0.0300074876186 | {'n_neighbors': 21} |        2        |
|  0.483719097395 | 0.0164284609326 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.50      0.14      0.22        14
          1       0.49      0.96      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.36      0.49      0.36        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.354509723306 | 0.0264640878455 |  {'n_neighbors': 3} |        2        |
|  0.342430682288 | 0.0710230603997 |  {'n_neighbors': 5} |        3        |
|  0.360998747905 | 0.0884445614086 | {'n_neighbors': 11} |        1        |
|  0.338539835714 | 0.0745397193519 | {'n_neighbors': 21} |        4        |
|  0.289987251383 | 0.0838885867743 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.29      0.24        14
          1       0.46      0.63      0.53        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.27      0.37      0.31        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.392276422764 | 0.0663143780376 |  {'n_neighbors': 3} |        5        |
|  0.394365113932 | 0.0526913845744 |  {'n_neighbors': 5} |        4        |
|  0.451219512195 | 0.0323813638483 | {'n_neighbors': 11} |        3        |
|  0.479653192578 | 0.0197967841031 | {'n_neighbors': 21} |        1        |
|  0.473476024556 | 0.0208811617252 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.43      0.21      0.29        14
          1       0.50      0.89      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.34      0.47      0.37        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.383367139959 | 0.0429157696461 |  {'n_neighbors': 3} |        5        |
|  0.430205702971 | 0.0572623753701 |  {'n_neighbors': 5} |        4        |
|  0.458355756096 | 0.0378543705855 | {'n_neighbors': 11} |        3        |
|  0.45847735646  |  0.024035848255 | {'n_neighbors': 21} |        2        |
|  0.474645030426 | 0.0207438992316 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.46      0.93      0.62        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.45      0.30        56

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.347547548953 |  0.070638132219 |  {'n_neighbors': 3} |        2        |
|  0.347999170843 |  0.059994735456 |  {'n_neighbors': 5} |        1        |
|  0.322157214084 | 0.0523919444414 | {'n_neighbors': 11} |        3        |
|  0.305201986352 | 0.0616096714318 | {'n_neighbors': 21} |        4        |
|  0.276468124689 | 0.0581415509144 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.19      0.23      0.21        13
          1       0.49      0.67      0.56        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.28      0.38      0.32        56

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.371196754564 | 0.0739709599432 |  {'n_neighbors': 3} |        5        |
|  0.430081515365 | 0.0413407348561 |  {'n_neighbors': 5} |        4        |
|  0.452249865463 | 0.0516533533604 | {'n_neighbors': 11} |        3        |
|  0.458439410247 |  0.045836187933 | {'n_neighbors': 21} |        2        |
|  0.482862110361 | 0.0186019713794 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.46      0.93      0.62        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.45      0.30        56

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.386639676113 | 0.0351576374572 |  {'n_neighbors': 3} |        5        |
|  0.396761133603 | 0.0464407257635 |  {'n_neighbors': 5} |        4        |
|  0.439494340246 | 0.0435419731172 | {'n_neighbors': 11} |        3        |
|  0.477729419703 | 0.0348830610486 | {'n_neighbors': 21} |        2        |
|  0.485870445344 | 0.0137823489886 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        55

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.321034852851 | 0.0472099676925 |  {'n_neighbors': 3} |        1        |
|  0.307587486911 | 0.0517701608282 |  {'n_neighbors': 5} |        2        |
|  0.279528043311 | 0.0446440407368 | {'n_neighbors': 11} |        5        |
|  0.306244731484 | 0.0778220154297 | {'n_neighbors': 21} |        3        |
|  0.280562320418 | 0.0772332329213 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.19      0.31      0.24        13
          1       0.56      0.56      0.56        27
          2       0.33      0.20      0.25        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.38      0.38      0.37        55

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.396761133603 | 0.0779344693307 |  {'n_neighbors': 3} |        4        |
|  0.384574072544 |  0.058507911525 |  {'n_neighbors': 5} |        5        |
|  0.429131620259 | 0.0377189800901 | {'n_neighbors': 11} |        3        |
|  0.477774105594 | 0.0230075814812 | {'n_neighbors': 21} |        1        |
|  0.47572915806  | 0.0179171118896 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.25      0.08      0.12        13
          1       0.49      0.93      0.64        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.30      0.47      0.34        55

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.373737373737 | 0.0469036195163 |  {'n_neighbors': 3} |        5        |
|  0.398330241187 | 0.0505986740383 |  {'n_neighbors': 5} |        4        |
|  0.458522297808 | 0.0469190138173 | {'n_neighbors': 11} |        3        |
|  0.460523603381 | 0.0319437492925 | {'n_neighbors': 21} |        2        |
|  0.478768089054 | 0.0103976853227 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+------------------+---------------------+-----------------+
| test_mean_score |  test_std_score  |        params       | test_rank_score |
+-----------------+------------------+---------------------+-----------------+
|  0.312944635779 | 0.0732537249625  |  {'n_neighbors': 3} |        3        |
|  0.336405592726 | 0.0731463375228  |  {'n_neighbors': 5} |        1        |
|  0.313469949481 | 0.0292082829028  | {'n_neighbors': 11} |        2        |
|  0.29323348886  | 0.0601219265108  | {'n_neighbors': 21} |        4        |
|  0.236071012286 | 0.00800173381626 | {'n_neighbors': 31} |        5        |
+-----------------+------------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.15      0.15      0.15        13
          1       0.46      0.63      0.53        27
          2       0.25      0.10      0.14        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.31      0.37      0.33        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+------------------+---------------------+-----------------+
| test_mean_score |  test_std_score  |        params       | test_rank_score |
+-----------------+------------------+---------------------+-----------------+
|  0.375757575758 | 0.0618792147361  |  {'n_neighbors': 3} |        5        |
|  0.392018827733 | 0.0657228444951  |  {'n_neighbors': 5} |        4        |
|  0.446358139215 | 0.0366604790648  | {'n_neighbors': 11} |        3        |
|  0.460423830138 | 0.0267094916998  | {'n_neighbors': 21} |        2        |
|  0.486868686869 | 0.00988744360806 | {'n_neighbors': 31} |        1        |
+-----------------+------------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.385858585859 | 0.0551330355785 |  {'n_neighbors': 3} |        4        |
|  0.38373015873  | 0.0815507233417 |  {'n_neighbors': 5} |        5        |
|  0.444320758606 | 0.0498163320307 | {'n_neighbors': 11} |        3        |
|  0.468498763142 |  0.047269045445 | {'n_neighbors': 21} |        2        |
|  0.476767676768 | 0.0287231123253 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.348788870396 |  0.059617926966 |  {'n_neighbors': 3} |        2        |
|  0.35000765359  | 0.0903506130302 |  {'n_neighbors': 5} |        1        |
|  0.324489271261 | 0.0803250303086 | {'n_neighbors': 11} |        4        |
|  0.289555082284 | 0.0477622265431 | {'n_neighbors': 21} |        5        |
|  0.328262565124 |  0.093992205542 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.12      0.15      0.14        13
          1       0.51      0.67      0.58        27
          2       0.33      0.10      0.15        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.35      0.39      0.35        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.385858585859 | 0.0695242091819 |  {'n_neighbors': 3} |        5        |
|  0.418016903731 | 0.0424606062058 |  {'n_neighbors': 5} |        4        |
|  0.438611420326 | 0.0540630172182 | {'n_neighbors': 11} |        3        |
|  0.456565656566 | 0.0296613325424 | {'n_neighbors': 21} |        2        |
|  0.466686422044 | 0.0170602746979 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.381048387097 | 0.0460714291407 |  {'n_neighbors': 3} |        5        |
|  0.41118145847  | 0.0457299631737 |  {'n_neighbors': 5} |        4        |
|  0.45564516129  | 0.0431066809471 | {'n_neighbors': 11} |        3        |
|  0.481917414143 | 0.0333374249523 | {'n_neighbors': 21} |        1        |
|  0.473769749835 | 0.0225606518602 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.25      0.08      0.12        13
          1       0.47      0.88      0.61        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.29      0.45      0.33        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.349313019088 | 0.0496277117013 |  {'n_neighbors': 3} |        1        |
|  0.344829274935 | 0.0440564090363 |  {'n_neighbors': 5} |        2        |
|  0.290781165641 |  0.100672679644 | {'n_neighbors': 11} |        3        |
|  0.286804934428 | 0.0482965705197 | {'n_neighbors': 21} |        5        |
|  0.290444768415 |  0.057671714507 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.31      0.38      0.34        13
          1       0.51      0.69      0.59        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.33      0.43      0.37        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.383064516129 | 0.0491291631011 |  {'n_neighbors': 3} |        5        |
|  0.417577284946 | 0.0471558992808 |  {'n_neighbors': 5} |        4        |
|  0.439553091398 | 0.0191043099246 | {'n_neighbors': 11} |        3        |
|  0.463578629032 | 0.0334867830199 | {'n_neighbors': 21} |        2        |
|  0.473872647849 | 0.0259994931971 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      0.96      0.64        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.47      0.31        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.372983870968 | 0.0484205942922 |  {'n_neighbors': 3} |        5        |
|  0.413471033575 | 0.0804904828296 |  {'n_neighbors': 5} |        4        |
|  0.449539993417 | 0.0418516657502 | {'n_neighbors': 11} |        2        |
|  0.447642363397 | 0.0474549547833 | {'n_neighbors': 21} |        3        |
|  0.479838709677 | 0.0200754011313 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.49      0.33        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+------------------+---------------------+-----------------+
| test_mean_score |  test_std_score  |        params       | test_rank_score |
+-----------------+------------------+---------------------+-----------------+
|  0.335515614793 | 0.0456716869889  |  {'n_neighbors': 3} |        2        |
|  0.349222452641 | 0.0674879175997  |  {'n_neighbors': 5} |        1        |
|  0.309946486702 | 0.0726332518707  | {'n_neighbors': 11} |        4        |
|  0.310766206162 | 0.0699837643783  | {'n_neighbors': 21} |        3        |
|  0.235339229377 | 0.00775350960753 | {'n_neighbors': 31} |        5        |
+-----------------+------------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.08      0.08      0.08        13
          1       0.39      0.54      0.45        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.21      0.28      0.24        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.381048387097 | 0.0722671382639 |  {'n_neighbors': 3} |        5        |
|  0.413387096774 | 0.0567757300095 |  {'n_neighbors': 5} |        4        |
|  0.437333669355 |  0.051584645519 | {'n_neighbors': 11} |        3        |
|  0.469736668861 | 0.0298666230972 | {'n_neighbors': 21} |        1        |
|  0.465663265306 | 0.0211052734522 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      0.92      0.65        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.45      0.32        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.385080645161 | 0.0660474293236 |  {'n_neighbors': 3} |        5        |
|  0.423562756368 | 0.0488324015923 |  {'n_neighbors': 5} |        4        |
|  0.445755143714 | 0.0398257700925 | {'n_neighbors': 11} |        3        |
|  0.451567669562 | 0.0311630831424 | {'n_neighbors': 21} |        2        |
|  0.477861352357 | 0.0162072873036 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.49      0.33        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.318992609051 | 0.0351085290227 |  {'n_neighbors': 3} |        2        |
|  0.387009796052 | 0.0511390762465 |  {'n_neighbors': 5} |        1        |
|  0.277002218788 | 0.0327688470441 | {'n_neighbors': 11} |        3        |
|  0.249055408427 | 0.0252186767593 | {'n_neighbors': 21} |        5        |
|  0.25005692275  | 0.0339822677221 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.38      0.36        13
          1       0.53      0.69      0.60        26
          2       0.25      0.10      0.14        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.39      0.45      0.41        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.389112903226 | 0.0741322827148 |  {'n_neighbors': 3} |        5        |
|  0.41332616716  | 0.0488570513268 |  {'n_neighbors': 5} |        4        |
|  0.43743228138  | 0.0406390167437 | {'n_neighbors': 11} |        3        |
|  0.45564516129  | 0.0272047858027 | {'n_neighbors': 21} |        2        |
|  0.479859282423 | 0.0116118161102 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.49      0.33        53

Evaluating RandomForestClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.380081300813 |  0.05487317986  | {'n_estimators': 2}  |        6        |
|  0.363943089431 | 0.0512700283675 | {'n_estimators': 3}  |        7        |
|  0.398699186992 | 0.0608916608661 | {'n_estimators': 5}  |        5        |
|  0.412720189702 | 0.0290750863968 | {'n_estimators': 10} |        4        |
|  0.43916796402  | 0.0436563381498 | {'n_estimators': 20} |        2        |
|  0.432926829268 | 0.0360090862876 | {'n_estimators': 40} |        3        |
|  0.445118563686 |  0.035381915515 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.25      0.07      0.11        14
          1       0.46      0.81      0.59        27
          2       0.20      0.09      0.13        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.32      0.42      0.33        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.330578803487 | 0.0936903933395 | {'n_estimators': 2}  |        5        |
|  0.329881916608 | 0.0462440226421 | {'n_estimators': 3}  |        6        |
|  0.357208554347 | 0.0471564837314 | {'n_estimators': 5}  |        1        |
|  0.356461002873 | 0.0684632270263 | {'n_estimators': 10} |        2        |
|  0.340369863336 |  0.054838723878 | {'n_estimators': 20} |        3        |
|  0.32984265378  |  0.051219395854 | {'n_estimators': 40} |        7        |
|  0.333711646037 | 0.0711221785567 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.17      0.21      0.19        14
          1       0.44      0.59      0.51        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.25      0.33      0.29        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.331300813008 | 0.0554451183934 | {'n_estimators': 2}  |        6        |
|  0.29674796748  |  0.031212051765 | {'n_estimators': 3}  |        7        |
|  0.396189370057 | 0.0781829023749 | {'n_estimators': 5}  |        5        |
|  0.408470908689 | 0.0302382677468 | {'n_estimators': 10} |        4        |
|  0.447258171561 | 0.0452541333953 | {'n_estimators': 20} |        1        |
|  0.443149922571 | 0.0251857366135 | {'n_estimators': 40} |        2        |
|  0.439042537747 | 0.0382787624653 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.09      0.07      0.08        14
          1       0.45      0.74      0.56        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.37      0.29        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.382113821138 |  0.050877862944 | {'n_estimators': 2}  |        6        |
|  0.367595818815 | 0.0698037970303 | {'n_estimators': 3}  |        7        |
|  0.418640285382 |  0.032717670242 | {'n_estimators': 5}  |        5        |
|  0.420872566506 | 0.0759992309919 | {'n_estimators': 10} |        4        |
|  0.430931376183 | 0.0352189166931 | {'n_estimators': 20} |        3        |
|  0.443047950888 | 0.0363076302651 | {'n_estimators': 40} |        2        |
|  0.47152224711  | 0.0417804577853 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.14      0.20        14
          1       0.48      0.89      0.62        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.31      0.46      0.34        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.361715742187 | 0.0776943357352 | {'n_estimators': 2}  |        3        |
|  0.362507968825 |  0.054353289117 | {'n_estimators': 3}  |        2        |
|  0.307357740814 | 0.0541420128797 | {'n_estimators': 5}  |        7        |
|  0.316169245078 | 0.0211059456398 | {'n_estimators': 10} |        6        |
|  0.356643810818 | 0.0756325528257 | {'n_estimators': 20} |        4        |
|  0.364182262169 |  0.090119287224 | {'n_estimators': 40} |        1        |
|  0.349795748181 | 0.0902868455072 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.23      0.21      0.22        14
          1       0.44      0.70      0.54        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.27      0.39      0.31        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.373983739837 | 0.0521590595039 | {'n_estimators': 2}  |        6        |
|  0.359883130081 | 0.0420792879968 | {'n_estimators': 3}  |        7        |
|  0.380081300813 | 0.0568157431469 | {'n_estimators': 5}  |        5        |
|  0.429158197832 | 0.0768552400469 | {'n_estimators': 10} |        4        |
|  0.459434281843 | 0.0268847271884 | {'n_estimators': 20} |        2        |
|  0.437118902439 | 0.0304860829389 | {'n_estimators': 40} |        3        |
|  0.473416327913 | 0.0343301132616 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.17      0.07      0.10        14
          1       0.46      0.81      0.59        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.26      0.40      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.353658536585 | 0.0525925937887 | {'n_estimators': 2}  |        7        |
|  0.382128511974 | 0.0560166197846 | {'n_estimators': 3}  |        5        |
|  0.39862286378  | 0.0605403883986 | {'n_estimators': 5}  |        4        |
|  0.367964726108 |  0.039984406659 | {'n_estimators': 10} |        6        |
|  0.418463269454 | 0.0496218800278 | {'n_estimators': 20} |        3        |
|  0.422515347602 | 0.0527789472127 | {'n_estimators': 40} |        2        |
|  0.45325203252  | 0.0391771536114 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.14      0.20        14
          1       0.49      0.93      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.31      0.47      0.35        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.328358116829 | 0.0647607891866 | {'n_estimators': 2}  |        5        |
|  0.330417160584 | 0.0335186650418 | {'n_estimators': 3}  |        4        |
|  0.337615359244 | 0.0835598165218 | {'n_estimators': 5}  |        2        |
|  0.336428012487 |  0.043295889003 | {'n_estimators': 10} |        3        |
|  0.310651804338 | 0.0684495301105 | {'n_estimators': 20} |        6        |
|  0.30695172151  | 0.0359872714827 | {'n_estimators': 40} |        7        |
|  0.343826867087 | 0.0467944853232 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.07      0.11        14
          1       0.48      0.93      0.63        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.28      0.46      0.33        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.365853658537 | 0.0638198921672 | {'n_estimators': 2}  |        5        |
|  0.343827775012 | 0.0598945269472 | {'n_estimators': 3}  |        7        |
|  0.357584133809 | 0.0735123617845 | {'n_estimators': 5}  |        6        |
|  0.400378850727 | 0.0631222656301 | {'n_estimators': 10} |        4        |
|  0.434941098391 | 0.0289830960276 | {'n_estimators': 20} |        3        |
|  0.447299651568 | 0.0640390173436 | {'n_estimators': 40} |        2        |
|  0.453229564183 | 0.0338924109596 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.21      0.26        14
          1       0.50      0.89      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.32      0.47      0.37        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.361054766734 | 0.0479306390627 | {'n_estimators': 2}  |        7        |
|  0.367139959432 | 0.0660569205862 | {'n_estimators': 3}  |        6        |
|  0.381338742394 |  0.034268291144 | {'n_estimators': 5}  |        5        |
|  0.401222557989 | 0.0715836488687 | {'n_estimators': 10} |        4        |
|  0.413793103448 | 0.0512577412825 | {'n_estimators': 20} |        3        |
|  0.448420747609 | 0.0413640478765 | {'n_estimators': 40} |        2        |
|  0.456410150267 | 0.0397962853278 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.17      0.08      0.11        13
          1       0.46      0.81      0.59        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.26      0.41      0.31        56

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.340197755069 | 0.0672867229886 | {'n_estimators': 2}  |        3        |
|  0.330927355236 | 0.0705868267954 | {'n_estimators': 3}  |        4        |
|  0.348491519965 |  0.07085502866  | {'n_estimators': 5}  |        2        |
|  0.308487179507 | 0.0349841391646 | {'n_estimators': 10} |        7        |
|  0.319848322329 | 0.0882285164036 | {'n_estimators': 20} |        6        |
|  0.369477759243 | 0.0726218856818 | {'n_estimators': 40} |        1        |
|  0.320619289597 | 0.0824611500727 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.15      0.21        13
          1       0.50      0.93      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.32      0.48      0.36        56

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.336713995943 | 0.0414470811666 | {'n_estimators': 2}  |        7        |
|  0.364945978391 | 0.0632455332978 | {'n_estimators': 3}  |        6        |
|  0.422030881318 | 0.0456373430004 | {'n_estimators': 5}  |        5        |
|  0.438069193195 | 0.0521628249257 | {'n_estimators': 10} |        3        |
|   0.4340951898  | 0.0448094517493 | {'n_estimators': 20} |        4        |
|  0.438133874239 | 0.0421857400559 | {'n_estimators': 40} |        2        |
|  0.444278573498 | 0.0433064613846 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.15      0.17        13
          1       0.48      0.78      0.59        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.28      0.41      0.33        56

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.372469635628 | 0.0829336706488 | {'n_estimators': 2}  |        6        |
|  0.37476245559  | 0.0511954408795 | {'n_estimators': 3}  |        5        |
|  0.37044534413  | 0.0455266346378 | {'n_estimators': 5}  |        7        |
|  0.417229543639 | 0.0709089027755 | {'n_estimators': 10} |        4        |
|  0.429086108127 | 0.0382615373212 | {'n_estimators': 20} |        3        |
|  0.455402758269 | 0.0475007378935 | {'n_estimators': 40} |        2        |
|  0.457592298053 | 0.0413309849793 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.27      0.23      0.25        13
          1       0.52      0.81      0.64        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.32      0.45      0.37        55

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.332899599326 | 0.0582429593778 | {'n_estimators': 2}  |        3        |
|  0.321855152745 | 0.0764977301211 | {'n_estimators': 3}  |        6        |
|  0.339640317971 |  0.057658682102 | {'n_estimators': 5}  |        2        |
|  0.331931381583 | 0.0722843057469 | {'n_estimators': 10} |        4        |
|  0.381638539835 | 0.0771597847353 | {'n_estimators': 20} |        1        |
|  0.330496698262 | 0.0459915723462 | {'n_estimators': 40} |        5        |
|  0.318624713964 | 0.0593214751667 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.18      0.15      0.17        13
          1       0.53      0.78      0.63        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.30      0.42      0.35        55

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.346153846154 | 0.0569439309921 | {'n_estimators': 2}  |        7        |
|  0.374075573549 | 0.0840144165984 | {'n_estimators': 3}  |        6        |
|  0.374652496626 | 0.0617351769689 | {'n_estimators': 5}  |        5        |
|  0.398736504723 | 0.0345155484363 | {'n_estimators': 10} |        4        |
|  0.457489878543 | 0.0391743682603 | {'n_estimators': 20} |        2        |
|  0.451538461538 | 0.0413936090743 | {'n_estimators': 40} |        3        |
|  0.463513832659 | 0.0506118509235 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.14      0.08      0.10        13
          1       0.48      0.81      0.60        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.27      0.42      0.32        55

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.365656565657 | 0.0636222534945 | {'n_estimators': 2}  |        7        |
|  0.391779839208 | 0.0396158894928 | {'n_estimators': 3}  |        5        |
|  0.387854737855 | 0.0565576146582 | {'n_estimators': 5}  |        6        |
|  0.432323232323 | 0.0543130513029 | {'n_estimators': 10} |        4        |
|  0.452401566687 | 0.0484214088122 | {'n_estimators': 20} |        2        |
|  0.464893836322 | 0.0438396457724 | {'n_estimators': 40} |        1        |
|  0.44840239126  | 0.0420042346539 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.08      0.11        13
          1       0.49      0.85      0.62        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.29      0.44      0.34        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.331303631183 | 0.0541601335586 | {'n_estimators': 2}  |        5        |
|  0.313840919821 | 0.0449903937634 | {'n_estimators': 3}  |        6        |
|  0.345684944951 | 0.0554365991529 | {'n_estimators': 5}  |        2        |
|  0.338962590017 | 0.0607576868326 | {'n_estimators': 10} |        3        |
|  0.361126312791 | 0.0460150473866 | {'n_estimators': 20} |        1        |
|  0.299201048779 | 0.0410324459323 | {'n_estimators': 40} |        7        |
|  0.334257325142 | 0.0774625360252 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.22      0.15      0.18        13
          1       0.45      0.70      0.55        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.28      0.39      0.32        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.375757575758 | 0.0675472700059 | {'n_estimators': 2}  |        7        |
|  0.397872431801 |  0.042457667438 | {'n_estimators': 3}  |        5        |
|  0.391894282966 | 0.0662983803764 | {'n_estimators': 5}  |        6        |
|  0.410202363774 | 0.0496496783976 | {'n_estimators': 10} |        4        |
|  0.417949048306 | 0.0526394871222 | {'n_estimators': 20} |        3        |
|  0.450463821892 | 0.0386506495753 | {'n_estimators': 40} |        1        |
|  0.44425462104  | 0.0362140196561 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.25      0.08      0.12        13
          1       0.43      0.74      0.55        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.28      0.39      0.30        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.339393939394 | 0.0567566357987 | {'n_estimators': 2}  |        7        |
|  0.343548821549 | 0.0362166011641 | {'n_estimators': 3}  |        6        |
|  0.377804713805 | 0.0618004409265 | {'n_estimators': 5}  |        5        |
|  0.41396969697  | 0.0420234190901 | {'n_estimators': 10} |        4        |
|  0.426218855219 | 0.0368250998683 | {'n_estimators': 20} |        2        |
|  0.422468013468 | 0.0580489338909 | {'n_estimators': 40} |        3        |
|  0.436442760943 | 0.0383289140394 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.50      0.08      0.13        13
          1       0.51      0.96      0.67        27
          2       1.00      0.10      0.18        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.56      0.52      0.40        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.335040728051 | 0.0455924941078 | {'n_estimators': 2}  |        4        |
|  0.361774032296 | 0.0556488883486 | {'n_estimators': 3}  |        1        |
|  0.343816374347 | 0.0494747953357 | {'n_estimators': 5}  |        3        |
|  0.350038287874 | 0.0595359113887 | {'n_estimators': 10} |        2        |
|  0.327857952144 | 0.0676718694178 | {'n_estimators': 20} |        5        |
|  0.30938109838  | 0.0499819218623 | {'n_estimators': 40} |        7        |
|   0.3145585388  |  0.074265916192 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.31      0.24        13
          1       0.41      0.44      0.43        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.26      0.30      0.27        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.353535353535 | 0.0501487596326 | {'n_estimators': 2}  |        4        |
|  0.347580292723 |  0.076568588771 | {'n_estimators': 3}  |        5        |
|  0.337219989006 | 0.0461120975221 | {'n_estimators': 5}  |        7        |
|  0.341207998351 | 0.0477926244617 | {'n_estimators': 10} |        6        |
|  0.414076135505 | 0.0526835859014 | {'n_estimators': 20} |        3        |
|  0.480766852195 | 0.0409688589376 | {'n_estimators': 40} |        1        |
|  0.438383838384 | 0.0358189843521 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      0.89      0.63        27
          2       0.33      0.10      0.15        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.31      0.46      0.34        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.362903225806 | 0.0606352637187 | {'n_estimators': 2}  |        6        |
|  0.38314680711  | 0.0488302003077 | {'n_estimators': 3}  |        5        |
|  0.352837153006 | 0.0465069990146 | {'n_estimators': 5}  |        7        |
|  0.409084752853 | 0.0526043399898 | {'n_estimators': 10} |        4        |
|  0.411184887261 | 0.0545249058521 | {'n_estimators': 20} |        3        |
|  0.445499369102 | 0.0269488472221 | {'n_estimators': 40} |        1        |
|  0.443589532587 | 0.0361517303268 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.14      0.08      0.10        13
          1       0.44      0.77      0.56        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.40      0.30        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.350882104459 | 0.0686200909171 | {'n_estimators': 2}  |        3        |
|  0.335063044023 | 0.0557765453842 | {'n_estimators': 3}  |        4        |
|  0.332096675585 | 0.0320971458607 | {'n_estimators': 5}  |        6        |
|  0.36889454366  |  0.05688030554  | {'n_estimators': 10} |        2        |
|  0.333631047078 |  0.051809662472 | {'n_estimators': 20} |        5        |
|  0.372726544659 | 0.0731972590979 | {'n_estimators': 40} |        1        |
|   0.3059991716  | 0.0727415301716 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.25      0.15      0.19        13
          1       0.49      0.85      0.62        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.30      0.45      0.35        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.350806451613 | 0.0344467563795 | {'n_estimators': 2}  |        7        |
|  0.369381926158 | 0.0631084004846 | {'n_estimators': 3}  |        6        |
|  0.378826530612 | 0.0782701376437 | {'n_estimators': 5}  |        5        |
|  0.433508887426 | 0.0457906843559 | {'n_estimators': 10} |        3        |
|  0.425212070715 | 0.0380742495283 | {'n_estimators': 20} |        4        |
|  0.443525242758 | 0.0375425918533 | {'n_estimators': 40} |        2        |
|  0.457596143296 | 0.0314412215171 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.08      0.11        13
          1       0.49      0.88      0.63        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.29      0.45      0.34        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.362903225806 | 0.0692985583029 | {'n_estimators': 2}  |        6        |
|  0.366666021247 |  0.06382314019  | {'n_estimators': 3}  |        5        |
|  0.361193973557 | 0.0710793485527 | {'n_estimators': 5}  |        7        |
|  0.41723241716  | 0.0443310584239 | {'n_estimators': 10} |        4        |
|  0.42151069097  | 0.0426974875365 | {'n_estimators': 20} |        3        |
|  0.455480579329 | 0.0398872459641 | {'n_estimators': 40} |        1        |
|  0.439450982006 |  0.029987742057 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.36      0.31      0.33        13
          1       0.55      0.85      0.67        26
          2       0.50      0.10      0.17        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.45      0.51      0.44        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.345740259493 | 0.0806212653465 | {'n_estimators': 2}  |        2        |
|  0.353499936111 | 0.0846444586111 | {'n_estimators': 3}  |        1        |
|  0.339163654914 | 0.0502881123888 | {'n_estimators': 5}  |        4        |
|  0.321722807613 |  0.049853886918 | {'n_estimators': 10} |        6        |
|  0.340214721846 | 0.0513751262492 | {'n_estimators': 20} |        3        |
|  0.328973279042 |  0.077862926117 | {'n_estimators': 40} |        5        |
|  0.298084749416 | 0.0426922161624 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.19      0.23      0.21        13
          1       0.44      0.54      0.48        26
          2       0.25      0.10      0.14        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.31      0.34      0.31        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.370967741935 | 0.0710608763744 | {'n_estimators': 2}  |        7        |
|  0.379032258065 | 0.0411604861329 | {'n_estimators': 3}  |        5        |
|  0.379032258065 |  0.08139342289  | {'n_estimators': 5}  |        5        |
|  0.421323924731 | 0.0432083242469 | {'n_estimators': 10} |        4        |
|  0.441451612903 | 0.0480328818814 | {'n_estimators': 20} |        3        |
|  0.447410954301 | 0.0326538975398 | {'n_estimators': 40} |        1        |
|  0.441572580645 | 0.0318560726098 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.18      0.15      0.17        13
          1       0.46      0.73      0.57        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.27      0.40      0.32        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.338709677419 |  0.061136082296 | {'n_estimators': 2}  |        7        |
|  0.368898640101 | 0.0499891789677 | {'n_estimators': 3}  |        6        |
|  0.395462475313 | 0.0581799632438 | {'n_estimators': 5}  |        4        |
|  0.391454973118 | 0.0680963001649 | {'n_estimators': 10} |        5        |
|  0.407379032258 | 0.0439044165084 | {'n_estimators': 20} |        3        |
|  0.45564516129  | 0.0233412471652 | {'n_estimators': 40} |        1        |
|  0.447620967742 | 0.0395523714398 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.08      0.11        13
          1       0.52      0.96      0.68        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.30      0.49      0.36        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.348411169127 | 0.0428831538413 | {'n_estimators': 2}  |        2        |
|  0.334382511302 | 0.0519957337168 | {'n_estimators': 3}  |        5        |
|  0.341671246926 | 0.0478383446125 | {'n_estimators': 5}  |        3        |
|  0.361346116013 | 0.0953296453976 | {'n_estimators': 10} |        1        |
|  0.305938153753 | 0.0733756930952 | {'n_estimators': 20} |        7        |
|  0.341267594022 | 0.0677746044447 | {'n_estimators': 40} |        4        |
|  0.322460951781 |  0.053693157544 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.38      0.38      0.38        13
          1       0.51      0.69      0.59        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.35      0.43      0.38        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.405241935484 | 0.0639251718819 | {'n_estimators': 2}  |        4        |
|  0.387216061828 | 0.0697507896343 | {'n_estimators': 3}  |        7        |
|  0.393220766129 | 0.0881892135956 | {'n_estimators': 5}  |        6        |
|  0.403346774194 | 0.0481370629636 | {'n_estimators': 10} |        5        |
|  0.429512768817 | 0.0379838623849 | {'n_estimators': 20} |        2        |
|  0.42346438172  | 0.0408457535749 | {'n_estimators': 40} |        3        |
|  0.455643481183 | 0.0326020402919 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.51      0.96      0.67        26
          2       1.00      0.10      0.18        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.44      0.49      0.36        53

Evaluating MLPClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        9        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        4        |
|  0.487867151012 | 0.0098088281735  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        4        |
|  0.487845528455 | 0.00861839016232 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        4        |
|  0.487845528455 | 0.00861839016232 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        4        |
|  0.487867151012 | 0.0098088281735  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.485772357724 | 0.00804396904489 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.483780487805 | 0.0129305626971  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        14       |
|  0.477699359972 | 0.0178619776842  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        19       |
|  0.479777720118 | 0.0170024737357  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        16       |
|  0.479715447154 | 0.0161611359588  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        17       |
|  0.473577235772 | 0.0261617918306  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        20       |
|  0.479632452575 | 0.0197035498621  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        18       |
|  0.48581300813  | 0.0101831774254  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        11       |
|  0.485770663957 | 0.00792213146875 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.481788617886 | 0.0132584165983  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.487823905899 | 0.00738318770146 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.487886178862 | 0.0199131336649  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        1        |
|  0.471580284553 | 0.0238085215223  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        21       |
|  0.485834630687 | 0.0112125581469  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        10       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.50      0.07      0.12        14
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.36      0.49      0.34        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.238027698884 | 0.00836752217225 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        10       |
|  0.238027698884 | 0.00836752217225 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        10       |
|  0.238007788481 | 0.00712857147328 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        14       |
|  0.238007788481 | 0.00712857147328 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|  0.238027698884 | 0.00836752217225 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        10       |
|  0.238048227255 | 0.00838446264646 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        9        |
|  0.238027698884 | 0.00836752217225 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        10       |
|  0.237012056689 | 0.00897552795965 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        20       |
|  0.261413841794 | 0.0748221108428  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.268272357724 | 0.0579549901311  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        4        |
|  0.238445717675 | 0.0083530979605  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.237013227889 | 0.00947223123535 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.237944685918 | 0.0071085104181  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        16       |
|  0.266894863701 | 0.0715412751252  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.237529727172 | 0.00841483429526 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        18       |
|  0.275091355691 |  0.079819305543  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        2        |
|  0.236451635323 |  0.009778245461  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        21       |
|  0.271644343605 | 0.0804276185952  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|  0.245022358198 | 0.0353911492582  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.281538081938 | 0.0784344988938  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.237919600976 | 0.0107880548598  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        17       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.47      0.32        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        8        |
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        8        |
|  0.487825618052 | 0.00862517403599 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.487825618052 | 0.00862517403599 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.487825618052 | 0.00862517403599 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        2        |
|  0.487825618052 | 0.00862517403599 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.487825618052 | 0.00862517403599 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.477663016426 | 0.0214179516308  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        16       |
|  0.483760577402 | 0.0179781797817  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.485750753553 | 0.00792429948903 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.479736152591 | 0.0184766409914  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        15       |
|  0.475628767767 | 0.0171533819542  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.475550854488 | 0.0231457118441  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        20       |
|  0.475631325701 | 0.0204657613848  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        18       |
|  0.487825618052 | 0.00862517403599 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        2        |
|  0.483760577402 | 0.0111718567474  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.483760577402 | 0.0111718567474  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.477662152259 | 0.0116616595232  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        17       |
|  0.479778496765 | 0.0161991388038  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        14       |
|  0.491933002876 | 0.0181461306615  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.471648415464 | 0.0328081484612  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.07      0.11        14
          1       0.48      0.89      0.62        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.28      0.44      0.32        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        4        |
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        4        |
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        4        |
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        4        |
|  0.487825618052 | 0.00862517403599 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        3        |
|  0.487804878049 | 0.00736134723135 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        4        |
|  0.487804878049 | 0.00860812617509 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        4        |
|  0.483760577402 | 0.00917575846202 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.483760577402 | 0.0155001591924  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.485793097727 | 0.0175219788618  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
|  0.475589845694 | 0.0171738537119  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        20       |
|  0.48172719291  | 0.0133230031321  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        18       |
|  0.485750753553 | 0.00792429948903 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.48587605774  | 0.0150424036256  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        10       |
|  0.483760577402 | 0.0113255044217  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.489837398374 | 0.0141719150735  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        1        |
|  0.483760577402 | 0.0127984994989  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        13       |
|  0.487847240609 | 0.0133278566294  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.483698357392 | 0.0199423479946  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        17       |
|  0.475671976108 | 0.0318276784637  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        19       |
|  0.475565628431 | 0.0174037083551  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.46      0.96      0.63        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.46      0.30        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.238027698884 | 0.00836752217225 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        12       |
|  0.238048227255 | 0.00838446264646 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        10       |
|  0.238027698884 | 0.00836752217225 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        12       |
|  0.238007788481 | 0.00712857147328 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|  0.238048227255 | 0.00838446264646 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        10       |
|  0.238007788481 | 0.00712857147328 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|  0.238091261119 | 0.00963135240291 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        9        |
|  0.256322170979 | 0.0580593667976  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        5        |
|  0.235996856154 | 0.0108169861611  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        21       |
|  0.257266617777 |  0.056391700877  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.236459851895 | 0.0098962724718  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        19       |
|  0.238474650189 | 0.0077452931495  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        8        |
|  0.236815063585 | 0.00784432628785 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        18       |
|  0.262977867046 | 0.0625966944545  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.237572761036 | 0.0096601137457  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        16       |
|  0.236055057207 | 0.0114654926818  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        20       |
|  0.258716028885 | 0.0643860668499  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.237531727972 | 0.00947357124167 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        17       |
|  0.256828511893 |  0.057771154906  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.255211356648 | 0.0583822726554  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.239829697079 | 0.0130325047691  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        7        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       1.00      0.07      0.13        14
          1       0.49      0.93      0.64        27
          2       0.20      0.09      0.13        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.52      0.47      0.36        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        3        |
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        6        |
|  0.487867151012 | 0.0098088281735  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.487824788452 | 0.00735345366363 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        5        |
|  0.487804878049 | 0.00736134723135 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        6        |
|  0.487845528455 | 0.00861839016232 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        3        |
|  0.48581300813  | 0.0101831774254  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.48581300813  | 0.0120847538626  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.485772357724 | 0.0112155612626  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.485834630687 | 0.0129626797757  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
|  0.477703666833 |  0.023059330358  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        18       |
|  0.48581300813  | 0.0163808642269  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.475691056911 | 0.0220096666474  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        20       |
|  0.485770663957 | 0.00792213146875 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        15       |
|  0.48581300813  | 0.0101831774254  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.48987804878  | 0.00631246794933 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.483739837398 | 0.00925734131289 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        16       |
|  0.477642276423 | 0.0179653535469  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        19       |
|  0.479674796748 | 0.0155017413208  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        17       |
|  0.475691056911 | 0.0191578384431  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        20       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        7        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.487804878049 | 0.00736134723135 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        7        |
|  0.487845528455 | 0.00861839016232 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.487845528455 | 0.00861839016232 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.48575078812  | 0.00916090020653 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.483739837398 | 0.00925734131289 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.481707317073 | 0.0123695484703  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.481727227476 | 0.0126348349647  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        13       |
|  0.481707317073 | 0.0108244271731  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        14       |
|  0.481705623306 | 0.0116387793782  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        16       |
|  0.471458333333 | 0.0224144573404  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        20       |
|  0.48581300813  | 0.00794237134903 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.483759747802 | 0.0102217069074  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.487886178862 | 0.0139561943263  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.479674796748 | 0.0248876812493  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.479694707151 | 0.0140818158632  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        17       |
|  0.473593668915 | 0.00926323408771 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        19       |
|  0.469574468085 | 0.0409633965069  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.46      0.93      0.62        27
          2       0.50      0.09      0.15        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.32      0.46      0.32        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.238027698884 | 0.00836752217225 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|  0.237969740251 | 0.00582451468229 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        18       |
|  0.238007788481 | 0.00712857147328 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|  0.238048227255 | 0.00838446264646 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        10       |
|  0.238048227255 | 0.00838446264646 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        10       |
|  0.238048227255 | 0.00838446264646 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        10       |
|  0.238048227255 | 0.00838446264646 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        10       |
|  0.247949155415 | 0.0362241249684  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        5        |
|  0.237540308806 | 0.00841453493207 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        20       |
|  0.256161369198 | 0.0568443642649  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.238464245245 | 0.00779141774346 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
|  0.237541809327 | 0.00984165087464 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.242422829153 | 0.0192935721252  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
|  0.283101063691 | 0.0697377226827  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.238048227255 | 0.00838446264646 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        10       |
|  0.239054117416 | 0.0094208080605  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.237519127526 | 0.00840883404109 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        21       |
|  0.255121880993 | 0.0609813324756  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.242393996316 |  0.01923257308   |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.238005864695 | 0.00958026508818 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        17       |
|  0.289345005224 |  0.104752452391  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.40      0.14      0.21        14
          1       0.45      0.81      0.58        27
          2       0.33      0.09      0.14        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.38      0.44      0.35        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00736134723135 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.487845528455 | 0.00861839016232 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.487804878049 | 0.00736134723135 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        6        |
|  0.487867151012 | 0.0098088281735  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.487824788452 | 0.00735345366363 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        5        |
|  0.481707317073 | 0.00983892204631 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        16       |
|  0.481788617886 | 0.0132584165983  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.483780487805 | 0.0128002532967  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
|  0.475609756098 | 0.0249759603893  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        21       |
|  0.481707317073 | 0.0140891306795  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        16       |
|  0.47579398028  | 0.0295763422146  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        20       |
|  0.477662186826 | 0.0140727125593  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        19       |
|  0.48581300813  | 0.0101831774254  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.483821138211 | 0.0127563500713  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
|  0.485772357724 | 0.00913480382895 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.483738143631 |  0.01107869208   |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        12       |
|  0.48176699533  | 0.0106512386034  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        14       |
|  0.48174796748  |  0.026868716686  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        15       |
|  0.477682926829 | 0.0192709498866  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        18       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.486815415822 | 0.00767362845229 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        8        |
|  0.486815415822 | 0.00624616335453 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        8        |
|  0.486836113756 | 0.00769537062935 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        5        |
|  0.486815415822 | 0.00767362845229 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        8        |
|  0.486815415822 | 0.00767362845229 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        8        |
|  0.486836113756 | 0.00769537062935 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        5        |
|  0.486836113756 | 0.00769537062935 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        5        |
|  0.482820714493 | 0.0100634301859  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        16       |
|  0.48480771619  | 0.0091920008807  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.486878372038 | 0.0151156771854  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.482779318624 | 0.0118511752353  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        18       |
|  0.484890507927 | 0.0182745868294  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.482779318624 | 0.0133355354476  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        18       |
|  0.491018821322 | 0.0180542743214  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.48480771619  | 0.0111087801653  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.486878372038 | 0.0136477071593  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        3        |
|  0.48882394337  | 0.00835718481276 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.482779318624 | 0.0135768175679  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.482800016558 | 0.0125379624134  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        17       |
|  0.480730223124 | 0.0285370097694  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        21       |
|  0.484726580287 | 0.0129768678224  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        15       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      0.96      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.46      0.31        56

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.237048133655 | 0.00743684471496 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        11       |
|  0.237068620386 | 0.00745855262641 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        7        |
|  0.237048133655 | 0.00743684471496 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        11       |
|  0.237068620386 | 0.00745855262641 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        7        |
|  0.237068620386 | 0.00745855262641 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        7        |
|  0.237068620386 | 0.00745855262641 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        7        |
|  0.237048133655 | 0.00743684471496 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        11       |
|  0.247567324571 | 0.0296659658366  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        6        |
|  0.236034551586 | 0.00799038759862 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        18       |
|  0.236489676964 | 0.00595169870424 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        16       |
|  0.23704748207  | 0.00745079547022 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        14       |
|  0.235956223784 | 0.00521827478279 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.254248117097 | 0.0583410863982  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
|  0.279738451161 | 0.0903702908709  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.236551172027 | 0.00742468497473 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        15       |
|  0.236045111757 | 0.00799204885789 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        17       |
|  0.235483026501 | 0.00689266980723 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        20       |
|  0.23484242774  | 0.0055772865756  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        21       |
|  0.291341197509 | 0.0858469782761  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.268080847514 | 0.0630295622014  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.301138497952 | 0.0900511884008  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.48      0.32        56

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.486815415822 | 0.00767362845229 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        7        |
|  0.486836113756 | 0.00769537062935 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.486836113756 | 0.00769537062935 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.486836113756 | 0.00769537062935 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.486815415822 | 0.00767362845229 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        7        |
|  0.486836113756 | 0.00769537062935 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.486836113756 | 0.00769537062935 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.480750921058 | 0.0164147740583  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.484787018256 | 0.0157491870898  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.480730223124 | 0.0104770580258  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        15       |
|  0.478553490362 | 0.0215874779788  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        19       |
|  0.478682783458 | 0.0122498445361  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        17       |
|  0.488864511322 | 0.0124251311778  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.468559837728 | 0.0311651996905  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.486815415822 | 0.00624616335453 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        7        |
|  0.484787018256 | 0.0101546470648  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.484767148239 | 0.00918753835107 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        13       |
|  0.47868026521  | 0.0123402249447  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.478722523492 | 0.0136835975151  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        16       |
|  0.48480771619  | 0.0213206929132  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        10       |
|  0.474645030426 | 0.0201545126126  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        20       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.48      0.32        56

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485829959514 | 0.00784949104047 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        3        |
|  0.485829959514 | 0.00646410978624 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        3        |
|  0.48585061555  | 0.00787329033964 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.485829959514 | 0.00646410978624 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        3        |
|  0.485829959514 | 0.00646410978624 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        3        |
|  0.48585061555  | 0.00787329033964 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.485829959514 | 0.00646410978624 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        3        |
|  0.481802032554 | 0.00981203584738 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.481802032554 | 0.0116236566783  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.477732793522 | 0.0115882671144  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        20       |
|  0.477753449558 | 0.0116882288103  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        19       |
|  0.481802032554 | 0.0116236566783  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.479776880388 | 0.00993307496092 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        18       |
|  0.481740064447 | 0.0107199513031  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        17       |
|  0.483805668016 | 0.0110274955652  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.481802032554 | 0.0159660390078  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.481781376518 | 0.00970136819285 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.485767130739 | 0.0101326478262  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.481781376518 | 0.0153148020165  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        15       |
|  0.483743699909 | 0.0191198901579  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        10       |
|  0.475771296373 | 0.0113210654909  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        55

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.236092364071 | 0.00761235208931 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        10       |
|  0.236112809331 | 0.00763607756053 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        6        |
|  0.236112809331 | 0.00763607756053 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        6        |
|  0.236112809331 | 0.00763607756053 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        6        |
|  0.236034640088 | 0.00466692046155 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        12       |
|  0.236112809331 | 0.00763607756053 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        6        |
|  0.236072534277 | 0.0062249484832  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        11       |
|  0.242153820791 | 0.0222421191541  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        5        |
|  0.234418080772 | 0.00574591582267 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        20       |
|  0.235017757986 | 0.00638587922113 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        19       |
|  0.235577745103 |  0.00898210364   |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        14       |
|  0.235576578644 | 0.0084586566274  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        15       |
|  0.253574522761 | 0.0556657168565  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.252073705384 | 0.0593984456901  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.235596408439 | 0.00753790541978 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.235556133385 | 0.00610071512839 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        16       |
|  0.235545594591 | 0.00609769805703 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        17       |
|  0.235041725192 | 0.00735027140222 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.234027223955 | 0.0085795748466  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        21       |
|  0.264340521634 | 0.0876608861692  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.248239168015 |  0.041997310644  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        4        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      0.96      0.66        27
          2       0.50      0.10      0.17        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.34      0.49      0.35        55

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485829959514 | 0.00646410978624 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.485870445344 | 0.00787086561898 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.485849789308 | 0.00646121964943 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        3        |
|  0.485849789308 | 0.00646121964943 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        3        |
|  0.485849789308 | 0.00646121964943 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        3        |
|  0.485870445344 | 0.00787086561898 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.485829959514 | 0.0048084695641  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        6        |
|  0.481821862348 |  0.013135534069  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.481821862348 | 0.00981827059241 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.477773279352 |  0.027188741211  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        17       |
|  0.481821862348 |  0.011628920179  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.477752623317 |  0.020903149161  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.475687019747 | 0.0121772688581  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        21       |
|  0.481821862348 | 0.0133799319954  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        10       |
|  0.481737516869 | 0.0100140852495  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        15       |
|  0.477773279352 | 0.0296469805206  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        17       |
|  0.481862348178 | 0.0115876188067  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.481882177972 | 0.0177130854627  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.475706815115 | 0.0112963737831  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        20       |
|  0.479735602743 | 0.0109417552619  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        16       |
|  0.481821862348 | 0.0131933745355  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        10       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        55

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        7        |
|  0.484869099155 | 0.00902454739074 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.484848484848 | 0.00900158623091 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        7        |
|  0.484869099155 | 0.00902454739074 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.484869099155 | 0.00902454739074 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        2        |
|  0.484869099155 | 0.00902454739074 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.484848484848 | 0.00900158623091 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        7        |
|  0.484869099155 | 0.0189297927044  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        2        |
|  0.488909503195 | 0.0137614014866  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        1        |
|  0.480869923727 | 0.0103758588993  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.482849756064 | 0.0205264872448  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.480808080808 | 0.0217371000766  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        15       |
|  0.480788291074 |   0.0209877609   |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        16       |
|  0.478807634165 | 0.0104620636048  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        19       |
|  0.480766852195 | 0.00935363611952 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        17       |
|  0.482808493094 | 0.00772584275524 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.484746237889 |  0.020174317058  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.48276472205  | 0.0137267217572  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        13       |
|  0.474768089054 | 0.0220704566638  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        20       |
|  0.478808493094 | 0.0384866114716  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        18       |
|  0.470647701505 | 0.0352004023986  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      0.96      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.48      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.235159081815 | 0.00870439255828 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|  0.235179485771 | 0.00872728945721 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        12       |
|  0.23513929208  | 0.00752132799119 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.235179485771 | 0.00872728945721 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        12       |
|  0.235179485771 | 0.00872728945721 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        12       |
|  0.235179485771 | 0.00872728945721 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        12       |
|  0.235159081815 | 0.00870439255828 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.234022877673 | 0.00855058516923 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        21       |
|  0.265002304081 | 0.0616662426783  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.307254200713 |  0.138677287062  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        2        |
|  0.27538337942  | 0.0875757561695  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.300449103851 | 0.0980173338661  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        3        |
|  0.269561008297 | 0.0667856918841  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        8        |
|  0.27640175348  |  0.105814582762  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.234586343628 | 0.00894357922804 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        19       |
|  0.234565518972 | 0.0086970826984  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        20       |
|  0.25935086936  |  0.045387497867  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.249562434003 | 0.0306692470034  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        11       |
|  0.278414503749 |  0.104722802257  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.333358011252 |  0.137026185771  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.275216266856 | 0.0664761055365  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        7        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.08      0.12        13
          1       0.52      0.96      0.68        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.34      0.50      0.37        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.484848484848 | 0.0078255236628  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        6        |
|  0.484848484848 | 0.00900158623091 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        6        |
|  0.484869099155 | 0.00902454739074 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.484848484848 | 0.00900158623091 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        6        |
|  0.484869099155 | 0.00902454739074 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.484869099155 | 0.00902454739074 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.480808080808 |  0.010352857307  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.484869099155 | 0.0142379510167  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        2        |
|  0.482806809593 | 0.00998667602682 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
|  0.482849721707 |  0.01191129444   |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.472621624407 | 0.0269881526333  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        20       |
|  0.480787466502 | 0.0301821493978  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        16       |
|  0.484910327767 |  0.018073833752  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.482808493094 | 0.00772584275524 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        11       |
|  0.47872431801  | 0.0122801285251  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        18       |
|  0.48276472205  | 0.0102939625453  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        13       |
|  0.478787878788 | 0.0269304160267  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        17       |
|  0.474809317666 | 0.0168372276258  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        19       |
|  0.480808080808 | 0.0314317381868  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        14       |
|  0.468749570535 | 0.0377097360056  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.08      0.12        13
          1       0.51      0.93      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.34      0.48      0.36        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        3        |
|  0.484848484848 | 0.0078255236628  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        3        |
|  0.484869099155 | 0.00902454739074 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.484869099155 | 0.00902454739074 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.484848484848 | 0.0078255236628  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        3        |
|  0.484848484848 | 0.0078255236628  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        3        |
|  0.484828695114 | 0.00652769781199 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        7        |
|  0.478687280973 | 0.0187593617843  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.478787878788 | 0.0130645339344  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.482828282828 |  0.013378878935  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.476830378616 | 0.0320043037169  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        15       |
|  0.476767676768 | 0.0186129501466  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        16       |
|  0.476747887034 |  0.016297755092  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        17       |
|  0.470768054697 |  0.018548835321  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        20       |
|  0.480828695114 | 0.0103808542812  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.484788291074 | 0.0129100251878  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.480869923727 | 0.0150233692881  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.47276850134  |  0.028491007434  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        19       |
|  0.468581220367 |  0.019055622909  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        21       |
|  0.472850958565 | 0.0210393452057  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        18       |
|  0.482808493094 | 0.0205378969244  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        10       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.235120666448 | 0.00629012974162 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        19       |
|  0.235216751941 | 0.00870796110954 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        13       |
|  0.235216751941 | 0.00870796110954 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        13       |
|  0.235216751941 | 0.00870796110954 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        13       |
|  0.235216751941 | 0.00870796110954 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        13       |
|  0.235216751941 | 0.00870796110954 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        13       |
|  0.235176558251 | 0.00749909167141 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.296137148931 |  0.100720080352  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.282601660823 | 0.0770333636209  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.233540316965 | 0.00912295586363 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        21       |
|  0.262304671201 | 0.0594428542389  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.296236958169 |  0.100454854977  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.263498537658 | 0.0617644842464  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.276455461567 | 0.0742444279927  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
|  0.233672667641 | 0.00926529122556 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        20       |
|  0.255318945631 | 0.0570590234623  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.262799041729 | 0.0629439111539  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.290848227954 | 0.0691559048982  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.288136875503 | 0.0810096195705  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.297770376779 | 0.0826590631582  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.27891355683  | 0.0774128095495  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        7        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.46      0.81      0.59        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.23      0.41      0.29        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        2        |
|  0.484828695114 | 0.00652769781199 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        6        |
|  0.484848484848 | 0.00900158623091 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.484828695114 | 0.00652769781199 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        6        |
|  0.484848484848 | 0.00900158623091 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        2        |
|  0.484848484848 | 0.00900158623091 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.484869099155 | 0.00902454739074 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.480808080808 | 0.0200263011614  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        15       |
|  0.480808080808 | 0.0152225629189  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        15       |
|  0.484786641929 | 0.0200154745034  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.482848897135 | 0.0162864086571  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.48091115234  | 0.0198819873486  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        13       |
|  0.482849721707 | 0.0266947987271  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.476787432145 | 0.0133489720725  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        19       |
|  0.482848897135 | 0.00993395750997 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        10       |
|  0.480808080808 | 0.0168699150416  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        15       |
|  0.482828282828 | 0.0248766784625  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        12       |
|  0.474809317666 | 0.0128034861431  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        20       |
|  0.470707070707 | 0.0392842268663  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        21       |
|  0.476871607229 |  0.024181516878  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        18       |
|  0.480827836185 | 0.0217341306368  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        14       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00648222292375 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.485905295741 | 0.00639135338926 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        3        |
|  0.485887096774 | 0.00648222292375 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        6        |
|  0.485925868486 | 0.0078082531897  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.485885545906 | 0.00472236351412 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        10       |
|  0.485905295741 | 0.00639135338926 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        3        |
|  0.485887096774 | 0.00648222292375 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        6        |
|  0.481893610422 | 0.0131006641178  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.483889166709 | 0.0135355036774  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.485905295741 | 0.0167710508404  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.47987748139  | 0.0160976691006  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        16       |
|  0.483867736766 | 0.0110599721587  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        13       |
|  0.475880764061 | 0.0165680130413  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        19       |
|  0.46983560794  | 0.0248373260384  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.485887096774 | 0.0119506316947  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        6        |
|  0.481893610422 | 0.00978726795376 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        14       |
|  0.485925868486 | 0.0134883861084  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.483909739454 | 0.00907989494495 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        11       |
|  0.477861352357 | 0.0149228826408  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        17       |
|  0.475806451613 | 0.0187848363376  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        20       |
|  0.477799634122 | 0.0210279647584  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        18       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.23614689238  | 0.00755096587865 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        13       |
|  0.236167255199 | 0.00757464085505 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        10       |
|  0.236127142544 | 0.00615619455406 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|  0.236167255199 | 0.00757464085505 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        10       |
|  0.236167255199 | 0.00757464085505 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        10       |
|  0.236089401154 | 0.00458273377759 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.236129080658 | 0.00624343257476 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
|  0.235089993649 | 0.00763707128284 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        21       |
|  0.236008626754 | 0.00467513431536 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        18       |
|  0.244395568211 | 0.0356506685255  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.260210650666 | 0.0595028747037  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.264692470981 | 0.0634166451552  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.259252221994 | 0.0712646890771  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.254210323147 | 0.0565910067254  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|  0.235568995022 | 0.00604391984475 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        19       |
|  0.235121675677 | 0.00988349412068 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        20       |
|  0.25425350769  | 0.0583010593727  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.253078767728 | 0.0583978316432  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.236038292455 | 0.00758962408352 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        17       |
|  0.255202276353 | 0.0599369349469  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.263999431904 | 0.0711762028232  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      0.96      0.64        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.47      0.31        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        8        |
|  0.485907669519 | 0.00780973118882 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.485887096774 | 0.00639310039872 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        8        |
|  0.485887903549 | 0.00648273424528 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        7        |
|  0.485907669519 | 0.00780973118882 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        2        |
|  0.485907669519 | 0.00780973118882 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.485907669519 | 0.00780973118882 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.481875411455 | 0.0115906726522  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.485907669519 | 0.0134892417569  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        2        |
|  0.473768892638 | 0.0134476478384  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        19       |
|  0.483849537799 | 0.0111318001866  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.485949672208 | 0.0197636387457  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.471815339039 |  0.028244620059  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        20       |
|  0.481813693219 | 0.0207873300682  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        17       |
|  0.485887096774 | 0.00778598536642 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.481855645484 | 0.0126028747306  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        14       |
|  0.481833408767 | 0.00983022003723 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        16       |
|  0.485866524029 | 0.0175129517591  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        11       |
|  0.481835088874 | 0.0148191876709  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        15       |
|  0.471672975642 | 0.0283320669675  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        21       |
|  0.473893186307 | 0.0305277689178  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        18       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.47      0.92      0.62        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.23      0.45      0.31        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00648222292375 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        7        |
|  0.485925868486 | 0.0078082531897  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.485905295741 | 0.00639135338926 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        5        |
|  0.485925868486 | 0.0078082531897  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.485905295741 | 0.00639135338926 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        5        |
|  0.485925868486 | 0.0078082531897  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.485925868486 | 0.0078082531897  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.483909739454 | 0.00907989494495 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        8        |
|  0.481851607734 |  0.011432032422  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        16       |
|  0.477859801489 |  0.016998730407  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        18       |
|  0.477935664806 | 0.0216281152183  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        17       |
|  0.481893610422 |  0.011734328797  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.471851736973 | 0.0246368042396  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        21       |
|  0.475883995037 | 0.0201558982605  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        20       |
|  0.483909739454 | 0.0125809887743  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.483909739454 | 0.00907989494495 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.481873037677 |  0.015494749009  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        14       |
|  0.483869416873 | 0.0128289337975  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        11       |
|  0.481893610422 | 0.0134650916149  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        12       |
|  0.477840779612 | 0.0126464992245  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        19       |
|  0.481853287841 | 0.00753640041278 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        15       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.236128290026 | 0.00624293014164 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|  0.236184918482 |  0.007573109718  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        9        |
|  0.236184918482 |  0.007573109718  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        9        |
|  0.236184918482 |  0.007573109718  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        9        |
|  0.236144805827 | 0.00615442565538 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|  0.236107064437 | 0.00458050280102 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.236184918482 |  0.007573109718  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        9        |
|  0.255397845242 | 0.0590289960781  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.236083043999 | 0.00618029944467 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        17       |
|  0.235037235792 | 0.00770108896541 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        20       |
|  0.23615575771  | 0.00860256515027 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        13       |
|  0.243066638912 | 0.0302325914943  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.253200896115 | 0.0585396830913  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
|  0.27238660897  | 0.0773150950735  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.235116168566 | 0.00586928989991 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        19       |
|  0.234602672845 | 0.00645321897615 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        21       |
|  0.235661059089 | 0.00834341087598 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        18       |
|  0.242691570063 | 0.0217348622219  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.253621887092 | 0.0569663169783  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.299284281565 |  0.145237416242  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.244568230726 | 0.0263857942805  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        6        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      0.92      0.63        26
          2       0.50      0.10      0.17        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.33      0.47      0.34        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.485907669519 | 0.00780973118882 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.485887903549 | 0.00648273424528 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        5        |
|  0.485867346939 | 0.00472465161339 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        7        |
|  0.485907669519 | 0.00780973118882 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.485907669519 | 0.00780973118882 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.485907669519 | 0.00780973118882 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.481833408767 | 0.00966468461409 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.483891540487 | 0.0111517977434  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.483974688666 | 0.0157236171253  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.473790322581 | 0.0262083649699  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        21       |
|  0.479838709677 | 0.0125011148203  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        16       |
|  0.47578502167  | 0.0108610813686  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        20       |
|  0.47979998451  | 0.0108170865968  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        17       |
|  0.483892363397 | 0.0092292053764  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        10       |
|  0.48185483871  | 0.0125567445878  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.479859282423 | 0.0160875355836  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.475827024358 | 0.0202340693344  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        19       |
|  0.483932685978 |  0.021057662808  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        9        |
|  0.479879048394 | 0.0182564344477  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        14       |
|  0.477842296193 | 0.0119252337054  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        18       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.485907669519 | 0.00780973118882 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.485907669519 | 0.00780973118882 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.485887903549 | 0.00648273424528 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        5        |
|  0.485907669519 | 0.00780973118882 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.485887096774 | 0.00639310039872 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        6        |
|  0.485887096774 | 0.00639310039872 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        6        |
|  0.483912920007 | 0.00793690997652 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.48185483871  | 0.00740556523271 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.479859282423 | 0.0145145120381  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.481875411455 | 0.00978094737249 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.463709677419 | 0.0290012261788  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        21       |
|  0.47784315339  | 0.0245194315275  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        16       |
|  0.473810895326 | 0.0192627303421  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        18       |
|  0.485887096774 | 0.00778598536642 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        6        |
|  0.483891540487 | 0.00907712469052 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.485907669519 | 0.00780973118882 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.479838709677 | 0.00896889544053 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        15       |
|  0.473790322581 | 0.0143123425245  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        19       |
|  0.475827024358 | 0.0158521227157  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        17       |
|  0.469778637261 | 0.0238239827571  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        20       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.23614689238  | 0.00755096587865 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        13       |
|  0.236167255199 | 0.00757464085505 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        10       |
|  0.236127142544 | 0.00615619455406 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|  0.236127142544 | 0.00615619455406 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|  0.23614689238  | 0.00755096587865 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        13       |
|  0.236167255199 | 0.00757464085505 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        10       |
|  0.236167255199 | 0.00757464085505 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        10       |
|  0.235119078028 | 0.00795583904935 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        20       |
|  0.235120241645 | 0.00849306233039 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        19       |
|  0.245080504795 |  0.028693100682  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        7        |
|  0.252667543954 |  0.031403090534  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.268790181343 | 0.0788338385832  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.255733791656 | 0.0603224186144  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.243698864617 | 0.0286778167804  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
|  0.235654100185 | 0.00804885673515 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        17       |
|  0.235575082524 | 0.00441528998024 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        18       |
|  0.234545800132 | 0.00839972593812 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        21       |
|  0.253224981482 | 0.0624828921911  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.242712057405 | 0.0304075310077  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        9        |
|  0.25855753157  | 0.0680526788922  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.317100833037 |  0.10071812685   |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.50      0.08      0.13        13
          1       0.50      0.96      0.66        26
          2       1.00      0.10      0.18        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.56      0.51      0.39        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.485887903549 | 0.00648273424528 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        4        |
|  0.485907669519 | 0.00780973118882 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.485907669519 | 0.00780973118882 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.485887096774 | 0.00639310039872 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        6        |
|  0.485887903549 | 0.00648273424528 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        4        |
|  0.485867346939 | 0.00472465161339 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        8        |
|  0.481835088874 | 0.0142219519223  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.481875411455 | 0.0171940110245  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.48185483871  | 0.00868221479429 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
|  0.477885156079 | 0.0215671433184  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        17       |
|  0.483870967742 | 0.0148431410669  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        10       |
|  0.471794766294 | 0.0347837620933  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        21       |
|  0.48185483871  | 0.00975349625275 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        12       |
|  0.485949672208 | 0.0150339434166  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        1        |
|  0.483891540487 | 0.00907712469052 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.481816113542 | 0.00856904426378 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.475827024358 | 0.0128086437545  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.473790322581 | 0.0248253510163  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        20       |
|  0.479859282423 | 0.0265592617231  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        16       |
|  0.473810895326 | 0.0164536039906  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        19       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

Evaluating SVC
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.487804878049 | 0.0097612046506  |        {'C': 0.001}        |        1        |
|  0.487804878049 | 0.00860812617509 |        {'C': 0.01}         |        1        |
|  0.487804878049 | 0.00860812617509 | {'C': 0.10000000000000001} |        1        |
|  0.487784138045 | 0.00734130654994 |         {'C': 1.0}         |        4        |
|  0.483782181572 |  0.012675904823  |        {'C': 10.0}         |        5        |
|  0.455347637022 | 0.0517156048979  |        {'C': 100.0}        |        6        |
|  0.392361111111 | 0.0647174022871  |       {'C': 1000.0}        |        7        |
|  0.378472222222 | 0.0573528532029  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.238007788481 | 0.00712857147328 |        {'C': 0.001}        |        6        |
|  0.238067536283 | 0.00837776330142 |        {'C': 0.01}         |        4        |
|  0.238007788481 | 0.00712857147328 | {'C': 0.10000000000000001} |        6        |
|  0.238067536283 | 0.00837776330142 |         {'C': 1.0}         |        4        |
|  0.237986965393 | 0.00759501603139 |        {'C': 10.0}         |        8        |
|  0.378292899454 | 0.0942112819475  |        {'C': 100.0}        |        1        |
|  0.31488879544  | 0.0824555035197  |       {'C': 1000.0}        |        3        |
|  0.360510575285 | 0.0564068533433  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.33      0.14      0.20        14
          1       0.45      0.81      0.58        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.29      0.42      0.32        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.487804878049 | 0.00736134723135 |        {'C': 0.001}        |        4        |
|  0.487845528455 | 0.00861839016232 |        {'C': 0.01}         |        1        |
|  0.487845528455 | 0.00861839016232 | {'C': 0.10000000000000001} |        1        |
|  0.487845528455 | 0.00861839016232 |         {'C': 1.0}         |        1        |
|  0.483738143631 | 0.00656737178276 |        {'C': 10.0}         |        5        |
|  0.447027439024 | 0.0357130489874  |        {'C': 100.0}        |        6        |
|  0.375924796748 | 0.0425861419746  |       {'C': 1000.0}        |        7        |
|  0.349703590786 | 0.0355792162777  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |        {'C': 0.001}        |        3        |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.01}         |        3        |
|  0.487847240609 | 0.00981483312777 | {'C': 0.10000000000000001} |        1        |
|  0.487825618052 | 0.00862517403599 |         {'C': 1.0}         |        2        |
|  0.48575244732  | 0.00804610842743 |        {'C': 10.0}         |        5        |
|  0.457355905517 | 0.0369580279879  |        {'C': 100.0}        |        6        |
|  0.384146341463 | 0.0400320834785  |       {'C': 1000.0}        |        7        |
|  0.369766605829 | 0.0254993745909  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.238027698884 | 0.00836752217225 |        {'C': 0.001}        |        7        |
|  0.238091261119 | 0.00963135240291 |        {'C': 0.01}         |        4        |
|  0.238048227255 | 0.00838446264646 | {'C': 0.10000000000000001} |        5        |
|  0.238048227255 | 0.00838446264646 |         {'C': 1.0}         |        5        |
|  0.237531727972 | 0.00947357124167 |        {'C': 10.0}         |        8        |
|  0.282968497753 | 0.0623034370944  |        {'C': 100.0}        |        3        |
|  0.330060542754 | 0.0372709081427  |       {'C': 1000.0}        |        1        |
|  0.321535506538 | 0.0392156516841  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.27      0.29      0.28        14
          1       0.47      0.67      0.55        27
          2       0.50      0.09      0.15        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.39      0.40      0.36        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |        {'C': 0.001}        |        1        |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.01}         |        1        |
|  0.487784967646 | 0.00596368925175 | {'C': 0.10000000000000001} |        4        |
|  0.487804878049 | 0.00736134723135 |         {'C': 1.0}         |        1        |
|  0.483760577402 | 0.0127984994989  |        {'C': 10.0}         |        5        |
|  0.45325203252  | 0.0246835144107  |        {'C': 100.0}        |        6        |
|  0.400307781649 | 0.0348292287104  |       {'C': 1000.0}        |        7        |
|  0.359897820917 | 0.0792732054619  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |        {'C': 0.001}        |        3        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.01}         |        1        |
|  0.487804878049 | 0.00736134723135 | {'C': 0.10000000000000001} |        3        |
|  0.487825618052 | 0.00862517403599 |         {'C': 1.0}         |        1        |
|  0.483760577402 |  0.018905654015  |        {'C': 10.0}         |        5        |
|  0.445183307063 | 0.0477114508362  |        {'C': 100.0}        |        6        |
|  0.422839244676 | 0.0468231113924  |       {'C': 1000.0}        |        7        |
|  0.35581549693  | 0.0622041450997  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.238027698884 | 0.00836752217225 |        {'C': 0.001}        |        7        |
|  0.238048227255 | 0.00838446264646 |        {'C': 0.01}         |        4        |
|  0.238048227255 | 0.00838446264646 | {'C': 0.10000000000000001} |        4        |
|  0.238048227255 | 0.00838446264646 |         {'C': 1.0}         |        4        |
|  0.237529727172 | 0.00841483429526 |        {'C': 10.0}         |        8        |
|  0.333079389658 | 0.0967792484789  |        {'C': 100.0}        |        2        |
|  0.347898399404 | 0.0515763639864  |       {'C': 1000.0}        |        1        |
|  0.328443331337 | 0.0497389748036  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.29      0.14      0.19        14
          1       0.48      0.74      0.58        27
          2       0.17      0.09      0.12        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.33      0.40      0.34        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |        {'C': 0.001}        |        4        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.01}         |        1        |
|  0.487825618052 | 0.00862517403599 | {'C': 0.10000000000000001} |        1        |
|  0.487825618052 | 0.00862517403599 |         {'C': 1.0}         |        1        |
|  0.485772357724 | 0.0128997927994  |        {'C': 10.0}         |        5        |
|  0.44931143189  | 0.0405937709055  |        {'C': 100.0}        |        6        |
|  0.396424423428 | 0.0357321476191  |       {'C': 1000.0}        |        7        |
|  0.380054511642 | 0.0287138580045  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.486815415822 | 0.00767362845229 |        {'C': 0.001}        |        3        |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.01}         |        1        |
|  0.486836113756 | 0.00769537062935 | {'C': 0.10000000000000001} |        1        |
|  0.486795545805 | 0.00451543676528 |         {'C': 1.0}         |        4        |
|  0.484726580287 | 0.0129768678224  |        {'C': 10.0}         |        5        |
|  0.437952560334 | 0.0468169743523  |        {'C': 100.0}        |        6        |
|  0.356678878448 | 0.0505758550445  |       {'C': 1000.0}        |        8        |
|  0.373333609306 | 0.0737347652615  |       {'C': 10000.0}       |        7        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      1.00      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.23      0.48      0.31        56

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.237048133655 | 0.00743684471496 |        {'C': 0.001}        |        5        |
|  0.237068620386 | 0.00745855262641 |        {'C': 0.01}         |        4        |
|  0.237028263638 | 0.00600897487947 | {'C': 0.10000000000000001} |        6        |
|  0.237028263638 | 0.00600897487947 |         {'C': 1.0}         |        6        |
|  0.235353181625 | 0.00905751026142 |        {'C': 10.0}         |        8        |
|  0.330123901065 | 0.0863848474615  |        {'C': 100.0}        |        3        |
|  0.333572614272 | 0.0709950335185  |       {'C': 1000.0}        |        2        |
|  0.348126867714 | 0.0434154912866  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.19      0.23      0.21        13
          1       0.52      0.59      0.55        27
          2       0.14      0.09      0.11        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.32      0.36      0.34        56

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.486815415822 | 0.00767362845229 |        {'C': 0.001}        |        3        |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.01}         |        1        |
|  0.486836113756 | 0.00769537062935 | {'C': 0.10000000000000001} |        1        |
|  0.486795545805 | 0.00451543676528 |         {'C': 1.0}         |        4        |
|  0.480751748975 | 0.0104809023327  |        {'C': 10.0}         |        5        |
|  0.452273875067 | 0.0365274820522  |        {'C': 100.0}        |        6        |
|  0.379061969615 | 0.0685010970994  |       {'C': 1000.0}        |        7        |
|  0.363165956038 | 0.0351336192618  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      1.00      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.23      0.48      0.31        56

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485829959514 | 0.00784949104047 |        {'C': 0.001}        |        2        |
|  0.48585061555  | 0.00787329033964 |        {'C': 0.01}         |        1        |
|  0.485829959514 | 0.00646410978624 | {'C': 0.10000000000000001} |        2        |
|  0.485829959514 | 0.00646410978624 |         {'C': 1.0}         |        2        |
|  0.479715772949 | 0.00898240117982 |        {'C': 10.0}         |        5        |
|  0.455424274973 | 0.0379547709924  |        {'C': 100.0}        |        6        |
|  0.386557051971 | 0.0559551118596  |       {'C': 1000.0}        |        7        |
|  0.35020242915  | 0.0615080609857  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        55

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.236092364071 | 0.00761235208931 |        {'C': 0.001}        |        5        |
|  0.236112809331 | 0.00763607756053 |        {'C': 0.01}         |        4        |
|  0.236072534277 | 0.0062249484832  | {'C': 0.10000000000000001} |        6        |
|  0.236072534277 | 0.0062249484832  |         {'C': 1.0}         |        6        |
|  0.23557678942  | 0.00813498853649 |        {'C': 10.0}         |        8        |
|  0.325558967461 |  0.119578660537  |        {'C': 100.0}        |        1        |
|  0.317297270282 | 0.0412174541514  |       {'C': 1000.0}        |        2        |
|  0.312077916822 | 0.0810431150035  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.23      0.35        13
          1       0.48      0.85      0.61        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.41      0.47      0.38        55

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485829959514 | 0.0048084695641  |        {'C': 0.001}        |        4        |
|  0.485889497499 | 0.00784519973821 |        {'C': 0.01}         |        1        |
|  0.485889497499 | 0.00784519973821 | {'C': 0.10000000000000001} |        1        |
|  0.485868841464 | 0.00642999065182 |         {'C': 1.0}         |        3        |
|  0.483865206001 | 0.0142969750307  |        {'C': 10.0}         |        5        |
|  0.453411526554 | 0.0432809494704  |        {'C': 100.0}        |        6        |
|  0.372434905136 | 0.0441012705343  |       {'C': 1000.0}        |        7        |
|  0.36020232992  | 0.0507849995181  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        55

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |        {'C': 0.001}        |        2        |
|  0.484848484848 | 0.0078255236628  |        {'C': 0.01}         |        2        |
|  0.484869099155 | 0.00902454739074 | {'C': 0.10000000000000001} |        1        |
|  0.484828695114 | 0.00652769781199 |         {'C': 1.0}         |        4        |
|  0.482806809593 | 0.00759902529854 |        {'C': 10.0}         |        5        |
|  0.45245825603  | 0.0411853630073  |        {'C': 100.0}        |        6        |
|  0.392268810555 |  0.060272046508  |       {'C': 1000.0}        |        7        |
|  0.357575757576 | 0.0519295018234  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.235120666448 | 0.00629012974162 |        {'C': 0.001}        |        5        |
|  0.235120666448 | 0.00629012974162 |        {'C': 0.01}         |        5        |
|  0.235120666448 | 0.00629012974162 | {'C': 0.10000000000000001} |        5        |
|  0.235120666448 | 0.00629012974162 |         {'C': 1.0}         |        5        |
|  0.25227568887  | 0.0590052738904  |        {'C': 10.0}         |        4        |
|  0.321061410283 |  0.074133332897  |        {'C': 100.0}        |        3        |
|  0.371857651958 | 0.0485049019236  |       {'C': 1000.0}        |        1        |
|  0.342367459344 | 0.0724856437305  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.09      0.08      0.08        13
          1       0.53      0.70      0.60        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.29      0.37      0.32        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |        {'C': 0.001}        |        3        |
|  0.484869099155 | 0.00902454739074 |        {'C': 0.01}         |        1        |
|  0.484869099155 | 0.00902454739074 | {'C': 0.10000000000000001} |        1        |
|  0.484848484848 | 0.0078255236628  |         {'C': 1.0}         |        3        |
|  0.482848897135 | 0.0118775513668  |        {'C': 10.0}         |        5        |
|  0.458567717996 | 0.0444057739776  |        {'C': 100.0}        |        6        |
|  0.383838383838 | 0.0608650982372  |       {'C': 1000.0}        |        7        |
|  0.357396825397 |  0.080908153176  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |        {'C': 0.001}        |        4        |
|  0.484869099155 | 0.00902454739074 |        {'C': 0.01}         |        1        |
|  0.484869099155 | 0.00902454739074 | {'C': 0.10000000000000001} |        1        |
|  0.484869099155 | 0.00902454739074 |         {'C': 1.0}         |        1        |
|  0.480808080808 | 0.0112315099716  |        {'C': 10.0}         |        5        |
|  0.446443173229 | 0.0386732924742  |        {'C': 100.0}        |        6        |
|  0.379686318972 | 0.0518346078875  |       {'C': 1000.0}        |        7        |
|  0.339258709544 | 0.0604133972265  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.235159081815 | 0.00870439255828 |        {'C': 0.001}        |        6        |
|  0.235179485771 | 0.00872728945721 |        {'C': 0.01}         |        4        |
|  0.235159081815 | 0.00870439255828 | {'C': 0.10000000000000001} |        6        |
|  0.235179485771 | 0.00872728945721 |         {'C': 1.0}         |        4        |
|  0.23361339481  | 0.00813178662291 |        {'C': 10.0}         |        8        |
|  0.316085463901 | 0.0934363717786  |        {'C': 100.0}        |        3        |
|  0.333830121007 | 0.0605740232406  |       {'C': 1000.0}        |        2        |
|  0.350831765119 | 0.0540440962128  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.10      0.08      0.09        13
          1       0.46      0.63      0.53        27
          2       1.00      0.10      0.18        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.44      0.35      0.32        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.484848484848 | 0.0078255236628  |        {'C': 0.001}        |        3        |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.01}         |        1        |
|  0.484848484848 | 0.0065278777965  | {'C': 0.10000000000000001} |        3        |
|  0.484888888889 | 0.00902458897894 |         {'C': 1.0}         |        1        |
|  0.478828282828 | 0.0121521129477  |        {'C': 10.0}         |        5        |
|  0.438503367003 | 0.0246700229839  |        {'C': 100.0}        |        6        |
|  0.396140177283 | 0.0420760196465  |       {'C': 1000.0}        |        7        |
|  0.333316498316 | 0.0384659780621  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485887096774 | 0.00472055635648 |        {'C': 0.001}        |        3        |
|  0.485925821942 | 0.00635839223918 |        {'C': 0.01}         |        2        |
|  0.485887096774 | 0.00472055635648 | {'C': 0.10000000000000001} |        3        |
|  0.485946394687 | 0.00778124199821 |         {'C': 1.0}         |        1        |
|  0.481914136622 | 0.0133351429667  |        {'C': 10.0}         |        5        |
|  0.423520517078 | 0.0337430491365  |        {'C': 100.0}        |        6        |
|  0.374962938805 |  0.055968859825  |       {'C': 1000.0}        |        7        |
|  0.352687042559 | 0.0522312358657  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.236127142544 | 0.00615619455406 |        {'C': 0.001}        |        6        |
|  0.236186408509 | 0.00757204400565 |        {'C': 0.01}         |        4        |
|  0.236186408509 | 0.00757204400565 | {'C': 0.10000000000000001} |        4        |
|  0.236127142544 | 0.00615619455406 |         {'C': 1.0}         |        6        |
|  0.234646260191 | 0.00894589730291 |        {'C': 10.0}         |        8        |
|  0.329888237887 | 0.0869616344616  |        {'C': 100.0}        |        2        |
|  0.323245285431 | 0.0763773782898  |       {'C': 1000.0}        |        3        |
|  0.358765173037 | 0.0511586513843  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.27      0.31      0.29        13
          1       0.48      0.50      0.49        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.30      0.32      0.31        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |        {'C': 0.001}        |        3        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.01}         |        1        |
|  0.485887096774 | 0.00639310039872 | {'C': 0.10000000000000001} |        3        |
|  0.485907669519 | 0.00780973118882 |         {'C': 1.0}         |        1        |
|  0.481875411455 | 0.0115906726522  |        {'C': 10.0}         |        5        |
|  0.443466096116 | 0.0504912122989  |        {'C': 100.0}        |        6        |
|  0.368803317698 | 0.0461291631108  |       {'C': 1000.0}        |        7        |
|  0.336958422482 | 0.0466577513331  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485887096774 | 0.00472055635648 |        {'C': 0.001}        |        3        |
|  0.485946394687 | 0.00778124199821 |        {'C': 0.01}         |        1        |
|  0.485946394687 | 0.00778124199821 | {'C': 0.10000000000000001} |        1        |
|  0.485887096774 | 0.00472055635648 |         {'C': 1.0}         |        3        |
|  0.481914136622 | 0.00977420365218 |        {'C': 10.0}         |        5        |
|  0.449690662555 | 0.0312507939014  |        {'C': 100.0}        |        6        |
|  0.367021959994 | 0.0572847740336  |       {'C': 1000.0}        |        7        |
|  0.351063409235 | 0.0889640093286  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.23614689238  | 0.00755096587865 |        {'C': 0.001}        |        6        |
|  0.236129080658 | 0.00624343257476 |        {'C': 0.01}         |        7        |
|  0.236167255199 | 0.00757464085505 | {'C': 0.10000000000000001} |        4        |
|  0.236167255199 | 0.00757464085505 |         {'C': 1.0}         |        4        |
|  0.235101266307 | 0.0067247397948  |        {'C': 10.0}         |        8        |
|  0.365059013119 |  0.115368864331  |        {'C': 100.0}        |        1        |
|  0.323411276286 | 0.0616467420417  |       {'C': 1000.0}        |        3        |
|  0.332461812345 | 0.0682043334042  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.25      0.08      0.12        13
          1       0.49      0.88      0.63        26
          2       0.50      0.10      0.17        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.40      0.47      0.37        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |        {'C': 0.001}        |        2        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.01}         |        2        |
|  0.485887096774 | 0.00639310039872 | {'C': 0.10000000000000001} |        2        |
|  0.485887903549 | 0.00648273424528 |         {'C': 1.0}         |        1        |
|  0.481874554257 | 0.0145832431505  |        {'C': 10.0}         |        5        |
|  0.449532484365 | 0.0366278700258  |        {'C': 100.0}        |        6        |
|  0.393312163575 | 0.0629493078136  |       {'C': 1000.0}        |        7        |
|  0.338627386438 | 0.0620418081453  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485887096774 | 0.00472055635648 |        {'C': 0.001}        |        4        |
|  0.485946394687 | 0.00778124199821 |        {'C': 0.01}         |        1        |
|  0.485946394687 | 0.00778124199821 | {'C': 0.10000000000000001} |        1        |
|  0.485925821942 | 0.00635839223918 |         {'C': 1.0}         |        3        |
|  0.47989800759  | 0.0148930230358  |        {'C': 10.0}         |        5        |
|  0.457755178684 |  0.024684066726  |        {'C': 100.0}        |        6        |
|  0.389107255806 | 0.0579652592422  |       {'C': 1000.0}        |        7        |
|  0.368830546331 | 0.0557238322185  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.23614689238  | 0.00755096587865 |        {'C': 0.001}        |        6        |
|  0.236089401154 | 0.00458273377759 |        {'C': 0.01}         |        8        |
|  0.236127142544 | 0.00615619455406 | {'C': 0.10000000000000001} |        7        |
|  0.236167255199 | 0.00757464085505 |         {'C': 1.0}         |        5        |
|  0.245617778882 | 0.0283037034187  |        {'C': 10.0}         |        4        |
|  0.33064308195  | 0.0885300761944  |        {'C': 100.0}        |        3        |
|  0.33563471107  | 0.0204249849418  |       {'C': 1000.0}        |        2        |
|  0.346254395054 | 0.0563505305433  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.20      0.23      0.21        13
          1       0.46      0.50      0.48        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.28      0.30      0.29        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |        {'C': 0.001}        |        3        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.01}         |        3        |
|  0.485907669519 | 0.00780973118882 | {'C': 0.10000000000000001} |        1        |
|  0.485907669519 | 0.00780973118882 |         {'C': 1.0}         |        1        |
|  0.481855645484 | 0.0107339755726  |        {'C': 10.0}         |        5        |
|  0.447539499671 | 0.0329238804579  |        {'C': 100.0}        |        6        |
|  0.383163951064 | 0.0388838360075  |       {'C': 1000.0}        |        7        |
|  0.360887096774 | 0.0492144092539  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

Evaluating SVC
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 0.01}                |        8        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        8        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.001, 'gamma': 1.0}                |        8        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 10.0}                |        8        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 100.0}               |        8        |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.001, 'gamma': 1000.0}               |        8        |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.001, 'gamma': 10000.0}              |        8        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 0.001}                |        8        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 0.01}                |        8        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        8        |
|  0.487804878049 | 0.00736134723135 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 10.0}                |        8        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 100.0}                |        8        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 1000.0}               |        8        |
|  0.487847240609 | 0.00981483312777 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        8        |
|  0.487825618052 | 0.00862517403599 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        8        |
|  0.487804878049 | 0.00860812617509 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        8        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        8        |
|  0.487804878049 | 0.00860812617509 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|  0.487804878049 | 0.00860812617509 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 0.001}                |        8        |
|  0.487847240609 | 0.00981483312777 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.487784967646 | 0.00596368925175 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        37       |
|  0.487847240609 | 0.00981483312777 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 10.0}                 |        8        |
|  0.487847240609 | 0.00981483312777 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.487825618052 | 0.00862517403599 |               {'C': 1.0, 'gamma': 1000.0}                |        8        |
|  0.487847240609 | 0.00981483312777 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.487784967646 | 0.00596368925175 |               {'C': 10.0, 'gamma': 0.001}                |        37       |
|  0.487847240609 | 0.00981483312777 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.487825618052 | 0.00862517403599 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        8        |
|  0.485834577734 | 0.0164053952498  |                {'C': 10.0, 'gamma': 1.0}                 |        40       |
|  0.434785486587 | 0.0508088263872  |                {'C': 10.0, 'gamma': 10.0}                |        56       |
|  0.451280003871 | 0.0398397451238  |               {'C': 10.0, 'gamma': 100.0}                |        53       |
|  0.483781317405 | 0.0174885466715  |               {'C': 10.0, 'gamma': 1000.0}               |        41       |
|  0.487825618052 | 0.00862517403599 |              {'C': 10.0, 'gamma': 10000.0}               |        8        |
|  0.487784967646 | 0.00596368925175 |               {'C': 100.0, 'gamma': 0.001}               |        37       |
|  0.487847240609 | 0.00981483312777 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.475508544881 |  0.020567346187  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        46       |
|  0.432945840938 | 0.0423437361326  |                {'C': 100.0, 'gamma': 1.0}                |        57       |
|  0.420648747304 | 0.0669886492511  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.453313388363 | 0.0343487678366  |               {'C': 100.0, 'gamma': 100.0}               |        52       |
|  0.475568276091 | 0.0248403137853  |              {'C': 100.0, 'gamma': 1000.0}               |        45       |
|  0.477642276423 | 0.0259079244727  |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.487825618052 | 0.00862517403599 |              {'C': 1000.0, 'gamma': 0.001}               |        8        |
|  0.479737880925 | 0.0207650973851  |               {'C': 1000.0, 'gamma': 0.01}               |        42       |
|  0.437139538742 | 0.0507045097372  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        55       |
|  0.364172854101 | 0.0575976964408  |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.394240673912 |  0.063016571811  |               {'C': 1000.0, 'gamma': 10.0}               |        61       |
|  0.422764227642 | 0.0377553411344  |              {'C': 1000.0, 'gamma': 100.0}               |        58       |
|  0.46762485482  | 0.0200142375915  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|   0.4715853129  | 0.0134749072409  |             {'C': 1000.0, 'gamma': 10000.0}              |        47       |
|  0.475608873544 |  0.01363248863   |              {'C': 10000.0, 'gamma': 0.001}              |        44       |
|  0.441137222922 | 0.0310732347429  |              {'C': 10000.0, 'gamma': 0.01}               |        54       |
|  0.361871577899 |  0.059174138983  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        64       |
|  0.372034179525 | 0.0296954770208  |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.400438275985 | 0.0726807882363  |              {'C': 10000.0, 'gamma': 10.0}               |        60       |
|  0.457126092307 | 0.0406369362148  |              {'C': 10000.0, 'gamma': 100.0}              |        51       |
|  0.469470715115 | 0.0196693654367  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.469532935125 | 0.0283215554326  |             {'C': 10000.0, 'gamma': 10000.0}             |        48       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01, 'gamma': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.238027698884 | 0.00836752217225 |               {'C': 0.001, 'gamma': 0.001}               |        49       |
|  0.238048227255 | 0.00838446264646 |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|  0.237969740251 | 0.00582451468229 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        56       |
|  0.238091261119 | 0.00963135240291 |                {'C': 0.001, 'gamma': 1.0}                |        25       |
|  0.238048227255 | 0.00838446264646 |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|  0.238007788481 | 0.00712857147328 |               {'C': 0.001, 'gamma': 100.0}               |        51       |
|  0.238091261119 | 0.00963135240291 |              {'C': 0.001, 'gamma': 1000.0}               |        25       |
|  0.238048227255 | 0.00838446264646 |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|  0.238048227255 | 0.00838446264646 |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|  0.237969740251 | 0.00582451468229 |                {'C': 0.01, 'gamma': 0.01}                |        56       |
|  0.238048227255 | 0.00838446264646 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|  0.238048227255 | 0.00838446264646 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.238048227255 | 0.00838446264646 |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|  0.238048227255 | 0.00838446264646 |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|  0.238048227255 | 0.00838446264646 |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|  0.238007788481 | 0.00712857147328 |              {'C': 0.01, 'gamma': 10000.0}               |        51       |
|  0.237969740251 | 0.00582451468229 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        56       |
|  0.238048227255 | 0.00838446264646 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|  0.238091261119 | 0.00963135240291 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        25       |
|  0.238048227255 | 0.00838446264646 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.237969740251 | 0.00582451468229 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        56       |
|  0.238048227255 | 0.00838446264646 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|  0.237969740251 | 0.00582451468229 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        56       |
|  0.238048227255 | 0.00838446264646 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.237969740251 | 0.00582451468229 |                {'C': 1.0, 'gamma': 0.001}                |        56       |
|  0.238007788481 | 0.00712857147328 |                {'C': 1.0, 'gamma': 0.01}                 |        51       |
|  0.238091261119 | 0.00963135240291 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.238007788481 | 0.00712857147328 |                 {'C': 1.0, 'gamma': 1.0}                 |        51       |
|  0.238048227255 | 0.00838446264646 |                {'C': 1.0, 'gamma': 10.0}                 |        31       |
|  0.238059038533 | 0.0087126546853  |                {'C': 1.0, 'gamma': 100.0}                |        30       |
|  0.238027698884 | 0.00836752217225 |               {'C': 1.0, 'gamma': 1000.0}                |        49       |
|  0.238048227255 | 0.00838446264646 |               {'C': 1.0, 'gamma': 10000.0}               |        31       |
|  0.238048227255 | 0.00838446264646 |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|  0.238048227255 | 0.00838446264646 |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|  0.238091261119 | 0.00963135240291 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.288229831699 | 0.0875941236353  |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.364468933737 | 0.0789763607101  |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.353797754147 | 0.0901822527553  |               {'C': 10.0, 'gamma': 100.0}                |        8        |
|  0.25541775039  | 0.0574523614173  |               {'C': 10.0, 'gamma': 1000.0}               |        20       |
|  0.237969740251 | 0.00582451468229 |              {'C': 10.0, 'gamma': 10000.0}               |        56       |
|  0.238007788481 | 0.00712857147328 |               {'C': 100.0, 'gamma': 0.001}               |        51       |
|  0.237969740251 | 0.00582451468229 |               {'C': 100.0, 'gamma': 0.01}                |        56       |
|  0.265957879056 | 0.0645606080314  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.317716928123 | 0.0413408179193  |                {'C': 100.0, 'gamma': 1.0}                |        13       |
|  0.367097583938 |  0.050189564419  |               {'C': 100.0, 'gamma': 10.0}                |        1        |
|  0.313545396547 | 0.0653898424658  |               {'C': 100.0, 'gamma': 100.0}               |        14       |
|  0.257067531036 | 0.0604769606071  |              {'C': 100.0, 'gamma': 1000.0}               |        18       |
|  0.240990701072 | 0.0230141806869  |              {'C': 100.0, 'gamma': 10000.0}              |        24       |
|  0.238048227255 | 0.00838446264646 |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
|  0.253159214566 | 0.0572250883277  |               {'C': 1000.0, 'gamma': 0.01}               |        21       |
|  0.356312095546 | 0.0778876488522  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.337824018595 | 0.0382215731073  |               {'C': 1000.0, 'gamma': 1.0}                |        10       |
|   0.3602578826  | 0.0885902178759  |               {'C': 1000.0, 'gamma': 10.0}               |        3        |
|  0.331118679103 | 0.0538836051172  |              {'C': 1000.0, 'gamma': 100.0}               |        11       |
|  0.235722983086 | 0.0144511314515  |              {'C': 1000.0, 'gamma': 1000.0}              |        64       |
|  0.241960085628 | 0.0186655012114  |             {'C': 1000.0, 'gamma': 10000.0}              |        23       |
|  0.271951391616 | 0.0803737647664  |              {'C': 10000.0, 'gamma': 0.001}              |        16       |
|  0.321466494032 | 0.0585772171982  |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.343042999184 | 0.0625442068246  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        9        |
|  0.355166457616 |  0.063144324578  |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.356870526417 | 0.0466616784398  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.356932948118 |  0.118230577026  |              {'C': 10000.0, 'gamma': 100.0}              |        4        |
|  0.256519591712 | 0.0445729533642  |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
|  0.253132901748 |  0.060979929782  |             {'C': 10000.0, 'gamma': 10000.0}             |        22       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.30      0.21      0.25        14
          1       0.42      0.56      0.48        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.27      0.32      0.29        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |               {'C': 0.001, 'gamma': 0.001}               |        25       |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.001, 'gamma': 0.01}                |        25       |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.487784967646 | 0.00596368925175 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.487784967646 | 0.00596368925175 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.487804878049 | 0.00860812617509 |                {'C': 0.01, 'gamma': 10.0}                |        25       |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.487784967646 | 0.00596368925175 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.487825618052 | 0.00862517403599 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.487825618052 | 0.00862517403599 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        2        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.487804878049 | 0.00860812617509 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        25       |
|  0.487825618052 | 0.00862517403599 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.487804878049 | 0.00736134723135 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        25       |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.487804878049 | 0.00736134723135 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.487825618052 | 0.00862517403599 |                 {'C': 1.0, 'gamma': 1.0}                 |        2        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 10.0}                 |        2        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 100.0}                |        2        |
|  0.487804878049 | 0.00736134723135 |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.487784967646 | 0.00596368925175 |               {'C': 1.0, 'gamma': 10000.0}               |        35       |
|  0.487804878049 | 0.00736134723135 |               {'C': 10.0, 'gamma': 0.001}                |        25       |
|  0.487847240609 | 0.00981483312777 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.487804878049 | 0.00860812617509 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.475609756098 | 0.0228605704473  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.414260826282 | 0.0635133709113  |                {'C': 10.0, 'gamma': 10.0}                |        58       |
|  0.46355981417  | 0.0415350857123  |               {'C': 10.0, 'gamma': 100.0}                |        50       |
|  0.48170643452  | 0.0125795871153  |               {'C': 10.0, 'gamma': 1000.0}               |        39       |
|  0.48168740667  |  0.01518285518   |              {'C': 10.0, 'gamma': 10000.0}               |        40       |
|  0.487825618052 | 0.00862517403599 |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.487825618052 | 0.00862517403599 |               {'C': 100.0, 'gamma': 0.01}                |        2        |
|  0.477662152259 | 0.0149066310736  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        44       |
|  0.420599324317 | 0.0560318224103  |                {'C': 100.0, 'gamma': 1.0}                |        57       |
|  0.379971551629 | 0.0341226586239  |               {'C': 100.0, 'gamma': 10.0}                |        61       |
|  0.453586520233 | 0.0554753898753  |               {'C': 100.0, 'gamma': 100.0}               |        52       |
|  0.477619808086 | 0.0161428472829  |              {'C': 100.0, 'gamma': 1000.0}               |        45       |
|  0.475671976108 | 0.0145400202246  |              {'C': 100.0, 'gamma': 10000.0}              |        46       |
|  0.487804878049 | 0.00860812617509 |              {'C': 1000.0, 'gamma': 0.001}               |        25       |
|  0.473619598332 | 0.0247675517924  |               {'C': 1000.0, 'gamma': 0.01}               |        48       |
|  0.447049043195 | 0.0511100902091  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        55       |
|  0.341520449643 | 0.0373664600774  |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.39831508213  | 0.0443352075112  |               {'C': 1000.0, 'gamma': 10.0}               |        59       |
|  0.44912477186  | 0.0544338499713  |              {'C': 1000.0, 'gamma': 100.0}               |        54       |
|  0.471586195454 | 0.0161063472168  |              {'C': 1000.0, 'gamma': 1000.0}              |        49       |
|  0.479674796748 | 0.0184845854754  |             {'C': 1000.0, 'gamma': 10000.0}              |        41       |
|  0.477662152259 | 0.0241491892421  |              {'C': 10000.0, 'gamma': 0.001}              |        43       |
|  0.451489132238 | 0.0568048051088  |              {'C': 10000.0, 'gamma': 0.01}               |        53       |
|  0.373942259831 | 0.0440395627366  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        62       |
|  0.341407831425 | 0.0423122575355  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.382129376141 | 0.0506139790028  |              {'C': 10000.0, 'gamma': 10.0}               |        60       |
|  0.443276090924 |  0.059814068146  |              {'C': 10000.0, 'gamma': 100.0}              |        56       |
|  0.463393029976 |  0.027690758752  |             {'C': 10000.0, 'gamma': 1000.0}              |        51       |
|  0.479674796748 | 0.0162326282845  |             {'C': 10000.0, 'gamma': 10000.0}             |        41       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |               {'C': 0.001, 'gamma': 0.001}               |        24       |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 0.01}                |        7        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        7        |
|  0.487847240609 | 0.00981483312777 |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.001, 'gamma': 10.0}                |        24       |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.001, 'gamma': 100.0}               |        24       |
|  0.487804878049 | 0.00736134723135 |              {'C': 0.001, 'gamma': 1000.0}               |        24       |
|  0.487804878049 | 0.00860812617509 |              {'C': 0.001, 'gamma': 10000.0}              |        24       |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 0.001}                |        7        |
|  0.487847240609 | 0.00981483312777 |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        7        |
|  0.487804878049 | 0.00736134723135 |                {'C': 0.01, 'gamma': 1.0}                 |        24       |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 10.0}                |        7        |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.01, 'gamma': 100.0}                |        24       |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.01, 'gamma': 1000.0}               |        24       |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.01, 'gamma': 10000.0}               |        7        |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        24       |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        24       |
|  0.487825618052 | 0.00862517403599 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        7        |
|  0.487825618052 | 0.00862517403599 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        7        |
|  0.487804878049 | 0.00860812617509 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        24       |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        7        |
|  0.487804878049 | 0.00860812617509 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        24       |
|  0.487825618052 | 0.00862517403599 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        7        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 0.001}                |        7        |
|  0.487804878049 | 0.00736134723135 |                {'C': 1.0, 'gamma': 0.01}                 |        24       |
|  0.487804878049 | 0.00860812617509 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.487804878049 | 0.00860812617509 |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 10.0}                 |        7        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 100.0}                |        7        |
|  0.487825618052 | 0.00862517403599 |               {'C': 1.0, 'gamma': 1000.0}                |        7        |
|  0.487804878049 | 0.00736134723135 |               {'C': 1.0, 'gamma': 10000.0}               |        24       |
|  0.487825618052 | 0.00862517403599 |               {'C': 10.0, 'gamma': 0.001}                |        7        |
|  0.487847240609 | 0.00981483312777 |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.487825618052 | 0.00862517403599 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        7        |
|  0.473577235772 | 0.0235455175701  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.406421105027 | 0.0552405324264  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.463474261656 | 0.0309641339558  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.487888720615 | 0.0133642947286  |               {'C': 10.0, 'gamma': 1000.0}               |        1        |
|  0.487825618052 | 0.00862517403599 |              {'C': 10.0, 'gamma': 10000.0}               |        7        |
|  0.487847240609 | 0.00981483312777 |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.487804878049 | 0.00860812617509 |               {'C': 100.0, 'gamma': 0.01}                |        24       |
|  0.481708199627 | 0.0167410217304  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        42       |
|  0.394432500556 | 0.0504701511349  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.379930935789 | 0.0630273398645  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.445140098722 | 0.0362962834009  |               {'C': 100.0, 'gamma': 100.0}               |        52       |
|  0.477704496433 | 0.0182687563818  |              {'C': 100.0, 'gamma': 1000.0}               |        46       |
|  0.48170643452  | 0.00867675046995 |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.487847240609 | 0.00981483312777 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.477726118989 | 0.0154095777136  |               {'C': 1000.0, 'gamma': 0.01}               |        45       |
|  0.406504065041 | 0.0463980652164  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.371951219512 | 0.0588233649099  |               {'C': 1000.0, 'gamma': 1.0}                |        61       |
|  0.37014511089  |  0.05661292625   |               {'C': 1000.0, 'gamma': 10.0}               |        63       |
|  0.442799070848 | 0.0435084835958  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|  0.467415726453 | 0.0209310201687  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.479673914195 | 0.0139712325013  |             {'C': 1000.0, 'gamma': 10000.0}              |        44       |
|  0.473511559095 | 0.0249129460835  |              {'C': 10000.0, 'gamma': 0.001}              |        48       |
|  0.422698550965 | 0.0310933871925  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.370015485869 | 0.0659105634438  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        64       |
|  0.375780342625 | 0.0644077278138  |               {'C': 10000.0, 'gamma': 1.0}               |        60       |
|  0.371951219512 |  0.061028642469  |              {'C': 10000.0, 'gamma': 10.0}               |        61       |
|  0.430753276921 | 0.0355670224388  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.471566285051 | 0.0167003625394  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.481749679633 | 0.0141002681788  |             {'C': 10000.0, 'gamma': 10000.0}             |        41       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.238048880164 | 0.00957727172968 |               {'C': 0.001, 'gamma': 0.001}               |        21       |
|  0.238027698884 | 0.00836752217225 |               {'C': 0.001, 'gamma': 0.01}                |        27       |
|  0.238027698884 | 0.00836752217225 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        27       |
|  0.238027698884 | 0.00836752217225 |                {'C': 0.001, 'gamma': 1.0}                |        27       |
|  0.238027698884 | 0.00836752217225 |               {'C': 0.001, 'gamma': 10.0}                |        27       |
|  0.238027698884 | 0.00836752217225 |               {'C': 0.001, 'gamma': 100.0}               |        27       |
|  0.237987260111 | 0.00710852195597 |              {'C': 0.001, 'gamma': 1000.0}               |        48       |
|  0.238048880164 | 0.00957727172968 |              {'C': 0.001, 'gamma': 10000.0}              |        21       |
|  0.23794921188  | 0.00579982433327 |               {'C': 0.01, 'gamma': 0.001}                |        54       |
|  0.23794921188  | 0.00579982433327 |                {'C': 0.01, 'gamma': 0.01}                |        54       |
|  0.238027698884 | 0.00836752217225 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        27       |
|  0.238048880164 | 0.00957727172968 |                {'C': 0.01, 'gamma': 1.0}                 |        21       |
|  0.23794921188  | 0.00579982433327 |                {'C': 0.01, 'gamma': 10.0}                |        54       |
|  0.238027698884 | 0.00836752217225 |               {'C': 0.01, 'gamma': 100.0}                |        27       |
|  0.238027698884 | 0.00836752217225 |               {'C': 0.01, 'gamma': 1000.0}               |        27       |
|  0.237987260111 | 0.00710852195597 |              {'C': 0.01, 'gamma': 10000.0}               |        46       |
|  0.237987260111 | 0.00710852195597 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        48       |
|  0.238027698884 | 0.00836752217225 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        27       |
|  0.238027698884 | 0.00836752217225 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        27       |
|  0.238027698884 | 0.00836752217225 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        27       |
|  0.238027698884 | 0.00836752217225 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        27       |
|  0.238048880164 | 0.00957727172968 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        21       |
|  0.237987260111 | 0.00710852195597 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        48       |
|  0.238027698884 | 0.00836752217225 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        27       |
|  0.23794921188  | 0.00579982433327 |                {'C': 1.0, 'gamma': 0.001}                |        54       |
|  0.23794921188  | 0.00579982433327 |                {'C': 1.0, 'gamma': 0.01}                 |        54       |
|  0.237987260111 | 0.00710852195597 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        46       |
|  0.237987260111 | 0.00710852195597 |                 {'C': 1.0, 'gamma': 1.0}                 |        48       |
|  0.238027698884 | 0.00836752217225 |                {'C': 1.0, 'gamma': 10.0}                 |        27       |
|  0.237509198801 | 0.00839668754486 |                {'C': 1.0, 'gamma': 100.0}                |        59       |
|  0.238027698884 | 0.00836752217225 |               {'C': 1.0, 'gamma': 1000.0}                |        27       |
|  0.237987260111 | 0.00710852195597 |               {'C': 1.0, 'gamma': 10000.0}               |        48       |
|  0.238048880164 | 0.00957727172968 |               {'C': 10.0, 'gamma': 0.001}                |        21       |
|  0.238027698884 | 0.00836752217225 |                {'C': 10.0, 'gamma': 0.01}                |        27       |
|  0.238048880164 | 0.00957727172968 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.255661481305 | 0.0579644757101  |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.345110183944 | 0.0830701990517  |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.311762265635 | 0.0565476403008  |               {'C': 10.0, 'gamma': 100.0}                |        12       |
|  0.255409531612 | 0.0595426609946  |               {'C': 10.0, 'gamma': 1000.0}               |        18       |
|  0.238027698884 | 0.00836752217225 |              {'C': 10.0, 'gamma': 10000.0}               |        27       |
|  0.238027698884 | 0.00836752217225 |               {'C': 100.0, 'gamma': 0.001}               |        27       |
|  0.237987260111 | 0.00710852195597 |               {'C': 100.0, 'gamma': 0.01}                |        48       |
|  0.234856785768 | 0.0112151075649  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        63       |
|  0.32644313095  | 0.0963918183546  |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.372094335671 | 0.0691746681006  |               {'C': 100.0, 'gamma': 10.0}                |        2        |
|  0.309623685615 | 0.0874204222216  |               {'C': 100.0, 'gamma': 100.0}               |        13       |
|  0.253629500581 | 0.0583962584998  |              {'C': 100.0, 'gamma': 1000.0}               |        19       |
|  0.23545803895  | 0.0104145666683  |              {'C': 100.0, 'gamma': 10000.0}              |        60       |
|  0.238027698884 | 0.00836752217225 |              {'C': 1000.0, 'gamma': 0.001}               |        27       |
|  0.265804851328 | 0.0658846854574  |               {'C': 1000.0, 'gamma': 0.01}               |        16       |
|  0.352827480556 | 0.0727581552813  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.334154464063 |  0.052457039918  |               {'C': 1000.0, 'gamma': 1.0}                |        8        |
|  0.367852738519 | 0.0635564281875  |               {'C': 1000.0, 'gamma': 10.0}               |        3        |
|  0.330026260383 | 0.0514339004849  |              {'C': 1000.0, 'gamma': 100.0}               |        10       |
|  0.240332693557 | 0.0196442489275  |              {'C': 1000.0, 'gamma': 1000.0}              |        20       |
|  0.235418948067 |  0.010996355709  |             {'C': 1000.0, 'gamma': 10000.0}              |        61       |
|  0.279034126822 |  0.077705144427  |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|  0.331024495726 | 0.0674991445452  |              {'C': 10000.0, 'gamma': 0.01}               |        9        |
|  0.308153292886 | 0.0847864421944  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        14       |
|  0.339406136966 | 0.0686539367574  |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.373856321974 | 0.0608419314887  |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.342845267887 |  0.130544580899  |              {'C': 10000.0, 'gamma': 100.0}              |        6        |
|  0.234776166644 | 0.0114235296714  |             {'C': 10000.0, 'gamma': 1000.0}              |        64       |
|  0.235369568824 | 0.0101871195072  |             {'C': 10000.0, 'gamma': 10000.0}             |        62       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.36      0.36      0.36        14
          1       0.44      0.44      0.44        27
          2       0.11      0.09      0.10        11
          3       0.14      0.25      0.18         4
          4       0.00      0.00      0.00         1

avg / total       0.33      0.33      0.33        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.487804878049 | 0.0097612046506  |               {'C': 0.001, 'gamma': 0.001}               |        1        |
|  0.487804878049 | 0.00860812617509 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.487804878049 | 0.00860812617509 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        1        |
|  0.487804878049 | 0.0097612046506  |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.487764227642 | 0.00593886457224 |               {'C': 0.001, 'gamma': 10.0}                |        33       |
|  0.487804878049 | 0.00860812617509 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.487804878049 | 0.00860812617509 |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.487804878049 | 0.00860812617509 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.487804878049 | 0.00860812617509 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.487804878049 | 0.00860812617509 |                {'C': 0.01, 'gamma': 0.01}                |        1        |
|  0.487804878049 | 0.00860812617509 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.487804878049 | 0.00860812617509 |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.487764227642 | 0.00593886457224 |                {'C': 0.01, 'gamma': 10.0}                |        33       |
|  0.487804878049 | 0.0097612046506  |               {'C': 0.01, 'gamma': 100.0}                |        1        |
|  0.487764227642 | 0.00593886457224 |               {'C': 0.01, 'gamma': 1000.0}               |        33       |
|  0.487804878049 | 0.00860812617509 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.487804878049 | 0.0097612046506  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.487804878049 | 0.00860812617509 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.487764227642 | 0.00593886457224 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        33       |
|  0.487804878049 | 0.00860812617509 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.487784138045 | 0.00734130654994 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|  0.487784138045 | 0.00734130654994 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|  0.487784138045 | 0.00734130654994 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|  0.487804878049 | 0.00860812617509 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.487804878049 | 0.00860812617509 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.487804878049 | 0.00860812617509 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.487784138045 | 0.00734130654994 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.487804878049 | 0.00860812617509 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.487804878049 | 0.0097612046506  |                {'C': 1.0, 'gamma': 10.0}                 |        1        |
|  0.485731707317 | 0.0101661832083  |                {'C': 1.0, 'gamma': 100.0}                |        38       |
|  0.487804878049 | 0.00860812617509 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.487804878049 | 0.00860812617509 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.487804878049 | 0.0097612046506  |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.487804878049 | 0.0097612046506  |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.487804878049 | 0.0097612046506  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.473577235772 | 0.0176150416384  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.424839092141 |  0.036847737326  |                {'C': 10.0, 'gamma': 10.0}                |        56       |
|  0.463502710027 | 0.0396382878742  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.483697493225 |  0.015784660023  |               {'C': 10.0, 'gamma': 1000.0}               |        40       |
|  0.483739837398 | 0.0168413538604  |              {'C': 10.0, 'gamma': 10000.0}               |        39       |
|  0.487804878049 | 0.00860812617509 |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.487764227642 | 0.00593886457224 |               {'C': 100.0, 'gamma': 0.01}                |        33       |
|  0.473557359936 | 0.00669507250811 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        48       |
|  0.422679539295 | 0.0270676585345  |                {'C': 100.0, 'gamma': 1.0}                |        57       |
|  0.375973915989 | 0.0392216994032  |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.434832317073 | 0.0441106690497  |               {'C': 100.0, 'gamma': 100.0}               |        53       |
|  0.479696400918 |  0.017715567815  |              {'C': 100.0, 'gamma': 1000.0}               |        41       |
|  0.475609756098 | 0.0258333662976  |              {'C': 100.0, 'gamma': 10000.0}              |        44       |
|  0.487804878049 | 0.00860812617509 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.479654056745 | 0.0167456881058  |               {'C': 1000.0, 'gamma': 0.01}               |        42       |
|  0.410399728997 | 0.0367282644405  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        58       |
|  0.36970697832  | 0.0578689537757  |               {'C': 1000.0, 'gamma': 1.0}                |        61       |
|  0.392468267795 | 0.0487330719457  |               {'C': 1000.0, 'gamma': 10.0}               |        59       |
|  0.445079607046 | 0.0218942126549  |              {'C': 1000.0, 'gamma': 100.0}               |        52       |
|  0.467437330623 | 0.0198244209433  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.479654056745 | 0.0188875959918  |             {'C': 1000.0, 'gamma': 10000.0}              |        42       |
|  0.473619579946 | 0.0137753367433  |              {'C': 10000.0, 'gamma': 0.001}              |        46       |
|  0.426871612466 | 0.0300366641447  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.365755143521 | 0.0564072443324  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        62       |
|  0.347306910569 | 0.0706032131685  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.359840785908 | 0.0540505499672  |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.428861788618 |  0.036873606305  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.469554539295 |  0.024450862895  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.475530149051 | 0.0157242233019  |             {'C': 10000.0, 'gamma': 10000.0}             |        45       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |               {'C': 0.001, 'gamma': 0.001}               |        24       |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.001, 'gamma': 0.01}                |        24       |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        7        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.001, 'gamma': 1.0}                |        7        |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.001, 'gamma': 10.0}                |        24       |
|  0.487847240609 | 0.00981483312777 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.487784967646 | 0.00596368925175 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.487784967646 | 0.00596368925175 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.487804878049 | 0.00860812617509 |               {'C': 0.01, 'gamma': 0.001}                |        24       |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 0.01}                |        7        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        7        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 1.0}                 |        7        |
|  0.487847240609 | 0.00981483312777 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 100.0}                |        7        |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.01, 'gamma': 1000.0}               |        24       |
|  0.487804878049 | 0.00736134723135 |              {'C': 0.01, 'gamma': 10000.0}               |        24       |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        24       |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        7        |
|  0.487825618052 | 0.00862517403599 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        7        |
|  0.487825618052 | 0.00862517403599 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        7        |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        24       |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        7        |
|  0.487804878049 | 0.00860812617509 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        24       |
|  0.487825618052 | 0.00862517403599 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        7        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 0.001}                |        7        |
|  0.487784967646 | 0.00596368925175 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.487804878049 | 0.00736134723135 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.487825618052 | 0.00862517403599 |                 {'C': 1.0, 'gamma': 1.0}                 |        7        |
|  0.485793097727 | 0.0119467296897  |                {'C': 1.0, 'gamma': 10.0}                 |        38       |
|  0.485772357724 | 0.0126450775624  |                {'C': 1.0, 'gamma': 100.0}                |        40       |
|  0.487847240609 | 0.00981483312777 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.487825618052 | 0.00862517403599 |               {'C': 1.0, 'gamma': 10000.0}               |        7        |
|  0.487847240609 | 0.00981483312777 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.487825618052 | 0.00862517403599 |                {'C': 10.0, 'gamma': 0.01}                |        7        |
|  0.487847240609 | 0.00981483312777 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.473598805376 |  0.012170124832  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.424817487971 | 0.0537128642412  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.455243072839 | 0.0326026290795  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.48174879708  | 0.0108162379207  |               {'C': 10.0, 'gamma': 1000.0}               |        43       |
|  0.487804878049 | 0.00860812617509 |              {'C': 10.0, 'gamma': 10000.0}               |        24       |
|  0.487825618052 | 0.00862517403599 |               {'C': 100.0, 'gamma': 0.001}               |        7        |
|  0.487825618052 | 0.00862517403599 |               {'C': 100.0, 'gamma': 0.01}                |        7        |
|  0.475609756098 |  0.01230382143   |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        46       |
|  0.45312494484  |  0.062510012162  |                {'C': 100.0, 'gamma': 1.0}                |        52       |
|  0.402540996073 | 0.0470183857234  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.436883849068 | 0.0391295418371  |               {'C': 100.0, 'gamma': 100.0}               |        54       |
|  0.467419943587 | 0.0276722639951  |              {'C': 100.0, 'gamma': 1000.0}               |        50       |
|  0.483739837398 | 0.0102194702006  |              {'C': 100.0, 'gamma': 10000.0}              |        42       |
|  0.487847240609 | 0.00981483312777 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.479778496765 | 0.0185833692115  |               {'C': 1000.0, 'gamma': 0.01}               |        44       |
|  0.429110668658 | 0.0412549091036  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.36600215696  | 0.0469039639403  |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.394241538079 | 0.0471864531191  |               {'C': 1000.0, 'gamma': 10.0}               |        60       |
|  0.437137049942 | 0.0379703617702  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|  0.469405902605 | 0.0181952238946  |              {'C': 1000.0, 'gamma': 1000.0}              |        49       |
|  0.483760577402 |  0.012924972854  |             {'C': 1000.0, 'gamma': 10000.0}              |        41       |
|  0.479674796748 | 0.0184342462074  |              {'C': 10000.0, 'gamma': 0.001}              |        45       |
|  0.434893672916 | 0.0407445516611  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.379956860793 | 0.0560371149907  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        61       |
|  0.327523484744 | 0.0758654927897  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.369639573309 | 0.0545723867021  |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.418699186992 | 0.0510814510948  |              {'C': 10000.0, 'gamma': 100.0}              |        58       |
|  0.469573585532 | 0.0353109910969  |             {'C': 10000.0, 'gamma': 1000.0}              |        48       |
|  0.485793097727 | 0.0134233561231  |             {'C': 10000.0, 'gamma': 10000.0}             |        38       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.238007788481 | 0.00712857147328 |               {'C': 0.001, 'gamma': 0.001}               |        57       |
|  0.238067536283 | 0.00837776330142 |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|  0.238067536283 | 0.00837776330142 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|  0.238067536283 | 0.00837776330142 |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|  0.238067536283 | 0.00837776330142 |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|  0.237989049278 | 0.00581512737302 |               {'C': 0.001, 'gamma': 100.0}               |        61       |
|  0.238067536283 | 0.00837776330142 |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|  0.238067536283 | 0.00837776330142 |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|  0.238067536283 | 0.00837776330142 |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|  0.238027097509 | 0.00712080030482 |                {'C': 0.01, 'gamma': 0.01}                |        52       |
|  0.238007788481 | 0.00712857147328 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        57       |
|  0.238067536283 | 0.00837776330142 |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|  0.238067536283 | 0.00837776330142 |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|  0.238067536283 | 0.00837776330142 |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|  0.237989049278 | 0.00581512737302 |               {'C': 0.01, 'gamma': 1000.0}               |        61       |
|  0.238027097509 | 0.00712080030482 |              {'C': 0.01, 'gamma': 10000.0}               |        52       |
|  0.238067536283 | 0.00837776330142 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|  0.238110570147 | 0.00962543460264 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        27       |
|  0.238027097509 | 0.00712080030482 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        52       |
|  0.238027097509 | 0.00712080030482 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        52       |
|  0.238027097509 | 0.00712080030482 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        52       |
|  0.238067536283 | 0.00837776330142 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|  0.238110570147 | 0.00962543460264 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        27       |
|  0.238007788481 | 0.00712857147328 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        57       |
|  0.238067536283 | 0.00837776330142 |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|  0.238067536283 | 0.00837776330142 |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|  0.238067536283 | 0.00837776330142 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|  0.238067536283 | 0.00837776330142 |                 {'C': 1.0, 'gamma': 1.0}                 |        30       |
|  0.238110570147 | 0.00962543460264 |                {'C': 1.0, 'gamma': 10.0}                 |        27       |
|  0.238565296362 | 0.00861691433763 |                {'C': 1.0, 'gamma': 100.0}                |        26       |
|  0.238067536283 | 0.00837776330142 |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
|  0.238067536283 | 0.00837776330142 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.237989049278 | 0.00581512737302 |               {'C': 10.0, 'gamma': 0.001}                |        61       |
|  0.238067536283 | 0.00837776330142 |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|   0.2375490362  | 0.00840934978142 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        64       |
|  0.321109847397 |  0.108981101002  |                {'C': 10.0, 'gamma': 1.0}                 |        14       |
|  0.350918651711 | 0.0507228130941  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.32324263671  |  0.116264412971  |               {'C': 10.0, 'gamma': 100.0}                |        13       |
|  0.261805618459 | 0.0762301890456  |               {'C': 10.0, 'gamma': 1000.0}               |        22       |
|  0.238007788481 | 0.00712857147328 |              {'C': 10.0, 'gamma': 10000.0}               |        57       |
|  0.238067536283 | 0.00837776330142 |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|  0.238067536283 | 0.00837776330142 |               {'C': 100.0, 'gamma': 0.01}                |        30       |
|  0.303507331665 |  0.111079315349  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.364363541612 | 0.0559893257305  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.357235121177 | 0.0797332437896  |               {'C': 100.0, 'gamma': 10.0}                |        4        |
|  0.28812717435  | 0.0564053856064  |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.290614351259 |  0.115312701663  |              {'C': 100.0, 'gamma': 1000.0}               |        17       |
|  0.255791723359 | 0.0579811157731  |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|  0.238067536283 | 0.00837776330142 |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
|  0.277051022864 | 0.0807066840154  |               {'C': 1000.0, 'gamma': 0.01}               |        21       |
|  0.336595545314 | 0.0509202422128  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.350501573287 | 0.0687813657751  |               {'C': 1000.0, 'gamma': 1.0}                |        7        |
|  0.343834492432 | 0.0992609624105  |               {'C': 1000.0, 'gamma': 10.0}               |        9        |
|  0.303956965375 |  0.083996778531  |              {'C': 1000.0, 'gamma': 100.0}               |        15       |
|  0.282582011469 | 0.0639495299241  |              {'C': 1000.0, 'gamma': 1000.0}              |        19       |
|  0.257793227286 | 0.0561156396912  |             {'C': 1000.0, 'gamma': 10000.0}              |        23       |
|  0.332378091849 |  0.144267001502  |              {'C': 10000.0, 'gamma': 0.001}              |        12       |
|  0.381466948347 | 0.0974994907647  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.374116591375 | 0.0368220303508  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.349965263709 |  0.082985624459  |               {'C': 10000.0, 'gamma': 1.0}               |        8        |
|  0.356731425109 | 0.0522412386936  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.334928805622 | 0.0680327971686  |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
|  0.277455291767 | 0.0667314950535  |             {'C': 10000.0, 'gamma': 1000.0}              |        20       |
|  0.25680977269  |  0.060745573857  |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.22      0.14      0.17        14
          1       0.42      0.67      0.51        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.25      0.35      0.29        57

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.487804878049 | 0.00860812617509 |               {'C': 0.001, 'gamma': 0.001}               |        27       |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 0.01}                |        6        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        6        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.001, 'gamma': 1.0}                |        6        |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.001, 'gamma': 10.0}                |        27       |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.001, 'gamma': 100.0}               |        6        |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.001, 'gamma': 1000.0}               |        6        |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.001, 'gamma': 10000.0}              |        6        |
|  0.487847240609 | 0.00981483312777 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 0.01}                |        6        |
|  0.487784967646 | 0.00596368925175 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        37       |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 1.0}                 |        6        |
|  0.487825618052 | 0.00862517403599 |                {'C': 0.01, 'gamma': 10.0}                |        6        |
|  0.487825618052 | 0.00862517403599 |               {'C': 0.01, 'gamma': 100.0}                |        6        |
|  0.487804878049 | 0.00736134723135 |               {'C': 0.01, 'gamma': 1000.0}               |        27       |
|  0.487825618052 | 0.00862517403599 |              {'C': 0.01, 'gamma': 10000.0}               |        6        |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        27       |
|  0.487804878049 | 0.00736134723135 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        27       |
|  0.487825618052 | 0.00862517403599 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        6        |
|  0.487784967646 | 0.00596368925175 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        37       |
|  0.487847240609 | 0.00981483312777 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.487825618052 | 0.00862517403599 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        6        |
|  0.487825618052 | 0.00862517403599 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        6        |
|  0.487804878049 | 0.00736134723135 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        27       |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 0.001}                |        6        |
|  0.487825618052 | 0.00862517403599 |                {'C': 1.0, 'gamma': 0.01}                 |        6        |
|  0.487825618052 | 0.00862517403599 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        6        |
|  0.487825618052 | 0.00862517403599 |                 {'C': 1.0, 'gamma': 1.0}                 |        6        |
|  0.48585620029  | 0.0111910853671  |                {'C': 1.0, 'gamma': 10.0}                 |        39       |
|  0.487804878049 | 0.00736134723135 |                {'C': 1.0, 'gamma': 100.0}                |        27       |
|  0.487847240609 | 0.00981483312777 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.487804878049 | 0.00860812617509 |               {'C': 1.0, 'gamma': 10000.0}               |        27       |
|  0.487825618052 | 0.00862517403599 |               {'C': 10.0, 'gamma': 0.001}                |        6        |
|  0.487825618052 | 0.00862517403599 |                {'C': 10.0, 'gamma': 0.01}                |        6        |
|  0.487804878049 | 0.00736134723135 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        27       |
|  0.481834404753 | 0.0247764741966  |                {'C': 10.0, 'gamma': 1.0}                 |        43       |
|  0.449037491013 | 0.0535597654822  |                {'C': 10.0, 'gamma': 10.0}                |        52       |
|  0.461484949671 | 0.0233861688427  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.481728057076 | 0.0148521162754  |               {'C': 10.0, 'gamma': 1000.0}               |        45       |
|  0.485814720284 | 0.0112142036181  |              {'C': 10.0, 'gamma': 10000.0}               |        40       |
|  0.487847240609 | 0.00981483312777 |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.487847240609 | 0.00981483312777 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.481707317073 | 0.0141466687562  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        46       |
|  0.418699186992 | 0.0397075586515  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.388354833803 | 0.0430125538051  |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.447046450694 | 0.0326768400025  |               {'C': 100.0, 'gamma': 100.0}               |        53       |
|  0.479694672584 |  0.014922044869  |              {'C': 100.0, 'gamma': 1000.0}               |        47       |
|  0.483739837398 | 0.0187534790748  |              {'C': 100.0, 'gamma': 10000.0}              |        41       |
|  0.487804878049 | 0.00736134723135 |              {'C': 1000.0, 'gamma': 0.001}               |        27       |
|  0.47762402522  | 0.0242860443353  |               {'C': 1000.0, 'gamma': 0.01}               |        48       |
|  0.445392435429 | 0.0439256435729  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        54       |
|  0.367944078038 | 0.0221615021734  |               {'C': 1000.0, 'gamma': 1.0}                |        62       |
|  0.388226937116 | 0.0432348576756  |               {'C': 1000.0, 'gamma': 10.0}               |        61       |
|  0.439045130247 | 0.0604325491733  |              {'C': 1000.0, 'gamma': 100.0}               |        56       |
|  0.47156545545  | 0.0344779740777  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.487825618052 | 0.00862517403599 |             {'C': 1000.0, 'gamma': 10000.0}              |        6        |
|  0.483739837398 | 0.0174984314572  |              {'C': 10000.0, 'gamma': 0.001}              |        41       |
|  0.443276090924 | 0.0442119842934  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.396274058404 | 0.0699926205066  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        59       |
|  0.349457582722 | 0.0703671591488  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.353586810741 | 0.0595031601933  |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.439006968641 |  0.051450757744  |              {'C': 10000.0, 'gamma': 100.0}              |        57       |
|  0.475839624468 | 0.0386005034486  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.481769537083 | 0.0100041939779  |             {'C': 10000.0, 'gamma': 10000.0}             |        44       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.01, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        14
          1       0.47      1.00      0.64        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.22      0.47      0.30        57

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.486815415822 | 0.00767362845229 |               {'C': 0.001, 'gamma': 0.001}               |        25       |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.486815415822 | 0.00624616335453 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        25       |
|  0.486815415822 | 0.00767362845229 |                {'C': 0.001, 'gamma': 1.0}                |        25       |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.486815415822 | 0.00624616335453 |              {'C': 0.001, 'gamma': 1000.0}               |        25       |
|  0.486836113756 | 0.00769537062935 |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.486815415822 | 0.00767362845229 |                {'C': 0.01, 'gamma': 1.0}                 |        25       |
|  0.486836113756 | 0.00769537062935 |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.486795545805 | 0.00451543676528 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.486836113756 | 0.00769537062935 |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.486836113756 | 0.00769537062935 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.486795545805 | 0.00451543676528 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.486815415822 | 0.00767362845229 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        25       |
|  0.486836113756 | 0.00769537062935 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.486815415822 | 0.00624616335453 |                {'C': 1.0, 'gamma': 0.01}                 |        25       |
|  0.486836113756 | 0.00769537062935 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.486836113756 | 0.00769537062935 |                 {'C': 1.0, 'gamma': 1.0}                 |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 1.0, 'gamma': 10.0}                 |        2        |
|  0.490892908888 | 0.0104402859312  |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.486836113756 | 0.00769537062935 |               {'C': 1.0, 'gamma': 1000.0}                |        2        |
|  0.486815415822 | 0.00767362845229 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|  0.486815415822 | 0.00767362845229 |               {'C': 10.0, 'gamma': 0.001}                |        25       |
|  0.486795545805 | 0.00451543676528 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.486836113756 | 0.00769537062935 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.474581211795 | 0.0169701411985  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.423935091278 |  0.039329675662  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.446147286501 | 0.0245332380519  |               {'C': 10.0, 'gamma': 100.0}                |        53       |
|  0.480750058644 | 0.0151019503418  |               {'C': 10.0, 'gamma': 1000.0}               |        39       |
|  0.478722523492 | 0.0298898922685  |              {'C': 10.0, 'gamma': 10000.0}               |        43       |
|  0.486795545805 | 0.00451543676528 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.486815415822 | 0.00767362845229 |               {'C': 100.0, 'gamma': 0.01}                |        25       |
|  0.478763919361 | 0.0137417999056  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        41       |
|  0.417908542727 | 0.0564560290682  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.369143346994 | 0.0481381312843  |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.450363766196 | 0.0349178636994  |               {'C': 100.0, 'gamma': 100.0}               |        51       |
|  0.470505443557 | 0.0195869226448  |              {'C': 100.0, 'gamma': 1000.0}               |        49       |
|  0.478743221427 | 0.0131630635081  |              {'C': 100.0, 'gamma': 10000.0}              |        42       |
|  0.486836113756 | 0.00769537062935 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.47868026521  | 0.0151188431922  |               {'C': 1000.0, 'gamma': 0.01}               |        44       |
|  0.434179706365 | 0.0493783803951  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.334768390115 | 0.0335924513205  |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.371213140429 | 0.0410678858611  |               {'C': 1000.0, 'gamma': 10.0}               |        59       |
|  0.446346642105 | 0.0554805127215  |              {'C': 1000.0, 'gamma': 100.0}               |        52       |
|  0.476694125926 | 0.0209216451335  |              {'C': 1000.0, 'gamma': 1000.0}              |        45       |
|  0.476571594155 | 0.0197091042069  |             {'C': 1000.0, 'gamma': 10000.0}              |        46       |
|  0.472635605967 | 0.0121627614391  |              {'C': 10000.0, 'gamma': 0.001}              |        48       |
|  0.434222827062 | 0.0422979640147  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.367029570449 | 0.0645293309572  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        61       |
|  0.346690400298 |  0.043359266875  |               {'C': 10000.0, 'gamma': 1.0}               |        63       |
|  0.350966248568 | 0.0608028633841  |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.444532123194 | 0.0558206047838  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.464439223965 | 0.0211878884317  |             {'C': 10000.0, 'gamma': 1000.0}              |        50       |
|  0.480730223124 | 0.0131411744258  |             {'C': 10000.0, 'gamma': 10000.0}             |        40       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      1.00      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.23      0.48      0.31        56

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.237028263638 | 0.00600897487947 |               {'C': 0.001, 'gamma': 0.001}               |        54       |
|  0.237087890247 | 0.00745356918921 |               {'C': 0.001, 'gamma': 0.01}                |        25       |
|  0.237087890247 | 0.00745356918921 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        25       |
|  0.237087890247 | 0.00745356918921 |                {'C': 0.001, 'gamma': 1.0}                |        25       |
|  0.237009562446 | 0.00437090411636 |               {'C': 0.001, 'gamma': 10.0}                |        58       |
|  0.237009562446 | 0.00437090411636 |               {'C': 0.001, 'gamma': 100.0}               |        58       |
|  0.237028263638 | 0.00600897487947 |              {'C': 0.001, 'gamma': 1000.0}               |        54       |
|  0.237087890247 | 0.00745356918921 |              {'C': 0.001, 'gamma': 10000.0}              |        25       |
|  0.237047533499 | 0.00600291769203 |               {'C': 0.01, 'gamma': 0.001}                |        51       |
|  0.237087890247 | 0.00745356918921 |                {'C': 0.01, 'gamma': 0.01}                |        25       |
|  0.237087890247 | 0.00745356918921 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        25       |
|  0.237087890247 | 0.00745356918921 |                {'C': 0.01, 'gamma': 1.0}                 |        25       |
|  0.237087890247 | 0.00745356918921 |                {'C': 0.01, 'gamma': 10.0}                |        25       |
|  0.237087890247 | 0.00745356918921 |               {'C': 0.01, 'gamma': 100.0}                |        25       |
|  0.237028263638 | 0.00600897487947 |               {'C': 0.01, 'gamma': 1000.0}               |        54       |
|  0.237087890247 | 0.00745356918921 |              {'C': 0.01, 'gamma': 10000.0}               |        25       |
|  0.237087890247 | 0.00745356918921 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        25       |
|  0.237047533499 | 0.00600291769203 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        51       |
|  0.237009562446 | 0.00437090411636 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        58       |
|  0.237087890247 | 0.00745356918921 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        25       |
|  0.237087890247 | 0.00745356918921 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        25       |
|  0.237087890247 | 0.00745356918921 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        25       |
|  0.237087890247 | 0.00745356918921 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        25       |
|  0.237087890247 | 0.00745356918921 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        25       |
|  0.237087890247 | 0.00745356918921 |                {'C': 1.0, 'gamma': 0.001}                |        25       |
|  0.237087890247 | 0.00745356918921 |                {'C': 1.0, 'gamma': 0.01}                 |        25       |
|  0.237087890247 | 0.00745356918921 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.237087890247 | 0.00745356918921 |                 {'C': 1.0, 'gamma': 1.0}                 |        25       |
|  0.237087890247 | 0.00745356918921 |                {'C': 1.0, 'gamma': 10.0}                 |        25       |
|  0.237067192313 | 0.00778559519414 |                {'C': 1.0, 'gamma': 100.0}                |        50       |
|  0.236571269806 | 0.00805174514425 |               {'C': 1.0, 'gamma': 1000.0}                |        62       |
|  0.237087890247 | 0.00745356918921 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|  0.237009562446 | 0.00437090411636 |               {'C': 10.0, 'gamma': 0.001}                |        58       |
|  0.237047533499 | 0.00600291769203 |                {'C': 10.0, 'gamma': 0.01}                |        51       |
|  0.237028263638 | 0.00600897487947 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        54       |
|  0.276973379638 | 0.0828457572525  |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.341141193432 | 0.0666180512261  |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.326752311357 | 0.0739274196811  |               {'C': 10.0, 'gamma': 100.0}                |        13       |
|  0.25519643594  | 0.0625883186243  |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.235952646649 | 0.00480799829904 |              {'C': 10.0, 'gamma': 10000.0}               |        63       |
|  0.237087890247 | 0.00745356918921 |               {'C': 100.0, 'gamma': 0.001}               |        25       |
|  0.237087890247 | 0.00745356918921 |               {'C': 100.0, 'gamma': 0.01}                |        25       |
|  0.261367905451 | 0.0591796091165  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        19       |
|  0.359729450463 | 0.0896772119494  |                {'C': 100.0, 'gamma': 1.0}                |        2        |
|  0.350808961971 | 0.0657076566727  |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.356321665533 | 0.0837449286925  |               {'C': 100.0, 'gamma': 100.0}               |        3        |
|  0.278920239409 | 0.0946367094273  |              {'C': 100.0, 'gamma': 1000.0}               |        15       |
|  0.253724539484 | 0.0566592080922  |              {'C': 100.0, 'gamma': 10000.0}              |        22       |
|  0.237087890247 | 0.00745356918921 |              {'C': 1000.0, 'gamma': 0.001}               |        25       |
|  0.234416042345 | 0.00802213279137 |               {'C': 1000.0, 'gamma': 0.01}               |        64       |
|  0.340008659294 | 0.0840709682364  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.34318061878  | 0.0658958346495  |               {'C': 1000.0, 'gamma': 1.0}                |        7        |
|  0.336419152369 |  0.055957609545  |               {'C': 1000.0, 'gamma': 10.0}               |        11       |
|  0.334649837244 | 0.0852787103347  |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
|  0.274874592537 |  0.067132400825  |              {'C': 1000.0, 'gamma': 1000.0}              |        17       |
|  0.244512555989 | 0.0261462643895  |             {'C': 1000.0, 'gamma': 10000.0}              |        23       |
|  0.239991876302 | 0.0197216564044  |              {'C': 10000.0, 'gamma': 0.001}              |        24       |
|  0.309326518679 | 0.0590552504837  |              {'C': 10000.0, 'gamma': 0.01}               |        14       |
|  0.356038271382 |  0.05446639945   |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.360932763301 | 0.0556168629641  |               {'C': 10000.0, 'gamma': 1.0}               |        1        |
|  0.354982157046 | 0.0521145674689  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.337156758894 | 0.0689649513426  |              {'C': 10000.0, 'gamma': 100.0}              |        10       |
|  0.268236150665 | 0.0782685010415  |             {'C': 10000.0, 'gamma': 1000.0}              |        18       |
|  0.255798517308 | 0.0601463185185  |             {'C': 10000.0, 'gamma': 10000.0}             |        20       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.12      0.15      0.14        13
          1       0.56      0.52      0.54        27
          2       0.14      0.18      0.16        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.33      0.32      0.32        56

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.486815415822 | 0.00767362845229 |               {'C': 0.001, 'gamma': 0.001}               |        23       |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.486815415822 | 0.00624616335453 |                {'C': 0.001, 'gamma': 1.0}                |        23       |
|  0.486815415822 | 0.00767362845229 |               {'C': 0.001, 'gamma': 10.0}                |        23       |
|  0.486815415822 | 0.00624616335453 |               {'C': 0.001, 'gamma': 100.0}               |        23       |
|  0.486836113756 | 0.00769537062935 |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.486836113756 | 0.00769537062935 |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.486815415822 | 0.00624616335453 |               {'C': 0.01, 'gamma': 0.001}                |        23       |
|  0.486815415822 | 0.00767362845229 |                {'C': 0.01, 'gamma': 0.01}                |        23       |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.486836113756 | 0.00769537062935 |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.486836113756 | 0.00769537062935 |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.486815415822 | 0.00624616335453 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        23       |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.486815415822 | 0.00624616335453 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        23       |
|  0.486795545805 | 0.00451543676528 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        36       |
|  0.486836113756 | 0.00769537062935 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.486815415822 | 0.00624616335453 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        23       |
|  0.486836113756 | 0.00769537062935 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.486836113756 | 0.00769537062935 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.486815415822 | 0.00767362845229 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.486795545805 | 0.00451543676528 |                 {'C': 1.0, 'gamma': 1.0}                 |        36       |
|  0.486836113756 | 0.00769537062935 |                {'C': 1.0, 'gamma': 10.0}                 |        2        |
|  0.488906769604 | 0.0139574109039  |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.48480771619  | 0.0126803449471  |               {'C': 1.0, 'gamma': 1000.0}                |        38       |
|  0.486815415822 | 0.00624616335453 |               {'C': 1.0, 'gamma': 10000.0}               |        23       |
|  0.486836113756 | 0.00769537062935 |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.486836113756 | 0.00769537062935 |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.486836113756 | 0.00769537062935 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.478722523492 | 0.0152527514608  |                {'C': 10.0, 'gamma': 1.0}                 |        42       |
|  0.409918277656 | 0.0563356470474  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.438234776669 | 0.0477454128242  |               {'C': 10.0, 'gamma': 100.0}                |        52       |
|  0.480730223124 |  0.013696458594  |               {'C': 10.0, 'gamma': 1000.0}               |        40       |
|  0.482779318624 | 0.0100766183756  |              {'C': 10.0, 'gamma': 10000.0}               |        39       |
|  0.486815415822 | 0.00624616335453 |               {'C': 100.0, 'gamma': 0.001}               |        23       |
|  0.486815415822 | 0.00767362845229 |               {'C': 100.0, 'gamma': 0.01}                |        23       |
|  0.478701825558 | 0.0175577524272  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        43       |
|  0.397690110527 | 0.0729347660643  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.383677608975 | 0.0563661498063  |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.440268245229 | 0.0440337448416  |               {'C': 100.0, 'gamma': 100.0}               |        51       |
|  0.470524416663 | 0.0323910633767  |              {'C': 100.0, 'gamma': 1000.0}               |        48       |
|  0.47880531523  | 0.0152017725699  |              {'C': 100.0, 'gamma': 10000.0}              |        41       |
|  0.486836113756 | 0.00769537062935 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.476693263512 | 0.0171481832384  |               {'C': 1000.0, 'gamma': 0.01}               |        44       |
|  0.418035317575 | 0.0447509132925  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.359150556774 | 0.0491972236041  |               {'C': 1000.0, 'gamma': 1.0}                |        62       |
|  0.363391908488 | 0.0588692732023  |               {'C': 1000.0, 'gamma': 10.0}               |        61       |
|  0.438075920023 | 0.0406704628562  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|   0.4624969988  | 0.0206535495956  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.47261663286  | 0.0264269107514  |             {'C': 1000.0, 'gamma': 10000.0}              |        47       |
|  0.476673427992 |  0.018194855153  |              {'C': 10000.0, 'gamma': 0.001}              |        45       |
|  0.425963488844 | 0.0494757709518  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.395684894648 | 0.0414860104619  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        59       |
|   0.3486633274  | 0.0657317288219  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.359026369168 | 0.0459164839689  |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.432066792234 | 0.0452117607835  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.468458831809 |  0.016615101809  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.474686426295 | 0.0197907859985  |             {'C': 10000.0, 'gamma': 10000.0}             |        46       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      1.00      0.65        27
          2       0.00      0.00      0.00        11
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.23      0.48      0.31        56

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485829959514 | 0.00784949104047 |               {'C': 0.001, 'gamma': 0.001}               |        22       |
|  0.485829959514 | 0.00646410978624 |               {'C': 0.001, 'gamma': 0.01}                |        22       |
|  0.48581012972  | 0.00481227067794 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        33       |
|  0.48585061555  | 0.00787329033964 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.48585061555  | 0.00787329033964 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.48581012972  | 0.00481227067794 |               {'C': 0.001, 'gamma': 100.0}               |        33       |
|  0.48581012972  | 0.00481227067794 |              {'C': 0.001, 'gamma': 1000.0}               |        33       |
|  0.48585061555  | 0.00787329033964 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.485829959514 | 0.00646410978624 |               {'C': 0.01, 'gamma': 0.001}                |        22       |
|  0.48585061555  | 0.00787329033964 |                {'C': 0.01, 'gamma': 0.01}                |        1        |
|  0.48585061555  | 0.00787329033964 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.48585061555  | 0.00787329033964 |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.485829959514 | 0.00784949104047 |                {'C': 0.01, 'gamma': 10.0}                |        22       |
|  0.485829959514 | 0.00646410978624 |               {'C': 0.01, 'gamma': 100.0}                |        22       |
|  0.48585061555  | 0.00787329033964 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.48581012972  | 0.00481227067794 |              {'C': 0.01, 'gamma': 10000.0}               |        33       |
|  0.485829959514 | 0.00646410978624 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        22       |
|  0.48585061555  | 0.00787329033964 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.48585061555  | 0.00787329033964 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.48585061555  | 0.00787329033964 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.485829959514 | 0.00784949104047 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        22       |
|  0.48585061555  | 0.00787329033964 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        1        |
|  0.485829959514 | 0.00784949104047 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        22       |
|  0.48585061555  | 0.00787329033964 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.48585061555  | 0.00787329033964 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.48585061555  | 0.00787329033964 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.48585061555  | 0.00787329033964 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.48585061555  | 0.00787329033964 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.48585061555  | 0.00787329033964 |                {'C': 1.0, 'gamma': 10.0}                 |        1        |
|  0.48585061555  | 0.00787329033964 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.48585061555  | 0.00787329033964 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.485829959514 | 0.00646410978624 |               {'C': 1.0, 'gamma': 10000.0}               |        22       |
|  0.485829959514 | 0.00646410978624 |               {'C': 10.0, 'gamma': 0.001}                |        22       |
|  0.48585061555  | 0.00787329033964 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.48581012972  | 0.00481227067794 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        33       |
|  0.469616623978 | 0.0127366046577  |                {'C': 10.0, 'gamma': 1.0}                 |        48       |
|  0.427270924564 | 0.0427453003585  |                {'C': 10.0, 'gamma': 10.0}                |        54       |
|  0.443381806164 | 0.0412053212629  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.47572915806  | 0.0191399208591  |               {'C': 10.0, 'gamma': 1000.0}               |        42       |
|  0.483867636123 | 0.00910376584816 |              {'C': 10.0, 'gamma': 10000.0}               |        38       |
|  0.485829959514 | 0.00784949104047 |               {'C': 100.0, 'gamma': 0.001}               |        22       |
|  0.48585061555  | 0.00787329033964 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.471659919028 | 0.0215204019989  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        47       |
|  0.407025462007 |   0.058607761    |                {'C': 100.0, 'gamma': 1.0}                |        57       |
|  0.370336039274 | 0.0406991492245  |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.425101214575 | 0.0359554632759  |               {'C': 100.0, 'gamma': 100.0}               |        55       |
|  0.471679714396 | 0.0188017247661  |              {'C': 100.0, 'gamma': 1000.0}               |        46       |
|  0.475667189953 | 0.0173227656786  |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.483805668016 | 0.00793363202269 |              {'C': 1000.0, 'gamma': 0.001}               |        39       |
|  0.473665206973 | 0.0174905747331  |               {'C': 1000.0, 'gamma': 0.01}               |        45       |
|   0.4352433281  | 0.0367110979339  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        52       |
|  0.348203751136 | 0.0603859403724  |               {'C': 1000.0, 'gamma': 1.0}                |        62       |
|  0.374466385745 | 0.0550984042913  |               {'C': 1000.0, 'gamma': 10.0}               |        59       |
|  0.431174089069 | 0.0392978921877  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|  0.461538461538 | 0.0267833119402  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.481781376518 | 0.0152650019472  |             {'C': 1000.0, 'gamma': 10000.0}              |        40       |
|  0.475812642871 | 0.0220882557758  |              {'C': 10000.0, 'gamma': 0.001}              |        41       |
|  0.416897325732 | 0.0401360281651  |              {'C': 10000.0, 'gamma': 0.01}               |        56       |
|  0.343989919855 | 0.0495808684715  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.354431752458 | 0.0738707638862  |               {'C': 10000.0, 'gamma': 1.0}               |        61       |
|  0.339903329753 | 0.0503642958109  |              {'C': 10000.0, 'gamma': 10.0}               |        64       |
|  0.404651739238 | 0.0542266699236  |              {'C': 10000.0, 'gamma': 100.0}              |        58       |
|  0.467693960175 | 0.0276959755065  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.473684210526 | 0.0194816728564  |             {'C': 10000.0, 'gamma': 10000.0}             |        44       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        55

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.236072534277 | 0.0062249484832  |               {'C': 0.001, 'gamma': 0.001}               |        51       |
|  0.236072534277 | 0.0062249484832  |               {'C': 0.001, 'gamma': 0.01}                |        51       |
|  0.236132040184 | 0.00763362824581 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        24       |
|  0.236132040184 | 0.00763362824581 |                {'C': 0.001, 'gamma': 1.0}                |        24       |
|  0.23609176513  | 0.00622206817309 |               {'C': 0.001, 'gamma': 10.0}                |        45       |
|  0.23609176513  | 0.00622206817309 |               {'C': 0.001, 'gamma': 100.0}               |        45       |
|  0.236132040184 | 0.00763362824581 |              {'C': 0.001, 'gamma': 1000.0}               |        24       |
|  0.236132040184 | 0.00763362824581 |              {'C': 0.001, 'gamma': 10000.0}              |        24       |
|  0.236132040184 | 0.00763362824581 |               {'C': 0.01, 'gamma': 0.001}                |        24       |
|  0.236132040184 | 0.00763362824581 |                {'C': 0.01, 'gamma': 0.01}                |        24       |
|  0.23609176513  | 0.00622206817309 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        45       |
|  0.236072534277 | 0.0062249484832  |                {'C': 0.01, 'gamma': 1.0}                 |        51       |
|  0.236132040184 | 0.00763362824581 |                {'C': 0.01, 'gamma': 10.0}                |        24       |
|  0.236132040184 | 0.00763362824581 |               {'C': 0.01, 'gamma': 100.0}                |        24       |
|  0.236053870941 | 0.00466323415686 |               {'C': 0.01, 'gamma': 1000.0}               |        55       |
|  0.236132040184 | 0.00763362824581 |              {'C': 0.01, 'gamma': 10000.0}               |        24       |
|  0.236132040184 | 0.00763362824581 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        24       |
|  0.236132040184 | 0.00763362824581 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        24       |
|  0.236072534277 | 0.0062249484832  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        51       |
|  0.236132040184 | 0.00763362824581 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        24       |
|  0.236132040184 | 0.00763362824581 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        24       |
|  0.236132040184 | 0.00763362824581 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        24       |
|  0.236132040184 | 0.00763362824581 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        24       |
|  0.236053870941 | 0.00466323415686 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        55       |
|  0.236132040184 | 0.00763362824581 |                {'C': 1.0, 'gamma': 0.001}                |        24       |
|  0.236132040184 | 0.00763362824581 |                {'C': 1.0, 'gamma': 0.01}                 |        24       |
|  0.236132040184 | 0.00763362824581 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.23609176513  | 0.00622206817309 |                 {'C': 1.0, 'gamma': 1.0}                 |        45       |
|  0.237521275717 | 0.0061524166047  |                {'C': 1.0, 'gamma': 10.0}                 |        22       |
|  0.236549016857 | 0.00520992442826 |                {'C': 1.0, 'gamma': 100.0}                |        23       |
|  0.23609176513  | 0.00622206817309 |               {'C': 1.0, 'gamma': 1000.0}                |        45       |
|  0.236053870941 | 0.00466323415686 |               {'C': 1.0, 'gamma': 10000.0}               |        55       |
|  0.236132040184 | 0.00763362824581 |               {'C': 10.0, 'gamma': 0.001}                |        24       |
|  0.236132040184 | 0.00763362824581 |                {'C': 10.0, 'gamma': 0.01}                |        24       |
|  0.236053870941 | 0.00466323415686 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        55       |
|  0.320158273004 |  0.137524008463  |                {'C': 10.0, 'gamma': 1.0}                 |        11       |
|   0.3450380667  | 0.0785006945238  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.324332067085 | 0.0759869640727  |               {'C': 10.0, 'gamma': 100.0}                |        9        |
|  0.234533507606 | 0.0095757343253  |               {'C': 10.0, 'gamma': 1000.0}               |        61       |
|  0.235536660332 | 0.00887863918409 |              {'C': 10.0, 'gamma': 10000.0}               |        60       |
|  0.23609176513  | 0.00622206817309 |               {'C': 100.0, 'gamma': 0.001}               |        45       |
|  0.236053870941 | 0.00466323415686 |               {'C': 100.0, 'gamma': 0.01}                |        55       |
|  0.265642564076 | 0.0658602405111  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.332258581029 | 0.0602051324711  |                {'C': 100.0, 'gamma': 1.0}                |        7        |
|  0.345795589654 | 0.0398812403541  |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.291337390921 | 0.0522375492137  |               {'C': 100.0, 'gamma': 100.0}               |        15       |
|  0.230221865314 | 0.00890838773849 |              {'C': 100.0, 'gamma': 1000.0}               |        64       |
|  0.234073630967 | 0.0121554272577  |              {'C': 100.0, 'gamma': 10000.0}              |        62       |
|  0.236132040184 | 0.00763362824581 |              {'C': 1000.0, 'gamma': 0.001}               |        24       |
|  0.282950230014 | 0.0826661097184  |               {'C': 1000.0, 'gamma': 0.01}               |        16       |
|  0.324090237139 | 0.0591418538603  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.348103119386 | 0.0600321840222  |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.349324726853 | 0.0624271134995  |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.303471561901 | 0.0898763590541  |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.233385422976 | 0.0102554709424  |              {'C': 1000.0, 'gamma': 1000.0}              |        63       |
|  0.252075905218 | 0.0536770368351  |             {'C': 1000.0, 'gamma': 10000.0}              |        21       |
|  0.25371456927  | 0.0570785358205  |              {'C': 10000.0, 'gamma': 0.001}              |        19       |
|  0.314071890053 | 0.0291147211529  |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.347489190999 | 0.0746530366367  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.328497224854 | 0.0769188687397  |               {'C': 10000.0, 'gamma': 1.0}               |        8        |
|  0.355324927383 | 0.0779567131994  |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.294706404427 | 0.0671112106183  |              {'C': 10000.0, 'gamma': 100.0}              |        14       |
|  0.262362469291 | 0.0512361500924  |             {'C': 10000.0, 'gamma': 1000.0}              |        18       |
|  0.25266753077  | 0.0587253376923  |             {'C': 10000.0, 'gamma': 10000.0}             |        20       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.14      0.15      0.15        13
          1       0.54      0.48      0.51        27
          2       0.14      0.20      0.17        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.33      0.31      0.32        55

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485829959514 | 0.00784949104047 |               {'C': 0.001, 'gamma': 0.001}               |        21       |
|  0.48585061555  | 0.00787329033964 |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.48581012972  | 0.00481227067794 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        37       |
|  0.48585061555  | 0.00787329033964 |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.48585061555  | 0.00787329033964 |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.485829959514 | 0.00646410978624 |               {'C': 0.001, 'gamma': 100.0}               |        21       |
|  0.485829959514 | 0.00646410978624 |              {'C': 0.001, 'gamma': 1000.0}               |        21       |
|  0.48585061555  | 0.00787329033964 |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.48585061555  | 0.00787329033964 |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.48585061555  | 0.00787329033964 |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.48585061555  | 0.00787329033964 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.48585061555  | 0.00787329033964 |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.48585061555  | 0.00787329033964 |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.485829959514 | 0.00646410978624 |               {'C': 0.01, 'gamma': 100.0}                |        21       |
|  0.48585061555  | 0.00787329033964 |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.48585061555  | 0.00787329033964 |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.485829959514 | 0.00784949104047 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        21       |
|  0.48585061555  | 0.00787329033964 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.485829959514 | 0.00646410978624 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        21       |
|  0.485829959514 | 0.00784949104047 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        21       |
|  0.485829959514 | 0.00646410978624 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        21       |
|  0.485829959514 | 0.00646410978624 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        21       |
|  0.485829959514 | 0.00646410978624 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        21       |
|  0.48585061555  | 0.00787329033964 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.485829959514 | 0.00784949104047 |                {'C': 1.0, 'gamma': 0.001}                |        21       |
|  0.485829959514 | 0.00646410978624 |                {'C': 1.0, 'gamma': 0.01}                 |        21       |
|  0.48581012972  | 0.00481227067794 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        37       |
|  0.48585061555  | 0.00787329033964 |                 {'C': 1.0, 'gamma': 1.0}                 |        2        |
|  0.48585061555  | 0.00787329033964 |                {'C': 1.0, 'gamma': 10.0}                 |        2        |
|  0.487874907048 | 0.00864234181412 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.48585061555  | 0.00787329033964 |               {'C': 1.0, 'gamma': 1000.0}                |        2        |
|  0.485829959514 | 0.00646410978624 |               {'C': 1.0, 'gamma': 10000.0}               |        21       |
|  0.48585061555  | 0.00787329033964 |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.48581012972  | 0.00481227067794 |                {'C': 10.0, 'gamma': 0.01}                |        37       |
|  0.485829959514 | 0.00646410978624 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.471554056845 | 0.0202630384892  |                {'C': 10.0, 'gamma': 1.0}                 |        46       |
|  0.447343461676 |  0.055185061328  |                {'C': 10.0, 'gamma': 10.0}                |        51       |
|  0.439246295684 |  0.039647241984  |               {'C': 10.0, 'gamma': 100.0}                |        52       |
|  0.477753449558 | 0.0191907870797  |               {'C': 10.0, 'gamma': 1000.0}               |        41       |
|  0.48585061555  | 0.00787329033964 |              {'C': 10.0, 'gamma': 10000.0}               |        2        |
|  0.485829959514 | 0.00646410978624 |               {'C': 100.0, 'gamma': 0.001}               |        21       |
|  0.48585061555  | 0.00787329033964 |               {'C': 100.0, 'gamma': 0.01}                |        2        |
|  0.471638402324 | 0.0166344701544  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        45       |
|  0.412765257925 | 0.0575305989387  |                {'C': 100.0, 'gamma': 1.0}                |        57       |
|  0.392606688424 | 0.0539231986642  |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.435409437054 | 0.0512429185214  |               {'C': 100.0, 'gamma': 100.0}               |        53       |
|  0.465606839902 | 0.0177831604838  |              {'C': 100.0, 'gamma': 1000.0}               |        48       |
|  0.475749814096 | 0.0119197974409  |              {'C': 100.0, 'gamma': 10000.0}              |        42       |
|  0.485829959514 | 0.00784949104047 |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.469575311906 | 0.0237613344502  |               {'C': 1000.0, 'gamma': 0.01}               |        47       |
|  0.433092518384 | 0.0406603136665  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        54       |
|  0.382549781046 | 0.0413940775016  |               {'C': 1000.0, 'gamma': 1.0}                |        61       |
|  0.392712550607 | 0.0502212726944  |               {'C': 1000.0, 'gamma': 10.0}               |        59       |
|  0.425101214575 | 0.0500823020799  |              {'C': 1000.0, 'gamma': 100.0}               |        55       |
|  0.463604065108 | 0.0338685153784  |              {'C': 1000.0, 'gamma': 1000.0}              |        49       |
|  0.475667189953 | 0.0185882083398  |             {'C': 1000.0, 'gamma': 10000.0}              |        44       |
|  0.479922333306 | 0.0246702268677  |              {'C': 10000.0, 'gamma': 0.001}              |        40       |
|  0.415041725192 | 0.0648004174556  |              {'C': 10000.0, 'gamma': 0.01}               |        56       |
|  0.339957035446 | 0.0631041346162  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.358299595142 | 0.0457226360236  |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.335825828307 | 0.0579050862177  |              {'C': 10000.0, 'gamma': 10.0}               |        64       |
|  0.410931174089 | 0.0366998553379  |              {'C': 10000.0, 'gamma': 100.0}              |        58       |
|  0.457448566471 | 0.0228814069822  |             {'C': 10000.0, 'gamma': 1000.0}              |        50       |
|  0.475728297392 | 0.0168686084198  |             {'C': 10000.0, 'gamma': 10000.0}             |        43       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         4
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        55

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.484848484848 | 0.0065278777965  |               {'C': 0.001, 'gamma': 0.001}               |        32       |
|  0.484907902555 | 0.00900433124482 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.484867498515 | 0.00649996153155 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        28       |
|  0.484867498515 | 0.00649996153155 |                {'C': 0.001, 'gamma': 1.0}                |        28       |
|  0.484887288249 | 0.00780230388835 |               {'C': 0.001, 'gamma': 10.0}                |        22       |
|  0.484907902555 | 0.00900433124482 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.484887288249 | 0.00780230388835 |              {'C': 0.001, 'gamma': 1000.0}               |        22       |
|  0.484907902555 | 0.00900433124482 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.484907902555 | 0.00900433124482 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.484907902555 | 0.00900433124482 |                {'C': 0.01, 'gamma': 0.01}                |        1        |
|  0.484907902555 | 0.00900433124482 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.484887288249 | 0.00780230388835 |                {'C': 0.01, 'gamma': 1.0}                 |        22       |
|  0.484907902555 | 0.00900433124482 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.484848484848 | 0.0065278777965  |               {'C': 0.01, 'gamma': 100.0}                |        32       |
|  0.484907902555 | 0.00900433124482 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.484907902555 | 0.00900433124482 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.484887288249 | 0.00780230388835 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        22       |
|  0.484907902555 | 0.00900433124482 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.484907902555 | 0.00900433124482 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.484907902555 | 0.00900433124482 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.484907902555 | 0.00900433124482 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.484848484848 | 0.0065278777965  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        32       |
|  0.484848484848 | 0.0065278777965  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        32       |
|  0.484907902555 | 0.00900433124482 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.484907902555 | 0.00900433124482 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.484848484848 | 0.0065278777965  |                {'C': 1.0, 'gamma': 0.01}                 |        32       |
|  0.484848484848 | 0.0065278777965  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        32       |
|  0.484887288249 | 0.00780230388835 |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.482887700535 | 0.00992349831376 |                {'C': 1.0, 'gamma': 10.0}                 |        39       |
|  0.484907902555 | 0.00900433124482 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.484848484848 | 0.0065278777965  |               {'C': 1.0, 'gamma': 1000.0}                |        32       |
|  0.484907902555 | 0.00900433124482 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.484907902555 | 0.00900433124482 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.484867498515 | 0.00649996153155 |                {'C': 10.0, 'gamma': 0.01}                |        28       |
|  0.484907902555 | 0.00900433124482 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.47880768469  | 0.0187389741729  |                {'C': 10.0, 'gamma': 1.0}                 |        42       |
|  0.412091503268 | 0.0742952407576  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.446645375322 |  0.043175080325  |               {'C': 10.0, 'gamma': 100.0}                |        52       |
|  0.480808080808 | 0.0135466296962  |               {'C': 10.0, 'gamma': 1000.0}               |        40       |
|  0.484907902555 | 0.00900433124482 |              {'C': 10.0, 'gamma': 10000.0}               |        1        |
|  0.484907902555 | 0.00900433124482 |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.484887288249 | 0.00780230388835 |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.472786690434 |  0.020619046646  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        47       |
|  0.428129332541 | 0.0312165142102  |                {'C': 100.0, 'gamma': 1.0}                |        56       |
|  0.38205504424  | 0.0507963426006  |               {'C': 100.0, 'gamma': 10.0}                |        61       |
|  0.450641216082 | 0.0323375695956  |               {'C': 100.0, 'gamma': 100.0}               |        51       |
|  0.476824618736 | 0.0171737396176  |              {'C': 100.0, 'gamma': 1000.0}               |        44       |
|  0.476746286393 | 0.0100754624806  |              {'C': 100.0, 'gamma': 10000.0}              |        45       |
|  0.484867498515 | 0.00649996153155 |              {'C': 1000.0, 'gamma': 0.001}               |        28       |
|  0.478787878788 | 0.0120660342074  |               {'C': 1000.0, 'gamma': 0.01}               |        43       |
|  0.430399683106 |  0.05007274765   |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        55       |
|  0.398195286195 | 0.0588939105901  |               {'C': 1000.0, 'gamma': 1.0}                |        59       |
|  0.390022776787 | 0.0454070171106  |               {'C': 1000.0, 'gamma': 10.0}               |        60       |
|  0.440398381575 | 0.0322446046341  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|  0.460705090117 | 0.0207369475332  |              {'C': 1000.0, 'gamma': 1000.0}              |        49       |
|  0.478886116063 | 0.0172120380616  |             {'C': 1000.0, 'gamma': 10000.0}              |        41       |
|  0.472727272727 | 0.0251517700897  |              {'C': 10000.0, 'gamma': 0.001}              |        48       |
|  0.410101010101 | 0.0451974708367  |              {'C': 10000.0, 'gamma': 0.01}               |        58       |
|  0.369989106754 | 0.0462107307423  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.345256486433 | 0.0690284933051  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.373737373737 | 0.0566418781452  |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.434437512379 | 0.0426296308171  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.456778570014 | 0.0456642773462  |             {'C': 10000.0, 'gamma': 1000.0}              |        50       |
|  0.474846504258 |  0.018061971083  |             {'C': 10000.0, 'gamma': 10000.0}             |        46       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.23513929208  | 0.00752132799119 |               {'C': 0.001, 'gamma': 0.001}               |        48       |
|  0.23513929208  | 0.00752132799119 |               {'C': 0.001, 'gamma': 0.01}                |        48       |
|  0.23513929208  | 0.00752132799119 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        48       |
|  0.235198677774 | 0.00872720355866 |                {'C': 0.001, 'gamma': 1.0}                |        25       |
|  0.235198677774 | 0.00872720355866 |               {'C': 0.001, 'gamma': 10.0}                |        25       |
|  0.23513929208  | 0.00752132799119 |               {'C': 0.001, 'gamma': 100.0}               |        48       |
|  0.235198677774 | 0.00872720355866 |              {'C': 0.001, 'gamma': 1000.0}               |        25       |
|  0.235198677774 | 0.00872720355866 |              {'C': 0.001, 'gamma': 10000.0}              |        25       |
|  0.235158484084 | 0.00752133088158 |               {'C': 0.01, 'gamma': 0.001}                |        43       |
|  0.235198677774 | 0.00872720355866 |                {'C': 0.01, 'gamma': 0.01}                |        25       |
|  0.235198677774 | 0.00872720355866 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        25       |
|  0.235198677774 | 0.00872720355866 |                {'C': 0.01, 'gamma': 1.0}                 |        25       |
|  0.235198677774 | 0.00872720355866 |                {'C': 0.01, 'gamma': 10.0}                |        25       |
|  0.235120666448 | 0.00629012974162 |               {'C': 0.01, 'gamma': 100.0}                |        53       |
|  0.235120666448 | 0.00629012974162 |               {'C': 0.01, 'gamma': 1000.0}               |        53       |
|  0.235158484084 | 0.00752133088158 |              {'C': 0.01, 'gamma': 10000.0}               |        43       |
|  0.235120666448 | 0.00629012974162 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        53       |
|  0.235198677774 | 0.00872720355866 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        25       |
|  0.235198677774 | 0.00872720355866 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        25       |
|  0.235198677774 | 0.00872720355866 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        25       |
|  0.23513929208  | 0.00752132799119 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        48       |
|  0.235198677774 | 0.00872720355866 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        25       |
|  0.235198677774 | 0.00872720355866 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        25       |
|  0.235198677774 | 0.00872720355866 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        25       |
|  0.235120666448 | 0.00629012974162 |                {'C': 1.0, 'gamma': 0.001}                |        53       |
|  0.235158484084 | 0.00752133088158 |                {'C': 1.0, 'gamma': 0.01}                 |        43       |
|  0.235198677774 | 0.00872720355866 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.235120666448 | 0.00629012974162 |                 {'C': 1.0, 'gamma': 1.0}                 |        53       |
|  0.235120666448 | 0.00629012974162 |                {'C': 1.0, 'gamma': 10.0}                 |        53       |
|  0.235139648102 | 0.00796706722044 |                {'C': 1.0, 'gamma': 100.0}                |        47       |
|  0.235120666448 | 0.00629012974162 |               {'C': 1.0, 'gamma': 1000.0}                |        53       |
|  0.235198677774 | 0.00872720355866 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|  0.235158484084 | 0.00752133088158 |               {'C': 10.0, 'gamma': 0.001}                |        43       |
|  0.235198677774 | 0.00872720355866 |                {'C': 10.0, 'gamma': 0.01}                |        25       |
|  0.235198677774 | 0.00872720355866 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.271928209582 | 0.0776399347061  |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.379184868215 | 0.0764924024012  |                {'C': 10.0, 'gamma': 10.0}                |        1        |
|  0.279099960267 | 0.0668893201587  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.264352138792 | 0.0627431775348  |               {'C': 10.0, 'gamma': 1000.0}               |        17       |
|  0.234620985962 | 0.00920209613892 |              {'C': 10.0, 'gamma': 10000.0}               |        63       |
|  0.235120666448 | 0.00629012974162 |               {'C': 100.0, 'gamma': 0.001}               |        53       |
|  0.235120666448 | 0.00629012974162 |               {'C': 100.0, 'gamma': 0.01}                |        53       |
|  0.231055931334 | 0.00905294402331 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        64       |
|  0.353812158711 | 0.0986842981804  |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.332452406694 | 0.0677993593101  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.333085419834 | 0.0663875184353  |               {'C': 100.0, 'gamma': 100.0}               |        10       |
|  0.29059201037  |  0.102744434852  |              {'C': 100.0, 'gamma': 1000.0}               |        14       |
|  0.249616986188 | 0.0604190812472  |              {'C': 100.0, 'gamma': 10000.0}              |        21       |
|  0.235120666448 | 0.00629012974162 |              {'C': 1000.0, 'gamma': 0.001}               |        53       |
|  0.259649282862 | 0.0629876836151  |               {'C': 1000.0, 'gamma': 0.01}               |        18       |
|  0.32230687679  | 0.0933677564947  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.334583468079 | 0.0658491813611  |               {'C': 1000.0, 'gamma': 1.0}                |        8        |
|  0.362912718927 | 0.0685734865921  |               {'C': 1000.0, 'gamma': 10.0}               |        4        |
|  0.337586844174 | 0.0759265877618  |              {'C': 1000.0, 'gamma': 100.0}               |        7        |
|  0.244340163298 | 0.0376378961971  |              {'C': 1000.0, 'gamma': 1000.0}              |        22       |
|  0.250202560075 |  0.059895725585  |             {'C': 1000.0, 'gamma': 10000.0}              |        20       |
|  0.241398333336 | 0.0301666903863  |              {'C': 10000.0, 'gamma': 0.001}              |        24       |
|  0.329180217971 | 0.0734496980997  |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.357971420116 | 0.0791823334842  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.366447624633 | 0.0509995857278  |               {'C': 10000.0, 'gamma': 1.0}               |        3        |
|  0.371768942413 | 0.0673170793989  |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.333988968765 | 0.0540681239643  |              {'C': 10000.0, 'gamma': 100.0}              |        9        |
|  0.258651294648 | 0.0436381140544  |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
|  0.241705674146 | 0.0312639404933  |             {'C': 10000.0, 'gamma': 10000.0}             |        23       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.12      0.08      0.10        13
          1       0.46      0.63      0.53        27
          2       0.38      0.30      0.33        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.33      0.39      0.35        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.484848484848 | 0.00900158623091 |               {'C': 0.001, 'gamma': 0.001}               |        24       |
|  0.484848484848 | 0.0078255236628  |               {'C': 0.001, 'gamma': 0.01}                |        24       |
|  0.484848484848 | 0.0078255236628  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        24       |
|  0.484869099155 | 0.00902454739074 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.484869099155 | 0.00902454739074 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.484869099155 | 0.00902454739074 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.484848484848 | 0.00900158623091 |              {'C': 0.001, 'gamma': 1000.0}               |        24       |
|  0.484869099155 | 0.00902454739074 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.484869099155 | 0.00902454739074 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.484828695114 | 0.00652769781199 |                {'C': 0.01, 'gamma': 0.01}                |        33       |
|  0.484848484848 | 0.0078255236628  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        24       |
|  0.484848484848 | 0.0078255236628  |                {'C': 0.01, 'gamma': 1.0}                 |        24       |
|  0.484869099155 | 0.00902454739074 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.484869099155 | 0.00902454739074 |               {'C': 0.01, 'gamma': 100.0}                |        1        |
|  0.484869099155 | 0.00902454739074 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.484869099155 | 0.00902454739074 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.484869099155 | 0.00902454739074 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.484869099155 | 0.00902454739074 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.484869099155 | 0.00902454739074 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.484869099155 | 0.00902454739074 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.484869099155 | 0.00902454739074 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.484828695114 | 0.00652769781199 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        33       |
|  0.484848484848 | 0.00900158623091 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        24       |
|  0.484848484848 | 0.00900158623091 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        24       |
|  0.484869099155 | 0.00902454739074 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.484869099155 | 0.00902454739074 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.484869099155 | 0.00902454739074 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.484869099155 | 0.00902454739074 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.482848897135 | 0.0132164103964  |                {'C': 1.0, 'gamma': 10.0}                 |        38       |
|  0.482890125747 | 0.00992034494602 |                {'C': 1.0, 'gamma': 100.0}                |        37       |
|  0.484869099155 | 0.00902454739074 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.484828695114 | 0.00652769781199 |               {'C': 1.0, 'gamma': 10000.0}               |        33       |
|  0.484869099155 | 0.00902454739074 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.484869099155 | 0.00902454739074 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.484869099155 | 0.00902454739074 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.476746203532 | 0.0203076173245  |                {'C': 10.0, 'gamma': 1.0}                 |        41       |
|  0.430344258916 | 0.0295332682848  |                {'C': 10.0, 'gamma': 10.0}                |        55       |
|  0.444650587508 | 0.0524422115869  |               {'C': 10.0, 'gamma': 100.0}                |        52       |
|  0.480747062461 | 0.0137197047574  |               {'C': 10.0, 'gamma': 1000.0}               |        39       |
|  0.478808493094 | 0.0188692872929  |              {'C': 10.0, 'gamma': 10000.0}               |        40       |
|  0.484828695114 | 0.00652769781199 |               {'C': 100.0, 'gamma': 0.001}               |        33       |
|  0.484869099155 | 0.00902454739074 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.468663677592 | 0.0178756998484  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        47       |
|  0.412121212121 |  0.04682328518   |                {'C': 100.0, 'gamma': 1.0}                |        59       |
|  0.394080258366 | 0.0419475426177  |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.450442348657 | 0.0333872644303  |               {'C': 100.0, 'gamma': 100.0}               |        51       |
|  0.474686456401 | 0.0219649993345  |              {'C': 100.0, 'gamma': 1000.0}               |        44       |
|  0.474747474747 | 0.0215581767963  |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.484848484848 | 0.0078255236628  |              {'C': 1000.0, 'gamma': 0.001}               |        24       |
|  0.466728509586 | 0.0194602083234  |               {'C': 1000.0, 'gamma': 0.01}               |        48       |
|  0.426195629767 | 0.0515429324749  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        57       |
|  0.361682951969 | 0.0803078425877  |               {'C': 1000.0, 'gamma': 1.0}                |        62       |
|  0.422289012575 |  0.039853121151  |               {'C': 1000.0, 'gamma': 10.0}               |        58       |
|  0.43650876108  | 0.0502038151804  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|  0.454586683158 |  0.021622602688  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.472870713942 | 0.0250752151411  |             {'C': 1000.0, 'gamma': 10000.0}              |        45       |
|  0.470789527932 | 0.0240896601968  |              {'C': 10000.0, 'gamma': 0.001}              |        46       |
|  0.43048855906  | 0.0368908449541  |              {'C': 10000.0, 'gamma': 0.01}               |        54       |
|  0.361657390229 | 0.0503987807159  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.335075242218 | 0.0516569907505  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.392026386312 | 0.0582436286118  |              {'C': 10000.0, 'gamma': 10.0}               |        61       |
|  0.430303030303 |  0.069375589282  |              {'C': 10000.0, 'gamma': 100.0}              |        56       |
|  0.45670995671  | 0.0258534962008  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.474766371195 | 0.0144583350512  |             {'C': 10000.0, 'gamma': 10000.0}             |        42       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.484848484848 | 0.0078255236628  |               {'C': 0.001, 'gamma': 0.001}               |        28       |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.484848484848 | 0.0065278777965  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        28       |
|  0.484888888889 | 0.00902458897894 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.484848484848 | 0.0065278777965  |               {'C': 0.001, 'gamma': 100.0}               |        28       |
|  0.484888888889 | 0.00902458897894 |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.484888888889 | 0.00902458897894 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.484848484848 | 0.0065278777965  |                {'C': 0.01, 'gamma': 0.01}                |        28       |
|  0.484848484848 | 0.0065278777965  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        28       |
|  0.484868274583 | 0.0078256237535  |                {'C': 0.01, 'gamma': 1.0}                 |        23       |
|  0.484888888889 | 0.00902458897894 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.484868274583 | 0.0078256237535  |               {'C': 0.01, 'gamma': 100.0}                |        23       |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.484888888889 | 0.00902458897894 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.484888888889 | 0.00902458897894 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.484888888889 | 0.00902458897894 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        1        |
|  0.484888888889 | 0.00902458897894 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.484848484848 | 0.0065278777965  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        28       |
|  0.484848484848 | 0.0065278777965  |                {'C': 1.0, 'gamma': 0.001}                |        28       |
|  0.484848484848 | 0.0078255236628  |                {'C': 1.0, 'gamma': 0.01}                 |        28       |
|  0.484848484848 | 0.0078255236628  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        28       |
|  0.484868274583 | 0.0078256237535  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.484888888889 | 0.00902458897894 |                {'C': 1.0, 'gamma': 10.0}                 |        1        |
|  0.480848484848 | 0.0103885900526  |                {'C': 1.0, 'gamma': 100.0}                |        39       |
|  0.484868274583 | 0.0078256237535  |               {'C': 1.0, 'gamma': 1000.0}                |        23       |
|  0.484888888889 | 0.00902458897894 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.484868274583 | 0.0078256237535  |               {'C': 10.0, 'gamma': 0.001}                |        23       |
|  0.484848484848 | 0.0078255236628  |                {'C': 10.0, 'gamma': 0.01}                |        28       |
|  0.484888888889 | 0.00902458897894 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.466663299663 | 0.0172482697095  |                {'C': 10.0, 'gamma': 1.0}                 |        49       |
|  0.432358585859 | 0.0431013452111  |                {'C': 10.0, 'gamma': 10.0}                |        54       |
|  0.440404040404 | 0.0436067581412  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.480808080808 | 0.0158841547138  |               {'C': 10.0, 'gamma': 1000.0}               |        40       |
|  0.482909090909 | 0.0116823623675  |              {'C': 10.0, 'gamma': 10000.0}               |        38       |
|  0.484888888889 | 0.00902458897894 |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.484888888889 | 0.00902458897894 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.472767676768 | 0.0186831309033  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        45       |
|  0.438420875421 | 0.0359302617492  |                {'C': 100.0, 'gamma': 1.0}                |        52       |
|  0.406052188552 | 0.0793795877389  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.43838047138  | 0.0436192492117  |               {'C': 100.0, 'gamma': 100.0}               |        53       |
|  0.474747474747 | 0.0200109557752  |              {'C': 100.0, 'gamma': 1000.0}               |        44       |
|  0.47482996633  | 0.0214787728702  |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.484888888889 | 0.00902458897894 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.466703703704 | 0.0207818600304  |               {'C': 1000.0, 'gamma': 0.01}               |        48       |
|  0.414321170893 | 0.0407845819374  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        57       |
|  0.357607744108 | 0.0420265883125  |               {'C': 1000.0, 'gamma': 1.0}                |        61       |
|  0.355503367003 | 0.0315329072383  |               {'C': 1000.0, 'gamma': 10.0}               |        62       |
|  0.420279461279 | 0.0380675089356  |              {'C': 1000.0, 'gamma': 100.0}               |        56       |
|  0.470745791246 |  0.025662692358  |              {'C': 1000.0, 'gamma': 1000.0}              |        47       |
|  0.476808080808 | 0.0133320164514  |             {'C': 1000.0, 'gamma': 10000.0}              |        42       |
|  0.472705833849 | 0.0211537949541  |              {'C': 10000.0, 'gamma': 0.001}              |        46       |
|  0.422372053872 | 0.0644907534676  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.365730639731 | 0.0492429125801  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        60       |
|  0.337574074074 | 0.0818804247482  |               {'C': 10000.0, 'gamma': 1.0}               |        63       |
|  0.333333333333 | 0.0408595169242  |              {'C': 10000.0, 'gamma': 10.0}               |        64       |
|  0.412033670034 | 0.0491294955899  |              {'C': 10000.0, 'gamma': 100.0}              |        58       |
|  0.462582491582 | 0.0277976515459  |             {'C': 10000.0, 'gamma': 1000.0}              |        50       |
|  0.480806397306 | 0.00836957040508 |             {'C': 10000.0, 'gamma': 10000.0}             |        41       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.23513929208  | 0.00752132799119 |               {'C': 0.001, 'gamma': 0.001}               |        54       |
|  0.235198677774 | 0.00872720355866 |               {'C': 0.001, 'gamma': 0.01}                |        26       |
|  0.235198677774 | 0.00872720355866 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        26       |
|  0.235198677774 | 0.00872720355866 |                {'C': 0.001, 'gamma': 1.0}                |        26       |
|  0.235198677774 | 0.00872720355866 |               {'C': 0.001, 'gamma': 10.0}                |        26       |
|  0.235198677774 | 0.00872720355866 |               {'C': 0.001, 'gamma': 100.0}               |        26       |
|  0.235198677774 | 0.00872720355866 |              {'C': 0.001, 'gamma': 1000.0}               |        26       |
|  0.235158484084 | 0.00752133088158 |              {'C': 0.001, 'gamma': 10000.0}              |        49       |
|  0.235158484084 | 0.00752133088158 |               {'C': 0.01, 'gamma': 0.001}                |        49       |
|  0.235198677774 | 0.00872720355866 |                {'C': 0.01, 'gamma': 0.01}                |        26       |
|  0.235198677774 | 0.00872720355866 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        26       |
|  0.235198677774 | 0.00872720355866 |                {'C': 0.01, 'gamma': 1.0}                 |        26       |
|  0.235120666448 | 0.00629012974162 |                {'C': 0.01, 'gamma': 10.0}                |        58       |
|  0.235158484084 | 0.00752133088158 |               {'C': 0.01, 'gamma': 100.0}                |        49       |
|  0.235198677774 | 0.00872720355866 |               {'C': 0.01, 'gamma': 1000.0}               |        26       |
|  0.235158484084 | 0.00752133088158 |              {'C': 0.01, 'gamma': 10000.0}               |        49       |
|  0.235120666448 | 0.00629012974162 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        58       |
|  0.235198677774 | 0.00872720355866 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        26       |
|  0.235198677774 | 0.00872720355866 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        26       |
|  0.235198677774 | 0.00872720355866 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        26       |
|  0.235120666448 | 0.00629012974162 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        58       |
|  0.235158484084 | 0.00752133088158 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        49       |
|  0.235198677774 | 0.00872720355866 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        26       |
|  0.23513929208  | 0.00752132799119 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        54       |
|  0.235198677774 | 0.00872720355866 |                {'C': 1.0, 'gamma': 0.001}                |        26       |
|  0.235198677774 | 0.00872720355866 |                {'C': 1.0, 'gamma': 0.01}                 |        26       |
|  0.235120666448 | 0.00629012974162 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        58       |
|  0.23513929208  | 0.00752132799119 |                 {'C': 1.0, 'gamma': 1.0}                 |        54       |
|  0.235120666448 | 0.00629012974162 |                {'C': 1.0, 'gamma': 10.0}                 |        58       |
|  0.235693421126 | 0.0091128444784  |                {'C': 1.0, 'gamma': 100.0}                |        25       |
|  0.235198677774 | 0.00872720355866 |               {'C': 1.0, 'gamma': 1000.0}                |        26       |
|  0.235198677774 | 0.00872720355866 |               {'C': 1.0, 'gamma': 10000.0}               |        26       |
|  0.235198677774 | 0.00872720355866 |               {'C': 10.0, 'gamma': 0.001}                |        26       |
|  0.235198677774 | 0.00872720355866 |                {'C': 10.0, 'gamma': 0.01}                |        26       |
|  0.235198677774 | 0.00872720355866 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.262043527032 | 0.0699468073804  |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.331164632456 | 0.0770381182938  |                {'C': 10.0, 'gamma': 10.0}                |        10       |
|  0.351747697724 |  0.111213599462  |               {'C': 10.0, 'gamma': 100.0}                |        4        |
|  0.252749018158 | 0.0587206953127  |               {'C': 10.0, 'gamma': 1000.0}               |        19       |
|  0.23468530879  | 0.0096214038338  |              {'C': 10.0, 'gamma': 10000.0}               |        63       |
|  0.235198677774 | 0.00872720355866 |               {'C': 100.0, 'gamma': 0.001}               |        26       |
|  0.23513929208  | 0.00752132799119 |               {'C': 100.0, 'gamma': 0.01}                |        54       |
|  0.230486087542 | 0.00974408162218 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        64       |
|  0.346702568134 | 0.0729473374421  |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.366098857807 | 0.0486788029092  |               {'C': 100.0, 'gamma': 10.0}                |        1        |
|  0.321031555065 | 0.0877895707374  |               {'C': 100.0, 'gamma': 100.0}               |        12       |
|  0.256522446398 | 0.0697688337306  |              {'C': 100.0, 'gamma': 1000.0}               |        18       |
|  0.251171844759 | 0.0592247680463  |              {'C': 100.0, 'gamma': 10000.0}              |        21       |
|  0.235198677774 | 0.00872720355866 |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.24170766282  |  0.031563296712  |               {'C': 1000.0, 'gamma': 0.01}               |        24       |
|  0.336499180148 | 0.0933484519749  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.331224440815 | 0.0664335095518  |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.338131530608 | 0.0472742899547  |               {'C': 1000.0, 'gamma': 10.0}               |        7        |
|  0.288106701108 | 0.0590798626145  |              {'C': 1000.0, 'gamma': 100.0}               |        14       |
|  0.251919112971 | 0.0400566617889  |              {'C': 1000.0, 'gamma': 1000.0}              |        20       |
|  0.243250922548 | 0.0308496785717  |             {'C': 1000.0, 'gamma': 10000.0}              |        22       |
|  0.262065550205 |  0.066849639873  |              {'C': 10000.0, 'gamma': 0.001}              |        16       |
|  0.325989405689 | 0.0735550512817  |              {'C': 10000.0, 'gamma': 0.01}               |        11       |
|  0.363824262055 | 0.0669913212968  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.353733049763 | 0.0603024467559  |               {'C': 10000.0, 'gamma': 1.0}               |        3        |
|  0.347760297178 | 0.0638495369106  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.303982092607 | 0.0600872012723  |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
|  0.276034739518 | 0.0726362321656  |             {'C': 10000.0, 'gamma': 1000.0}              |        15       |
|  0.242187161885 | 0.0309746296622  |             {'C': 10000.0, 'gamma': 10000.0}             |        23       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.11      0.08      0.09        13
          1       0.47      0.59      0.52        27
          2       0.22      0.20      0.21        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.30      0.35      0.32        54

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.484848484848 | 0.0078255236628  |               {'C': 0.001, 'gamma': 0.001}               |        26       |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.484848484848 | 0.0065278777965  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        26       |
|  0.484848484848 | 0.0065278777965  |                {'C': 0.001, 'gamma': 1.0}                |        26       |
|  0.484848484848 | 0.0065278777965  |               {'C': 0.001, 'gamma': 10.0}                |        26       |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.484848484848 | 0.0078255236628  |              {'C': 0.001, 'gamma': 1000.0}               |        26       |
|  0.484888888889 | 0.00902458897894 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.484888888889 | 0.00902458897894 |                {'C': 0.01, 'gamma': 0.01}                |        1        |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.484868274583 | 0.0078256237535  |                {'C': 0.01, 'gamma': 1.0}                 |        23       |
|  0.484848484848 | 0.0065278777965  |                {'C': 0.01, 'gamma': 10.0}                |        26       |
|  0.484848484848 | 0.0065278777965  |               {'C': 0.01, 'gamma': 100.0}                |        26       |
|  0.484888888889 | 0.00902458897894 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.484888888889 | 0.00902458897894 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.484848484848 | 0.0065278777965  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        26       |
|  0.484848484848 | 0.0065278777965  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        26       |
|  0.484888888889 | 0.00902458897894 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.484868274583 | 0.0078256237535  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        23       |
|  0.484888888889 | 0.00902458897894 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        1        |
|  0.484848484848 | 0.0065278777965  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        26       |
|  0.484888888889 | 0.00902458897894 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.484888888889 | 0.00902458897894 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.484888888889 | 0.00902458897894 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.484848484848 | 0.0078255236628  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.484888888889 | 0.00902458897894 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.484868274583 | 0.0078256237535  |                {'C': 1.0, 'gamma': 10.0}                 |        23       |
|  0.480888888889 | 0.0120747431216  |                {'C': 1.0, 'gamma': 100.0}                |        38       |
|  0.484888888889 | 0.00902458897894 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.484888888889 | 0.00902458897894 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.484888888889 | 0.00902458897894 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.484888888889 | 0.00902458897894 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.484888888889 | 0.00902458897894 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.474787878788 | 0.0141834002856  |                {'C': 10.0, 'gamma': 1.0}                 |        44       |
|  0.418132996633 |  0.069064123227  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.430321170893 | 0.0436902973847  |               {'C': 10.0, 'gamma': 100.0}                |        53       |
|  0.480808080808 | 0.0150074925049  |               {'C': 10.0, 'gamma': 1000.0}               |        39       |
|  0.478828282828 | 0.0163473797839  |              {'C': 10.0, 'gamma': 10000.0}               |        40       |
|  0.484848484848 | 0.0065278777965  |               {'C': 100.0, 'gamma': 0.001}               |        26       |
|  0.484888888889 | 0.00902458897894 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.474767264482 |  0.017233928125  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        45       |
|  0.420195286195 | 0.0250121953009  |                {'C': 100.0, 'gamma': 1.0}                |        56       |
|  0.393927609428 | 0.0545591994121  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.434173400673 | 0.0586940483766  |               {'C': 100.0, 'gamma': 100.0}               |        51       |
|  0.474828282828 | 0.0267975834035  |              {'C': 100.0, 'gamma': 1000.0}               |        43       |
|  0.476705833849 | 0.0165512620655  |              {'C': 100.0, 'gamma': 10000.0}              |        42       |
|  0.484888888889 | 0.00902458897894 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.474745791246 |  0.011136907166  |               {'C': 1000.0, 'gamma': 0.01}               |        46       |
|  0.432242424242 | 0.0266499192839  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        52       |
|  0.351324675325 | 0.0462549746033  |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.370183501684 | 0.0763634264434  |               {'C': 1000.0, 'gamma': 10.0}               |        60       |
|  0.422222222222 | 0.0415798040427  |              {'C': 1000.0, 'gamma': 100.0}               |        54       |
|  0.460644781145 | 0.0214544310025  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.476808080808 | 0.0204608676562  |             {'C': 1000.0, 'gamma': 10000.0}              |        41       |
|  0.474745791246 | 0.00669381002034 |              {'C': 10000.0, 'gamma': 0.001}              |        46       |
|  0.420281144781 | 0.0459758538318  |              {'C': 10000.0, 'gamma': 0.01}               |        55       |
|  0.359501683502 | 0.0671200842858  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        62       |
|  0.359450010307 |  0.072516619903  |               {'C': 10000.0, 'gamma': 1.0}               |        63       |
|  0.369437710438 |  0.04531128099   |              {'C': 10000.0, 'gamma': 10.0}               |        61       |
|  0.411932385075 | 0.0448164524165  |              {'C': 10000.0, 'gamma': 100.0}              |        58       |
|  0.470787878788 |  0.025029235826  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.472767676768 | 0.0216506743941  |             {'C': 10000.0, 'gamma': 10000.0}             |        48       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.50      1.00      0.67        27
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.50      0.33        54

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00648222292375 |               {'C': 0.001, 'gamma': 0.001}               |        28       |
|  0.485925868486 | 0.0078082531897  |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.485925868486 | 0.0078082531897  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        1        |
|  0.485885545906 | 0.00472236351412 |                {'C': 0.001, 'gamma': 1.0}                |        34       |
|  0.485925868486 | 0.0078082531897  |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.485925868486 | 0.0078082531897  |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.485925868486 | 0.0078082531897  |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.485925868486 | 0.0078082531897  |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.485887096774 | 0.00648222292375 |               {'C': 0.01, 'gamma': 0.001}                |        28       |
|  0.485905295741 | 0.00639135338926 |                {'C': 0.01, 'gamma': 0.01}                |        21       |
|  0.485925868486 | 0.0078082531897  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.485925868486 | 0.0078082531897  |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.485925868486 | 0.0078082531897  |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.485887096774 | 0.00648222292375 |               {'C': 0.01, 'gamma': 100.0}                |        28       |
|  0.485905295741 | 0.00639135338926 |               {'C': 0.01, 'gamma': 1000.0}               |        21       |
|  0.485925868486 | 0.0078082531897  |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.485925868486 | 0.0078082531897  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.485905295741 | 0.00639135338926 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        21       |
|  0.485925868486 | 0.0078082531897  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.485925868486 | 0.0078082531897  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.485887096774 | 0.00648222292375 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        28       |
|  0.485885545906 | 0.00472236351412 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        34       |
|  0.485925868486 | 0.0078082531897  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.485925868486 | 0.0078082531897  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.485887096774 | 0.00648222292375 |                {'C': 1.0, 'gamma': 0.001}                |        28       |
|  0.485925868486 | 0.0078082531897  |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.485905295741 | 0.00639135338926 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.485905295741 | 0.00639135338926 |                 {'C': 1.0, 'gamma': 1.0}                 |        21       |
|  0.483889166709 | 0.0100458388845  |                {'C': 1.0, 'gamma': 10.0}                 |        39       |
|  0.483909739454 | 0.00907989494495 |                {'C': 1.0, 'gamma': 100.0}                |        38       |
|  0.485905295741 | 0.00639135338926 |               {'C': 1.0, 'gamma': 1000.0}                |        21       |
|  0.485885545906 | 0.00472236351412 |               {'C': 1.0, 'gamma': 10000.0}               |        34       |
|  0.485887096774 | 0.00648222292375 |               {'C': 10.0, 'gamma': 0.001}                |        28       |
|  0.485885545906 | 0.00472236351412 |                {'C': 10.0, 'gamma': 0.01}                |        34       |
|  0.485925868486 | 0.0078082531897  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.479916253102 |  0.014497936451  |                {'C': 10.0, 'gamma': 1.0}                 |        40       |
|  0.435710039289 | 0.0437985458801  |                {'C': 10.0, 'gamma': 10.0}                |        52       |
|  0.441684113937 | 0.0375945237618  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.479838709677 | 0.0273778980097  |               {'C': 10.0, 'gamma': 1000.0}               |        42       |
|  0.485905295741 | 0.00639135338926 |              {'C': 10.0, 'gamma': 10000.0}               |        21       |
|  0.485925868486 | 0.0078082531897  |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.485925868486 | 0.0078082531897  |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.475845223325 |  0.019302884961  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        46       |
|  0.419518629412 | 0.0498248812471  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.384906172457 | 0.0418138914463  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.43365836952  | 0.0284887655978  |               {'C': 100.0, 'gamma': 100.0}               |        53       |
|  0.473903406741 | 0.0245843002544  |              {'C': 100.0, 'gamma': 1000.0}               |        47       |
|  0.469815035195 | 0.0283033635413  |              {'C': 100.0, 'gamma': 10000.0}              |        48       |
|  0.485925868486 | 0.0078082531897  |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.479835478701 | 0.0116506896301  |               {'C': 1000.0, 'gamma': 0.01}               |        43       |
|  0.423364479942 | 0.0523688921791  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        57       |
|  0.344486662531 | 0.0602128870161  |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.377097628754 | 0.0556233300096  |               {'C': 1000.0, 'gamma': 10.0}               |        60       |
|  0.425530618575 | 0.0608150476001  |              {'C': 1000.0, 'gamma': 100.0}               |        55       |
|  0.465603287841 | 0.0187703174286  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.479916253102 | 0.0181977444557  |             {'C': 1000.0, 'gamma': 10000.0}              |        40       |
|  0.477838405834 |  0.013668989504  |              {'C': 10000.0, 'gamma': 0.001}              |        45       |
|  0.42535825062  | 0.0449307293243  |              {'C': 10000.0, 'gamma': 0.01}               |        56       |
|  0.357074545079 | 0.0649385460475  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        61       |
|  0.338858560794 | 0.0532247505432  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.34481945306  | 0.0406936137647  |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.427414702233 | 0.0544911090298  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.467760134451 | 0.0249316887852  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.479776991442 | 0.0154230602539  |             {'C': 10000.0, 'gamma': 10000.0}             |        44       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.23614689238  | 0.00755096587865 |               {'C': 0.001, 'gamma': 0.001}               |        51       |
|  0.23614689238  | 0.00755096587865 |               {'C': 0.001, 'gamma': 0.01}                |        51       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        26       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.001, 'gamma': 1.0}                |        26       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.001, 'gamma': 10.0}                |        26       |
|  0.236127142544 | 0.00615619455406 |               {'C': 0.001, 'gamma': 100.0}               |        57       |
|  0.236089401154 | 0.00458273377759 |              {'C': 0.001, 'gamma': 1000.0}               |        59       |
|  0.236167255199 | 0.00757464085505 |              {'C': 0.001, 'gamma': 10000.0}              |        26       |
|  0.236089401154 | 0.00458273377759 |               {'C': 0.01, 'gamma': 0.001}                |        59       |
|  0.236089401154 | 0.00458273377759 |                {'C': 0.01, 'gamma': 0.01}                |        59       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        26       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.01, 'gamma': 1.0}                 |        26       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.01, 'gamma': 10.0}                |        26       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.01, 'gamma': 100.0}                |        26       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.01, 'gamma': 1000.0}               |        26       |
|  0.236167255199 | 0.00757464085505 |              {'C': 0.01, 'gamma': 10000.0}               |        26       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        26       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        26       |
|  0.236167255199 | 0.00757464085505 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        26       |
|  0.236167255199 | 0.00757464085505 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        26       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        26       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        26       |
|  0.236167255199 | 0.00757464085505 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        26       |
|  0.236167255199 | 0.00757464085505 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        26       |
|  0.236167255199 | 0.00757464085505 |                {'C': 1.0, 'gamma': 0.001}                |        26       |
|  0.236127142544 | 0.00615619455406 |                {'C': 1.0, 'gamma': 0.01}                 |        57       |
|  0.236129080658 | 0.00624343257476 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        54       |
|  0.236167255199 | 0.00757464085505 |                 {'C': 1.0, 'gamma': 1.0}                 |        26       |
|  0.236089401154 | 0.00458273377759 |                {'C': 1.0, 'gamma': 10.0}                 |        59       |
|  0.235625094951 | 0.00944869297357 |                {'C': 1.0, 'gamma': 100.0}                |        64       |
|  0.236129080658 | 0.00624343257476 |               {'C': 1.0, 'gamma': 1000.0}                |        54       |
|  0.23614689238  | 0.00755096587865 |               {'C': 1.0, 'gamma': 10000.0}               |        51       |
|  0.236167255199 | 0.00757464085505 |               {'C': 10.0, 'gamma': 0.001}                |        26       |
|  0.236167255199 | 0.00757464085505 |                {'C': 10.0, 'gamma': 0.01}                |        26       |
|  0.236167255199 | 0.00757464085505 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.283416683514 | 0.0765513805078  |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.362247407861 | 0.0545244144659  |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.333790595417 | 0.0702593746344  |               {'C': 10.0, 'gamma': 100.0}                |        6        |
|  0.280899442475 | 0.0905253073607  |               {'C': 10.0, 'gamma': 1000.0}               |        16       |
|  0.236167255199 | 0.00757464085505 |              {'C': 10.0, 'gamma': 10000.0}               |        26       |
|  0.236129080658 | 0.00624343257476 |               {'C': 100.0, 'gamma': 0.001}               |        54       |
|  0.236089401154 | 0.00458273377759 |               {'C': 100.0, 'gamma': 0.01}                |        59       |
|  0.246992929979 | 0.0343994018363  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        23       |
|  0.301433540275 | 0.0464788604252  |                {'C': 100.0, 'gamma': 1.0}                |        14       |
|  0.329540278146 | 0.0709868985825  |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.366997384127 | 0.0984572012485  |               {'C': 100.0, 'gamma': 100.0}               |        1        |
|  0.255061435834 | 0.0462484291009  |              {'C': 100.0, 'gamma': 1000.0}               |        20       |
|  0.255221019972 | 0.0567180824169  |              {'C': 100.0, 'gamma': 10000.0}              |        19       |
|  0.236167255199 | 0.00757464085505 |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.246146531055 | 0.0340111466114  |               {'C': 1000.0, 'gamma': 0.01}               |        24       |
|  0.340647571248 |  0.122372731982  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        5        |
|  0.346525661542 | 0.0418193992863  |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.32640300227  | 0.0499938830933  |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.305644336776 |  0.057900380898  |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
|  0.263066156026 | 0.0808595038342  |              {'C': 1000.0, 'gamma': 1000.0}              |        17       |
|  0.254725289422 | 0.0607733144354  |             {'C': 1000.0, 'gamma': 10000.0}              |        21       |
|  0.252082193969 | 0.0590577413854  |              {'C': 10000.0, 'gamma': 0.001}              |        22       |
|  0.305091367275 | 0.0433126838518  |              {'C': 10000.0, 'gamma': 0.01}               |        13       |
|  0.310416617472 | 0.0641954533493  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        11       |
|  0.32240143777  | 0.0569853494937  |               {'C': 10000.0, 'gamma': 1.0}               |        9        |
|  0.316062378042 | 0.0229324840346  |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.353102242843 |  0.045186462721  |              {'C': 10000.0, 'gamma': 100.0}              |        3        |
|  0.242905652667 | 0.0242542657701  |             {'C': 10000.0, 'gamma': 1000.0}              |        25       |
|  0.25577390431  | 0.0604706349454  |             {'C': 10000.0, 'gamma': 10000.0}             |        18       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.10      0.08      0.09        13
          1       0.45      0.73      0.56        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.25      0.38      0.30        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |               {'C': 0.001, 'gamma': 0.001}               |        27       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        27       |
|  0.485867346939 | 0.00472465161339 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.485887903549 | 0.00648273424528 |               {'C': 0.001, 'gamma': 100.0}               |        23       |
|  0.485887903549 | 0.00648273424528 |              {'C': 0.001, 'gamma': 1000.0}               |        23       |
|  0.485887903549 | 0.00648273424528 |              {'C': 0.001, 'gamma': 10000.0}              |        23       |
|  0.485867346939 | 0.00472465161339 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.485887903549 | 0.00648273424528 |                {'C': 0.01, 'gamma': 0.01}                |        23       |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.485867346939 | 0.00472465161339 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 0.01, 'gamma': 100.0}                |        27       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.485907669519 | 0.00780973118882 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        27       |
|  0.485887096774 | 0.00639310039872 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        27       |
|  0.485907669519 | 0.00780973118882 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        1        |
|  0.485907669519 | 0.00780973118882 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.485907669519 | 0.00780973118882 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.485907669519 | 0.00780973118882 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.485907669519 | 0.00780973118882 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 1.0, 'gamma': 10.0}                 |        1        |
|  0.473831468071 | 0.0232608269411  |                {'C': 1.0, 'gamma': 100.0}                |        45       |
|  0.485907669519 | 0.00780973118882 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.485907669519 | 0.00780973118882 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.485907669519 | 0.00780973118882 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.485887096774 | 0.00778598536642 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        27       |
|  0.48185483871  | 0.0104596849523  |                {'C': 10.0, 'gamma': 1.0}                 |        39       |
|  0.411431760204 | 0.0403296086957  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.453587886768 | 0.0448681015132  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.479838709677 | 0.0148171229011  |               {'C': 10.0, 'gamma': 1000.0}               |        42       |
|  0.485907669519 | 0.00780973118882 |              {'C': 10.0, 'gamma': 10000.0}               |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 100.0, 'gamma': 0.001}               |        27       |
|  0.485887096774 | 0.00639310039872 |               {'C': 100.0, 'gamma': 0.01}                |        27       |
|  0.479858425225 | 0.0119112960332  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        41       |
|  0.405133071374 | 0.0702370170801  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.384767767994 | 0.0779761468266  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.445605661619 | 0.0390752175623  |               {'C': 100.0, 'gamma': 100.0}               |        52       |
|  0.471918202765 |  0.023861714311  |              {'C': 100.0, 'gamma': 1000.0}               |        47       |
|  0.473790322581 | 0.0175199813927  |              {'C': 100.0, 'gamma': 10000.0}              |        46       |
|  0.485867346939 | 0.00472465161339 |              {'C': 1000.0, 'gamma': 0.001}               |        35       |
|  0.467885087503 | 0.0219938399585  |               {'C': 1000.0, 'gamma': 0.01}               |        50       |
|  0.423612539774 | 0.0307469298441  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.352793435923 | 0.0371332714651  |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.370774872449 | 0.0668803109383  |               {'C': 1000.0, 'gamma': 10.0}               |        61       |
|  0.441573403555 | 0.0263438181999  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|  0.471836768982 | 0.0243316625917  |              {'C': 1000.0, 'gamma': 1000.0}              |        48       |
|  0.475787524687 | 0.0158513037035  |             {'C': 1000.0, 'gamma': 10000.0}              |        43       |
|  0.473852040816 | 0.0159734420765  |              {'C': 10000.0, 'gamma': 0.001}              |        44       |
|  0.439578670178 |  0.040144371766  |              {'C': 10000.0, 'gamma': 0.01}               |        54       |
|  0.381583278473 | 0.0756319620923  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        60       |
|  0.314639565504 | 0.0395096494322  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.366976629361 | 0.0350421120056  |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.439369548223 | 0.0502814375987  |              {'C': 10000.0, 'gamma': 100.0}              |        55       |
|  0.471774193548 | 0.0118471190008  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.479860105332 |  0.011789228779  |             {'C': 10000.0, 'gamma': 10000.0}             |        40       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |               {'C': 0.001, 'gamma': 0.001}               |        25       |
|  0.485887096774 | 0.00778598536642 |               {'C': 0.001, 'gamma': 0.01}                |        25       |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 0.001, 'gamma': 100.0}               |        25       |
|  0.485907669519 | 0.00780973118882 |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.485887903549 | 0.00648273424528 |              {'C': 0.001, 'gamma': 10000.0}              |        24       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.01, 'gamma': 0.01}                |        1        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        25       |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.01, 'gamma': 100.0}                |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 0.01, 'gamma': 1000.0}               |        25       |
|  0.485907669519 | 0.00780973118882 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.485907669519 | 0.00780973118882 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.485907669519 | 0.00780973118882 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        25       |
|  0.485907669519 | 0.00780973118882 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.485907669519 | 0.00780973118882 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.485887096774 | 0.00778598536642 |                {'C': 1.0, 'gamma': 0.001}                |        25       |
|  0.485907669519 | 0.00780973118882 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.485907669519 | 0.00780973118882 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.485887096774 | 0.00639310039872 |                 {'C': 1.0, 'gamma': 1.0}                 |        25       |
|  0.485887096774 | 0.00639310039872 |                {'C': 1.0, 'gamma': 10.0}                 |        25       |
|  0.485907669519 | 0.00780973118882 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.485907669519 | 0.00780973118882 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 10.0, 'gamma': 0.001}                |        25       |
|  0.485887096774 | 0.00639310039872 |                {'C': 10.0, 'gamma': 0.01}                |        25       |
|  0.485867346939 | 0.00472465161339 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        38       |
|  0.477759148014 |  0.013658008613  |                {'C': 10.0, 'gamma': 1.0}                 |        42       |
|  0.41935483871  | 0.0340122474342  |                {'C': 10.0, 'gamma': 10.0}                |        57       |
|  0.465578368444 | 0.0319204482177  |               {'C': 10.0, 'gamma': 100.0}                |        49       |
|  0.481835088874 | 0.0075280927882  |               {'C': 10.0, 'gamma': 1000.0}               |        41       |
|  0.483849537799 | 0.00645182102083 |              {'C': 10.0, 'gamma': 10000.0}               |        39       |
|  0.485887096774 | 0.00639310039872 |               {'C': 100.0, 'gamma': 0.001}               |        25       |
|  0.485907669519 | 0.00780973118882 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.469738314681 | 0.0230447231784  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        47       |
|  0.413365598255 | 0.0328128505803  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.405451696808 | 0.0605605455982  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.451673764264 | 0.0411773733574  |               {'C': 100.0, 'gamma': 100.0}               |        52       |
|  0.469675773535 |  0.018580624859  |              {'C': 100.0, 'gamma': 1000.0}               |        48       |
|  0.475806451613 | 0.0160724862407  |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.485907669519 | 0.00780973118882 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.48185483871  | 0.0177680795458  |               {'C': 1000.0, 'gamma': 0.01}               |        40       |
|  0.425362080316 | 0.0290600328347  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.345046082949 | 0.0546438431237  |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.381272972899 | 0.0492315198342  |               {'C': 1000.0, 'gamma': 10.0}               |        61       |
|  0.437850593867 | 0.0549529511223  |              {'C': 1000.0, 'gamma': 100.0}               |        54       |
|  0.461634298881 | 0.0190257445208  |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.471774193548 | 0.0190620771922  |             {'C': 1000.0, 'gamma': 10000.0}              |        46       |
|  0.473791129355 | 0.0278177020281  |              {'C': 10000.0, 'gamma': 0.001}              |        44       |
|  0.443630678078 | 0.0484205306039  |              {'C': 10000.0, 'gamma': 0.01}               |        53       |
|  0.387279357307 | 0.0710692126648  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        60       |
|  0.346786194316 |  0.050082811326  |               {'C': 10000.0, 'gamma': 1.0}               |        63       |
|  0.362874938282 | 0.0611297235858  |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.433591178407 | 0.0506451098311  |              {'C': 10000.0, 'gamma': 100.0}              |        55       |
|  0.453550775149 | 0.0192282640263  |             {'C': 10000.0, 'gamma': 1000.0}              |        51       |
|  0.471877057275 | 0.0210130734388  |             {'C': 10000.0, 'gamma': 10000.0}             |        45       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.23614689238  | 0.00755096587865 |               {'C': 0.001, 'gamma': 0.001}               |        42       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.001, 'gamma': 0.01}                |        22       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        22       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.001, 'gamma': 1.0}                |        22       |
|  0.23614689238  | 0.00755096587865 |               {'C': 0.001, 'gamma': 10.0}                |        42       |
|  0.236127142544 | 0.00615619455406 |               {'C': 0.001, 'gamma': 100.0}               |        48       |
|  0.236167255199 | 0.00757464085505 |              {'C': 0.001, 'gamma': 1000.0}               |        22       |
|  0.236167255199 | 0.00757464085505 |              {'C': 0.001, 'gamma': 10000.0}              |        22       |
|  0.236089401154 | 0.00458273377759 |               {'C': 0.01, 'gamma': 0.001}                |        55       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.01, 'gamma': 0.01}                |        22       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        22       |
|  0.236127142544 | 0.00615619455406 |                {'C': 0.01, 'gamma': 1.0}                 |        48       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.01, 'gamma': 10.0}                |        22       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.01, 'gamma': 100.0}                |        22       |
|  0.236089401154 | 0.00458273377759 |               {'C': 0.01, 'gamma': 1000.0}               |        55       |
|  0.236167255199 | 0.00757464085505 |              {'C': 0.01, 'gamma': 10000.0}               |        22       |
|  0.236089401154 | 0.00458273377759 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        55       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        22       |
|  0.236127142544 | 0.00615619455406 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        48       |
|  0.236129080658 | 0.00624343257476 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        45       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        22       |
|  0.236127142544 | 0.00615619455406 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        48       |
|  0.236127142544 | 0.00615619455406 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        48       |
|  0.236129080658 | 0.00624343257476 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        45       |
|  0.236167255199 | 0.00757464085505 |                {'C': 1.0, 'gamma': 0.001}                |        22       |
|  0.236167255199 | 0.00757464085505 |                {'C': 1.0, 'gamma': 0.01}                 |        22       |
|  0.23614689238  | 0.00755096587865 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        42       |
|  0.236167255199 | 0.00757464085505 |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.236661001084 | 0.00795519931895 |                {'C': 1.0, 'gamma': 10.0}                 |        21       |
|  0.236167255199 | 0.00757464085505 |                {'C': 1.0, 'gamma': 100.0}                |        22       |
|  0.236167255199 | 0.00757464085505 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.236129080658 | 0.00624343257476 |               {'C': 1.0, 'gamma': 10000.0}               |        45       |
|  0.236089401154 | 0.00458273377759 |               {'C': 10.0, 'gamma': 0.001}                |        55       |
|  0.236127142544 | 0.00615619455406 |                {'C': 10.0, 'gamma': 0.01}                |        48       |
|  0.236167255199 | 0.00757464085505 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.253078999616 | 0.0592258924143  |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.319717728637 | 0.0485151546941  |                {'C': 10.0, 'gamma': 10.0}                |        11       |
|  0.322631974178 | 0.0710204238578  |               {'C': 10.0, 'gamma': 100.0}                |        10       |
|  0.25522063478  |  0.056723855248  |               {'C': 10.0, 'gamma': 1000.0}               |        16       |
|  0.234561215391 | 0.0099452497513  |              {'C': 10.0, 'gamma': 10000.0}               |        59       |
|  0.236167255199 | 0.00757464085505 |               {'C': 100.0, 'gamma': 0.001}               |        22       |
|  0.236167255199 | 0.00757464085505 |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.248558866065 | 0.0346869053737  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        18       |
|  0.336572649207 | 0.0655132285278  |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.392614242717 | 0.0490385344899  |               {'C': 100.0, 'gamma': 10.0}                |        1        |
|  0.313635923357 | 0.0655882632173  |               {'C': 100.0, 'gamma': 100.0}               |        13       |
|  0.232940246647 | 0.0081851770177  |              {'C': 100.0, 'gamma': 1000.0}               |        64       |
|  0.233969193053 | 0.00703851309726 |              {'C': 100.0, 'gamma': 10000.0}              |        61       |
|  0.236127142544 | 0.00615619455406 |              {'C': 1000.0, 'gamma': 0.001}               |        48       |
|  0.233429706131 | 0.00641938270619 |               {'C': 1000.0, 'gamma': 0.01}               |        63       |
|  0.316074313254 | 0.0617926802491  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.325304108619 | 0.0440864716616  |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.348188094877 | 0.0574466879343  |               {'C': 1000.0, 'gamma': 10.0}               |        3        |
|  0.283751471252 | 0.0263885556783  |              {'C': 1000.0, 'gamma': 100.0}               |        14       |
|  0.266034377552 | 0.0662786261808  |              {'C': 1000.0, 'gamma': 1000.0}              |        15       |
|  0.233515514991 | 0.00828985948494 |             {'C': 1000.0, 'gamma': 10000.0}              |        62       |
|  0.240590145506 | 0.0222138234427  |              {'C': 10000.0, 'gamma': 0.001}              |        19       |
|  0.334240432218 | 0.0788854166636  |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|  0.343404082062 | 0.0624904571251  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.336096494886 | 0.0802072463259  |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.361554236955 | 0.0522647646058  |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.345516252544 | 0.0684965126655  |              {'C': 10000.0, 'gamma': 100.0}              |        4        |
|  0.239046322341 | 0.0186400983684  |             {'C': 10000.0, 'gamma': 1000.0}              |        20       |
|  0.234552738418 | 0.00896885666304 |             {'C': 10000.0, 'gamma': 10000.0}             |        60       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.38      0.38      0.38        13
          1       0.48      0.58      0.53        26
          2       0.25      0.20      0.22        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.38      0.42      0.39        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |               {'C': 0.001, 'gamma': 0.001}               |        21       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        21       |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 0.001, 'gamma': 10.0}                |        21       |
|  0.485887903549 | 0.00648273424528 |               {'C': 0.001, 'gamma': 100.0}               |        18       |
|  0.485907669519 | 0.00780973118882 |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.485887096774 | 0.00639310039872 |              {'C': 0.001, 'gamma': 10000.0}              |        21       |
|  0.485867346939 | 0.00472465161339 |               {'C': 0.01, 'gamma': 0.001}                |        36       |
|  0.485887096774 | 0.00778598536642 |                {'C': 0.01, 'gamma': 0.01}                |        21       |
|  0.485887903549 | 0.00648273424528 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        18       |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.485887096774 | 0.00639310039872 |                {'C': 0.01, 'gamma': 10.0}                |        21       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.01, 'gamma': 100.0}                |        1        |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.485907669519 | 0.00780973118882 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.485887903549 | 0.00648273424528 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        18       |
|  0.485907669519 | 0.00780973118882 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.485887096774 | 0.00639310039872 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        21       |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        21       |
|  0.485907669519 | 0.00780973118882 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.485887096774 | 0.00778598536642 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        21       |
|  0.485887096774 | 0.00639310039872 |                {'C': 1.0, 'gamma': 0.001}                |        21       |
|  0.485887096774 | 0.00639310039872 |                {'C': 1.0, 'gamma': 0.01}                 |        21       |
|  0.485867346939 | 0.00472465161339 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        36       |
|  0.485907669519 | 0.00780973118882 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.485907669519 | 0.00780973118882 |                {'C': 1.0, 'gamma': 10.0}                 |        1        |
|  0.485867346939 | 0.00472465161339 |                {'C': 1.0, 'gamma': 100.0}                |        36       |
|  0.485867346939 | 0.00472465161339 |               {'C': 1.0, 'gamma': 1000.0}                |        36       |
|  0.485907669519 | 0.00780973118882 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.485887096774 | 0.00639310039872 |               {'C': 10.0, 'gamma': 0.001}                |        21       |
|  0.485907669519 | 0.00780973118882 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.485887096774 | 0.00778598536642 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.467678502853 | 0.0181740207301  |                {'C': 10.0, 'gamma': 1.0}                 |        48       |
|  0.405283080974 | 0.0386944300547  |                {'C': 10.0, 'gamma': 10.0}                |        58       |
|  0.453687321703 |  0.042925438728  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.483870967742 | 0.0148483873278  |               {'C': 10.0, 'gamma': 1000.0}               |        40       |
|  0.485887096774 | 0.00778598536642 |              {'C': 10.0, 'gamma': 10000.0}               |        21       |
|  0.485887096774 | 0.00778598536642 |               {'C': 100.0, 'gamma': 0.001}               |        21       |
|  0.485907669519 | 0.00780973118882 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.475788347597 | 0.0202478592363  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        42       |
|  0.415381727288 | 0.0215563805931  |                {'C': 100.0, 'gamma': 1.0}                |        57       |
|  0.393412606978 | 0.0663313054712  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.453675825169 | 0.0440698546485  |               {'C': 100.0, 'gamma': 100.0}               |        52       |
|  0.473790322581 | 0.0118667415591  |              {'C': 100.0, 'gamma': 1000.0}               |        45       |
|  0.471751906408 | 0.00903294650243 |              {'C': 100.0, 'gamma': 10000.0}              |        47       |
|  0.485907669519 | 0.00780973118882 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.475867312651 | 0.0142297597363  |               {'C': 1000.0, 'gamma': 0.01}               |        41       |
|  0.447557500823 | 0.0481399347241  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        53       |
|  0.336915562596 | 0.0644870456324  |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.388809249506 | 0.0670824233131  |               {'C': 1000.0, 'gamma': 10.0}               |        60       |
|  0.419289691683 | 0.0492413633674  |              {'C': 1000.0, 'gamma': 100.0}               |        56       |
|  0.461796412113 | 0.0298929113588  |              {'C': 1000.0, 'gamma': 1000.0}              |        49       |
|  0.473852040816 | 0.0161272536604  |             {'C': 1000.0, 'gamma': 10000.0}              |        43       |
|  0.473768892638 | 0.0194307110804  |              {'C': 10000.0, 'gamma': 0.001}              |        46       |
|  0.443524385561 | 0.0332170233686  |              {'C': 10000.0, 'gamma': 0.01}               |        54       |
|  0.385448534252 | 0.0778210349265  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        61       |
|  0.366935483871 | 0.0761376377607  |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.358841923866 | 0.0698011131252  |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.433344305464 | 0.0678113412689  |              {'C': 10000.0, 'gamma': 100.0}              |        55       |
|  0.459718564845 | 0.0180116062951  |             {'C': 10000.0, 'gamma': 1000.0}              |        50       |
|  0.473811718236 | 0.0175838474066  |             {'C': 10000.0, 'gamma': 10000.0}             |        44       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00778598536642 |               {'C': 0.001, 'gamma': 0.001}               |        17       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        17       |
|  0.485887096774 | 0.00639310039872 |                {'C': 0.001, 'gamma': 1.0}                |        17       |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.485887096774 | 0.00639310039872 |              {'C': 0.001, 'gamma': 1000.0}               |        17       |
|  0.485907669519 | 0.00780973118882 |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.485887096774 | 0.00778598536642 |               {'C': 0.01, 'gamma': 0.001}                |        17       |
|  0.485887096774 | 0.00639310039872 |                {'C': 0.01, 'gamma': 0.01}                |        17       |
|  0.485867346939 | 0.00472465161339 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        34       |
|  0.485887903549 | 0.00648273424528 |                {'C': 0.01, 'gamma': 1.0}                 |        14       |
|  0.485907669519 | 0.00780973118882 |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.485907669519 | 0.00780973118882 |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.485887903549 | 0.00648273424528 |               {'C': 0.01, 'gamma': 1000.0}               |        14       |
|  0.485867346939 | 0.00472465161339 |              {'C': 0.01, 'gamma': 10000.0}               |        34       |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        17       |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.485867346939 | 0.00472465161339 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        34       |
|  0.485887096774 | 0.00778598536642 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        17       |
|  0.485887096774 | 0.00639310039872 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        17       |
|  0.485907669519 | 0.00780973118882 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.485887096774 | 0.00639310039872 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        17       |
|  0.485867346939 | 0.00472465161339 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        34       |
|  0.485907669519 | 0.00780973118882 |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.485887096774 | 0.00639310039872 |                {'C': 1.0, 'gamma': 0.01}                 |        17       |
|  0.485907669519 | 0.00780973118882 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.485867346939 | 0.00472465161339 |                 {'C': 1.0, 'gamma': 1.0}                 |        34       |
|  0.485887096774 | 0.00639310039872 |                {'C': 1.0, 'gamma': 10.0}                 |        17       |
|  0.487903225806 | 0.00855225578735 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.485887096774 | 0.00778598536642 |               {'C': 1.0, 'gamma': 1000.0}                |        17       |
|  0.485867346939 | 0.00472465161339 |               {'C': 1.0, 'gamma': 10000.0}               |        34       |
|  0.485887096774 | 0.00639310039872 |               {'C': 10.0, 'gamma': 0.001}                |        17       |
|  0.485887096774 | 0.00778598536642 |                {'C': 10.0, 'gamma': 0.01}                |        17       |
|  0.485887096774 | 0.00639310039872 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        17       |
|  0.475827024358 | 0.0180830721126  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.431369321922 | 0.0401881732151  |                {'C': 10.0, 'gamma': 10.0}                |        53       |
|  0.459638694187 | 0.0318224463892  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.483891540487 | 0.0127686864609  |               {'C': 10.0, 'gamma': 1000.0}               |        41       |
|  0.483870967742 | 0.0078861314658  |              {'C': 10.0, 'gamma': 10000.0}               |        42       |
|  0.485907669519 | 0.00780973118882 |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.485887903549 | 0.00648273424528 |               {'C': 100.0, 'gamma': 0.01}                |        14       |
|  0.479817279734 | 0.0260941591744  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        45       |
|  0.413248847926 | 0.0407590195372  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.397303276149 | 0.0524416359689  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.439660138249 | 0.0521908120911  |               {'C': 100.0, 'gamma': 100.0}               |        52       |
|  0.477781435155 | 0.0256671026837  |              {'C': 100.0, 'gamma': 1000.0}               |        46       |
|  0.485887096774 | 0.00918645750318 |              {'C': 100.0, 'gamma': 10000.0}              |        17       |
|  0.485907669519 | 0.00780973118882 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.471793909096 | 0.0139910995151  |               {'C': 1000.0, 'gamma': 0.01}               |        50       |
|  0.425197498354 | 0.0531265036073  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        55       |
|  0.339056842495 | 0.0694932955826  |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.374781928901 | 0.0519958401804  |               {'C': 1000.0, 'gamma': 10.0}               |        61       |
|  0.423405097926 | 0.0369125463733  |              {'C': 1000.0, 'gamma': 100.0}               |        56       |
|  0.473790322581 | 0.0184235086944  |              {'C': 1000.0, 'gamma': 1000.0}              |        49       |
|  0.483932685978 | 0.0154973042847  |             {'C': 1000.0, 'gamma': 10000.0}              |        40       |
|  0.483870967742 | 0.0186478088056  |              {'C': 10000.0, 'gamma': 0.001}              |        42       |
|  0.415463161071 |  0.035172521578  |              {'C': 10000.0, 'gamma': 0.01}               |        57       |
|  0.389112903226 | 0.0665275540842  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        60       |
|  0.357076852919 | 0.0440788206033  |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.352904871626 |  0.063017098855  |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.427419354839 | 0.0371001181764  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.475785878868 | 0.0209092770008  |             {'C': 10000.0, 'gamma': 1000.0}              |        48       |
|  0.483849537799 | 0.00914299703315 |             {'C': 10000.0, 'gamma': 10000.0}             |        44       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.48      0.96      0.64        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.47      0.31        53

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.23614689238  | 0.00755096587865 |               {'C': 0.001, 'gamma': 0.001}               |        46       |
|  0.236127142544 | 0.00615619455406 |               {'C': 0.001, 'gamma': 0.01}                |        58       |
|  0.236129080658 | 0.00624343257476 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        53       |
|  0.23614689238  | 0.00755096587865 |                {'C': 0.001, 'gamma': 1.0}                |        46       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.001, 'gamma': 10.0}                |        25       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.001, 'gamma': 100.0}               |        25       |
|  0.23614689238  | 0.00755096587865 |              {'C': 0.001, 'gamma': 1000.0}               |        46       |
|  0.236129080658 | 0.00624343257476 |              {'C': 0.001, 'gamma': 10000.0}              |        53       |
|  0.236089401154 | 0.00458273377759 |               {'C': 0.01, 'gamma': 0.001}                |        60       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.01, 'gamma': 0.01}                |        25       |
|  0.236129080658 | 0.00624343257476 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        53       |
|  0.236167255199 | 0.00757464085505 |                {'C': 0.01, 'gamma': 1.0}                 |        25       |
|  0.236129080658 | 0.00624343257476 |                {'C': 0.01, 'gamma': 10.0}                |        53       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.01, 'gamma': 100.0}                |        25       |
|  0.236167255199 | 0.00757464085505 |               {'C': 0.01, 'gamma': 1000.0}               |        25       |
|  0.236167255199 | 0.00757464085505 |              {'C': 0.01, 'gamma': 10000.0}               |        25       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        25       |
|  0.236129080658 | 0.00624343257476 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        53       |
|  0.236167255199 | 0.00757464085505 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        25       |
|  0.236167255199 | 0.00757464085505 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        25       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        25       |
|  0.236167255199 | 0.00757464085505 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        25       |
|  0.236167255199 | 0.00757464085505 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        25       |
|  0.23614689238  | 0.00755096587865 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        46       |
|  0.236127142544 | 0.00615619455406 |                {'C': 1.0, 'gamma': 0.001}                |        58       |
|  0.236167255199 | 0.00757464085505 |                {'C': 1.0, 'gamma': 0.01}                 |        25       |
|  0.236167255199 | 0.00757464085505 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.23614689238  | 0.00755096587865 |                 {'C': 1.0, 'gamma': 1.0}                 |        46       |
|  0.236167255199 | 0.00757464085505 |                {'C': 1.0, 'gamma': 10.0}                 |        25       |
|  0.235654100185 | 0.00804885673515 |                {'C': 1.0, 'gamma': 100.0}                |        62       |
|  0.236167255199 | 0.00757464085505 |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.23614689238  | 0.00755096587865 |               {'C': 1.0, 'gamma': 10000.0}               |        46       |
|  0.236167255199 | 0.00757464085505 |               {'C': 10.0, 'gamma': 0.001}                |        25       |
|  0.236167255199 | 0.00757464085505 |                {'C': 10.0, 'gamma': 0.01}                |        25       |
|  0.23614689238  | 0.00755096587865 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        46       |
|  0.326147362296 | 0.0982645258581  |                {'C': 10.0, 'gamma': 1.0}                 |        11       |
|  0.340157614374 | 0.0670021030939  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.330297493574 | 0.0852226751908  |               {'C': 10.0, 'gamma': 100.0}                |        10       |
|  0.252660749948 | 0.0587781128235  |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.235633737366 | 0.00802527867398 |              {'C': 10.0, 'gamma': 10000.0}               |        63       |
|  0.236089401154 | 0.00458273377759 |               {'C': 100.0, 'gamma': 0.001}               |        60       |
|  0.236167255199 | 0.00757464085505 |               {'C': 100.0, 'gamma': 0.01}                |        25       |
|  0.283465433359 | 0.0836919992358  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.347349372504 | 0.0806733542859  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.349564826376 | 0.0520606831402  |               {'C': 100.0, 'gamma': 10.0}                |        2        |
|  0.350762398643 | 0.0660656080995  |               {'C': 100.0, 'gamma': 100.0}               |        1        |
|  0.24760431007  | 0.0420363022949  |              {'C': 100.0, 'gamma': 1000.0}               |        24       |
|  0.256153186943 | 0.0648522872037  |              {'C': 100.0, 'gamma': 10000.0}              |        20       |
|  0.236167255199 | 0.00757464085505 |              {'C': 1000.0, 'gamma': 0.001}               |        25       |
|  0.276260478103 | 0.0773773583162  |               {'C': 1000.0, 'gamma': 0.01}               |        18       |
|  0.343886000729 | 0.0645407387165  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.335080440425 | 0.0645436746488  |               {'C': 1000.0, 'gamma': 1.0}                |        8        |
|  0.341645107142 | 0.0560247132746  |               {'C': 1000.0, 'gamma': 10.0}               |        5        |
|  0.320902190378 | 0.0464400277041  |              {'C': 1000.0, 'gamma': 100.0}               |        15       |
|  0.258613106145 |  0.063962704084  |              {'C': 1000.0, 'gamma': 1000.0}              |        19       |
|  0.235101266307 | 0.0067247397948  |             {'C': 1000.0, 'gamma': 10000.0}              |        64       |
|  0.286314163721 |  0.106762850534  |              {'C': 10000.0, 'gamma': 0.001}              |        16       |
|  0.324851126847 | 0.0889839677648  |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.33263039601  | 0.0620264766141  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        9        |
|  0.336351141507 | 0.0522376501227  |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.321387641716 |  0.056448380355  |              {'C': 10000.0, 'gamma': 10.0}               |        14       |
|  0.324494597406 | 0.0655394129988  |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
|  0.253289603812 | 0.0425246821936  |             {'C': 10000.0, 'gamma': 1000.0}              |        22       |
|  0.254293007361 | 0.0582433096523  |             {'C': 10000.0, 'gamma': 10000.0}             |        21       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.11      0.08      0.09        13
          1       0.50      0.77      0.61        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.27      0.40      0.32        53

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485887096774 | 0.00639310039872 |               {'C': 0.001, 'gamma': 0.001}               |        32       |
|  0.485887096774 | 0.00639310039872 |               {'C': 0.001, 'gamma': 0.01}                |        32       |
|  0.48590684661  | 0.00639001346187 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        28       |
|  0.485927419355 | 0.00780715235919 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.485927419355 | 0.00780715235919 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.485927419355 | 0.00780715235919 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.485927419355 | 0.00780715235919 |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.485907653384 | 0.00647968755129 |              {'C': 0.001, 'gamma': 10000.0}              |        26       |
|  0.48590684661  | 0.00639001346187 |               {'C': 0.01, 'gamma': 0.001}                |        28       |
|  0.485887096774 | 0.00639310039872 |                {'C': 0.01, 'gamma': 0.01}                |        32       |
|  0.485887096774 | 0.00472055635648 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        32       |
|  0.485927419355 | 0.00780715235919 |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.485927419355 | 0.00780715235919 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.485907653384 | 0.00647968755129 |               {'C': 0.01, 'gamma': 100.0}                |        26       |
|  0.485927419355 | 0.00780715235919 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.485887096774 | 0.00472055635648 |              {'C': 0.01, 'gamma': 10000.0}               |        32       |
|  0.485927419355 | 0.00780715235919 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.485927419355 | 0.00780715235919 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.485887096774 | 0.00472055635648 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        32       |
|  0.48590684661  | 0.00639001346187 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        28       |
|  0.485927419355 | 0.00780715235919 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.485927419355 | 0.00780715235919 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        1        |
|  0.485927419355 | 0.00780715235919 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.485927419355 | 0.00780715235919 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.485927419355 | 0.00780715235919 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.48590684661  | 0.00639001346187 |                {'C': 1.0, 'gamma': 0.01}                 |        28       |
|  0.485927419355 | 0.00780715235919 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.485927419355 | 0.00780715235919 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.485927419355 | 0.00780715235919 |                {'C': 1.0, 'gamma': 10.0}                 |        1        |
|  0.483951612903 | 0.0109538492167  |                {'C': 1.0, 'gamma': 100.0}                |        38       |
|  0.485927419355 | 0.00780715235919 |               {'C': 1.0, 'gamma': 1000.0}                |        1        |
|  0.485927419355 | 0.00780715235919 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.485927419355 | 0.00780715235919 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.485927419355 | 0.00780715235919 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.485927419355 | 0.00780715235919 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.477861223118 | 0.0158070776157  |                {'C': 10.0, 'gamma': 1.0}                 |        45       |
|  0.421327284946 | 0.0363160875555  |                {'C': 10.0, 'gamma': 10.0}                |        58       |
|  0.453688281764 | 0.0467682679814  |               {'C': 10.0, 'gamma': 100.0}                |        51       |
|  0.477862903226 | 0.0157265458357  |               {'C': 10.0, 'gamma': 1000.0}               |        44       |
|  0.483911290323 | 0.0125805541263  |              {'C': 10.0, 'gamma': 10000.0}               |        39       |
|  0.485927419355 | 0.00780715235919 |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.485927419355 | 0.00780715235919 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.47780118499  | 0.0175568403867  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        47       |
|  0.451769153226 | 0.0713880896908  |                {'C': 100.0, 'gamma': 1.0}                |        52       |
|  0.397049731183 | 0.0444403705081  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.429377767236 | 0.0426972608136  |               {'C': 100.0, 'gamma': 100.0}               |        55       |
|  0.465662442396 | 0.0255755427309  |              {'C': 100.0, 'gamma': 1000.0}               |        50       |
|  0.483889894668 | 0.0119858589315  |              {'C': 100.0, 'gamma': 10000.0}              |        40       |
|  0.485927419355 | 0.00780715235919 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.477803605313 | 0.0152812143699  |               {'C': 1000.0, 'gamma': 0.01}               |        46       |
|  0.421355945604 | 0.0492352594481  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        57       |
|  0.362728494624 | 0.0595936701659  |               {'C': 1000.0, 'gamma': 1.0}                |        61       |
|  0.360941408822 | 0.0731721113873  |               {'C': 1000.0, 'gamma': 10.0}               |        62       |
|  0.437379032258 | 0.0365423663066  |              {'C': 1000.0, 'gamma': 100.0}               |        54       |
|  0.465785895003 | 0.0342624277118  |              {'C': 1000.0, 'gamma': 1000.0}              |        49       |
|  0.483869287634 | 0.0111293776333  |             {'C': 1000.0, 'gamma': 10000.0}              |        41       |
|  0.479838709677 | 0.0201626804089  |              {'C': 10000.0, 'gamma': 0.001}              |        43       |
|  0.423330961417 | 0.0272698447937  |              {'C': 10000.0, 'gamma': 0.01}               |        56       |
|  0.373036537196 | 0.0651829799983  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        60       |
|  0.352731854839 | 0.0493288531174  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.354742943548 | 0.0608166023164  |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.437476958525 |  0.035551421357  |              {'C': 10000.0, 'gamma': 100.0}              |        53       |
|  0.471774193548 | 0.0200951350187  |             {'C': 10000.0, 'gamma': 1000.0}              |        48       |
|  0.479879032258 | 0.0175815239497  |             {'C': 10000.0, 'gamma': 10000.0}             |        42       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.00      0.00      0.00        13
          1       0.49      1.00      0.66        26
          2       0.00      0.00      0.00        10
          3       0.00      0.00      0.00         3
          4       0.00      0.00      0.00         1

avg / total       0.24      0.49      0.32        53


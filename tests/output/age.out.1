Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.511842113276 | 0.0256209905351 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      1.00      0.85       103
          1       0.00      0.00      0.00        30
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         2

avg / total       0.56      0.75      0.64       138


Accuracy on test set (using best parameters): 0.75

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.548239991727 | 0.0613939195557 |  {'n_neighbors': 3} |        1        |
|  0.507271261994 |  0.051647278514 |  {'n_neighbors': 5} |        5        |
|  0.53288769112  | 0.0432434532488 | {'n_neighbors': 11} |        2        |
|  0.51132241779  | 0.0252948036034 | {'n_neighbors': 21} |        4        |
|  0.513722979872 | 0.0251425702753 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.89      0.83       102
          1       0.48      0.33      0.39        30
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         1

avg / total       0.68      0.73      0.70       138


Accuracy on test set (using best parameters): 0.73

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.555083413654 | 0.0520086606507 | {'n_estimators': 2}  |        1        |
|  0.54310546066  | 0.0770759056873 | {'n_estimators': 3}  |        3        |
|  0.539182417689 |  0.055894818865 | {'n_estimators': 5}  |        6        |
|  0.54018813356  | 0.0472527996755 | {'n_estimators': 10} |        4        |
|  0.553107159493 | 0.0496341124545 | {'n_estimators': 20} |        2        |
|  0.523927225939 | 0.0520236038774 | {'n_estimators': 40} |        7        |
|  0.539689240076 | 0.0422379294695 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.87      0.79        97
          1       0.25      0.13      0.17        38
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         3

avg / total       0.57      0.64      0.60       138


Accuracy on test set (using best parameters): 0.64

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.530294696079 | 0.0165304982677 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        12       |
|  0.530294696079 | 0.0165304982677 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        12       |
|  0.530294696079 | 0.0165304982677 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        12       |
|  0.530294696079 | 0.0165304982677 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        12       |
|  0.530294696079 | 0.0165304982677 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        12       |
|  0.530294696079 | 0.0165304982677 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        12       |
|  0.530294696079 | 0.0165304982677 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        12       |
|  0.527927363234 | 0.0173832791995 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        20       |
|  0.532032964572 | 0.0268335137474 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.53700026005  | 0.0307693883144 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.54648138752  | 0.0471422732489 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.545619002275 | 0.0424834131446 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.54815017432  | 0.0417286086854 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.551586025203 | 0.0409978882178 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.530294696079 | 0.0165304982677 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.52673887964  | 0.0166434427385 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        21       |
|  0.532032964572 | 0.0268335137474 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.536138565911 | 0.0332292732337 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        9        |
|  0.542434607777 | 0.0335442095632 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.541965480864 | 0.0379533788739 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.55133514167  | 0.0405991586879 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      1.00      0.83        97
          1       0.00      0.00      0.00        34
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         3

avg / total       0.49      0.70      0.58       138


Accuracy on test set (using best parameters): 0.70

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.545946404581 | 0.0212558706876 |        {'C': 0.001}        |        4        |
|  0.545946404581 | 0.0212558706876 |        {'C': 0.01}         |        4        |
|  0.545946404581 | 0.0212558706876 | {'C': 0.10000000000000001} |        4        |
|  0.545946404581 | 0.0212558706876 |         {'C': 1.0}         |        4        |
|  0.551228135791 |  0.023741664532 |        {'C': 10.0}         |        3        |
|  0.542854597658 | 0.0361343664775 |        {'C': 100.0}        |        8        |
|  0.563586886454 | 0.0571581270083 |       {'C': 1000.0}        |        1        |
|  0.56193589019  | 0.0573971328589 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.82      0.72        92
          1       0.21      0.11      0.14        38
          2       0.00      0.00      0.00         7
          3       0.00      0.00      0.00         1

avg / total       0.49      0.57      0.52       138


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.533385239914 | 0.0141149648134 |               {'C': 0.001, 'gamma': 0.001}               |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 0.001, 'gamma': 0.01}                |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 0.001, 'gamma': 1.0}                |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 0.001, 'gamma': 10.0}                |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 0.001, 'gamma': 100.0}               |        22       |
|  0.533385239914 | 0.0141149648134 |              {'C': 0.001, 'gamma': 1000.0}               |        22       |
|  0.533385239914 | 0.0141149648134 |              {'C': 0.001, 'gamma': 10000.0}              |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 0.01, 'gamma': 0.001}                |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 0.01, 'gamma': 0.01}                |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 0.01, 'gamma': 1.0}                 |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 0.01, 'gamma': 10.0}                |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 0.01, 'gamma': 100.0}                |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 0.01, 'gamma': 1000.0}               |        22       |
|  0.533385239914 | 0.0141149648134 |              {'C': 0.01, 'gamma': 10000.0}               |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        22       |
|  0.533385239914 | 0.0141149648134 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        22       |
|  0.533385239914 | 0.0141149648134 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        22       |
|  0.533385239914 | 0.0141149648134 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        22       |
|  0.533385239914 | 0.0141149648134 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 1.0, 'gamma': 0.001}                |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 1.0, 'gamma': 0.01}                 |        22       |
|  0.533385239914 | 0.0141149648134 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.533385239914 | 0.0141149648134 |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 1.0, 'gamma': 10.0}                 |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 1.0, 'gamma': 100.0}                |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 1.0, 'gamma': 10000.0}               |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 10.0, 'gamma': 0.001}                |        22       |
|  0.533385239914 | 0.0141149648134 |                {'C': 10.0, 'gamma': 0.01}                |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.54089978598  | 0.0260135558857 |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.561098307489 |  0.042995713607 |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.54133105102  | 0.0363796255462 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.538881832781 | 0.0306515952822 |               {'C': 10.0, 'gamma': 1000.0}               |        18       |
|   0.5374768807  | 0.0202720483505 |              {'C': 10.0, 'gamma': 10000.0}               |        20       |
|  0.533385239914 | 0.0141149648134 |               {'C': 100.0, 'gamma': 0.001}               |        22       |
|  0.533385239914 | 0.0141149648134 |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.533385239914 | 0.0141149648134 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        22       |
|  0.556974186455 | 0.0514314318235 |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.537300130347 |  0.048793460587 |               {'C': 100.0, 'gamma': 10.0}                |        21       |
|  0.54165727335  | 0.0512020695475 |               {'C': 100.0, 'gamma': 100.0}               |        15       |
|  0.542065029881 | 0.0393834394058 |              {'C': 100.0, 'gamma': 1000.0}               |        14       |
|  0.553346781775 | 0.0332122059164 |              {'C': 100.0, 'gamma': 10000.0}              |        8        |
|  0.533385239914 | 0.0141149648134 |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.538655729951 | 0.0184383540888 |               {'C': 1000.0, 'gamma': 0.01}               |        19       |
|  0.551036610078 | 0.0330073785241 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        11       |
|  0.532291237345 | 0.0689562927622 |               {'C': 1000.0, 'gamma': 1.0}                |        61       |
|  0.53136055569  | 0.0569868559125 |               {'C': 1000.0, 'gamma': 10.0}               |        62       |
|  0.546165979031 | 0.0462468107641 |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.557643298134 | 0.0375368506787 |              {'C': 1000.0, 'gamma': 1000.0}              |        4        |
|  0.553346781775 | 0.0332122059164 |             {'C': 1000.0, 'gamma': 10000.0}              |        8        |
|  0.531014389921 | 0.0148828852008 |              {'C': 10000.0, 'gamma': 0.001}              |        63       |
|  0.549020950928 | 0.0447387630743 |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.55536258866  |  0.056029293924 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        7        |
|  0.517829527432 | 0.0643348230193 |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.559584431974 | 0.0353093355176 |              {'C': 10000.0, 'gamma': 10.0}               |        3        |
|  0.573774694897 | 0.0377527584225 |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.557643298134 | 0.0375368506787 |             {'C': 10000.0, 'gamma': 1000.0}              |        4        |
|  0.553346781775 | 0.0332122059164 |             {'C': 10000.0, 'gamma': 10000.0}             |        8        |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.89      0.78        96
          1       0.21      0.09      0.12        35
          2       0.00      0.00      0.00         7

avg / total       0.54      0.64      0.57       138


Accuracy on test set (using best parameters): 0.64


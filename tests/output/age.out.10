Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.558481877965 | 0.0169429286683 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      1.00      0.78        88
          1       0.00      0.00      0.00        43
          2       0.00      0.00      0.00         6
          3       0.00      0.00      0.00         1

avg / total       0.41      0.64      0.50       138


Accuracy on test set (using best parameters): 0.64

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.564105950371 | 0.0550042951763 |  {'n_neighbors': 3} |        2        |
|  0.565475863777 | 0.0588812522061 |  {'n_neighbors': 5} |        1        |
|  0.555282201024 | 0.0503198994714 | {'n_neighbors': 11} |        3        |
|  0.537344127983 | 0.0235845319717 | {'n_neighbors': 21} |        5        |
|  0.539723363051 | 0.0241202000715 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.94      0.80        94
          1       0.38      0.13      0.20        38
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         2

avg / total       0.59      0.67      0.60       138


Accuracy on test set (using best parameters): 0.67

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.573772152299 | 0.0397454820593 | {'n_estimators': 2}  |        1        |
|  0.565619028911 | 0.0547814897509 | {'n_estimators': 3}  |        3        |
|  0.559729619472 | 0.0522856069678 | {'n_estimators': 5}  |        4        |
|  0.571023325692 | 0.0405903262388 | {'n_estimators': 10} |        2        |
|  0.559655044831 | 0.0348880522181 | {'n_estimators': 20} |        5        |
|  0.537111410637 | 0.0425512639906 | {'n_estimators': 40} |        6        |
|  0.53542823114  | 0.0543081231207 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.87      0.77        93
          1       0.40      0.20      0.26        41
          2       0.00      0.00      0.00         2
          3       0.00      0.00      0.00         2

avg / total       0.58      0.64      0.60       138


Accuracy on test set (using best parameters): 0.64

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.533441861097 | 0.0203750287209 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        14       |
|  0.533441861097 | 0.0203750287209 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        14       |
|  0.533441861097 | 0.0203750287209 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        14       |
|  0.533441861097 | 0.0203750287209 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|  0.533441861097 | 0.0203750287209 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|  0.533441861097 | 0.0203750287209 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|  0.533441861097 | 0.0203750287209 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
|  0.541287327067 | 0.0238172444494 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        9        |
|  0.541287327067 | 0.0238172444494 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.549449025228 | 0.0312716466262 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        2        |
|  0.54384652208  | 0.0326666829109 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.546766109728 | 0.0385750883041 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        3        |
|  0.540606457819 | 0.0330697064047 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.551295884652 | 0.0354918010749 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.533441861097 | 0.0203750287209 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.540968452506 | 0.0220341492913 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.545333789547 | 0.0251507241156 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.542692863688 | 0.0276816712673 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.544936869615 | 0.0240747932039 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.543143397767 | 0.0302988831649 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.539558028675 | 0.0244806630881 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        13       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      1.00      0.82        96
          1       0.00      0.00      0.00        36
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         2

avg / total       0.48      0.70      0.57       138


Accuracy on test set (using best parameters): 0.70

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.546036385937 | 0.0282245635452 |        {'C': 0.001}        |        4        |
|  0.546036385937 | 0.0282245635452 |        {'C': 0.01}         |        4        |
|  0.546036385937 | 0.0282245635452 | {'C': 0.10000000000000001} |        4        |
|  0.546036385937 | 0.0282245635452 |         {'C': 1.0}         |        4        |
|  0.551334427004 | 0.0371409677802 |        {'C': 10.0}         |        3        |
|  0.536717861893 | 0.0382032820881 |        {'C': 100.0}        |        8        |
|  0.570332277801 | 0.0329601942549 |       {'C': 1000.0}        |        2        |
|  0.577231792698 | 0.0504001405431 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.77      0.72        92
          1       0.31      0.20      0.24        40
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         2

avg / total       0.54      0.57      0.55       138


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.574301411352 |  0.015434930808 |               {'C': 0.001, 'gamma': 0.001}               |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 0.001, 'gamma': 0.01}                |        16       |
|  0.574301411352 |  0.015434930808 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 0.001, 'gamma': 1.0}                |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 0.001, 'gamma': 10.0}                |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 0.001, 'gamma': 100.0}               |        16       |
|  0.574301411352 |  0.015434930808 |              {'C': 0.001, 'gamma': 1000.0}               |        16       |
|  0.574301411352 |  0.015434930808 |              {'C': 0.001, 'gamma': 10000.0}              |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 0.01, 'gamma': 0.001}                |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 0.01, 'gamma': 0.01}                |        16       |
|  0.574301411352 |  0.015434930808 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 0.01, 'gamma': 1.0}                 |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 0.01, 'gamma': 10.0}                |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 0.01, 'gamma': 100.0}                |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 0.01, 'gamma': 1000.0}               |        16       |
|  0.574301411352 |  0.015434930808 |              {'C': 0.01, 'gamma': 10000.0}               |        16       |
|  0.574301411352 |  0.015434930808 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        16       |
|  0.574301411352 |  0.015434930808 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        16       |
|  0.574301411352 |  0.015434930808 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        16       |
|  0.574301411352 |  0.015434930808 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        16       |
|  0.574301411352 |  0.015434930808 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        16       |
|  0.574301411352 |  0.015434930808 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        16       |
|  0.574301411352 |  0.015434930808 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        16       |
|  0.574301411352 |  0.015434930808 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 1.0, 'gamma': 0.001}                |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 1.0, 'gamma': 0.01}                 |        16       |
|  0.574301411352 |  0.015434930808 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        16       |
|  0.574301411352 |  0.015434930808 |                 {'C': 1.0, 'gamma': 1.0}                 |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 1.0, 'gamma': 10.0}                 |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 1.0, 'gamma': 1000.0}                |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 1.0, 'gamma': 10000.0}               |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 10.0, 'gamma': 0.001}                |        16       |
|  0.574301411352 |  0.015434930808 |                {'C': 10.0, 'gamma': 0.01}                |        16       |
|  0.574301411352 |  0.015434930808 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        16       |
|  0.582470010192 | 0.0209952066309 |                {'C': 10.0, 'gamma': 1.0}                 |        6        |
|  0.588222849067 | 0.0541804048386 |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.581830284362 | 0.0327208974113 |               {'C': 10.0, 'gamma': 100.0}                |        7        |
|  0.573547167698 | 0.0161244710489 |               {'C': 10.0, 'gamma': 1000.0}               |        55       |
|  0.574301411352 |  0.015434930808 |              {'C': 10.0, 'gamma': 10000.0}               |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 100.0, 'gamma': 0.001}               |        16       |
|  0.574301411352 |  0.015434930808 |               {'C': 100.0, 'gamma': 0.01}                |        16       |
|  0.577154463062 | 0.0199264042459 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.578713694921 | 0.0300284229662 |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.59231180068  | 0.0611893082947 |               {'C': 100.0, 'gamma': 10.0}                |        2        |
|  0.586863815541 | 0.0283093241356 |               {'C': 100.0, 'gamma': 100.0}               |        5        |
|  0.571904959294 | 0.0173490884521 |              {'C': 100.0, 'gamma': 1000.0}               |        59       |
|  0.57956263536  | 0.0121953555026 |              {'C': 100.0, 'gamma': 10000.0}              |        8        |
|  0.574301411352 |  0.015434930808 |              {'C': 1000.0, 'gamma': 0.001}               |        16       |
|  0.575952774095 | 0.0188612101289 |               {'C': 1000.0, 'gamma': 0.01}               |        14       |
|  0.573023168344 |  0.033292903545 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        58       |
|  0.535553524155 | 0.0344590333803 |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.607475510263 | 0.0639608195609 |               {'C': 1000.0, 'gamma': 10.0}               |        1        |
|  0.577663996551 | 0.0289228983805 |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
|  0.573097516094 |  0.016337651784 |              {'C': 1000.0, 'gamma': 1000.0}              |        56       |
|  0.57956263536  | 0.0121953555026 |             {'C': 1000.0, 'gamma': 10000.0}              |        8        |
|  0.575952774095 | 0.0188612101289 |              {'C': 10000.0, 'gamma': 0.001}              |        14       |
|  0.565732397484 | 0.0239588720045 |              {'C': 10000.0, 'gamma': 0.01}               |        61       |
|  0.549231625954 | 0.0241297385732 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.550843362086 | 0.0445197233616 |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.590021459122 | 0.0427381405069 |              {'C': 10000.0, 'gamma': 10.0}               |        3        |
|  0.56759143423  | 0.0297984083952 |              {'C': 10000.0, 'gamma': 100.0}              |        60       |
|  0.573097516094 |  0.016337651784 |             {'C': 10000.0, 'gamma': 1000.0}              |        56       |
|  0.57956263536  | 0.0121953555026 |             {'C': 10000.0, 'gamma': 10000.0}             |        8        |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.77      0.68        83
          1       0.33      0.22      0.27        45
          2       0.00      0.00      0.00         7
          3       0.00      0.00      0.00         3

avg / total       0.47      0.54      0.49       138


Accuracy on test set (using best parameters): 0.54


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.549204513156 | 0.0303422964961 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      1.00      0.79        91
          1       0.00      0.00      0.00        40
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         3

avg / total       0.43      0.66      0.52       138


Average accuracy on test set (using best parameters): 0.66

===================================================================
[ 0.65942029  0.          0.          0.        ]
===================================================================
Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.54346833777  | 0.0504195292875 |  {'n_neighbors': 3} |        3        |
|  0.568075652973 |  0.039193219709 |  {'n_neighbors': 5} |        1        |
|  0.551627613098 | 0.0355692454783 | {'n_neighbors': 11} |        2        |
|  0.542822777233 | 0.0217991102808 | {'n_neighbors': 21} |        4        |
|  0.542822777233 | 0.0217991102808 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.89      0.77        93
          1       0.33      0.12      0.18        40
          2       0.00      0.00      0.00         5

avg / total       0.55      0.64      0.57       138


Average accuracy on test set (using best parameters): 0.64

===================================================================
[ 0.67479675  0.33333333  0.        ]
===================================================================
Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.557866380351 | 0.0539405297862 | {'n_estimators': 2}  |        5        |
|  0.588081877225 | 0.0749634837638 | {'n_estimators': 3}  |        1        |
|  0.577188309823 | 0.0818481444557 | {'n_estimators': 5}  |        2        |
|  0.553904030677 | 0.0376809351004 | {'n_estimators': 10} |        6        |
|  0.546872655296 | 0.0227397479665 | {'n_estimators': 20} |        7        |
|  0.569903087345 | 0.0389323557993 | {'n_estimators': 40} |        3        |
|  0.568161845267 | 0.0343908017109 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.82      0.71        88
          1       0.27      0.13      0.18        46
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.49      0.57      0.51       138


Average accuracy on test set (using best parameters): 0.57

===================================================================
[ 0.62068966  0.27272727  0.          0.        ]
===================================================================
Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.545900923096 | 0.0165761964026 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        14       |
|  0.545900923096 | 0.0165761964026 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        14       |
|  0.545900923096 | 0.0165761964026 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        14       |
|  0.545900923096 | 0.0165761964026 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|  0.545900923096 | 0.0165761964026 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|  0.545900923096 | 0.0165761964026 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|  0.545900923096 | 0.0165761964026 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
|  0.549988228294 | 0.0190861528974 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.555275803654 | 0.0283702977138 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.551394721565 | 0.0292184872373 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.558176333085 | 0.0402749729596 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.553832155479 | 0.0369808649886 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.556735234298 | 0.0333860456571 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.561800197042 | 0.0426198872211 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.545900923096 | 0.0165761964026 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.549994072444 | 0.0271252020024 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.55257953062  | 0.0282095855109 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.556692762632 | 0.0371452302773 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.550175065184 | 0.0306452043601 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        11       |
|  0.552878292018 | 0.0333428454898 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        8        |
|  0.566585275258 | 0.0339287212338 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      1.00      0.80        92
          1       0.00      0.00      0.00        37
          2       0.00      0.00      0.00         8
          3       0.00      0.00      0.00         1

avg / total       0.44      0.67      0.53       138


Average accuracy on test set (using best parameters): 0.67

===================================================================
[ 0.66666667  0.          0.          0.        ]
===================================================================
Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 128 candidates, totalling 1280 fits
Grid scores on validation set:

+-----------------+-----------------+------------------------------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                                    params                                    | test_rank_score |
+-----------------+-----------------+------------------------------------------------------------------------------+-----------------+
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 0.001, 'gamma': 0.001}               |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.001}                 |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 0.001, 'gamma': 0.01}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.01}                 |        18       |
|  0.539723363051 | 0.0241202000715 |        {'kernel': 'linear', 'C': 0.001, 'gamma': 0.10000000000000001}        |        18       |
|  0.539723363051 | 0.0241202000715 |         {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.10000000000000001}          |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 0.001, 'gamma': 1.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 0.001, 'gamma': 1.0}                  |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 0.001, 'gamma': 10.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 0.001, 'gamma': 10.0}                 |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 0.001, 'gamma': 100.0}               |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 0.001, 'gamma': 100.0}                 |        18       |
|  0.539723363051 | 0.0241202000715 |              {'kernel': 'linear', 'C': 0.001, 'gamma': 1000.0}               |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 0.001, 'gamma': 1000.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |              {'kernel': 'linear', 'C': 0.001, 'gamma': 10000.0}              |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'rbf', 'C': 0.001, 'gamma': 10000.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 0.01, 'gamma': 0.001}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.001}                 |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 0.01, 'gamma': 0.01}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.01}                  |        18       |
|  0.539723363051 | 0.0241202000715 |        {'kernel': 'linear', 'C': 0.01, 'gamma': 0.10000000000000001}         |        18       |
|  0.539723363051 | 0.0241202000715 |          {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.10000000000000001}          |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 0.01, 'gamma': 1.0}                 |        18       |
|  0.539723363051 | 0.0241202000715 |                  {'kernel': 'rbf', 'C': 0.01, 'gamma': 1.0}                  |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 0.01, 'gamma': 10.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 10.0}                  |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 0.01, 'gamma': 100.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 100.0}                 |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 0.01, 'gamma': 1000.0}               |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 0.01, 'gamma': 1000.0}                 |        18       |
|  0.539723363051 | 0.0241202000715 |              {'kernel': 'linear', 'C': 0.01, 'gamma': 10000.0}               |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 0.01, 'gamma': 10000.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 0.001}        |        18       |
|  0.539723363051 | 0.0241202000715 |         {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.001}          |        18       |
|  0.539723363051 | 0.0241202000715 |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 0.01}         |        18       |
|  0.539723363051 | 0.0241202000715 |          {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.01}          |        18       |
|  0.539723363051 | 0.0241202000715 | {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        18       |
|  0.539723363051 | 0.0241202000715 |  {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}   |        18       |
|  0.539723363051 | 0.0241202000715 |         {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 1.0}         |        18       |
|  0.539723363051 | 0.0241202000715 |          {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 1.0}           |        18       |
|  0.539723363051 | 0.0241202000715 |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 10.0}         |        18       |
|  0.539723363051 | 0.0241202000715 |          {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 10.0}          |        18       |
|  0.539723363051 | 0.0241202000715 |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 100.0}        |        18       |
|  0.539723363051 | 0.0241202000715 |         {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 100.0}          |        18       |
|  0.539723363051 | 0.0241202000715 |       {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 1000.0}        |        18       |
|  0.539723363051 | 0.0241202000715 |         {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 1000.0}         |        18       |
|  0.539723363051 | 0.0241202000715 |       {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 10000.0}       |        18       |
|  0.539723363051 | 0.0241202000715 |        {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 10000.0}         |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 1.0, 'gamma': 0.001}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}                  |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 1.0, 'gamma': 0.01}                 |        18       |
|  0.539723363051 | 0.0241202000715 |                  {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}                  |        18       |
|  0.539723363051 | 0.0241202000715 |         {'kernel': 'linear', 'C': 1.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.539723363051 | 0.0241202000715 |          {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.10000000000000001}           |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'linear', 'C': 1.0, 'gamma': 1.0}                 |        18       |
|  0.539723363051 | 0.0241202000715 |                  {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}                   |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.538528937039 | 0.0230561360076 |                  {'kernel': 'rbf', 'C': 1.0, 'gamma': 10.0}                  |        96       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'linear', 'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 100.0}                  |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 1.0, 'gamma': 1000.0}                |        18       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 1000.0}                 |        18       |
|  0.539723363051 | 0.0241202000715 |               {'kernel': 'linear', 'C': 1.0, 'gamma': 10000.0}               |        18       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 1.0, 'gamma': 10000.0}                 |        18       |
|  0.537365664548 | 0.0269444814376 |               {'kernel': 'linear', 'C': 10.0, 'gamma': 0.001}                |        98       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}                 |        18       |
|  0.537365664548 | 0.0269444814376 |                {'kernel': 'linear', 'C': 10.0, 'gamma': 0.01}                |        98       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}                  |        18       |
|  0.537365664548 | 0.0269444814376 |        {'kernel': 'linear', 'C': 10.0, 'gamma': 0.10000000000000001}         |        98       |
|  0.539723363051 | 0.0241202000715 |          {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.10000000000000001}          |        18       |
|  0.537365664548 | 0.0269444814376 |                {'kernel': 'linear', 'C': 10.0, 'gamma': 1.0}                 |        98       |
|  0.550107673081 | 0.0278546219579 |                  {'kernel': 'rbf', 'C': 10.0, 'gamma': 1.0}                  |        7        |
|  0.537365664548 | 0.0269444814376 |                {'kernel': 'linear', 'C': 10.0, 'gamma': 10.0}                |        98       |
|  0.551057908191 | 0.0589561516358 |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 10.0}                  |        6        |
|  0.537365664548 | 0.0269444814376 |               {'kernel': 'linear', 'C': 10.0, 'gamma': 100.0}                |        98       |
|  0.527783023339 | 0.0227089071309 |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 100.0}                 |       111       |
|  0.537365664548 | 0.0269444814376 |               {'kernel': 'linear', 'C': 10.0, 'gamma': 1000.0}               |        98       |
|  0.542609569062 | 0.0242715480267 |                {'kernel': 'rbf', 'C': 10.0, 'gamma': 1000.0}                 |        16       |
|  0.537365664548 | 0.0269444814376 |              {'kernel': 'linear', 'C': 10.0, 'gamma': 10000.0}               |        98       |
|  0.538528937039 | 0.0230561360076 |                {'kernel': 'rbf', 'C': 10.0, 'gamma': 10000.0}                |        96       |
|  0.538927756974 | 0.0387339711099 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 0.001}               |        87       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}                 |        18       |
|  0.538927756974 | 0.0387339711099 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 0.01}                |        87       |
|  0.539723363051 | 0.0241202000715 |                 {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}                 |        18       |
|  0.538927756974 | 0.0387339711099 |        {'kernel': 'linear', 'C': 100.0, 'gamma': 0.10000000000000001}        |        87       |
|  0.538544513799 | 0.0255985204899 |         {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.10000000000000001}          |        95       |
|  0.538927756974 | 0.0387339711099 |                {'kernel': 'linear', 'C': 100.0, 'gamma': 1.0}                |        87       |
|  0.562129771478 | 0.0415161312171 |                 {'kernel': 'rbf', 'C': 100.0, 'gamma': 1.0}                  |        2        |
|  0.538927756974 | 0.0387339711099 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 10.0}                |        87       |
|  0.534781891845 | 0.0577988741982 |                 {'kernel': 'rbf', 'C': 100.0, 'gamma': 10.0}                 |       109       |
|  0.538927756974 | 0.0387339711099 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 100.0}               |        87       |
|  0.552360013089 | 0.0367832195756 |                {'kernel': 'rbf', 'C': 100.0, 'gamma': 100.0}                 |        5        |
|  0.538927756974 | 0.0387339711099 |              {'kernel': 'linear', 'C': 100.0, 'gamma': 1000.0}               |        87       |
|  0.545471254786 | 0.0258752354681 |                {'kernel': 'rbf', 'C': 100.0, 'gamma': 1000.0}                |        11       |
|  0.538927756974 | 0.0387339711099 |              {'kernel': 'linear', 'C': 100.0, 'gamma': 10000.0}              |        87       |
|  0.543816512399 | 0.0330660203189 |               {'kernel': 'rbf', 'C': 100.0, 'gamma': 10000.0}                |        12       |
|  0.524559653836 | 0.0545345125127 |              {'kernel': 'linear', 'C': 1000.0, 'gamma': 0.001}               |       112       |
|  0.539723363051 | 0.0241202000715 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}                |        18       |
|  0.524559653836 | 0.0545345125127 |               {'kernel': 'linear', 'C': 1000.0, 'gamma': 0.01}               |       112       |
|  0.537365664548 | 0.0269444814376 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}                 |        98       |
|  0.524559653836 | 0.0545345125127 |       {'kernel': 'linear', 'C': 1000.0, 'gamma': 0.10000000000000001}        |       112       |
|  0.537038933596 | 0.0556083736045 |         {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.10000000000000001}         |       108       |
|  0.524559653836 | 0.0545345125127 |               {'kernel': 'linear', 'C': 1000.0, 'gamma': 1.0}                |       112       |
|  0.553880738686 | 0.0649002955932 |                 {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1.0}                 |        4        |
|  0.524559653836 | 0.0545345125127 |               {'kernel': 'linear', 'C': 1000.0, 'gamma': 10.0}               |       112       |
|  0.555581820429 | 0.0486307470688 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 10.0}                 |        3        |
|  0.524559653836 | 0.0545345125127 |              {'kernel': 'linear', 'C': 1000.0, 'gamma': 100.0}               |       112       |
|  0.548365686493 |  0.035596096758 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 100.0}                |        8        |
|  0.524559653836 | 0.0545345125127 |              {'kernel': 'linear', 'C': 1000.0, 'gamma': 1000.0}              |       112       |
|  0.547694993964 | 0.0449999813907 |               {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1000.0}                |        9        |
|  0.524559653836 | 0.0545345125127 |             {'kernel': 'linear', 'C': 1000.0, 'gamma': 10000.0}              |       112       |
|  0.543816512399 | 0.0330660203189 |               {'kernel': 'rbf', 'C': 1000.0, 'gamma': 10000.0}               |        12       |
|  0.510273852053 | 0.0398609000278 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 0.001}              |       120       |
|  0.537365664548 | 0.0269444814376 |               {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}                |        98       |
|  0.510273852053 | 0.0398609000278 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 0.01}               |       120       |
|  0.543801197889 | 0.0476003116949 |                {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}                |        15       |
|  0.510273852053 | 0.0398609000278 |       {'kernel': 'linear', 'C': 10000.0, 'gamma': 0.10000000000000001}       |       120       |
|  0.531468801316 | 0.0449704254008 |        {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.10000000000000001}         |       110       |
|  0.510273852053 | 0.0398609000278 |               {'kernel': 'linear', 'C': 10000.0, 'gamma': 1.0}               |       120       |
|  0.498277465154 | 0.0665909540466 |                {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1.0}                 |       128       |
|  0.510273852053 | 0.0398609000278 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 10.0}               |       120       |
|  0.540586729863 | 0.0471370477804 |                {'kernel': 'rbf', 'C': 10000.0, 'gamma': 10.0}                |        17       |
|  0.510273852053 | 0.0398609000278 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 100.0}              |       120       |
|  0.57601972237  | 0.0561307415084 |               {'kernel': 'rbf', 'C': 10000.0, 'gamma': 100.0}                |        1        |
|  0.510273852053 | 0.0398609000278 |             {'kernel': 'linear', 'C': 10000.0, 'gamma': 1000.0}              |       120       |
|  0.547694993964 | 0.0449999813907 |               {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1000.0}               |        9        |
|  0.510273852053 | 0.0398609000278 |             {'kernel': 'linear', 'C': 10000.0, 'gamma': 10000.0}             |       120       |
|  0.543816512399 | 0.0330660203189 |              {'kernel': 'rbf', 'C': 10000.0, 'gamma': 10000.0}               |        12       |
+-----------------+-----------------+------------------------------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'kernel': 'rbf', 'C': 10000.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.89      0.77        94
          1       0.27      0.10      0.15        40
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.54      0.64      0.57       138


Average accuracy on test set (using best parameters): 0.64

===================================================================
[ 0.68292683  0.26666667  0.          0.        ]
===================================================================

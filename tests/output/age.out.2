Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.536564637765 | 0.0209201402943 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      1.00      0.82        95
          1       0.00      0.00      0.00        36
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         3

avg / total       0.47      0.69      0.56       138


Accuracy on test set (using best parameters): 0.69

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.563778815064 | 0.0643788890547 |  {'n_neighbors': 3} |        1        |
|  0.549669751836 | 0.0549196111091 |  {'n_neighbors': 5} |        5        |
|  0.552912565778 |  0.03253428477  | {'n_neighbors': 11} |        4        |
|  0.553363777249 | 0.0241876387293 | {'n_neighbors': 21} |        3        |
|  0.557563408613 | 0.0241834601833 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.84      0.74        90
          1       0.32      0.17      0.22        41
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         2

avg / total       0.52      0.60      0.55       138


Accuracy on test set (using best parameters): 0.60

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.570057333503 | 0.0509283703175 | {'n_estimators': 2}  |        6        |
|  0.573637857232 | 0.0552725988535 | {'n_estimators': 3}  |        4        |
|  0.583296891116 | 0.0417156396442 | {'n_estimators': 5}  |        1        |
|  0.563250256235 | 0.0324669098434 | {'n_estimators': 10} |        7        |
|  0.572129143116 | 0.0288567930706 | {'n_estimators': 20} |        5        |
|  0.576248930403 | 0.0254338421799 | {'n_estimators': 40} |        2        |
|  0.576238103436 | 0.0231945331176 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.76      0.68        84
          1       0.32      0.25      0.28        44
          2       0.00      0.00      0.00         6
          3       0.00      0.00      0.00         4

avg / total       0.48      0.54      0.50       138


Accuracy on test set (using best parameters): 0.54

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.54915903167  |  0.027274705725 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.54915903167  |  0.027274705725 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        6        |
|  0.54915903167  |  0.027274705725 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        6        |
|  0.54915903167  |  0.027274705725 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        6        |
|  0.54915903167  |  0.027274705725 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        6        |
|  0.54915903167  |  0.027274705725 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        6        |
|  0.54915903167  |  0.027274705725 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        6        |
|  0.54915903167  |  0.027274705725 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        6        |
|  0.54915903167  |  0.027274705725 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.54915903167  |  0.027274705725 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.548429428324 | 0.0368181680071 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        19       |
|  0.554413342459 | 0.0351001234278 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        3        |
|  0.554689545833 | 0.0383775285813 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.549398148835 | 0.0384851151428 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.54915903167  |  0.027274705725 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        6        |
|  0.54915903167  |  0.027274705725 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        6        |
|  0.54915903167  |  0.027274705725 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.54796278021  | 0.0263028378956 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        21       |
|  0.550843510716 | 0.0360286185201 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.548403315346 | 0.0335618117279 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        20       |
|  0.559898066861 | 0.0310567788812 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      1.00      0.79        91
          1       0.00      0.00      0.00        40
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         2

avg / total       0.43      0.66      0.52       138


Accuracy on test set (using best parameters): 0.66

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.52412707724  | 0.0204819485286 |        {'C': 0.001}        |        4        |
|  0.52412707724  | 0.0204819485286 |        {'C': 0.01}         |        4        |
|  0.52412707724  | 0.0204819485286 | {'C': 0.10000000000000001} |        4        |
|  0.52412707724  | 0.0204819485286 |         {'C': 1.0}         |        4        |
|  0.529391972913 | 0.0185331884956 |        {'C': 10.0}         |        3        |
|  0.548737359288 | 0.0423350385424 |        {'C': 100.0}        |        1        |
|  0.544859783382 | 0.0502830032261 |       {'C': 1000.0}        |        2        |
|  0.510247861029 |  0.044238392247 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.96      0.82        99
          1       0.20      0.03      0.05        33
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         3

avg / total       0.56      0.70      0.60       138


Accuracy on test set (using best parameters): 0.70

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.524141935412 | 0.0220750555684 |               {'C': 0.001, 'gamma': 0.001}               |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 0.001, 'gamma': 0.01}                |        25       |
|  0.524141935412 | 0.0220750555684 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 0.001, 'gamma': 1.0}                |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 0.001, 'gamma': 10.0}                |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 0.001, 'gamma': 100.0}               |        25       |
|  0.524141935412 | 0.0220750555684 |              {'C': 0.001, 'gamma': 1000.0}               |        25       |
|  0.524141935412 | 0.0220750555684 |              {'C': 0.001, 'gamma': 10000.0}              |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 0.01, 'gamma': 0.001}                |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 0.01, 'gamma': 0.01}                |        25       |
|  0.524141935412 | 0.0220750555684 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 0.01, 'gamma': 1.0}                 |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 0.01, 'gamma': 10.0}                |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 0.01, 'gamma': 100.0}                |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 0.01, 'gamma': 1000.0}               |        25       |
|  0.524141935412 | 0.0220750555684 |              {'C': 0.01, 'gamma': 10000.0}               |        25       |
|  0.524141935412 | 0.0220750555684 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        25       |
|  0.524141935412 | 0.0220750555684 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        25       |
|  0.524141935412 | 0.0220750555684 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        25       |
|  0.524141935412 | 0.0220750555684 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        25       |
|  0.524141935412 | 0.0220750555684 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        25       |
|  0.524141935412 | 0.0220750555684 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        25       |
|  0.524141935412 | 0.0220750555684 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        25       |
|  0.524141935412 | 0.0220750555684 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 1.0, 'gamma': 0.001}                |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 1.0, 'gamma': 0.01}                 |        25       |
|  0.524141935412 | 0.0220750555684 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.524141935412 | 0.0220750555684 |                 {'C': 1.0, 'gamma': 1.0}                 |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 1.0, 'gamma': 10.0}                 |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 1.0, 'gamma': 100.0}                |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 10.0, 'gamma': 0.001}                |        25       |
|  0.524141935412 | 0.0220750555684 |                {'C': 10.0, 'gamma': 0.01}                |        25       |
|  0.524141935412 | 0.0220750555684 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.530824872333 | 0.0363297678318 |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|   0.5216381853  | 0.0389408665179 |                {'C': 10.0, 'gamma': 10.0}                |        63       |
|  0.534268427838 | 0.0314979251961 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.525544631196 | 0.0264208432159 |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.531086716986 | 0.0354151157016 |              {'C': 10.0, 'gamma': 10000.0}               |        16       |
|  0.524141935412 | 0.0220750555684 |               {'C': 100.0, 'gamma': 0.001}               |        25       |
|  0.524141935412 | 0.0220750555684 |               {'C': 100.0, 'gamma': 0.01}                |        25       |
|  0.528247144373 |  0.035059297494 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        19       |
|  0.535164302833 | 0.0637214190165 |                {'C': 100.0, 'gamma': 1.0}                |        9        |
|  0.534529282222 | 0.0530738022832 |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.535466388364 | 0.0396196138206 |               {'C': 100.0, 'gamma': 100.0}               |        8        |
|  0.52756865573  | 0.0349462932289 |              {'C': 100.0, 'gamma': 1000.0}               |        22       |
|  0.534851550932 | 0.0368207741482 |              {'C': 100.0, 'gamma': 10000.0}              |        10       |
|  0.524141935412 | 0.0220750555684 |              {'C': 1000.0, 'gamma': 0.001}               |        25       |
|  0.528247144373 |  0.035059297494 |               {'C': 1000.0, 'gamma': 0.01}               |        19       |
|  0.544875725613 | 0.0398447581449 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.513212392345 | 0.0537975413295 |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.533821333745 | 0.0696330433018 |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.539957237052 | 0.0386269050672 |              {'C': 1000.0, 'gamma': 100.0}               |        3        |
|  0.538127113505 | 0.0391020241182 |              {'C': 1000.0, 'gamma': 1000.0}              |        4        |
|  0.534851550932 | 0.0368207741482 |             {'C': 1000.0, 'gamma': 10000.0}              |        10       |
|  0.528247144373 |  0.035059297494 |              {'C': 10000.0, 'gamma': 0.001}              |        19       |
|  0.537716541501 |  0.061653027163 |              {'C': 10000.0, 'gamma': 0.01}               |        6        |
|  0.536807532046 | 0.0473111396655 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        7        |
|  0.530323366719 | 0.0610153930501 |               {'C': 10000.0, 'gamma': 1.0}               |        18       |
|  0.525416690564 |  0.071138542437 |              {'C': 10000.0, 'gamma': 10.0}               |        24       |
|  0.560392781571 | 0.0495348513501 |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.538127113505 | 0.0391020241182 |             {'C': 10000.0, 'gamma': 1000.0}              |        4        |
|  0.534851550932 | 0.0368207741482 |             {'C': 10000.0, 'gamma': 10000.0}             |        10       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.92      0.82        99
          1       0.43      0.17      0.24        36
          2       0.00      0.00      0.00         0
          3       0.00      0.00      0.00         3

avg / total       0.64      0.70      0.65       138


Accuracy on test set (using best parameters): 0.70


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.530318290974 | 0.0191268842508 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      1.00      0.83        97
          1       0.00      0.00      0.00        35
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         2

avg / total       0.49      0.70      0.58       138


Accuracy on test set (using best parameters): 0.70

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.560933749274 | 0.0480238878559 |  {'n_neighbors': 3} |        2        |
|  0.587252134676 | 0.0626246625741 |  {'n_neighbors': 5} |        1        |
|  0.556703710143 | 0.0508710957181 | {'n_neighbors': 11} |        3        |
|  0.532963025726 | 0.0262486983809 | {'n_neighbors': 21} |        4        |
|  0.530388049794 |  0.025182313332 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.81      0.74        97
          1       0.18      0.11      0.14        37
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.53      0.60      0.56       138


Accuracy on test set (using best parameters): 0.60

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.545516145012 | 0.0601975822615 | {'n_estimators': 2}  |        7        |
|  0.545537630869 | 0.0772870133716 | {'n_estimators': 3}  |        6        |
|  0.549484980886 | 0.0779410507052 | {'n_estimators': 5}  |        5        |
|  0.579432057325 | 0.0412813280466 | {'n_estimators': 10} |        1        |
|  0.55210197361  | 0.0350018000149 | {'n_estimators': 20} |        4        |
|  0.562758163588 | 0.0437459430167 | {'n_estimators': 40} |        2        |
|  0.557628978206 | 0.0518624826533 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.88      0.78        98
          1       0.20      0.08      0.12        36
          2       0.00      0.00      0.00         2
          3       0.00      0.00      0.00         2

avg / total       0.55      0.64      0.58       138


Accuracy on test set (using best parameters): 0.64

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.533511619917 | 0.0261345978706 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        5        |
|  0.533511619917 | 0.0261345978706 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        5        |
|  0.533511619917 | 0.0261345978706 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        5        |
|  0.533511619917 | 0.0261345978706 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        5        |
|  0.533511619917 | 0.0261345978706 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        5        |
|  0.533511619917 | 0.0261345978706 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        5        |
|  0.533511619917 | 0.0261345978706 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        5        |
|  0.53759225194  | 0.0279550977767 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        2        |
|  0.531153921414 | 0.0282479627467 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        17       |
|  0.526372797102 | 0.0282865395683 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        20       |
|  0.525528708638 | 0.0275828929607 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        21       |
|  0.533400233658 | 0.0476995636119 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        14       |
|  0.535264393491 | 0.0370911533044 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.551740874765 | 0.0553410787402 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.533511619917 | 0.0261345978706 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        5        |
|  0.533511619917 | 0.0261345978706 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.531153921414 | 0.0282479627467 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        17       |
|  0.536413402689 |  0.029154127907 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|  0.53331889088  | 0.0387695139567 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        15       |
|  0.532325094992 | 0.0374951909118 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        16       |
|  0.529291507549 | 0.0394260488675 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        19       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      1.00      0.82        96
          1       0.00      0.00      0.00        38
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.48      0.70      0.57       138


Accuracy on test set (using best parameters): 0.70

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.521017339423 | 0.0192474340537 |        {'C': 0.001}        |        3        |
|  0.521017339423 | 0.0192474340537 |        {'C': 0.01}         |        3        |
|  0.521017339423 | 0.0192474340537 | {'C': 0.10000000000000001} |        3        |
|  0.521017339423 | 0.0192474340537 |         {'C': 1.0}         |        3        |
|  0.526311424356 | 0.0295648039262 |        {'C': 10.0}         |        1        |
|  0.524043355435 | 0.0425361913084 |        {'C': 100.0}        |        2        |
|  0.517122349791 | 0.0516214903589 |       {'C': 1000.0}        |        8        |
|  0.51956455773  | 0.0825305113005 |       {'C': 10000.0}       |        7        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      1.00      0.84       100
          1       0.00      0.00      0.00        34
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.53      0.72      0.61       138


Accuracy on test set (using best parameters): 0.72

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.530304458667 | 0.0175398589189 |               {'C': 0.001, 'gamma': 0.001}               |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 0.001, 'gamma': 0.01}                |        16       |
|  0.530304458667 | 0.0175398589189 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 0.001, 'gamma': 1.0}                |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 0.001, 'gamma': 10.0}                |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 0.001, 'gamma': 100.0}               |        16       |
|  0.530304458667 | 0.0175398589189 |              {'C': 0.001, 'gamma': 1000.0}               |        16       |
|  0.530304458667 | 0.0175398589189 |              {'C': 0.001, 'gamma': 10000.0}              |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 0.01, 'gamma': 0.001}                |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 0.01, 'gamma': 0.01}                |        16       |
|  0.530304458667 | 0.0175398589189 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 0.01, 'gamma': 1.0}                 |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 0.01, 'gamma': 10.0}                |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 0.01, 'gamma': 100.0}                |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 0.01, 'gamma': 1000.0}               |        16       |
|  0.530304458667 | 0.0175398589189 |              {'C': 0.01, 'gamma': 10000.0}               |        16       |
|  0.530304458667 | 0.0175398589189 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        16       |
|  0.530304458667 | 0.0175398589189 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        16       |
|  0.530304458667 | 0.0175398589189 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        16       |
|  0.530304458667 | 0.0175398589189 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        16       |
|  0.530304458667 | 0.0175398589189 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        16       |
|  0.530304458667 | 0.0175398589189 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        16       |
|  0.530304458667 | 0.0175398589189 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        16       |
|  0.530304458667 | 0.0175398589189 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 1.0, 'gamma': 0.001}                |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 1.0, 'gamma': 0.01}                 |        16       |
|  0.530304458667 | 0.0175398589189 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        16       |
|  0.530304458667 | 0.0175398589189 |                 {'C': 1.0, 'gamma': 1.0}                 |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 1.0, 'gamma': 10.0}                 |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 1.0, 'gamma': 1000.0}                |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 1.0, 'gamma': 10000.0}               |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 10.0, 'gamma': 0.001}                |        16       |
|  0.530304458667 | 0.0175398589189 |                {'C': 10.0, 'gamma': 0.01}                |        16       |
|  0.530304458667 | 0.0175398589189 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        16       |
|  0.534321992583 | 0.0303768828725 |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.54146091029  | 0.0533231165234 |                {'C': 10.0, 'gamma': 10.0}                |        12       |
|   0.5497843405  | 0.0439446835513 |               {'C': 10.0, 'gamma': 100.0}                |        7        |
|  0.537914377748 | 0.0402826888829 |               {'C': 10.0, 'gamma': 1000.0}               |        14       |
|  0.529125609415 |  0.018945709644 |              {'C': 10.0, 'gamma': 10000.0}               |        54       |
|  0.530304458667 | 0.0175398589189 |               {'C': 100.0, 'gamma': 0.001}               |        16       |
|  0.530304458667 | 0.0175398589189 |               {'C': 100.0, 'gamma': 0.01}                |        16       |
|  0.527943218066 | 0.0194867242375 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        55       |
|  0.519045841819 | 0.0505631094861 |                {'C': 100.0, 'gamma': 1.0}                |        62       |
|  0.551091177019 | 0.0577760361625 |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.541285902343 | 0.0439660609152 |               {'C': 100.0, 'gamma': 100.0}               |        13       |
|  0.551346417257 |  0.042113371366 |              {'C': 100.0, 'gamma': 1000.0}               |        5        |
|  0.543755587702 | 0.0238714845676 |              {'C': 100.0, 'gamma': 10000.0}              |        8        |
|  0.530304458667 | 0.0175398589189 |              {'C': 1000.0, 'gamma': 0.001}               |        16       |
|  0.526754734472 | 0.0188307168845 |               {'C': 1000.0, 'gamma': 0.01}               |        57       |
|  0.517370640463 |  0.044628375357 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        63       |
|  0.542143355542 |  0.045993924032 |               {'C': 1000.0, 'gamma': 1.0}                |        11       |
|  0.523908377458 | 0.0476870936992 |               {'C': 1000.0, 'gamma': 10.0}               |        59       |
|  0.554989053362 |  0.040511277008 |              {'C': 1000.0, 'gamma': 100.0}               |        4        |
|  0.557057700549 | 0.0346886690996 |              {'C': 1000.0, 'gamma': 1000.0}              |        2        |
|  0.543755587702 | 0.0238714845676 |             {'C': 1000.0, 'gamma': 10000.0}              |        8        |
|  0.526754734472 | 0.0188307168845 |              {'C': 10000.0, 'gamma': 0.001}              |        57       |
|  0.521265761251 | 0.0565832245241 |              {'C': 10000.0, 'gamma': 0.01}               |        60       |
|  0.507709772217 | 0.0493914218138 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        64       |
|  0.519191305438 | 0.0527735671994 |               {'C': 10000.0, 'gamma': 1.0}               |        61       |
|  0.527447383363 | 0.0519651745793 |              {'C': 10000.0, 'gamma': 10.0}               |        56       |
|  0.57307032548  | 0.0522606779968 |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.557057700549 | 0.0346886690996 |             {'C': 10000.0, 'gamma': 1000.0}              |        2        |
|  0.543755587702 | 0.0238714845676 |             {'C': 10000.0, 'gamma': 10000.0}             |        8        |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.90      0.79        97
          1       0.27      0.12      0.17        33
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         3

avg / total       0.56      0.66      0.60       138


Accuracy on test set (using best parameters): 0.66


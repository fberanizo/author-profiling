Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.527194720851 | 0.0172342747534 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      1.00      0.83        98
          1       0.00      0.00      0.00        34
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         2

avg / total       0.50      0.71      0.59       138


Accuracy on test set (using best parameters): 0.71

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.578447231577 | 0.0558658298236 |  {'n_neighbors': 3} |        4        |
|  0.578283878817 | 0.0260307941727 |  {'n_neighbors': 5} |        5        |
|  0.584309600578 | 0.0258086865388 | {'n_neighbors': 11} |        3        |
|  0.589133264804 | 0.0235344603543 | {'n_neighbors': 21} |        2        |
|  0.59033632722  | 0.0242149739664 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      1.00      0.72        78
          1       0.00      0.00      0.00        51
          2       0.00      0.00      0.00         6
          3       0.00      0.00      0.00         3

avg / total       0.32      0.57      0.41       138


Accuracy on test set (using best parameters): 0.57

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.542999651643 | 0.0716338112862 | {'n_estimators': 2}  |        3        |
|  0.525313311233 | 0.0340939901638 | {'n_estimators': 3}  |        7        |
|  0.538817675853 | 0.0503172912938 | {'n_estimators': 5}  |        5        |
|  0.545803226447 |  0.040159020354 | {'n_estimators': 10} |        2        |
|  0.540468173722 | 0.0358659510723 | {'n_estimators': 20} |        4        |
|  0.548757087882 | 0.0419849726366 | {'n_estimators': 40} |        1        |
|  0.525939744887 | 0.0346047821954 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.95      0.81        98
          1       0.17      0.03      0.05        36
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.54      0.68      0.59       138


Accuracy on test set (using best parameters): 0.68

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.542891490269 | 0.0273095942867 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        13       |
|  0.542891490269 | 0.0273095942867 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        13       |
|  0.542891490269 | 0.0273095942867 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        13       |
|  0.542891490269 | 0.0273095942867 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        13       |
|  0.542891490269 | 0.0273095942867 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        13       |
|  0.542891490269 | 0.0273095942867 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        13       |
|  0.542891490269 | 0.0273095942867 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        13       |
|  0.555677169648 | 0.0369419296452 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.548380766298 | 0.0360211201024 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.552864557522 | 0.0390726573512 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.553340432585 | 0.0505316433988 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.55297008847  | 0.0621282424147 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.552280724085 | 0.0655750245494 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.554754578293 | 0.0675738290349 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.542891490269 | 0.0273095942867 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.541697064257 | 0.0265176070439 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        21       |
|  0.558298637652 | 0.0449344407961 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.553319471146 | 0.0398014538203 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.551428647849 | 0.0516943516042 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        10       |
|  0.543755048593 | 0.0526047463744 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        12       |
|  0.563266626845 | 0.0487969271308 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      1.00      0.81        93
          1       0.00      0.00      0.00        39
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         2

avg / total       0.45      0.67      0.54       138


Accuracy on test set (using best parameters): 0.67

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.53958494842  | 0.00701015909772 |        {'C': 0.001}        |        4        |
|  0.53958494842  | 0.00701015909772 |        {'C': 0.01}         |        4        |
|  0.53958494842  | 0.00701015909772 | {'C': 0.10000000000000001} |        4        |
|  0.53958494842  | 0.00701015909772 |         {'C': 1.0}         |        4        |
|  0.54488991118  | 0.0214198000408  |        {'C': 10.0}         |        3        |
|  0.567642719171 |  0.053985742092  |        {'C': 100.0}        |        1        |
|  0.557876323194 |  0.061470981174  |       {'C': 1000.0}        |        2        |
|  0.536899215434 | 0.0838373344933  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.89      0.77        94
          1       0.29      0.12      0.17        34
          2       0.00      0.00      0.00         8
          3       0.00      0.00      0.00         2

avg / total       0.54      0.64      0.57       138


Accuracy on test set (using best parameters): 0.64

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.558542406191 | 0.0232975047098 |               {'C': 0.001, 'gamma': 0.001}               |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 0.001, 'gamma': 0.01}                |        21       |
|  0.558542406191 | 0.0232975047098 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 0.001, 'gamma': 1.0}                |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 0.001, 'gamma': 10.0}                |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 0.001, 'gamma': 100.0}               |        21       |
|  0.558542406191 | 0.0232975047098 |              {'C': 0.001, 'gamma': 1000.0}               |        21       |
|  0.558542406191 | 0.0232975047098 |              {'C': 0.001, 'gamma': 10000.0}              |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 0.01, 'gamma': 0.001}                |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 0.01, 'gamma': 0.01}                |        21       |
|  0.558542406191 | 0.0232975047098 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 0.01, 'gamma': 1.0}                 |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 0.01, 'gamma': 10.0}                |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 0.01, 'gamma': 100.0}                |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 0.01, 'gamma': 1000.0}               |        21       |
|  0.558542406191 | 0.0232975047098 |              {'C': 0.01, 'gamma': 10000.0}               |        21       |
|  0.558542406191 | 0.0232975047098 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        21       |
|  0.558542406191 | 0.0232975047098 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        21       |
|  0.558542406191 | 0.0232975047098 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        21       |
|  0.558542406191 | 0.0232975047098 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        21       |
|  0.558542406191 | 0.0232975047098 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        21       |
|  0.558542406191 | 0.0232975047098 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        21       |
|  0.558542406191 | 0.0232975047098 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        21       |
|  0.558542406191 | 0.0232975047098 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 1.0, 'gamma': 0.001}                |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 1.0, 'gamma': 0.01}                 |        21       |
|  0.558542406191 | 0.0232975047098 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.558542406191 | 0.0232975047098 |                 {'C': 1.0, 'gamma': 1.0}                 |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 1.0, 'gamma': 10.0}                 |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 1.0, 'gamma': 100.0}                |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 1.0, 'gamma': 1000.0}                |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 1.0, 'gamma': 10000.0}               |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 10.0, 'gamma': 0.001}                |        21       |
|  0.558542406191 | 0.0232975047098 |                {'C': 10.0, 'gamma': 0.01}                |        21       |
|  0.558542406191 | 0.0232975047098 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.562641921584 | 0.0361847390207 |                {'C': 10.0, 'gamma': 1.0}                 |        18       |
|  0.578556879884 | 0.0516314038716 |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.552264477381 | 0.0301039332746 |               {'C': 10.0, 'gamma': 100.0}                |        61       |
|  0.560250132548 |  0.029929556016 |               {'C': 10.0, 'gamma': 1000.0}               |        20       |
|  0.558542406191 | 0.0232975047098 |              {'C': 10.0, 'gamma': 10000.0}               |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 100.0, 'gamma': 0.001}               |        21       |
|  0.558542406191 | 0.0232975047098 |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.567503941636 |  0.030346546002 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.589012109004 | 0.0282436335222 |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.571511947825 | 0.0692087700105 |               {'C': 100.0, 'gamma': 10.0}                |        10       |
|  0.570205647989 | 0.0453234402546 |               {'C': 100.0, 'gamma': 100.0}               |        11       |
|  0.562348769688 | 0.0260890830602 |              {'C': 100.0, 'gamma': 1000.0}               |        19       |
|  0.572105996203 |  0.028790159588 |              {'C': 100.0, 'gamma': 10000.0}              |        7        |
|  0.558542406191 | 0.0232975047098 |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.572777710934 | 0.0321279981891 |               {'C': 1000.0, 'gamma': 0.01}               |        5        |
|  0.568343120269 | 0.0372111349103 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.542476648224 | 0.0354316912384 |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.562643618085 | 0.0602916244429 |               {'C': 1000.0, 'gamma': 10.0}               |        17       |
|  0.556221850535 | 0.0237711658893 |              {'C': 1000.0, 'gamma': 100.0}               |        60       |
|  0.566930648308 | 0.0310364735029 |              {'C': 1000.0, 'gamma': 1000.0}              |        14       |
|  0.572105996203 |  0.028790159588 |             {'C': 1000.0, 'gamma': 10000.0}              |        7        |
|  0.572777710934 | 0.0321279981891 |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.583106135513 | 0.0538934023621 |              {'C': 10000.0, 'gamma': 0.01}               |        3        |
|  0.55013426479  | 0.0312830263748 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        62       |
|  0.527977446134 | 0.0556747593925 |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.566360477469 | 0.0552532392571 |              {'C': 10000.0, 'gamma': 10.0}               |        16       |
|  0.584274981524 |  0.043565145606 |              {'C': 10000.0, 'gamma': 100.0}              |        2        |
|  0.566930648308 | 0.0310364735029 |             {'C': 10000.0, 'gamma': 1000.0}              |        14       |
|  0.572105996203 |  0.028790159588 |             {'C': 10000.0, 'gamma': 10000.0}             |        7        |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.86      0.72        88
          1       0.19      0.07      0.10        46
          2       0.00      0.00      0.00         4

avg / total       0.46      0.57      0.49       138


Accuracy on test set (using best parameters): 0.57


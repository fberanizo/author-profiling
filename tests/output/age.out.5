Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.55228572107  | 0.0266646168744 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      1.00      0.79        90
          1       0.00      0.00      0.00        46
          2       0.00      0.00      0.00         1
          3       0.00      0.00      0.00         1

avg / total       0.43      0.65      0.51       138


Accuracy on test set (using best parameters): 0.65

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.547583054691 | 0.0587668288493 |  {'n_neighbors': 3} |        1        |
|  0.54729573389  | 0.0427385676971 |  {'n_neighbors': 5} |        2        |
|  0.542110422268 | 0.0412719038982 | {'n_neighbors': 11} |        4        |
|  0.541697064257 | 0.0265176070439 | {'n_neighbors': 21} |        5        |
|  0.542891490269 | 0.0273095942867 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.89      0.77        93
          1       0.40      0.15      0.22        40
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         2

avg / total       0.57      0.64      0.58       138


Accuracy on test set (using best parameters): 0.64

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.552402742171 | 0.0341576102222 | {'n_estimators': 2}  |        2        |
|  0.559691765365 | 0.0693357763124 | {'n_estimators': 3}  |        1        |
|  0.541425369408 | 0.0587984001214 | {'n_estimators': 5}  |        5        |
|  0.549003819556 |  0.059314250799 | {'n_estimators': 10} |        3        |
|  0.542397671194 | 0.0415064617089 | {'n_estimators': 20} |        4        |
|  0.539959489086 | 0.0427146264131 | {'n_estimators': 40} |        6        |
|  0.534670342841 | 0.0386748631462 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.77      0.72        99
          1       0.09      0.06      0.07        36
          2       0.00      0.00      0.00         1
          3       0.00      0.00      0.00         2

avg / total       0.51      0.57      0.53       138


Accuracy on test set (using best parameters): 0.57

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.536611595145 | 0.0249016041914 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        10       |
|  0.536611595145 | 0.0249016041914 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        10       |
|  0.536611595145 | 0.0249016041914 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        10       |
|  0.536611595145 | 0.0249016041914 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        10       |
|  0.536611595145 | 0.0249016041914 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        10       |
|  0.536611595145 | 0.0249016041914 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        10       |
|  0.536611595145 | 0.0249016041914 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        10       |
|  0.534219727099 | 0.0279135321581 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        17       |
|  0.537368323481 | 0.0242930698341 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.542960845865 | 0.0328385357602 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.543696940671 | 0.0391764191476 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.548073494774 | 0.0475594172309 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.550176265625 | 0.0431710131707 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.552724797595 | 0.0508776262125 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.534219727099 | 0.0279135321581 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        17       |
|  0.534219727099 | 0.0279135321581 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        17       |
|  0.534219727099 | 0.0279135321581 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        17       |
|  0.534219727099 | 0.0279135321581 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        17       |
|  0.551391785098 | 0.0517411018149 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.549582305768 | 0.0464288716124 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.553351707712 | 0.0461441050621 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      1.00      0.82        95
          1       0.00      0.00      0.00        39
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.47      0.69      0.56       138


Accuracy on test set (using best parameters): 0.69

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.549113550185 | 0.0238151223172 |        {'C': 0.001}        |        1        |
|  0.549113550185 | 0.0238151223172 |        {'C': 0.01}         |        1        |
|  0.549113550185 | 0.0238151223172 | {'C': 0.10000000000000001} |        1        |
|  0.549113550185 | 0.0238151223172 |         {'C': 1.0}         |        1        |
|  0.549113550185 | 0.0238151223172 |        {'C': 10.0}         |        1        |
|  0.545072530217 | 0.0275719015446 |        {'C': 100.0}        |        6        |
|  0.531329256486 | 0.0510312462465 |       {'C': 1000.0}        |        8        |
|  0.534792217493 | 0.0906744457185 |       {'C': 10000.0}       |        7        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      1.00      0.79        91
          1       0.00      0.00      0.00        42
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         1

avg / total       0.43      0.66      0.52       138


Accuracy on test set (using best parameters): 0.66

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.552259427468 |  0.024250393137 |               {'C': 0.001, 'gamma': 0.001}               |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 0.001, 'gamma': 0.01}                |        18       |
|  0.552259427468 |  0.024250393137 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 0.001, 'gamma': 1.0}                |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 0.001, 'gamma': 10.0}                |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 0.001, 'gamma': 100.0}               |        18       |
|  0.552259427468 |  0.024250393137 |              {'C': 0.001, 'gamma': 1000.0}               |        18       |
|  0.552259427468 |  0.024250393137 |              {'C': 0.001, 'gamma': 10000.0}              |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 0.01, 'gamma': 0.001}                |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 0.01, 'gamma': 0.01}                |        18       |
|  0.552259427468 |  0.024250393137 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 0.01, 'gamma': 1.0}                 |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 0.01, 'gamma': 10.0}                |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 0.01, 'gamma': 100.0}                |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 0.01, 'gamma': 1000.0}               |        18       |
|  0.552259427468 |  0.024250393137 |              {'C': 0.01, 'gamma': 10000.0}               |        18       |
|  0.552259427468 |  0.024250393137 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        18       |
|  0.552259427468 |  0.024250393137 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        18       |
|  0.552259427468 |  0.024250393137 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        18       |
|  0.552259427468 |  0.024250393137 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        18       |
|  0.552259427468 |  0.024250393137 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        18       |
|  0.552259427468 |  0.024250393137 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        18       |
|  0.552259427468 |  0.024250393137 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        18       |
|  0.552259427468 |  0.024250393137 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 1.0, 'gamma': 0.001}                |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 1.0, 'gamma': 0.01}                 |        18       |
|  0.552259427468 |  0.024250393137 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.552259427468 |  0.024250393137 |                 {'C': 1.0, 'gamma': 1.0}                 |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 1.0, 'gamma': 1000.0}                |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 1.0, 'gamma': 10000.0}               |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 10.0, 'gamma': 0.001}                |        18       |
|  0.552259427468 |  0.024250393137 |                {'C': 10.0, 'gamma': 0.01}                |        18       |
|  0.552259427468 |  0.024250393137 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.548688075295 | 0.0243583665642 |                {'C': 10.0, 'gamma': 1.0}                 |        60       |
|  0.554276948169 | 0.0595242554967 |                {'C': 10.0, 'gamma': 10.0}                |        17       |
|  0.562522476854 | 0.0403611517976 |               {'C': 10.0, 'gamma': 100.0}                |        13       |
|  0.571068496895 | 0.0278212921442 |               {'C': 10.0, 'gamma': 1000.0}               |        6        |
|  0.556378619284 |  0.034935867701 |              {'C': 10.0, 'gamma': 10000.0}               |        16       |
|  0.552259427468 |  0.024250393137 |               {'C': 100.0, 'gamma': 0.001}               |        18       |
|  0.552259427468 |  0.024250393137 |               {'C': 100.0, 'gamma': 0.01}                |        18       |
|  0.549866924547 | 0.0222691347417 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        57       |
|  0.572657643732 |  0.029496855626 |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.557566437142 |  0.073903260607 |               {'C': 100.0, 'gamma': 10.0}                |        15       |
|  0.569303588379 | 0.0413099097109 |               {'C': 100.0, 'gamma': 100.0}               |        8        |
|  0.564510617021 |  0.032198583982 |              {'C': 100.0, 'gamma': 1000.0}               |        12       |
|  0.566927198099 | 0.0404762108077 |              {'C': 100.0, 'gamma': 10000.0}              |        9        |
|  0.552259427468 |  0.024250393137 |              {'C': 1000.0, 'gamma': 0.001}               |        18       |
|  0.549866924547 | 0.0222691347417 |               {'C': 1000.0, 'gamma': 0.01}               |        57       |
|  0.549722455524 | 0.0426774628893 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        59       |
|  0.541361949317 |  0.07312459636  |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.561200956381 | 0.0621234359285 |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.570440770456 | 0.0550179366183 |              {'C': 1000.0, 'gamma': 100.0}               |        7        |
|  0.572342676845 | 0.0364120875244 |              {'C': 1000.0, 'gamma': 1000.0}              |        4        |
|  0.566927198099 | 0.0404762108077 |             {'C': 1000.0, 'gamma': 10000.0}              |        9        |
|  0.548670673086 | 0.0211077641378 |              {'C': 10000.0, 'gamma': 0.001}              |        61       |
|  0.549934653604 | 0.0329297679316 |              {'C': 10000.0, 'gamma': 0.01}               |        56       |
|  0.544396397988 | 0.0558009391197 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        62       |
|  0.520478780361 | 0.0579252791442 |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.594806246089 | 0.0521555386626 |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.575631576768 | 0.0554700603226 |              {'C': 10000.0, 'gamma': 100.0}              |        2        |
|  0.572342676845 | 0.0364120875244 |             {'C': 10000.0, 'gamma': 1000.0}              |        4        |
|  0.566927198099 | 0.0404762108077 |             {'C': 10000.0, 'gamma': 10000.0}             |        9        |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.62      0.65        90
          1       0.33      0.30      0.31        43
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         2

avg / total       0.54      0.50      0.52       138


Accuracy on test set (using best parameters): 0.50


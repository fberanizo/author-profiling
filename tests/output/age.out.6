Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.520994770394 | 0.0169377346292 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      1.00      0.84       100
          1       0.00      0.00      0.00        34
          2       0.00      0.00      0.00         4

avg / total       0.53      0.72      0.61       138


Accuracy on test set (using best parameters): 0.72

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.548864395863 |  0.065602371557 |  {'n_neighbors': 3} |        1        |
|  0.547389742858 | 0.0615755382721 |  {'n_neighbors': 5} |        2        |
|  0.53739714715  | 0.0339862588179 | {'n_neighbors': 11} |        3        |
|  0.537348812371 | 0.0375926666386 | {'n_neighbors': 21} |        4        |
|  0.530388049794 |  0.025182313332 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.84      0.76        97
          1       0.14      0.08      0.10        37
          2       0.00      0.00      0.00         2
          3       0.00      0.00      0.00         2

avg / total       0.53      0.61      0.56       138


Accuracy on test set (using best parameters): 0.61

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.551781013236 |  0.035820483966 | {'n_estimators': 2}  |        5        |
|  0.565840897318 | 0.0787052501779 | {'n_estimators': 3}  |        1        |
|  0.543112232239 | 0.0489941752232 | {'n_estimators': 5}  |        6        |
|  0.561588004247 | 0.0406224064279 | {'n_estimators': 10} |        2        |
|  0.552888290363 | 0.0577393762682 | {'n_estimators': 20} |        4        |
|  0.559300277913 |  0.03432425255  | {'n_estimators': 40} |        3        |
|  0.533070254178 | 0.0297886663995 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.83      0.75        93
          1       0.38      0.24      0.30        41
          2       0.00      0.00      0.00         4

avg / total       0.58      0.63      0.60       138


Accuracy on test set (using best parameters): 0.63

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.52724191064  | 0.0219652530949 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        8        |
|  0.52724191064  | 0.0219652530949 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        8        |
|  0.52724191064  | 0.0219652530949 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        8        |
|  0.52724191064  | 0.0219652530949 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        8        |
|  0.52724191064  | 0.0219652530949 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        8        |
|  0.52724191064  | 0.0219652530949 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        8        |
|  0.52724191064  | 0.0219652530949 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        8        |
|  0.526063061389 | 0.0229465692784 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        17       |
|  0.52488069499  | 0.0233775436701 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        19       |
|  0.530555532667 | 0.0292824658013 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        4        |
|  0.534688835714 | 0.0462006672035 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.534753505392 | 0.0533386066016 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.530422151425 | 0.0499415652761 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
|  0.527416534453 | 0.0444299717648 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|  0.52724191064  | 0.0219652530949 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.526063061389 | 0.0229465692784 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        17       |
|  0.524874577795 | 0.0222921386995 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        20       |
|  0.52654474721  | 0.0253188487436 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        16       |
|  0.524113684993 | 0.0276039679402 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        21       |
|  0.529401260353 | 0.0384213326323 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.539948316989 | 0.0463609080325 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      1.00      0.83        98
          1       0.00      0.00      0.00        36
          2       0.00      0.00      0.00         4

avg / total       0.50      0.71      0.59       138


Accuracy on test set (using best parameters): 0.71

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.549059624826 | 0.0190972501737 |        {'C': 0.001}        |        2        |
|  0.549059624826 | 0.0190972501737 |        {'C': 0.01}         |        2        |
|  0.549059624826 | 0.0190972501737 | {'C': 0.10000000000000001} |        2        |
|  0.549059624826 | 0.0190972501737 |         {'C': 1.0}         |        2        |
|  0.549059624826 | 0.0190972501737 |        {'C': 10.0}         |        2        |
|  0.555409142189 | 0.0267283843457 |        {'C': 100.0}        |        1        |
|  0.544612330825 | 0.0598341392938 |       {'C': 1000.0}        |        7        |
|  0.514261577427 | 0.0424925336397 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.97      0.78        91
          1       0.00      0.00      0.00        36
          2       0.00      0.00      0.00         9
          3       0.00      0.00      0.00         2

avg / total       0.43      0.64      0.51       138


Accuracy on test set (using best parameters): 0.64

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.524171248055 | 0.0240417730562 |               {'C': 0.001, 'gamma': 0.001}               |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 0.001, 'gamma': 0.01}                |        24       |
|  0.524171248055 | 0.0240417730562 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        24       |
|  0.524171248055 | 0.0240417730562 |                {'C': 0.001, 'gamma': 1.0}                |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 0.001, 'gamma': 10.0}                |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 0.001, 'gamma': 100.0}               |        24       |
|  0.524171248055 | 0.0240417730562 |              {'C': 0.001, 'gamma': 1000.0}               |        24       |
|  0.524171248055 | 0.0240417730562 |              {'C': 0.001, 'gamma': 10000.0}              |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 0.01, 'gamma': 0.001}                |        24       |
|  0.524171248055 | 0.0240417730562 |                {'C': 0.01, 'gamma': 0.01}                |        24       |
|  0.524171248055 | 0.0240417730562 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        24       |
|  0.524171248055 | 0.0240417730562 |                {'C': 0.01, 'gamma': 1.0}                 |        24       |
|  0.524171248055 | 0.0240417730562 |                {'C': 0.01, 'gamma': 10.0}                |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 0.01, 'gamma': 100.0}                |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 0.01, 'gamma': 1000.0}               |        24       |
|  0.524171248055 | 0.0240417730562 |              {'C': 0.01, 'gamma': 10000.0}               |        24       |
|  0.524171248055 | 0.0240417730562 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        24       |
|  0.524171248055 | 0.0240417730562 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        24       |
|  0.524171248055 | 0.0240417730562 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        24       |
|  0.524171248055 | 0.0240417730562 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        24       |
|  0.524171248055 | 0.0240417730562 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        24       |
|  0.524171248055 | 0.0240417730562 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        24       |
|  0.524171248055 | 0.0240417730562 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        24       |
|  0.524171248055 | 0.0240417730562 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        24       |
|  0.524171248055 | 0.0240417730562 |                {'C': 1.0, 'gamma': 0.001}                |        24       |
|  0.524171248055 | 0.0240417730562 |                {'C': 1.0, 'gamma': 0.01}                 |        24       |
|  0.524171248055 | 0.0240417730562 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.524171248055 | 0.0240417730562 |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.522982764461 | 0.0233217597881 |                {'C': 1.0, 'gamma': 10.0}                 |        61       |
|  0.524171248055 | 0.0240417730562 |                {'C': 1.0, 'gamma': 100.0}                |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 1.0, 'gamma': 1000.0}                |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 1.0, 'gamma': 10000.0}               |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 10.0, 'gamma': 0.001}                |        24       |
|  0.524171248055 | 0.0240417730562 |                {'C': 10.0, 'gamma': 0.01}                |        24       |
|  0.524171248055 | 0.0240417730562 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.541440030136 | 0.0427487270792 |                {'C': 10.0, 'gamma': 1.0}                 |        6        |
|  0.531540336458 |  0.045589740617 |                {'C': 10.0, 'gamma': 10.0}                |        17       |
|  0.52834452804  | 0.0451421528688 |               {'C': 10.0, 'gamma': 100.0}                |        19       |
|  0.525591473942 | 0.0227814622965 |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.534684064736 | 0.0216128149942 |              {'C': 10.0, 'gamma': 10000.0}               |        12       |
|  0.524171248055 | 0.0240417730562 |               {'C': 100.0, 'gamma': 0.001}               |        24       |
|  0.524171248055 | 0.0240417730562 |               {'C': 100.0, 'gamma': 0.01}                |        24       |
|  0.52590305316  | 0.0358233341892 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        22       |
|  0.549385790983 | 0.0503874754209 |                {'C': 100.0, 'gamma': 1.0}                |        2        |
|  0.529851447212 | 0.0681617006896 |               {'C': 100.0, 'gamma': 10.0}                |        18       |
|  0.53295817545  | 0.0391449952488 |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.537091583906 | 0.0286948772749 |              {'C': 100.0, 'gamma': 1000.0}               |        9        |
|  0.534684064736 | 0.0216128149942 |              {'C': 100.0, 'gamma': 10000.0}              |        12       |
|  0.524171248055 | 0.0240417730562 |              {'C': 1000.0, 'gamma': 0.001}               |        24       |
|  0.525934395692 | 0.0350427552117 |               {'C': 1000.0, 'gamma': 0.01}               |        21       |
|  0.545748147724 | 0.0632163723204 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.512630761842 | 0.0387555830334 |               {'C': 1000.0, 'gamma': 1.0}                |        62       |
|  0.543268751555 | 0.0697413105308 |               {'C': 1000.0, 'gamma': 10.0}               |        5        |
|  0.546503646833 | 0.0431782671656 |              {'C': 1000.0, 'gamma': 100.0}               |        3        |
|  0.537091583906 | 0.0286948772749 |              {'C': 1000.0, 'gamma': 1000.0}              |        9        |
|  0.534684064736 | 0.0216128149942 |             {'C': 1000.0, 'gamma': 10000.0}              |        12       |
|  0.527122879286 | 0.0354271242738 |              {'C': 10000.0, 'gamma': 0.001}              |        20       |
|  0.538496371617 | 0.0637609017984 |              {'C': 10000.0, 'gamma': 0.01}               |        7        |
|  0.499234880901 | 0.0577233666934 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.478352736539 |  0.064893017417 |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.537415077256 | 0.0667439368564 |              {'C': 10000.0, 'gamma': 10.0}               |        8        |
|  0.553271380417 | 0.0371479493581 |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.537091583906 | 0.0286948772749 |             {'C': 10000.0, 'gamma': 1000.0}              |        9        |
|  0.534684064736 | 0.0216128149942 |             {'C': 10000.0, 'gamma': 10000.0}             |        12       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.89      0.80        99
          1       0.38      0.19      0.25        32
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         3

avg / total       0.61      0.68      0.63       138


Accuracy on test set (using best parameters): 0.68


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.533511619917 | 0.0261345978706 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      1.00      0.82        96
          1       0.00      0.00      0.00        38
          2       0.00      0.00      0.00         2
          3       0.00      0.00      0.00         2

avg / total       0.48      0.70      0.57       138


Accuracy on test set (using best parameters): 0.70

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+------------------+---------------------+-----------------+
| test_mean_score |  test_std_score  |        params       | test_rank_score |
+-----------------+------------------+---------------------+-----------------+
|  0.533542533418 | 0.0614406335496  |  {'n_neighbors': 3} |        5        |
|  0.559478199463 | 0.0473627242363  |  {'n_neighbors': 5} |        2        |
|   0.5715938076  | 0.0398919905652  | {'n_neighbors': 11} |        1        |
|  0.538888128697 | 0.0167234678872  | {'n_neighbors': 21} |        3        |
|  0.538396464826 | 0.00718872857429 | {'n_neighbors': 31} |        4        |
+-----------------+------------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.99      0.81        94
          1       0.00      0.00      0.00        34
          2       0.00      0.00      0.00         8
          3       0.00      0.00      0.00         2

avg / total       0.46      0.67      0.55       138


Accuracy on test set (using best parameters): 0.67

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.557713006304 | 0.0499487161565 | {'n_estimators': 2}  |        3        |
|  0.569048891237 | 0.0369120035294 | {'n_estimators': 3}  |        2        |
|  0.58567383981  | 0.0556950864021 | {'n_estimators': 5}  |        1        |
|  0.55214539409  |  0.042240193768 | {'n_estimators': 10} |        4        |
|  0.534281350667 | 0.0366577228116 | {'n_estimators': 20} |        7        |
|  0.540068998694 | 0.0348702492691 | {'n_estimators': 40} |        5        |
|  0.53968791534  | 0.0300414000032 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.85      0.76        94
          1       0.29      0.17      0.21        36
          2       0.00      0.00      0.00         7
          3       0.00      0.00      0.00         1

avg / total       0.54      0.62      0.57       138


Accuracy on test set (using best parameters): 0.62

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.571192129453 | 0.0227420292058 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        9        |
|  0.571192129453 | 0.0227420292058 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        9        |
|  0.571192129453 | 0.0227420292058 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        9        |
|  0.571192129453 | 0.0227420292058 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        9        |
|  0.571192129453 | 0.0227420292058 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        9        |
|  0.571192129453 | 0.0227420292058 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        9        |
|  0.571192129453 | 0.0227420292058 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        9        |
|  0.571192129453 | 0.0227420292058 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        9        |
|  0.570005093749 | 0.0244032832524 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        19       |
|  0.567190455934 |  0.025693830426 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        21       |
|  0.57559373978  | 0.0286808011242 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.581898130495 | 0.0371052571638 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.581409603545 | 0.0423564122943 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.582866121932 | 0.0491587377256 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.571192129453 | 0.0227420292058 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.571192129453 | 0.0227420292058 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.568807187315 |  0.023874651603 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        20       |
|  0.574102155166 | 0.0294271117323 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.574997663264 | 0.0330028564353 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.577757083076 | 0.0376488917996 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.575506128585 | 0.0335898329969 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        6        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        84
          1       0.00      0.00      0.00        47
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         2

avg / total       0.37      0.61      0.46       138


Accuracy on test set (using best parameters): 0.61

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.524117314652 | 0.0196214251051 |        {'C': 0.001}        |        4        |
|  0.524117314652 | 0.0196214251051 |        {'C': 0.01}         |        4        |
|  0.524117314652 | 0.0196214251051 | {'C': 0.10000000000000001} |        4        |
|  0.524117314652 | 0.0196214251051 |         {'C': 1.0}         |        4        |
|  0.524117314652 | 0.0196214251051 |        {'C': 10.0}         |        4        |
|  0.539653898823 | 0.0442918254225 |        {'C': 100.0}        |        1        |
|  0.524475166634 | 0.0380760179748 |       {'C': 1000.0}        |        3        |
|  0.528069051161 | 0.0398525171019 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.95      0.82        99
          1       0.38      0.09      0.14        34
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         2

avg / total       0.62      0.70      0.63       138


Accuracy on test set (using best parameters): 0.70

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.54913580012  | 0.0255129339654 |               {'C': 0.001, 'gamma': 0.001}               |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 0.001, 'gamma': 0.01}                |        24       |
|  0.54913580012  | 0.0255129339654 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 0.001, 'gamma': 1.0}                |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 0.001, 'gamma': 10.0}                |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 0.001, 'gamma': 100.0}               |        24       |
|  0.54913580012  | 0.0255129339654 |              {'C': 0.001, 'gamma': 1000.0}               |        24       |
|  0.54913580012  | 0.0255129339654 |              {'C': 0.001, 'gamma': 10000.0}              |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 0.01, 'gamma': 0.001}                |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 0.01, 'gamma': 0.01}                |        24       |
|  0.54913580012  | 0.0255129339654 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 0.01, 'gamma': 1.0}                 |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 0.01, 'gamma': 10.0}                |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 0.01, 'gamma': 100.0}                |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 0.01, 'gamma': 1000.0}               |        24       |
|  0.54913580012  | 0.0255129339654 |              {'C': 0.01, 'gamma': 10000.0}               |        24       |
|  0.54913580012  | 0.0255129339654 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        24       |
|  0.54913580012  | 0.0255129339654 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        24       |
|  0.54913580012  | 0.0255129339654 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        24       |
|  0.54913580012  | 0.0255129339654 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        24       |
|  0.54913580012  | 0.0255129339654 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        24       |
|  0.54913580012  | 0.0255129339654 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        24       |
|  0.54913580012  | 0.0255129339654 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        24       |
|  0.54913580012  | 0.0255129339654 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 1.0, 'gamma': 0.001}                |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 1.0, 'gamma': 0.01}                 |        24       |
|  0.54913580012  | 0.0255129339654 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.54913580012  | 0.0255129339654 |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 1.0, 'gamma': 10.0}                 |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 1.0, 'gamma': 100.0}                |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 1.0, 'gamma': 1000.0}                |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 1.0, 'gamma': 10000.0}               |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 10.0, 'gamma': 0.001}                |        24       |
|  0.54913580012  | 0.0255129339654 |                {'C': 10.0, 'gamma': 0.01}                |        24       |
|  0.54913580012  | 0.0255129339654 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.556864996003 | 0.0282343298903 |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.563285928757 |  0.057530400813 |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.551396144066 | 0.0152354442905 |               {'C': 10.0, 'gamma': 100.0}                |        21       |
|  0.546353973912 | 0.0260580260006 |               {'C': 10.0, 'gamma': 1000.0}               |        64       |
|  0.559683338717 |  0.034718189818 |              {'C': 10.0, 'gamma': 10000.0}               |        10       |
|  0.54913580012  | 0.0255129339654 |               {'C': 100.0, 'gamma': 0.001}               |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 100.0, 'gamma': 0.01}                |        24       |
|  0.549903422888 | 0.0245231727129 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        23       |
|  0.594657430167 | 0.0399224038376 |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.565973158847 | 0.0653364720159 |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.555185758338 | 0.0427490393089 |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.55914021167  | 0.0315097359956 |              {'C': 100.0, 'gamma': 1000.0}               |        14       |
|  0.559683338717 |  0.034718189818 |              {'C': 100.0, 'gamma': 10000.0}              |        10       |
|  0.54913580012  | 0.0255129339654 |              {'C': 1000.0, 'gamma': 0.001}               |        24       |
|  0.54913580012  | 0.0255129339654 |               {'C': 1000.0, 'gamma': 0.01}               |        24       |
|  0.551930748239 | 0.0388928807031 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        20       |
|  0.563088635398 | 0.0532207958585 |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.582684022748 | 0.0810984750653 |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.573071711955 | 0.0341102965115 |              {'C': 1000.0, 'gamma': 100.0}               |        5        |
|  0.55914021167  | 0.0315097359956 |              {'C': 1000.0, 'gamma': 1000.0}              |        14       |
|  0.559683338717 |  0.034718189818 |             {'C': 1000.0, 'gamma': 10000.0}              |        10       |
|  0.54913580012  | 0.0255129339654 |              {'C': 10000.0, 'gamma': 0.001}              |        24       |
|  0.554758886958 |  0.049976733755 |              {'C': 10000.0, 'gamma': 0.01}               |        19       |
|   0.5744116836  | 0.0471555275984 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.550301851393 | 0.0794218588283 |               {'C': 10000.0, 'gamma': 1.0}               |        22       |
|  0.564749203193 | 0.0718599054302 |              {'C': 10000.0, 'gamma': 10.0}               |        7        |
|  0.579502418563 | 0.0303957210405 |              {'C': 10000.0, 'gamma': 100.0}              |        3        |
|  0.55914021167  | 0.0315097359956 |             {'C': 10000.0, 'gamma': 1000.0}              |        14       |
|  0.559683338717 |  0.034718189818 |             {'C': 10000.0, 'gamma': 10000.0}             |        10       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.85      0.74        91
          1       0.35      0.17      0.23        41
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         1

avg / total       0.54      0.61      0.56       138


Accuracy on test set (using best parameters): 0.61


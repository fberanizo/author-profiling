Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.539688759393 | 0.0211808218325 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      1.00      0.81        94
          1       0.00      0.00      0.00        37
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         2

avg / total       0.46      0.68      0.55       138


Accuracy on test set (using best parameters): 0.68

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.563745748387 | 0.0748360259248 |  {'n_neighbors': 3} |        1        |
|  0.556141221268 | 0.0515445847197 |  {'n_neighbors': 5} |        2        |
|  0.548180394523 |  0.038791112453 | {'n_neighbors': 11} |        4        |
|  0.550701770574 | 0.0332745307788 | {'n_neighbors': 21} |        3        |
|  0.546931503343 |  0.032936965349 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.86      0.77        93
          1       0.27      0.15      0.19        40
          2       0.00      0.00      0.00         5

avg / total       0.54      0.62      0.57       138


Accuracy on test set (using best parameters): 0.62

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.562184835854 | 0.0662756463935 | {'n_estimators': 2}  |        5        |
|  0.568708862067 | 0.0467663686344 | {'n_estimators': 3}  |        4        |
|  0.548263580207 | 0.0492340352336 | {'n_estimators': 5}  |        7        |
|  0.582860286448 | 0.0476160350294 | {'n_estimators': 10} |        1        |
|  0.574808002447 | 0.0277322798193 | {'n_estimators': 20} |        2        |
|  0.573838886288 | 0.0401298934596 | {'n_estimators': 40} |        3        |
|  0.561852976704 | 0.0238285014357 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.94      0.77        89
          1       0.40      0.11      0.17        38
          2       0.00      0.00      0.00         7
          3       0.00      0.00      0.00         4

avg / total       0.53      0.64      0.55       138


Accuracy on test set (using best parameters): 0.64

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.539711009328 |  0.023082382113 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        9        |
|  0.539711009328 |  0.023082382113 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        9        |
|  0.539711009328 |  0.023082382113 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        9        |
|  0.539711009328 |  0.023082382113 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        9        |
|  0.539711009328 |  0.023082382113 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        9        |
|  0.539711009328 |  0.023082382113 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        9        |
|  0.539711009328 |  0.023082382113 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        9        |
|  0.538532160077 | 0.0246224986027 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        19       |
|  0.537337734065 | 0.0235206969692 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        20       |
|  0.539878540454 | 0.0245396048333 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.53869005686  | 0.0246053968052 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        18       |
|   0.541634884   | 0.0239413607435 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.540213309172 | 0.0400003374552 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
|  0.542889592752 | 0.0388983028394 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.539711009328 |  0.023082382113 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.539711009328 |  0.023082382113 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.537337734065 | 0.0235206969692 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        20       |
|  0.541097501666 | 0.0234218828663 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.539903075654 | 0.0223979589901 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.54128730418  | 0.0289412229294 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.540606901416 | 0.0193172032194 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        5        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      1.00      0.81        94
          1       0.00      0.00      0.00        37
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         3

avg / total       0.46      0.68      0.55       138


Accuracy on test set (using best parameters): 0.68

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.539701113115 | 0.0223072959078 |        {'C': 0.001}        |        3        |
|  0.539701113115 | 0.0223072959078 |        {'C': 0.01}         |        3        |
|  0.539701113115 | 0.0223072959078 | {'C': 0.10000000000000001} |        3        |
|  0.539701113115 | 0.0223072959078 |         {'C': 1.0}         |        3        |
|  0.54496059439  | 0.0214411668524 |        {'C': 10.0}         |        2        |
|  0.553911444959 | 0.0431901488038 |        {'C': 100.0}        |        1        |
|  0.539640246345 |  0.052966166576 |       {'C': 1000.0}        |        7        |
|  0.525381735395 | 0.0856139276253 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.98      0.80        94
          1       0.00      0.00      0.00        38
          2       0.00      0.00      0.00         2
          3       0.00      0.00      0.00         4

avg / total       0.46      0.67      0.55       138


Accuracy on test set (using best parameters): 0.67

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.517944207103 | 0.0207721097696 |               {'C': 0.001, 'gamma': 0.001}               |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 0.001, 'gamma': 0.01}                |        25       |
|  0.517944207103 | 0.0207721097696 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 0.001, 'gamma': 1.0}                |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 0.001, 'gamma': 10.0}                |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 0.001, 'gamma': 100.0}               |        25       |
|  0.517944207103 | 0.0207721097696 |              {'C': 0.001, 'gamma': 1000.0}               |        25       |
|  0.517944207103 | 0.0207721097696 |              {'C': 0.001, 'gamma': 10000.0}              |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 0.01, 'gamma': 0.001}                |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 0.01, 'gamma': 0.01}                |        25       |
|  0.517944207103 | 0.0207721097696 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 0.01, 'gamma': 1.0}                 |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 0.01, 'gamma': 10.0}                |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 0.01, 'gamma': 100.0}                |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 0.01, 'gamma': 1000.0}               |        25       |
|  0.517944207103 | 0.0207721097696 |              {'C': 0.01, 'gamma': 10000.0}               |        25       |
|  0.517944207103 | 0.0207721097696 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        25       |
|  0.517944207103 | 0.0207721097696 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        25       |
|  0.517944207103 | 0.0207721097696 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        25       |
|  0.517944207103 | 0.0207721097696 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        25       |
|  0.517944207103 | 0.0207721097696 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        25       |
|  0.517944207103 | 0.0207721097696 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        25       |
|  0.517944207103 | 0.0207721097696 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        25       |
|  0.517944207103 | 0.0207721097696 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 1.0, 'gamma': 0.001}                |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 1.0, 'gamma': 0.01}                 |        25       |
|  0.517944207103 | 0.0207721097696 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.517944207103 | 0.0207721097696 |                 {'C': 1.0, 'gamma': 1.0}                 |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 1.0, 'gamma': 10.0}                 |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 1.0, 'gamma': 100.0}                |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 10.0, 'gamma': 0.001}                |        25       |
|  0.517944207103 | 0.0207721097696 |                {'C': 10.0, 'gamma': 0.01}                |        25       |
|  0.517944207103 | 0.0207721097696 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.52209774005  | 0.0274452940124 |                {'C': 10.0, 'gamma': 1.0}                 |        19       |
|  0.553389277018 | 0.0583250088369 |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.518929852555 | 0.0425332178596 |               {'C': 10.0, 'gamma': 100.0}                |        23       |
|  0.526121632225 |  0.032303240731 |               {'C': 10.0, 'gamma': 1000.0}               |        18       |
|  0.516774510408 | 0.0228406874185 |              {'C': 10.0, 'gamma': 10000.0}               |        63       |
|  0.517944207103 | 0.0207721097696 |               {'C': 100.0, 'gamma': 0.001}               |        25       |
|  0.517944207103 | 0.0207721097696 |               {'C': 100.0, 'gamma': 0.01}                |        25       |
|  0.529843571907 | 0.0346189284463 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.550066567966 | 0.0452884618173 |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.52813348053  | 0.0756493226935 |               {'C': 100.0, 'gamma': 10.0}                |        15       |
|  0.52757565293  | 0.0559077122702 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.527599614187 | 0.0240957713697 |              {'C': 100.0, 'gamma': 1000.0}               |        16       |
|  0.52206859534  | 0.0327144419121 |              {'C': 100.0, 'gamma': 10000.0}              |        20       |
|  0.517944207103 | 0.0207721097696 |              {'C': 1000.0, 'gamma': 0.001}               |        25       |
|  0.529843571907 | 0.0346189284463 |               {'C': 1000.0, 'gamma': 0.01}               |        12       |
|  0.567508719551 | 0.0542592882938 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.513538052959 | 0.0707022304646 |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.540026564196 | 0.0791313697457 |               {'C': 1000.0, 'gamma': 10.0}               |        6        |
|  0.54181608945  | 0.0594572808466 |              {'C': 1000.0, 'gamma': 100.0}               |        5        |
|  0.530189942477 | 0.0296842951373 |              {'C': 1000.0, 'gamma': 1000.0}              |        10       |
|  0.52206859534  | 0.0327144419121 |             {'C': 1000.0, 'gamma': 10000.0}              |        20       |
|  0.529843571907 | 0.0346189284463 |              {'C': 10000.0, 'gamma': 0.001}              |        12       |
|  0.534213428103 | 0.0439885777887 |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|   0.5314912124  | 0.0678962946564 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        9        |
|   0.5180114953  | 0.0603904986472 |               {'C': 10000.0, 'gamma': 1.0}               |        24       |
|  0.534469899013 | 0.0675967305416 |              {'C': 10000.0, 'gamma': 10.0}               |        7        |
|  0.547603098137 | 0.0557807371437 |              {'C': 10000.0, 'gamma': 100.0}              |        4        |
|  0.530189942477 | 0.0296842951373 |             {'C': 10000.0, 'gamma': 1000.0}              |        10       |
|  0.52206859534  | 0.0327144419121 |             {'C': 10000.0, 'gamma': 10000.0}             |        20       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.91      0.80       101
          1       0.11      0.03      0.05        33
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         1

avg / total       0.55      0.67      0.60       138


Accuracy on test set (using best parameters): 0.67


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.564808737352 | 0.0180992248271 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.77        86
          1       0.00      0.00      0.00        45
          2       0.00      0.00      0.00         5
          3       0.00      0.00      0.00         2

avg / total       0.39      0.62      0.48       138


Accuracy on test set (using best parameters): 0.62

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.572996764263 | 0.0585269565207 |  {'n_neighbors': 3} |        2        |
|  0.574094704494 | 0.0419101646925 |  {'n_neighbors': 5} |        1        |
|  0.558873632658 | 0.0226227231323 | {'n_neighbors': 11} |        5        |
|  0.565729629338 | 0.0232918234624 | {'n_neighbors': 21} |        4        |
|  0.56692024628  |  0.022351018843 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.91      0.75        87
          1       0.23      0.07      0.11        41
          2       0.00      0.00      0.00         9
          3       0.00      0.00      0.00         1

avg / total       0.47      0.59      0.50       138


Accuracy on test set (using best parameters): 0.59

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.544535124102 | 0.0423857203632 | {'n_estimators': 2}  |        1        |
|  0.512464736583 | 0.0656057949877 | {'n_estimators': 3}  |        7        |
|  0.538680540839 | 0.0817401755221 | {'n_estimators': 5}  |        3        |
|  0.524353796205 | 0.0289443573887 | {'n_estimators': 10} |        6        |
|  0.533592963697 |  0.052870498998 | {'n_estimators': 20} |        4        |
|  0.527908112505 | 0.0580019318334 | {'n_estimators': 40} |        5        |
|  0.543198536145 | 0.0422185617652 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.91      0.81       100
          1       0.23      0.10      0.14        30
          2       0.00      0.00      0.00         6
          3       0.00      0.00      0.00         2

avg / total       0.58      0.68      0.62       138


Accuracy on test set (using best parameters): 0.68

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.536600586383 | 0.0240624513335 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        12       |
|  0.536600586383 | 0.0240624513335 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        12       |
|  0.536600586383 | 0.0240624513335 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        12       |
|  0.536600586383 | 0.0240624513335 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        12       |
|  0.536600586383 | 0.0240624513335 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        12       |
|  0.536600586383 | 0.0240624513335 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        12       |
|  0.536600586383 | 0.0240624513335 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        12       |
|  0.540681218406 | 0.0255394201005 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        7        |
|  0.544774367755 | 0.0339999755479 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        5        |
|  0.538396081354 |  0.03490813499  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.546442444525 | 0.0427024479053 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        2        |
|  0.540237641766 | 0.0374117071838 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        8        |
|  0.549046720593 | 0.0352433468267 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.545319918837 |  0.040201018734 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.535421737131 | 0.0253995905102 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        19       |
|  0.535421737131 | 0.0253995905102 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        19       |
|  0.538307943143 | 0.0260248717073 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.546126778544 | 0.0408406135844 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|   0.5421609153  | 0.0355679601749 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.534473864382 | 0.0339386490095 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        21       |
|  0.538118736319 | 0.0349124407235 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        11       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      1.00      0.82        95
          1       0.00      0.00      0.00        38
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         1

avg / total       0.47      0.69      0.56       138


Accuracy on test set (using best parameters): 0.69

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.564808737352 | 0.0180992248271 |        {'C': 0.001}        |        5        |
|  0.564808737352 | 0.0180992248271 |        {'C': 0.01}         |        5        |
|  0.564808737352 | 0.0180992248271 | {'C': 0.10000000000000001} |        5        |
|  0.564808737352 | 0.0180992248271 |         {'C': 1.0}         |        5        |
|  0.568905089452 | 0.0255585499163 |        {'C': 10.0}         |        3        |
|  0.567330276763 | 0.0294117958454 |        {'C': 100.0}        |        4        |
|  0.58636198279  | 0.0443729418793 |       {'C': 1000.0}        |        1        |
|  0.569960751121 | 0.0567073155292 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.86      0.71        86
          1       0.25      0.04      0.08        45
          2       0.00      0.00      0.00         3
          3       0.00      0.00      0.00         4

avg / total       0.46      0.55      0.47       138


Accuracy on test set (using best parameters): 0.55

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.542868258719 | 0.0255445289218 |               {'C': 0.001, 'gamma': 0.001}               |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 0.001, 'gamma': 0.01}                |        20       |
|  0.542868258719 | 0.0255445289218 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        20       |
|  0.542868258719 | 0.0255445289218 |                {'C': 0.001, 'gamma': 1.0}                |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 0.001, 'gamma': 10.0}                |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 0.001, 'gamma': 100.0}               |        20       |
|  0.542868258719 | 0.0255445289218 |              {'C': 0.001, 'gamma': 1000.0}               |        20       |
|  0.542868258719 | 0.0255445289218 |              {'C': 0.001, 'gamma': 10000.0}              |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 0.01, 'gamma': 0.001}                |        20       |
|  0.542868258719 | 0.0255445289218 |                {'C': 0.01, 'gamma': 0.01}                |        20       |
|  0.542868258719 | 0.0255445289218 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        20       |
|  0.542868258719 | 0.0255445289218 |                {'C': 0.01, 'gamma': 1.0}                 |        20       |
|  0.542868258719 | 0.0255445289218 |                {'C': 0.01, 'gamma': 10.0}                |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 0.01, 'gamma': 100.0}                |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 0.01, 'gamma': 1000.0}               |        20       |
|  0.542868258719 | 0.0255445289218 |              {'C': 0.01, 'gamma': 10000.0}               |        20       |
|  0.542868258719 | 0.0255445289218 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        20       |
|  0.542868258719 | 0.0255445289218 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        20       |
|  0.542868258719 | 0.0255445289218 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        20       |
|  0.542868258719 | 0.0255445289218 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        20       |
|  0.542868258719 | 0.0255445289218 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        20       |
|  0.542868258719 | 0.0255445289218 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        20       |
|  0.542868258719 | 0.0255445289218 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        20       |
|  0.542868258719 | 0.0255445289218 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        20       |
|  0.542868258719 | 0.0255445289218 |                {'C': 1.0, 'gamma': 0.001}                |        20       |
|  0.542868258719 | 0.0255445289218 |                {'C': 1.0, 'gamma': 0.01}                 |        20       |
|  0.542868258719 | 0.0255445289218 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        20       |
|  0.542868258719 | 0.0255445289218 |                 {'C': 1.0, 'gamma': 1.0}                 |        20       |
|  0.543635881487 | 0.0247511893286 |                {'C': 1.0, 'gamma': 10.0}                 |        19       |
|  0.542868258719 | 0.0255445289218 |                {'C': 1.0, 'gamma': 100.0}                |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 1.0, 'gamma': 1000.0}                |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 1.0, 'gamma': 10000.0}               |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 10.0, 'gamma': 0.001}                |        20       |
|  0.542868258719 | 0.0255445289218 |                {'C': 10.0, 'gamma': 0.01}                |        20       |
|  0.542868258719 | 0.0255445289218 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        20       |
|  0.541673832707 | 0.0246948780991 |                {'C': 10.0, 'gamma': 1.0}                 |        61       |
|  0.559481518647 | 0.0688763394248 |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.555502758804 | 0.0501013742507 |               {'C': 10.0, 'gamma': 100.0}                |        12       |
|  0.540477581246 | 0.0232348521174 |               {'C': 10.0, 'gamma': 1000.0}               |        62       |
|  0.550048462883 | 0.0358300456472 |              {'C': 10.0, 'gamma': 10000.0}               |        16       |
|  0.542868258719 | 0.0255445289218 |               {'C': 100.0, 'gamma': 0.001}               |        20       |
|  0.542868258719 | 0.0255445289218 |               {'C': 100.0, 'gamma': 0.01}                |        20       |
|  0.541689409468 |  0.027082058146 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        58       |
|  0.556615274354 | 0.0646202537356 |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.563906690273 |  0.051907240694 |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.541884595332 | 0.0406637512182 |               {'C': 100.0, 'gamma': 100.0}               |        57       |
|  0.553412043691 | 0.0398650708556 |              {'C': 100.0, 'gamma': 1000.0}               |        15       |
|  0.559471026832 | 0.0425469311664 |              {'C': 100.0, 'gamma': 10000.0}              |        8        |
|  0.542868258719 | 0.0255445289218 |              {'C': 1000.0, 'gamma': 0.001}               |        20       |
|  0.541689409468 |  0.027082058146 |               {'C': 1000.0, 'gamma': 0.01}               |        58       |
|  0.554202787035 | 0.0516918749681 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        14       |
|  0.546196428465 | 0.0605080759773 |               {'C': 1000.0, 'gamma': 1.0}                |        17       |
|  0.568666907975 | 0.0403119880085 |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.561420374618 | 0.0569302243678 |              {'C': 1000.0, 'gamma': 100.0}               |        6        |
|  0.565372995472 | 0.0462441688409 |              {'C': 1000.0, 'gamma': 1000.0}              |        3        |
|  0.559471026832 | 0.0425469311664 |             {'C': 1000.0, 'gamma': 10000.0}              |        8        |
|  0.541689409468 |  0.027082058146 |              {'C': 10000.0, 'gamma': 0.001}              |        58       |
|  0.544708870108 |  0.04554307734  |              {'C': 10000.0, 'gamma': 0.01}               |        18       |
|  0.554910103554 | 0.0599384943101 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        13       |
|  0.522620145572 | 0.0741739698315 |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.538996229848 | 0.0454985436948 |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.589087083417 | 0.0512015324854 |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.565372995472 | 0.0462441688409 |             {'C': 10000.0, 'gamma': 1000.0}              |        3        |
|  0.559471026832 | 0.0425469311664 |             {'C': 10000.0, 'gamma': 10000.0}             |        8        |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.89      0.78        93
          1       0.29      0.13      0.18        38
          2       0.00      0.00      0.00         4
          3       0.00      0.00      0.00         3

avg / total       0.54      0.64      0.57       138


Accuracy on test set (using best parameters): 0.64


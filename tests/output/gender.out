Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.620295321376 | 0.0301189864687 |  {'n_neighbors': 3} |        2        |
|  0.646204950068 | 0.0496248483709 |  {'n_neighbors': 5} |        1        |
|  0.616446722091 | 0.0320549928026 | {'n_neighbors': 11} |        3        |
|  0.611343626985 | 0.0395479670588 | {'n_neighbors': 21} |        5        |
|  0.614516925532 | 0.0417054117845 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.78      0.70       100
          1       0.55      0.38      0.45        71

avg / total       0.60      0.61      0.60       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.627091525638 | 0.0223737146077 |  {'n_neighbors': 3} |        2        |
|  0.608956319365 | 0.0232663992003 |  {'n_neighbors': 5} |        4        |
|  0.601896058546 | 0.0257220562851 | {'n_neighbors': 11} |        5        |
|  0.612618907709 | 0.0348227668606 | {'n_neighbors': 21} |        3        |
|  0.627533671788 | 0.0399496354782 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.88      0.75       100
          1       0.66      0.32      0.43        71

avg / total       0.65      0.65      0.62       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.598583564488 | 0.0161361272215 |  {'n_neighbors': 3} |        4        |
|  0.598086273949 | 0.0370707357281 |  {'n_neighbors': 5} |        5        |
|  0.632465877951 | 0.0321402086795 | {'n_neighbors': 11} |        2        |
|  0.624920479671 | 0.0370052260457 | {'n_neighbors': 21} |        3        |
|  0.648987913346 | 0.0358518632332 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.88      0.75        99
          1       0.68      0.35      0.46        71

avg / total       0.66      0.66      0.63       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.616503079544 | 0.0542770138628 |  {'n_neighbors': 3} |        4        |
|  0.620060429893 | 0.0355198497335 |  {'n_neighbors': 5} |        3        |
|  0.621839763107 | 0.0401100359715 | {'n_neighbors': 11} |        1        |
|  0.620181845191 | 0.0457082351255 | {'n_neighbors': 21} |        2        |
|  0.612501044265 | 0.0213053037992 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.80      0.71        99
          1       0.57      0.38      0.46        71

avg / total       0.61      0.62      0.61       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.60967844816  |  0.041634318083 |  {'n_neighbors': 3} |        5        |
|  0.619176804316 | 0.0291383462089 |  {'n_neighbors': 5} |        4        |
|  0.626644389526 |  0.02548074884  | {'n_neighbors': 11} |        2        |
|  0.643519795234 | 0.0360091280015 | {'n_neighbors': 21} |        1        |
|  0.620295613669 | 0.0289341233981 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.75      0.72        99
          1       0.60      0.53      0.56        70

avg / total       0.65      0.66      0.65       169

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.626346558188 | 0.0308503479199 | {'n_estimators': 2}  |        7        |
|  0.643964944042 | 0.0164377234684 | {'n_estimators': 3}  |        5        |
|  0.638915716067 | 0.0420512745495 | {'n_estimators': 5}  |        6        |
|  0.678036392003 | 0.0375818984944 | {'n_estimators': 10} |        3        |
|  0.677442949042 | 0.0338873789163 | {'n_estimators': 20} |        4        |
|   0.7079758157  | 0.0338130939877 | {'n_estimators': 40} |        1        |
|  0.694422774254 | 0.0439159467146 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.89      0.81       100
          1       0.78      0.55      0.64        71

avg / total       0.75      0.75      0.74       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.616522169644 | 0.0141131438462 | {'n_estimators': 2}  |        7        |
|  0.639305643805 | 0.0362527328607 | {'n_estimators': 3}  |        6        |
|  0.65506913796  | 0.0444749072317 | {'n_estimators': 5}  |        5        |
|  0.666613142817 | 0.0329118197064 | {'n_estimators': 10} |        4        |
|  0.668995999795 | 0.0368038401898 | {'n_estimators': 20} |        3        |
|  0.68739087519  | 0.0627310588181 | {'n_estimators': 40} |        2        |
|  0.716077781052 | 0.0367703423288 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.82      0.76       100
          1       0.67      0.52      0.59        71

avg / total       0.69      0.70      0.69       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.562857865125 | 0.0166640211522 | {'n_estimators': 2}  |        7        |
|  0.616660640697 | 0.0315117844081 | {'n_estimators': 3}  |        6        |
|  0.672535008722 | 0.0211182541692 | {'n_estimators': 5}  |        5        |
|  0.681875646176 | 0.0254607283835 | {'n_estimators': 10} |        4        |
|  0.686834774137 | 0.0207940165245 | {'n_estimators': 20} |        3        |
|  0.725371895182 | 0.0360815823091 | {'n_estimators': 40} |        1        |
|  0.719387477993 | 0.0254631863983 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.82      0.75        99
          1       0.67      0.51      0.58        71

avg / total       0.69      0.69      0.68       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.58883035906  | 0.0286827441672 | {'n_estimators': 2}  |        7        |
|  0.625370240994 | 0.0244683093951 | {'n_estimators': 3}  |        6        |
|  0.663773090776 | 0.0204489533241 | {'n_estimators': 5}  |        4        |
|  0.657602079009 | 0.0272289099955 | {'n_estimators': 10} |        5        |
|  0.668282630136 | 0.0288461687308 | {'n_estimators': 20} |        3        |
|  0.698537629266 | 0.0160720489539 | {'n_estimators': 40} |        1        |
|  0.673747450989 | 0.0308390623127 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.82      0.79        99
          1       0.71      0.63      0.67        71

avg / total       0.74      0.74      0.74       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+------------------+----------------------+-----------------+
| test_mean_score |  test_std_score  |        params        | test_rank_score |
+-----------------+------------------+----------------------+-----------------+
|  0.573262527919 | 0.0247020649739  | {'n_estimators': 2}  |        7        |
|  0.644193634813 | 0.0357146223323  | {'n_estimators': 3}  |        6        |
|  0.658031100774 | 0.0143319539938  | {'n_estimators': 5}  |        4        |
|  0.689199267249 |  0.016429469899  | {'n_estimators': 10} |        3        |
|  0.654040155566 | 0.0209915139212  | {'n_estimators': 20} |        5        |
|  0.696317096852 | 0.0283167613822  | {'n_estimators': 40} |        2        |
|  0.706605060816 | 0.00481349343285 | {'n_estimators': 60} |        1        |
+-----------------+------------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.85      0.79        99
          1       0.73      0.59      0.65        70

avg / total       0.74      0.74      0.73       169

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.443305706138 | 0.0187646603312  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        20       |
|  0.480844836038 | 0.0535681918347  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        16       |
|  0.465845980864 | 0.0720238673683  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.430415249693 | 0.00188962676051 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        21       |
|  0.479134680259 | 0.0956740697183  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        17       |
|  0.581496094916 |  0.123795544722  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.469756811863 | 0.0798796721556  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.736333405971 | 0.0445071895775  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        8        |
|  0.744844450097 | 0.0308061571232  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.70620221332  | 0.0311176365899  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.743924452047 | 0.0275416735832  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.752327324404 | 0.0658218465982  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        3        |
|  0.735261225072 | 0.0381848190531  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.756489567221 | 0.0282243449171  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.71901150928  | 0.0218239046236  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.711688632269 | 0.0522111898217  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.750349359395 | 0.0231624365382  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.746924457204 | 0.0283593637863  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.72305602263  |  0.019499155981  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        11       |
|  0.736138702378 | 0.0233239590188  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        9        |
|  0.753991492929 | 0.0431492007158  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.81      0.79       100
          1       0.71      0.65      0.68        71

avg / total       0.74      0.74      0.74       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.455763184387 | 0.0290572030731 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.498035250117 | 0.0225091102991 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.524283586719 | 0.0566461154233 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.564271520869 |  0.114428497187 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|   0.5292239385  |  0.121944765984 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.585054450393 |  0.12932850771  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.637173129489 |  0.11386415506  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.733203615324 | 0.0360297222311 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.744413897519 | 0.0228398496425 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.761846684149 | 0.0299028897845 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        2        |
|  0.769662468261 | 0.0259712651648 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        1        |
|  0.746221510639 | 0.0315343252758 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.694248023896 |  0.132869779416 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        14       |
|  0.759079022352 |  0.035927712228 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.718413986638 | 0.0265638644013 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.741508748614 | 0.0141753064129 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
|  0.737286699798 | 0.0273781564976 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.741775469174 | 0.0242584710754 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        9        |
|  0.757573544208 |  0.019053703202 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.758869057441 | 0.0215417222847 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.751276823895 | 0.0388323384773 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        6        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.82      0.80       100
          1       0.72      0.66      0.69        71

avg / total       0.75      0.75      0.75       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+-------------------+-------------------------------------------------------+-----------------+
| test_mean_score |   test_std_score  |                         params                        | test_rank_score |
+-----------------+-------------------+-------------------------------------------------------+-----------------+
|  0.462719963017 |  0.0111666629912  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        20       |
|  0.496445653945 |   0.021415347928  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        18       |
|  0.533806951641 |   0.062045849473  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.555684901882 |   0.106518872789  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
|  0.564543188363 |   0.110825751348  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.482431359542 |  0.0938817083312  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        19       |
|  0.431149384659 | 0.000732080266919 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        21       |
|  0.726042994622 |  0.0500083527938  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.742713038222 |   0.041381673217  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.736445793816 |  0.0286389727998  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        7        |
|  0.742713260366 |  0.0320138592475  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.727025808454 |  0.0575336694414  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        10       |
|  0.734452786951 |  0.0147494829441  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        8        |
|  0.750529501114 |   0.037118424941  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.703530856037 |  0.0232820244268  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.715611768612 |  0.0400713424263  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.722219439312 |  0.0401070844114  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        12       |
|  0.76614689672  |  0.0297572987772  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        1        |
|  0.745550748081 |  0.0217989364888  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.753038696231 |  0.0189325032311  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.729367992895 |  0.0383336731284  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        9        |
+-----------------+-------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.80      0.79        99
          1       0.71      0.68      0.69        71

avg / total       0.75      0.75      0.75       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.434436827309 | 0.00708406711104 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.511573766455 | 0.0227626793902  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        18       |
|  0.488022958487 | 0.0697177737156  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.482837753113 |  0.104400192407  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.532678549005 |  0.126329386889  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.524943915579 |  0.115154039102  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.585368541117 |  0.129089256895  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.728071858476 |  0.012903031813  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.738817069921 | 0.0137544280518  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.736561523008 | 0.0488250012448  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.738088253066 | 0.0302407779564  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
|  0.74812896792  | 0.0517048130026  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.754158106466 | 0.0379761346763  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.753853221704 |  0.043886486874  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.710897127834 | 0.0404414678771  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.718168267522 | 0.0370460767209  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.73362510422  | 0.0412349796414  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.76229661259  | 0.0268031286901  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.74192785282  | 0.0283526649416  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.739206166588 | 0.0183821218591  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.768562444512 | 0.0512396912895  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.85      0.81        99
          1       0.75      0.65      0.70        71

avg / total       0.76      0.76      0.76       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.430119416573 | 0.0017163895695 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.481900609067 | 0.0360532402542 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.504317350283 | 0.0913948773757 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.500271502985 | 0.0885346285499 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.588570100117 |  0.132477057345 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.588021956144 |  0.130622291777 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.54633386927  |  0.143786959512 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.723920990526 | 0.0420943183338 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.731582135989 | 0.0286870851193 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.745159037933 | 0.0416961011469 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        4        |
|  0.739770661931 | 0.0265418873598 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.770231495813 | 0.0424021769107 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.734563643974 | 0.0127352133653 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.745971190089 | 0.0261878058758 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.716675736106 | 0.0183505450041 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.722363466834 | 0.0124804309605 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.738825007617 | 0.0320862106057 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.738349272281 | 0.0286800164758 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        9        |
|  0.739496429298 | 0.0412248441766 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.740864808073 | 0.0475218307895 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.745392540673 |  0.033848554039 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.84      0.81        99
          1       0.74      0.66      0.70        70

avg / total       0.76      0.76      0.76       169

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.430415249693 | 0.00188962676051 |        {'C': 0.001}        |        6        |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.01}         |        6        |
|  0.430415249693 | 0.00188962676051 | {'C': 0.10000000000000001} |        6        |
|  0.449975535831 | 0.0127043984091  |         {'C': 1.0}         |        5        |
|  0.692993103263 | 0.0372315066063  |        {'C': 10.0}         |        4        |
|  0.732225295713 | 0.0166034736248  |        {'C': 100.0}        |        3        |
|  0.761867685616 | 0.0312783208082  |       {'C': 1000.0}        |        2        |
|  0.765809894707 | 0.0352485500754  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.76      0.77       100
          1       0.68      0.70      0.69        71

avg / total       0.74      0.74      0.74       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.430415249693 | 0.00188962676051 |        {'C': 0.001}        |        6        |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.01}         |        6        |
|  0.430415249693 | 0.00188962676051 | {'C': 0.10000000000000001} |        6        |
|  0.470867873086 | 0.0274024502106  |         {'C': 1.0}         |        5        |
|  0.679925870635 | 0.0485965479785  |        {'C': 10.0}         |        4        |
|  0.716072212635 | 0.0305133204775  |        {'C': 100.0}        |        3        |
|  0.726411758763 | 0.0218809795246  |       {'C': 1000.0}        |        2        |
|  0.747756300492 | 0.0329502444798  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.84      0.75      0.79       100
          1       0.70      0.80      0.75        71

avg / total       0.78      0.77      0.77       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-------------------+----------------------------+-----------------+
| test_mean_score |   test_std_score  |           params           | test_rank_score |
+-----------------+-------------------+----------------------------+-----------------+
|  0.431149384659 | 0.000732080266919 |        {'C': 0.001}        |        6        |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.01}         |        6        |
|  0.431149384659 | 0.000732080266919 | {'C': 0.10000000000000001} |        6        |
|  0.437724269958 |  0.00884406658766 |         {'C': 1.0}         |        5        |
|  0.696443569886 |  0.0297468160907  |        {'C': 10.0}         |        4        |
|  0.766849117154 |  0.0315058387346  |        {'C': 100.0}        |        1        |
|  0.757100668367 |  0.0208574089539  |       {'C': 1000.0}        |        3        |
|  0.764914523862 |  0.0325960475401  |       {'C': 10000.0}       |        2        |
+-----------------+-------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.82      0.79        99
          1       0.72      0.66      0.69        71

avg / total       0.75      0.75      0.75       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-------------------+----------------------------+-----------------+
| test_mean_score |   test_std_score  |           params           | test_rank_score |
+-----------------+-------------------+----------------------------+-----------------+
|  0.431149384659 | 0.000732080266919 |        {'C': 0.001}        |        6        |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.01}         |        6        |
|  0.431149384659 | 0.000732080266919 | {'C': 0.10000000000000001} |        6        |
|  0.444298723366 |  0.00694024901719 |         {'C': 1.0}         |        5        |
|  0.672732029861 |  0.0310755043578  |        {'C': 10.0}         |        4        |
|  0.775690392058 |  0.0326943095806  |        {'C': 100.0}        |        1        |
|  0.769224801746 |  0.0135118487759  |       {'C': 1000.0}        |        2        |
|  0.736317985992 |  0.0437400266401  |       {'C': 10000.0}       |        3        |
+-----------------+-------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.80      0.77        99
          1       0.69      0.62      0.65        71

avg / total       0.72      0.72      0.72       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.430119416573 | 0.0017163895695 |        {'C': 0.001}        |        6        |
|  0.430119416573 | 0.0017163895695 |        {'C': 0.01}         |        6        |
|  0.430119416573 | 0.0017163895695 | {'C': 0.10000000000000001} |        6        |
|  0.439870034575 | 0.0124364057818 |         {'C': 1.0}         |        5        |
|  0.654628440755 | 0.0413367379256 |        {'C': 10.0}         |        4        |
|  0.726680743921 |  0.045535243361 |        {'C': 100.0}        |        3        |
|  0.749617297862 | 0.0209128608551 |       {'C': 1000.0}        |        1        |
|  0.746867774789 | 0.0215693187407 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.89      0.77      0.83        99
          1       0.73      0.87      0.79        70

avg / total       0.82      0.81      0.81       169

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.430415249693 | 0.00188962676051 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.430415249693 | 0.00188962676051 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.430415249693 | 0.00188962676051 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.430415249693 | 0.00188962676051 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.430415249693 | 0.00188962676051 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.49958340042  | 0.0143587962361  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.677873124961 | 0.0362798944799  |                {'C': 1.0, 'gamma': 10.0}                 |        12       |
|  0.610322069677 | 0.0322944249351  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.476985243905 | 0.0149462875419  |               {'C': 1.0, 'gamma': 1000.0}                |        27       |
|  0.448254787918 | 0.0196488215943  |               {'C': 1.0, 'gamma': 10000.0}               |        33       |
|  0.430415249693 | 0.00188962676051 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.504954821038 | 0.0226863204643  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.721562492206 |  0.023866887734  |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.706484658542 | 0.0584743995108  |                {'C': 10.0, 'gamma': 10.0}                |        10       |
|  0.619726881976 | 0.0297961645364  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.484787322287 | 0.0268054593412  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.457847584988 |  0.019830005109  |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|  0.430415249693 | 0.00188962676051 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.513703710897 | 0.0491853556912  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.723850505963 | 0.0262352086076  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.740659197557 | 0.0462475031905  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.648973426121 | 0.0217072039971  |               {'C': 100.0, 'gamma': 10.0}                |        14       |
|  0.623410218723 | 0.0139556546313  |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.472354746996 | 0.0287730953452  |              {'C': 100.0, 'gamma': 1000.0}               |        28       |
|  0.450840555778 | 0.0126899581839  |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
|  0.50257023095  | 0.0199019741405  |              {'C': 1000.0, 'gamma': 0.001}               |        23       |
|  0.723287323088 | 0.0658915412153  |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.756189125903 | 0.0183112468512  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.72769307286  | 0.0342117693873  |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.656551989702 | 0.0163968370701  |               {'C': 1000.0, 'gamma': 10.0}               |        13       |
|  0.597199659128 | 0.0350605728522  |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
|  0.477466989513 | 0.0238644498804  |              {'C': 1000.0, 'gamma': 1000.0}              |        26       |
|  0.443038614139 | 0.0161221932582  |             {'C': 1000.0, 'gamma': 10000.0}              |        34       |
|  0.719331713389 | 0.0129687204386  |              {'C': 10000.0, 'gamma': 0.001}              |        9        |
|  0.76107735564  | 0.0642543937603  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.726701644962 | 0.0342376920317  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.686853594224 | 0.0392273193915  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.631673291815 | 0.0240386174192  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.602019086569 | 0.0271289259262  |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
|  0.469972801345 | 0.0204491240055  |             {'C': 10000.0, 'gamma': 1000.0}              |        29       |
|   0.4562035319  | 0.0206311320264  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.82      0.81       100
          1       0.74      0.70      0.72        71

avg / total       0.77      0.77      0.77       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.430415249693 | 0.00188962676051 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.430415249693 | 0.00188962676051 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.430415249693 | 0.00188962676051 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.430415249693 | 0.00188962676051 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.430415249693 | 0.00188962676051 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.430415249693 | 0.00188962676051 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.430415249693 | 0.00188962676051 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.488324177362 |  0.037944418582  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.679928423308 | 0.0347449173936  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.630053678779 | 0.0205748302226  |                {'C': 1.0, 'gamma': 100.0}                |        17       |
|  0.482862140406 | 0.0345434110357  |               {'C': 1.0, 'gamma': 1000.0}                |        27       |
|  0.442875167678 | 0.0110503886342  |               {'C': 1.0, 'gamma': 10000.0}               |        34       |
|  0.430415249693 | 0.00188962676051 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.430415249693 | 0.00188962676051 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.499214820826 | 0.0274498019125  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.728480542335 | 0.0432069304562  |                {'C': 10.0, 'gamma': 1.0}                 |        4        |
|  0.712872679646 | 0.0436997586313  |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.665170626354 | 0.0214297441525  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.474655976664 | 0.0105518121478  |               {'C': 10.0, 'gamma': 1000.0}               |        28       |
|  0.45325973655  |  0.020130542142  |              {'C': 10.0, 'gamma': 10000.0}               |        33       |
|  0.430415249693 | 0.00188962676051 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.498394456482 | 0.0252659643577  |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.717064650477 | 0.0525600333749  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.718069067766 | 0.0279330453876  |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.711362444016 | 0.0339290110614  |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|  0.619889327199 | 0.0373611492903  |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.483726421696 | 0.0167012667343  |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
|  0.458097783791 | 0.0181701393659  |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
|  0.491419397342 | 0.0213188553167  |              {'C': 1000.0, 'gamma': 0.001}               |        23       |
|  0.700799443762 | 0.0523577281385  |               {'C': 1000.0, 'gamma': 0.01}               |        12       |
|  0.738747903854 | 0.0472903190846  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.724569714588 | 0.0405578877909  |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.666437409979 | 0.0344904550439  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.616605137694 | 0.0241530859864  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.46914119775  | 0.0316407135992  |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.464512500166 | 0.0189492566882  |             {'C': 1000.0, 'gamma': 10000.0}              |        30       |
|  0.708382548434 |  0.03275333173   |              {'C': 10000.0, 'gamma': 0.001}              |        10       |
|  0.740805778513 | 0.0455482821476  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.74801973215  | 0.0204119186653  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.705156453379 | 0.0114282873697  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.656682585736 | 0.0244509556242  |              {'C': 10000.0, 'gamma': 10.0}               |        16       |
|  0.611044758796 | 0.0295321793143  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.484591928341 | 0.0207518305847  |             {'C': 10000.0, 'gamma': 1000.0}              |        25       |
|  0.461683968424 | 0.0248267679087  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.85      0.84       100
          1       0.78      0.75      0.76        71

avg / total       0.81      0.81      0.81       171

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+-------------------+----------------------------------------------------------+-----------------+
| test_mean_score |   test_std_score  |                          params                          | test_rank_score |
+-----------------+-------------------+----------------------------------------------------------+-----------------+
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 0.001}               |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 0.01}                |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.001, 'gamma': 1.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 10.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 100.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |              {'C': 0.001, 'gamma': 1000.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |              {'C': 0.001, 'gamma': 10000.0}              |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.01, 'gamma': 0.001}                |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.01, 'gamma': 0.01}                |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.01, 'gamma': 1.0}                 |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.01, 'gamma': 10.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.01, 'gamma': 100.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.01, 'gamma': 1000.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |              {'C': 0.01, 'gamma': 10000.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        36       |
|  0.431149384659 | 0.000732080266919 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        36       |
|  0.431149384659 | 0.000732080266919 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        36       |
|  0.436553465055 |  0.0113319231197  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.431149384659 | 0.000732080266919 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 1.0, 'gamma': 0.001}                |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 1.0, 'gamma': 0.01}                 |        36       |
|  0.431149384659 | 0.000732080266919 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        36       |
|  0.471701567129 |  0.0141174746406  |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.715043339256 |  0.0326328429723  |                {'C': 1.0, 'gamma': 10.0}                 |        11       |
|  0.64386646115  |  0.0489048194553  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.506109819069 |  0.0300974724751  |               {'C': 1.0, 'gamma': 1000.0}                |        23       |
|   0.4497650448  |  0.0163265766618  |               {'C': 1.0, 'gamma': 10000.0}               |        33       |
|  0.431149384659 | 0.000732080266919 |               {'C': 10.0, 'gamma': 0.001}                |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 10.0, 'gamma': 0.01}                |        36       |
|  0.487838972538 |  0.0105114704729  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.723013750983 |  0.0525692411954  |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.726585111382 |  0.0467104831894  |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.648367744795 |  0.0239436643782  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.531795276504 |  0.0109242306379  |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.463692372487 |  0.0226123743818  |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|  0.431149384659 | 0.000732080266919 |               {'C': 100.0, 'gamma': 0.001}               |        36       |
|  0.494462367918 |  0.0122252009752  |               {'C': 100.0, 'gamma': 0.01}                |        24       |
|  0.736606079494 |  0.0397434431398  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.724971804678 |  0.0419517507175  |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.719769634698 |  0.0287834584279  |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|  0.646355373207 |  0.0426442680323  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.517760522401 |   0.014593750086  |              {'C': 100.0, 'gamma': 1000.0}               |        22       |
|  0.451111330584 |  0.0180335849219  |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
|  0.482209403977 |  0.0290454030943  |              {'C': 1000.0, 'gamma': 0.001}               |        28       |
|  0.718541644342 |  0.0307993679935  |               {'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.757273232267 |  0.0241487828312  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.711707380705 |  0.0210286593193  |               {'C': 1000.0, 'gamma': 1.0}                |        12       |
|  0.656631177718 |  0.0418677813034  |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.61395609749  |  0.0598368353355  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.482622931069 |  0.0325896791071  |              {'C': 1000.0, 'gamma': 1000.0}              |        27       |
|  0.447902867529 |  0.0199648305721  |             {'C': 1000.0, 'gamma': 10000.0}              |        34       |
|  0.706871448841 |  0.0672150365142  |              {'C': 10000.0, 'gamma': 0.001}              |        13       |
|  0.754471020796 |   0.026390544529  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.739252409093 |  0.0196696090913  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.721557782954 |  0.0441636727567  |               {'C': 10000.0, 'gamma': 1.0}               |        8        |
|  0.66705821491  |  0.0248121672085  |              {'C': 10000.0, 'gamma': 10.0}               |        14       |
|  0.600263643381 |  0.0211872414871  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.490496213004 |  0.0271466081178  |             {'C': 10000.0, 'gamma': 1000.0}              |        25       |
|  0.45257660223  |  0.0154640417286  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+-------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.86      0.82        99
          1       0.77      0.68      0.72        71

avg / total       0.78      0.78      0.78       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+-------------------+----------------------------------------------------------+-----------------+
| test_mean_score |   test_std_score  |                          params                          | test_rank_score |
+-----------------+-------------------+----------------------------------------------------------+-----------------+
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 0.001}               |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 0.01}                |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.001, 'gamma': 1.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 10.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.001, 'gamma': 100.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |              {'C': 0.001, 'gamma': 1000.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |              {'C': 0.001, 'gamma': 10000.0}              |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.01, 'gamma': 0.001}                |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.01, 'gamma': 0.01}                |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.01, 'gamma': 1.0}                 |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 0.01, 'gamma': 10.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.01, 'gamma': 100.0}                |        36       |
|  0.431149384659 | 0.000732080266919 |               {'C': 0.01, 'gamma': 1000.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |              {'C': 0.01, 'gamma': 10000.0}               |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        36       |
|  0.431149384659 | 0.000732080266919 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        36       |
|  0.431149384659 | 0.000732080266919 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        36       |
|  0.431149384659 | 0.000732080266919 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        36       |
|  0.436755320765 |  0.0108936568409  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.429069969597 |  0.00449146454258 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        64       |
|  0.431149384659 | 0.000732080266919 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 1.0, 'gamma': 0.001}                |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 1.0, 'gamma': 0.01}                 |        36       |
|  0.431149384659 | 0.000732080266919 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        36       |
|  0.510634574895 |  0.0120591920651  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.705302550679 |  0.0320421714789  |                {'C': 1.0, 'gamma': 10.0}                 |        8        |
|  0.633538635078 |  0.0237135277966  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.510737053034 |  0.00526432875114 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.461890097651 |  0.0205119391175  |               {'C': 1.0, 'gamma': 10000.0}               |        31       |
|  0.431149384659 | 0.000732080266919 |               {'C': 10.0, 'gamma': 0.001}                |        36       |
|  0.431149384659 | 0.000732080266919 |                {'C': 10.0, 'gamma': 0.01}                |        36       |
|  0.505232289982 |   0.043739561435  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.725650183306 |  0.0491677923639  |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.746557614313 |  0.0360918620818  |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.632790118283 |  0.00887634402083 |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.499474538688 |  0.0140695235642  |               {'C': 10.0, 'gamma': 1000.0}               |        28       |
|  0.45454946014  |   0.024086648698  |              {'C': 10.0, 'gamma': 10000.0}               |        33       |
|  0.431149384659 | 0.000732080266919 |               {'C': 100.0, 'gamma': 0.001}               |        36       |
|  0.512210866858 |  0.0180273338641  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.702511121064 |  0.0332762714157  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.752436324872 |  0.0294316522846  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.702346759614 |  0.0351903794115  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.623638599844 |   0.028779615647  |               {'C': 100.0, 'gamma': 100.0}               |        19       |
|  0.503042350102 |  0.0179599000232  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.447691039912 |  0.0140496918931  |              {'C': 100.0, 'gamma': 10000.0}              |        34       |
|  0.503579952156 |  0.0259152801611  |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.698496102516 |  0.0465336392468  |               {'C': 1000.0, 'gamma': 0.01}               |        12       |
|  0.748672136539 |  0.0414029254315  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.729022344703 |  0.0223631532605  |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.695745133952 |  0.0428037306591  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.625934865221 |  0.0493649555653  |              {'C': 1000.0, 'gamma': 100.0}               |        18       |
|  0.494038380191 |  0.0356368331036  |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.459197394513 |  0.00872852296702 |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.704323845039 |  0.0514521747466  |              {'C': 10000.0, 'gamma': 0.001}              |        9        |
|  0.745506813295 |  0.0128992577776  |              {'C': 10000.0, 'gamma': 0.01}               |        4        |
|  0.736965756273 |  0.0351214874739  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.698288621998 |  0.0441265529828  |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.665444135755 |  0.0250679702674  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.619147050768 |  0.0579474228593  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.50729146295  |  0.0180777053272  |             {'C': 10000.0, 'gamma': 1000.0}              |        24       |
|  0.463621991018 |  0.0170942301358  |             {'C': 10000.0, 'gamma': 10000.0}             |        30       |
+-----------------+-------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.84      0.75      0.79        99
          1       0.70      0.80      0.75        71

avg / total       0.78      0.77      0.77       170

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.430119416573 | 0.0017163895695  |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.430119416573 | 0.0017163895695  |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.430119416573 | 0.0017163895695  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.430119416573 | 0.0017163895695  |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.430119416573 | 0.0017163895695  |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.430119416573 | 0.0017163895695  |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.430119416573 | 0.0017163895695  |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.430119416573 | 0.0017163895695  |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.430119416573 | 0.0017163895695  |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.430119416573 | 0.0017163895695  |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.430119416573 | 0.0017163895695  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.430119416573 | 0.0017163895695  |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.430119416573 | 0.0017163895695  |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.430119416573 | 0.0017163895695  |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.430119416573 | 0.0017163895695  |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.430119416573 | 0.0017163895695  |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.430119416573 | 0.0017163895695  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.430119416573 | 0.0017163895695  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.430119416573 | 0.0017163895695  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.430119416573 | 0.0017163895695  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.430119416573 | 0.0017163895695  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.430119416573 | 0.0017163895695  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.430119416573 | 0.0017163895695  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.430119416573 | 0.0017163895695  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.430119416573 | 0.0017163895695  |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.430119416573 | 0.0017163895695  |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.430119416573 | 0.0017163895695  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.515069704152 | 0.0345642485867  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.724554434901 | 0.0437454114535  |                {'C': 1.0, 'gamma': 10.0}                 |        10       |
|  0.663573945033 | 0.0277512679681  |                {'C': 1.0, 'gamma': 100.0}                |        17       |
|  0.500762798224 | 0.0156971366876  |               {'C': 1.0, 'gamma': 1000.0}                |        27       |
|  0.465619629738 | 0.0180310901897  |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.430119416573 | 0.0017163895695  |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.430119416573 | 0.0017163895695  |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.510101126403 | 0.0286693342526  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.730155247827 | 0.0234760977993  |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.75599201644  | 0.0354808192352  |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.673739727373 | 0.0169467952387  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.512608453107 | 0.0153395280051  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.445568638837 | 0.00971010052298 |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|  0.430119416573 | 0.0017163895695  |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.518689327592 | 0.0196113193151  |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.727875411488 | 0.0649548318693  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.75336359447  | 0.0403312986092  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.703453056047 | 0.0344919659901  |               {'C': 100.0, 'gamma': 10.0}                |        14       |
|  0.659234112165 | 0.0269496692093  |               {'C': 100.0, 'gamma': 100.0}               |        19       |
|  0.514579890376 | 0.0208915593841  |              {'C': 100.0, 'gamma': 1000.0}               |        24       |
|  0.46026493384  | 0.0122299062896  |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
|  0.522344921724 | 0.0168497528991  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.734162572561 | 0.0299144498227  |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.756780976732 | 0.0402521247927  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.741571843347 | 0.0467761415372  |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.71283961255  | 0.0451374366209  |               {'C': 1000.0, 'gamma': 10.0}               |        13       |
|  0.664523934283 | 0.0334633862501  |              {'C': 1000.0, 'gamma': 100.0}               |        16       |
|  0.48187215728  | 0.0290609194512  |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.46430764423  | 0.0165866044445  |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.72289444511  |  0.042519491186  |              {'C': 10000.0, 'gamma': 0.001}              |        11       |
|  0.770991358227 | 0.0350969167862  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.745755560725 | 0.0561098623404  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.721017532373 | 0.0189751323751  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.661020147575 | 0.0325828870487  |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.639738357471 | 0.0461453093563  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.496495842958 | 0.0164728765211  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.449546824433 | 0.0193622041987  |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.69      0.72        99
          1       0.61      0.70      0.65        70

avg / total       0.70      0.69      0.69       169


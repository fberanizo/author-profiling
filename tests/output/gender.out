Evaluating KNeighborsClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.661437908497 |  0.037358959041 |  {'n_neighbors': 3} |        2        |
|  0.654901960784 | 0.0412510888865 |  {'n_neighbors': 5} |        4        |
|  0.639215686275 | 0.0408616380871 | {'n_neighbors': 11} |        5        |
|  0.670588235294 | 0.0279246322335 | {'n_neighbors': 21} |        1        |
|  0.658823529412 | 0.0459124085864 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.78      0.70        50
          1       0.56      0.39      0.46        36

avg / total       0.61      0.62      0.60        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.595380574237 | 0.0588292792597 |  {'n_neighbors': 3} |        5        |
|  0.61536497618  | 0.0695646612935 |  {'n_neighbors': 5} |        4        |
|  0.624286057443 |  0.127443132556 | {'n_neighbors': 11} |        3        |
|  0.641990059018 | 0.0684440258545 | {'n_neighbors': 21} |        2        |
|  0.697867578404 |  0.131860377774 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.72      0.68        50
          1       0.53      0.44      0.48        36

avg / total       0.60      0.60      0.60        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.471742567995 | 0.0663967055776 |  {'n_neighbors': 3} |        2        |
|  0.487261490618 | 0.0928653689984 |  {'n_neighbors': 5} |        1        |
|  0.411685641999 |  0.103527670888 | {'n_neighbors': 11} |        4        |
|  0.440387149483 | 0.0971764451407 | {'n_neighbors': 21} |        3        |
|  0.39299362218  | 0.0662835777654 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.72      0.67        50
          1       0.50      0.39      0.44        36

avg / total       0.57      0.58      0.57        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.624836601307 | 0.0393973554321 |  {'n_neighbors': 3} |        5        |
|  0.630065359477 | 0.0657427119772 |  {'n_neighbors': 5} |        4        |
|  0.63137254902  | 0.0493658188963 | {'n_neighbors': 11} |        3        |
|  0.645751633987 | 0.0367160854865 | {'n_neighbors': 21} |        1        |
|  0.643137254902 | 0.0427727510964 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.82      0.71        50
          1       0.55      0.31      0.39        36

avg / total       0.59      0.60      0.58        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.545119940992 |  0.073820764318 |  {'n_neighbors': 3} |        5        |
|  0.59533094309  |  0.057731034612 |  {'n_neighbors': 5} |        3        |
|  0.586191886948 | 0.0995077698082 | {'n_neighbors': 11} |        4        |
|  0.640690819488 | 0.0938869756494 | {'n_neighbors': 21} |        2        |
|  0.67463750663  |  0.154214762768 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.84      0.72        50
          1       0.60      0.33      0.43        36

avg / total       0.62      0.63      0.60        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.458976386253 | 0.0818634265085 |  {'n_neighbors': 3} |        1        |
|  0.449873497786 |  0.118910445395 |  {'n_neighbors': 5} |        2        |
|  0.402464157706 |  0.135641156844 | {'n_neighbors': 11} |        3        |
|  0.374488720219 |  0.101900134044 | {'n_neighbors': 21} |        4        |
|  0.358570524984 | 0.0605369527669 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.80      0.70        50
          1       0.55      0.33      0.41        36

avg / total       0.59      0.60      0.58        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.639215686275 | 0.0460376046042 |  {'n_neighbors': 3} |        4        |
|  0.645751633987 | 0.0406588781406 |  {'n_neighbors': 5} |        3        |
|  0.639215686275 | 0.0382056843413 | {'n_neighbors': 11} |        4        |
|  0.660130718954 | 0.0412363439897 | {'n_neighbors': 21} |        1        |
|  0.657516339869 | 0.0366818449311 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.88      0.76        50
          1       0.70      0.39      0.50        36

avg / total       0.68      0.67      0.65        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.568288987735 | 0.0778458011537 |  {'n_neighbors': 3} |        5        |
|  0.587721773694 | 0.0826467203276 |  {'n_neighbors': 5} |        3        |
|  0.581136110564 |  0.116380132042 | {'n_neighbors': 11} |        4        |
|  0.639647358719 | 0.0489021924506 | {'n_neighbors': 21} |        2        |
|  0.680381267881 |  0.118716589099 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.92      0.77        50
          1       0.76      0.36      0.49        36

avg / total       0.71      0.69      0.65        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.452681583386 |  0.102051602873 |  {'n_neighbors': 3} |        1        |
|  0.430987771453 | 0.0665401044326 |  {'n_neighbors': 5} |        2        |
|  0.371117963314 |  0.10259166029  | {'n_neighbors': 11} |        5        |
|  0.383413714948 | 0.0673270661057 | {'n_neighbors': 21} |        4        |
|  0.386675100148 |  0.106646160787 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.74      0.69        50
          1       0.55      0.44      0.49        36

avg / total       0.61      0.62      0.61        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.618300653595 | 0.0344295379635 |  {'n_neighbors': 3} |        4        |
|  0.616993464052 | 0.0434418107235 |  {'n_neighbors': 5} |        5        |
|  0.628758169935 | 0.0389993960908 | {'n_neighbors': 11} |        3        |
|  0.652287581699 | 0.0508289073912 | {'n_neighbors': 21} |        2        |
|  0.656209150327 | 0.0540072187337 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.92      0.80        50
          1       0.81      0.47      0.60        36

avg / total       0.75      0.73      0.71        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.53951036255  | 0.0673874431992 |  {'n_neighbors': 3} |        5        |
|  0.594445538592 | 0.0726933749497 |  {'n_neighbors': 5} |        3        |
|  0.585221965471 | 0.0903456992199 | {'n_neighbors': 11} |        4        |
|  0.605865757666 | 0.0737402294363 | {'n_neighbors': 21} |        2        |
|  0.667199384627 | 0.0895894434389 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.92      0.80        50
          1       0.81      0.47      0.60        36

avg / total       0.75      0.73      0.71        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.443399483449 |  0.105498264819 |  {'n_neighbors': 3} |        1        |
|  0.436907020873 | 0.0868007186215 |  {'n_neighbors': 5} |        2        |
|  0.39643553658  | 0.0735221220345 | {'n_neighbors': 11} |        4        |
|  0.402535315201 | 0.0677189053614 | {'n_neighbors': 21} |        3        |
|  0.355302551128 | 0.0555118969249 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.82      0.75        50
          1       0.67      0.50      0.57        36

avg / total       0.68      0.69      0.68        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.620104438642 | 0.0486028789444 |  {'n_neighbors': 3} |        5        |
|  0.648825065274 | 0.0395440422218 |  {'n_neighbors': 5} |        1        |
|  0.637075718016 | 0.0598689922185 | {'n_neighbors': 11} |        3        |
|  0.634464751958 | 0.0461354480934 | {'n_neighbors': 21} |        4        |
|  0.646214099217 | 0.0358002796584 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.84      0.76        50
          1       0.68      0.49      0.57        35

avg / total       0.69      0.69      0.68        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.550285709321 | 0.0458944804317 |  {'n_neighbors': 3} |        5        |
|  0.573032711542 | 0.0816569871549 |  {'n_neighbors': 5} |        4        |
|  0.617288592777 |  0.10816739195  | {'n_neighbors': 11} |        3        |
|  0.652115682655 |  0.087906518983 | {'n_neighbors': 21} |        1        |
|  0.637522183815 |  0.108703610464 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.88      0.77        50
          1       0.71      0.43      0.54        35

avg / total       0.70      0.69      0.67        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.451318116735 | 0.0687092596626 |  {'n_neighbors': 3} |        1        |
|  0.413867072349 |  0.101247266715 |  {'n_neighbors': 5} |        2        |
|  0.363496746821 | 0.0878272508578 | {'n_neighbors': 11} |        4        |
|  0.373029931357 |  0.106649128186 | {'n_neighbors': 21} |        3        |
|  0.335044586457 |  0.112820471136 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.80      0.77        50
          1       0.68      0.60      0.64        35

avg / total       0.71      0.72      0.71        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.616187989556 | 0.0477155727799 |  {'n_neighbors': 3} |        5        |
|  0.644908616188 | 0.0676140148792 |  {'n_neighbors': 5} |        3        |
|  0.629242819843 |  0.038294784919 | {'n_neighbors': 11} |        4        |
|  0.650130548303 | 0.0402275642261 | {'n_neighbors': 21} |        1        |
|  0.650130548303 | 0.0336324886488 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.76      0.71        50
          1       0.57      0.46      0.51        35

avg / total       0.63      0.64      0.63        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.56387178063  | 0.0594271020271 |  {'n_neighbors': 3} |        5        |
|  0.569811537857 | 0.0585834108984 |  {'n_neighbors': 5} |        4        |
|  0.602821456799 | 0.0927834352985 | {'n_neighbors': 11} |        3        |
|  0.644026201596 |  0.071645776411 | {'n_neighbors': 21} |        2        |
|  0.687444566126 | 0.0784675138358 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.84      0.74        50
          1       0.62      0.37      0.46        35

avg / total       0.64      0.65      0.62        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.463964983576 | 0.0721167020565 |  {'n_neighbors': 3} |        1        |
|  0.438952876274 | 0.0927733489021 |  {'n_neighbors': 5} |        2        |
|  0.373002295123 | 0.0693102244384 | {'n_neighbors': 11} |        5        |
|  0.394903352144 | 0.0916043900149 | {'n_neighbors': 21} |        3        |
|  0.379257295966 | 0.0899676196233 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.60      0.61        50
          1       0.46      0.49      0.47        35

avg / total       0.56      0.55      0.55        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.634464751958 | 0.0425737282665 |  {'n_neighbors': 3} |        5        |
|  0.647519582245 | 0.0412122042443 |  {'n_neighbors': 5} |        3        |
|  0.647519582245 | 0.0580654009043 | {'n_neighbors': 11} |        3        |
|  0.654046997389 |  0.036964730221 | {'n_neighbors': 21} |        2        |
|  0.665796344648 | 0.0418951544668 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.88      0.75        50
          1       0.65      0.31      0.42        35

avg / total       0.65      0.65      0.61        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.57720869625  |  0.075437424705 |  {'n_neighbors': 3} |        4        |
|  0.575849008671 | 0.0556587030313 |  {'n_neighbors': 5} |        5        |
|  0.62143034293  | 0.0985915886251 | {'n_neighbors': 11} |        3        |
|  0.685462493672 | 0.0846372829284 | {'n_neighbors': 21} |        2        |
|  0.737854665432 | 0.0613532774273 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.88      0.75        50
          1       0.65      0.31      0.42        35

avg / total       0.65      0.65      0.61        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.492138149583 | 0.0814172297351 |  {'n_neighbors': 3} |        1        |
|  0.47041080603  | 0.0786919295604 |  {'n_neighbors': 5} |        2        |
|  0.401164933041 | 0.0758704038726 | {'n_neighbors': 11} |        3        |
|  0.382456518993 | 0.0905757840141 | {'n_neighbors': 21} |        5        |
|  0.385567569275 |  0.072453605434 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.68      0.68        50
          1       0.54      0.54      0.54        35

avg / total       0.62      0.62      0.62        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.642764015645 | 0.0614379008959 |  {'n_neighbors': 3} |        3        |
|  0.627118644068 | 0.0359141224765 |  {'n_neighbors': 5} |        5        |
|  0.642764015645 | 0.0704216068541 | {'n_neighbors': 11} |        3        |
|  0.664928292047 |  0.055492374315 | {'n_neighbors': 21} |        2        |
|  0.674054758801 | 0.0475414371767 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.86      0.76        49
          1       0.68      0.43      0.53        35

avg / total       0.68      0.68      0.66        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.578227591149 |  0.039815821658 |  {'n_neighbors': 3} |        5        |
|  0.591428130593 |  0.101168453594 |  {'n_neighbors': 5} |        4        |
|  0.613170951608 | 0.0778978579453 | {'n_neighbors': 11} |        3        |
|  0.65111235792  | 0.0829446057729 | {'n_neighbors': 21} |        2        |
|  0.669501644639 |  0.114857137027 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.86      0.76        49
          1       0.68      0.43      0.53        35

avg / total       0.68      0.68      0.66        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.463994879505 | 0.0939250378602 |  {'n_neighbors': 3} |        1        |
|  0.429478855617 | 0.0883364507108 |  {'n_neighbors': 5} |        2        |
|  0.376107950961 | 0.0511771925001 | {'n_neighbors': 11} |        5        |
|  0.379211002229 | 0.0597742146915 | {'n_neighbors': 21} |        4        |
|  0.385652363629 | 0.0984142971234 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.69      0.66        49
          1       0.50      0.43      0.46        35

avg / total       0.58      0.58      0.58        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.625814863103 |  0.019467083287 |  {'n_neighbors': 3} |        5        |
|  0.633637548892 | 0.0435544651833 |  {'n_neighbors': 5} |        4        |
|  0.64667535854  | 0.0482819262964 | {'n_neighbors': 11} |        3        |
|  0.661016949153 | 0.0469059396058 | {'n_neighbors': 21} |        1        |
|  0.655801825293 | 0.0437316722919 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.90      0.76        49
          1       0.71      0.34      0.46        35

avg / total       0.68      0.67      0.63        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.549825493391 | 0.0603714421344 |  {'n_neighbors': 3} |        5        |
|  0.577606216759 | 0.0648768479058 |  {'n_neighbors': 5} |        4        |
|  0.625157563063 |  0.142965830002 | {'n_neighbors': 11} |        3        |
|  0.647418715255 | 0.0723932258489 | {'n_neighbors': 21} |        2        |
|  0.696275500982 |  0.120094120328 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.90      0.75        49
          1       0.69      0.31      0.43        35

avg / total       0.66      0.65      0.62        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.50782794297  | 0.0771404346608 |  {'n_neighbors': 3} |        1        |
|  0.451255414897 | 0.0948514560904 |  {'n_neighbors': 5} |        2        |
|  0.382427082895 |  0.100101153807 | {'n_neighbors': 11} |        4        |
|  0.404407357951 | 0.0842015219529 | {'n_neighbors': 21} |        3        |
|  0.363790375152 | 0.0674865520374 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.86      0.74        49
          1       0.65      0.37      0.47        35

avg / total       0.65      0.65      0.63        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.641460234681 | 0.0598328212277 |  {'n_neighbors': 3} |        3        |
|  0.631029986962 | 0.0456603252613 |  {'n_neighbors': 5} |        4        |
|  0.625814863103 |  0.038916405088 | {'n_neighbors': 11} |        5        |
|  0.657105606258 | 0.0305987543971 | {'n_neighbors': 21} |        1        |
|  0.655801825293 | 0.0435630237869 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.88      0.77        49
          1       0.71      0.43      0.54        35

avg / total       0.70      0.69      0.67        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.568616168076 |  0.105074537979 |  {'n_neighbors': 3} |        5        |
|  0.612410433779 | 0.0925755112981 |  {'n_neighbors': 5} |        3        |
|  0.629483618823 | 0.0794932703822 | {'n_neighbors': 11} |        2        |
|  0.578335500182 | 0.0677486268282 | {'n_neighbors': 21} |        4        |
|  0.668450230652 | 0.0764238046624 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.94      0.80        49
          1       0.83      0.43      0.57        35

avg / total       0.75      0.73      0.70        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.479483849939 | 0.0714972369972 |  {'n_neighbors': 3} |        1        |
|  0.420155244564 | 0.0727765708064 |  {'n_neighbors': 5} |        2        |
|  0.382423140009 | 0.0841205134862 | {'n_neighbors': 11} |        3        |
|  0.347815115448 | 0.0813856380416 | {'n_neighbors': 21} |        4        |
|  0.329062749716 | 0.0909108313346 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.65      0.64        49
          1       0.48      0.46      0.47        35

avg / total       0.57      0.57      0.57        84

Evaluating RandomForestClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.62614379085  |  0.042464140246 | {'n_estimators': 2}  |        6        |
|  0.618300653595 | 0.0390510230634 | {'n_estimators': 3}  |        7        |
|  0.667973856209 | 0.0253746786373 | {'n_estimators': 5}  |        5        |
|  0.695424836601 | 0.0355085653652 | {'n_estimators': 10} |        4        |
|  0.701960784314 | 0.0340756133452 | {'n_estimators': 20} |        3        |
|  0.722875816993 | 0.0318228978896 | {'n_estimators': 40} |        1        |
|  0.718954248366 | 0.0185194591217 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.76      0.69        50
          1       0.54      0.39      0.45        36

avg / total       0.59      0.60      0.59        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.668382183883 |  0.137765959566 | {'n_estimators': 2}  |        4        |
|  0.577688784132 | 0.0663945358822 | {'n_estimators': 3}  |        7        |
|  0.584639490644 | 0.0788626768628 | {'n_estimators': 5}  |        6        |
|  0.700987007489 | 0.0769415314081 | {'n_estimators': 10} |        3        |
|  0.64626220651  | 0.0874300289258 | {'n_estimators': 20} |        5        |
|  0.705113573751 | 0.0746671159928 | {'n_estimators': 40} |        2        |
|  0.72978026468  | 0.0371653792297 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.80      0.73        50
          1       0.63      0.47      0.54        36

avg / total       0.66      0.66      0.65        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.267205618807 | 0.0980278997765 | {'n_estimators': 2}  |        7        |
|  0.534575954038 | 0.0675482427604 | {'n_estimators': 3}  |        4        |
|  0.503076902804 | 0.0803770671975 | {'n_estimators': 5}  |        6        |
|  0.503289057559 |  0.115846351607 | {'n_estimators': 10} |        5        |
|  0.537796489564 | 0.0905631493943 | {'n_estimators': 20} |        3        |
|  0.575354469745 |  0.138404119469 | {'n_estimators': 40} |        2        |
|  0.597430423782 | 0.0830630401589 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.86      0.73        50
          1       0.61      0.31      0.41        36

avg / total       0.62      0.63      0.59        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.637908496732 | 0.0583268053234 | {'n_estimators': 2}  |        6        |
|  0.61568627451  | 0.0470744943879 | {'n_estimators': 3}  |        7        |
|  0.686274509804 | 0.0511558004758 | {'n_estimators': 5}  |        4        |
|  0.681045751634 | 0.0391990226943 | {'n_estimators': 10} |        5        |
|  0.704575163399 | 0.0388849807591 | {'n_estimators': 20} |        3        |
|  0.734640522876 | 0.0514279721252 | {'n_estimators': 40} |        1        |
|  0.724183006536 |  0.054183645589 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.74      0.69        50
          1       0.55      0.44      0.49        36

avg / total       0.61      0.62      0.61        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.629872383766 | 0.0949966207547 | {'n_estimators': 2}  |        5        |
|  0.592626375895 |  0.050993225198 | {'n_estimators': 3}  |        6        |
|  0.59139702053  | 0.0840931351315 | {'n_estimators': 5}  |        7        |
|  0.676299475673 | 0.0607225726139 | {'n_estimators': 10} |        4        |
|  0.683888951942 | 0.0854499399631 | {'n_estimators': 20} |        3        |
|  0.70375188629  | 0.0377956714686 | {'n_estimators': 40} |        2        |
|  0.713733801737 | 0.0528743691473 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.78      0.73        50
          1       0.62      0.50      0.55        36

avg / total       0.66      0.66      0.66        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.270573740249 |  0.100327775433 | {'n_estimators': 2}  |        7        |
|  0.537629137677 |  0.110866602035 | {'n_estimators': 3}  |        5        |
|  0.537762228547 | 0.0735852711664 | {'n_estimators': 5}  |        4        |
|  0.49686116382  |  0.130584378513 | {'n_estimators': 10} |        6        |
|  0.569203299599 | 0.0814563953484 | {'n_estimators': 20} |        2        |
|   0.5659419144  | 0.0855902026473 | {'n_estimators': 40} |        3        |
|  0.613226069998 | 0.0815227437099 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.74      0.70        50
          1       0.58      0.50      0.54        36

avg / total       0.63      0.64      0.63        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.603921568627 |  0.043818183556 | {'n_estimators': 2}  |        7        |
|  0.639215686275 |  0.058223009387 | {'n_estimators': 3}  |        6        |
|  0.664052287582 | 0.0520288907798 | {'n_estimators': 5}  |        5        |
|  0.688888888889 | 0.0332932954088 | {'n_estimators': 10} |        4        |
|  0.696732026144 | 0.0360163440057 | {'n_estimators': 20} |        3        |
|  0.713725490196 | 0.0497433092994 | {'n_estimators': 40} |        1        |
|  0.712418300654 | 0.0231688233634 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.94      0.80        50
          1       0.84      0.44      0.58        36

avg / total       0.76      0.73      0.71        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.58610024356  |  0.10095585149  | {'n_estimators': 2}  |        7        |
|  0.603903408401 | 0.0584357158691 | {'n_estimators': 3}  |        6        |
|  0.613108413985 | 0.0882602607177 | {'n_estimators': 5}  |        5        |
|  0.652962162645 | 0.0944999163042 | {'n_estimators': 10} |        4        |
|  0.681014793365 | 0.0949479962508 | {'n_estimators': 20} |        3        |
|  0.70797785421  | 0.0613269094844 | {'n_estimators': 40} |        2        |
|  0.723705375363 | 0.0676633747362 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.92      0.79        50
          1       0.80      0.44      0.57        36

avg / total       0.74      0.72      0.70        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.311256061564 | 0.0613212805433 | {'n_estimators': 2}  |        7        |
|  0.525511279781 |  0.122642346333 | {'n_estimators': 3}  |        4        |
|  0.518896268185 | 0.0688147614435 | {'n_estimators': 5}  |        5        |
|  0.462390628294 | 0.0865783940787 | {'n_estimators': 10} |        6        |
|  0.534719586759 | 0.0946623591294 | {'n_estimators': 20} |        3        |
|  0.581662449926 | 0.0522781031037 | {'n_estimators': 40} |        1        |
|  0.566013071895 | 0.0824577964662 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.88      0.79        50
          1       0.76      0.53      0.62        36

avg / total       0.74      0.73      0.72        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.656209150327 | 0.0406528452017 | {'n_estimators': 2}  |        5        |
|  0.628758169935 | 0.0324953693787 | {'n_estimators': 3}  |        7        |
|  0.653594771242 |  0.048306129051 | {'n_estimators': 5}  |        6        |
|  0.664052287582 | 0.0350705551386 | {'n_estimators': 10} |        4        |
|  0.704575163399 | 0.0518846874422 | {'n_estimators': 20} |        2        |
|  0.722875816993 | 0.0204748546552 | {'n_estimators': 40} |        1        |
|  0.704575163399 | 0.0634515461363 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.92      0.81        50
          1       0.82      0.50      0.62        36

avg / total       0.76      0.74      0.73        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.602250760166 | 0.0888220690092 | {'n_estimators': 2}  |        6        |
|  0.549234833858 |  0.065680857981 | {'n_estimators': 3}  |        7        |
|  0.63268359054  |  0.082340299928 | {'n_estimators': 5}  |        5        |
|  0.665701326939 | 0.0966931933819 | {'n_estimators': 10} |        4        |
|  0.683692758046 | 0.0799460856319 | {'n_estimators': 20} |        2        |
|  0.693223595707 |  0.098379083038 | {'n_estimators': 40} |        1        |
|  0.674309522624 | 0.0705281113671 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.88      0.78        50
          1       0.74      0.47      0.58        36

avg / total       0.72      0.71      0.69        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.254546173308 | 0.0526774657718 | {'n_estimators': 2}  |        7        |
|  0.556795540797 |  0.088571477156 | {'n_estimators': 3}  |        3        |
|  0.559614168248 | 0.0793713355229 | {'n_estimators': 5}  |        2        |
|  0.490362112587 | 0.0878452901794 | {'n_estimators': 10} |        6        |
|  0.525180529201 | 0.0680735379451 | {'n_estimators': 20} |        5        |
|  0.553246890154 |  0.12388934282  | {'n_estimators': 40} |        4        |
|  0.584855313093 | 0.0672291934496 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.84      0.80        50
          1       0.74      0.64      0.69        36

avg / total       0.75      0.76      0.75        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.627937336815 | 0.0391506975269 | {'n_estimators': 2}  |        7        |
|  0.638381201044 | 0.0556480420934 | {'n_estimators': 3}  |        6        |
|  0.677545691906 | 0.0619217714015 | {'n_estimators': 5}  |        5        |
|  0.678851174935 |  0.037990919091 | {'n_estimators': 10} |        4        |
|  0.716710182768 | 0.0365021816226 | {'n_estimators': 20} |        3        |
|  0.721932114883 | 0.0473513184429 | {'n_estimators': 40} |        2        |
|  0.72454308094  | 0.0513843760845 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.76      0.74        50
          1       0.62      0.57      0.60        35

avg / total       0.68      0.68      0.68        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.628179767916 | 0.0988270379586 | {'n_estimators': 2}  |        5        |
|  0.584292785164 | 0.0699899955196 | {'n_estimators': 3}  |        7        |
|  0.601219836264 | 0.0599441938103 | {'n_estimators': 5}  |        6        |
|  0.67784263259  |  0.052756887658 | {'n_estimators': 10} |        3        |
|  0.702801658157 | 0.0882029672713 | {'n_estimators': 20} |        2        |
|  0.669990255369 | 0.0902084691591 | {'n_estimators': 40} |        4        |
|  0.703252452844 | 0.0635289307252 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.74      0.71        50
          1       0.58      0.51      0.55        35

avg / total       0.64      0.65      0.64        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.313493588394 | 0.0964565329898 | {'n_estimators': 2}  |        7        |
|  0.573299187232 | 0.0893756426034 | {'n_estimators': 3}  |        3        |
|  0.554661837783 | 0.0921600018694 | {'n_estimators': 5}  |        5        |
|  0.501847679609 | 0.0720624308989 | {'n_estimators': 10} |        6        |
|  0.564500336899 |  0.11219561354  | {'n_estimators': 20} |        4        |
|  0.586235576518 | 0.0946725685301 | {'n_estimators': 40} |        2        |
|  0.592640602628 | 0.0671290569646 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.74      0.75        50
          1       0.64      0.66      0.65        35

avg / total       0.71      0.71      0.71        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.613577023499 | 0.0446904567636 | {'n_estimators': 2}  |        7        |
|  0.640992167102 | 0.0410147701418 | {'n_estimators': 3}  |        6        |
|  0.654046997389 | 0.0647007038785 | {'n_estimators': 5}  |        5        |
|  0.689295039164 | 0.0389604280176 | {'n_estimators': 10} |        4        |
|  0.699738903394 | 0.0392523481825 | {'n_estimators': 20} |        3        |
|  0.701044386423 | 0.0439605414851 | {'n_estimators': 40} |        2        |
|  0.723237597911 | 0.0565597198698 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.84      0.79        50
          1       0.72      0.60      0.66        35

avg / total       0.74      0.74      0.74        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.564791941205 | 0.0875643948513 | {'n_estimators': 2}  |        7        |
|  0.590302183547 | 0.0847664407526 | {'n_estimators': 3}  |        5        |
|  0.579179322164 | 0.0976835674353 | {'n_estimators': 5}  |        6        |
|  0.632020277678 | 0.0799215618741 | {'n_estimators': 10} |        4        |
|  0.69356091431  | 0.0623973778768 | {'n_estimators': 20} |        1        |
|  0.670731638097 | 0.0799257636626 | {'n_estimators': 40} |        3        |
|  0.691897247596 | 0.0705668719237 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.84      0.76        50
          1       0.68      0.49      0.57        35

avg / total       0.69      0.69      0.68        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.307309652152 | 0.0694621215244 | {'n_estimators': 2}  |        7        |
|  0.491824938937 | 0.0687171010019 | {'n_estimators': 3}  |        5        |
|  0.514052366714 | 0.0737869371686 | {'n_estimators': 5}  |        4        |
|  0.476305219826 |  0.121147044311 | {'n_estimators': 10} |        6        |
|  0.538938136949 | 0.0801286277453 | {'n_estimators': 20} |        3        |
|  0.579854238609 | 0.0717275673806 | {'n_estimators': 40} |        2        |
|  0.59261954645  |  0.078554099567 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.76      0.75        50
          1       0.64      0.60      0.62        35

avg / total       0.69      0.69      0.69        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.599216710183 | 0.0524246115798 | {'n_estimators': 2}  |        7        |
|  0.642297650131 | 0.0587792776669 | {'n_estimators': 3}  |        5        |
|  0.630548302872 | 0.0270838198201 | {'n_estimators': 5}  |        6        |
|  0.685378590078 | 0.0320635476921 | {'n_estimators': 10} |        4        |
|  0.701044386423 | 0.0260109718146 | {'n_estimators': 20} |        3        |
|  0.708877284595 | 0.0468624208235 | {'n_estimators': 40} |        2        |
|  0.715404699739 | 0.0465829840373 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.82      0.77        50
          1       0.69      0.57      0.62        35

avg / total       0.71      0.72      0.71        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.58109120866  |  0.107138237646 | {'n_estimators': 2}  |        7        |
|  0.593511315175 | 0.0904508684747 | {'n_estimators': 3}  |        6        |
|  0.600048050805 | 0.0556071886618 | {'n_estimators': 5}  |        5        |
|  0.644455796471 | 0.0740550769831 | {'n_estimators': 10} |        4        |
|  0.665403414992 | 0.0705518277919 | {'n_estimators': 20} |        3        |
|  0.689132462591 | 0.0839818985429 | {'n_estimators': 40} |        2        |
|  0.689609511572 | 0.0810274856092 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.84      0.78        50
          1       0.70      0.54      0.61        35

avg / total       0.72      0.72      0.71        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.335184083635 |  0.106152696322 | {'n_estimators': 2}  |        7        |
|  0.548941137455 |  0.106600829816 | {'n_estimators': 3}  |        2        |
|  0.527036132401 |  0.103992242728 | {'n_estimators': 5}  |        5        |
|  0.485838404363 | 0.0924456688345 | {'n_estimators': 10} |        6        |
|  0.529874768382 | 0.0618738530303 | {'n_estimators': 20} |        4        |
|  0.545469500126 | 0.0637199901422 | {'n_estimators': 40} |        3        |
|  0.561090552093 | 0.0931299874534 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.78      0.76        50
          1       0.67      0.63      0.65        35

avg / total       0.72      0.72      0.72        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.597131681877 | 0.0274972565471 | {'n_estimators': 2}  |        7        |
|  0.638852672751 |  0.051939776633 | {'n_estimators': 3}  |        6        |
|  0.655801825293 | 0.0472072798848 | {'n_estimators': 5}  |        5        |
|  0.683181225554 | 0.0524292385164 | {'n_estimators': 10} |        4        |
|  0.698826597132 | 0.0365157358599 | {'n_estimators': 20} |        2        |
|  0.702737940026 | 0.0611175356441 | {'n_estimators': 40} |        1        |
|  0.698826597132 | 0.0440603022394 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.80      0.80        49
          1       0.71      0.71      0.71        35

avg / total       0.76      0.76      0.76        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.579872293191 | 0.0587686592839 | {'n_estimators': 2}  |        6        |
|  0.550006537843 | 0.0376623947129 | {'n_estimators': 3}  |        7        |
|  0.601778842758 | 0.0510738562173 | {'n_estimators': 5}  |        5        |
|  0.637745595793 | 0.0888702891829 | {'n_estimators': 10} |        4        |
|  0.658078480675 | 0.0736221962514 | {'n_estimators': 20} |        3        |
|  0.688477787428 | 0.0720692551375 | {'n_estimators': 40} |        1        |
|  0.673605737605 | 0.0710532616244 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.84      0.80        49
          1       0.74      0.66      0.70        35

avg / total       0.76      0.76      0.76        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.322852704294 | 0.0894963728623 | {'n_estimators': 2}  |        7        |
|  0.523694116163 | 0.0968334127325 | {'n_estimators': 3}  |        3        |
|  0.529961990579 |  0.056713884413 | {'n_estimators': 5}  |        2        |
|  0.448172078059 |  0.11093840207  | {'n_estimators': 10} |        6        |
|  0.50477877781  |  0.106629927992 | {'n_estimators': 20} |        5        |
|  0.523507486226 | 0.0846125773987 | {'n_estimators': 40} |        4        |
|  0.538921541826 | 0.0934996063788 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.84      0.81        49
          1       0.75      0.69      0.72        35

avg / total       0.77      0.77      0.77        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.623207301173 | 0.0370859150262 | {'n_estimators': 2}  |        7        |
|  0.642764015645 |  0.050497086051 | {'n_estimators': 3}  |        6        |
|  0.658409387223 | 0.0454569643518 | {'n_estimators': 5}  |        5        |
|  0.672750977836 | 0.0481224233773 | {'n_estimators': 10} |        4        |
|  0.715775749674 | 0.0347320656379 | {'n_estimators': 20} |        2        |
|  0.713168187744 | 0.0597630303224 | {'n_estimators': 40} |        3        |
|  0.718383311604 | 0.0447025064787 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.86      0.80        49
          1       0.75      0.60      0.67        35

avg / total       0.75      0.75      0.74        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|   0.572592184   |  0.164863056513 | {'n_estimators': 2}  |        7        |
|  0.582631257054 | 0.0851653192572 | {'n_estimators': 3}  |        6        |
|  0.617310264239 |  0.041299103489 | {'n_estimators': 5}  |        5        |
|  0.662198451193 | 0.0549394177467 | {'n_estimators': 10} |        4        |
|  0.669433966405 |  0.055697961561 | {'n_estimators': 20} |        3        |
|  0.718194904153 | 0.0799759159178 | {'n_estimators': 40} |        1        |
|  0.710457364119 | 0.0751719828682 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.88      0.81        49
          1       0.78      0.60      0.68        35

avg / total       0.76      0.76      0.76        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.291222872944 |  0.103485971633 | {'n_estimators': 2}  |        7        |
|  0.545688848467 | 0.0789682968467 | {'n_estimators': 3}  |        4        |
|  0.564261155739 |  0.097779439273 | {'n_estimators': 5}  |        2        |
|  0.467050616142 | 0.0635433974978 | {'n_estimators': 10} |        6        |
|  0.532831097279 |  0.104354018031 | {'n_estimators': 20} |        5        |
|  0.548611841275 | 0.0841436262377 | {'n_estimators': 40} |        3        |
|  0.589202538167 | 0.0892324041697 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.86      0.79        49
          1       0.73      0.54      0.62        35

avg / total       0.73      0.73      0.72        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.619295958279 |  0.028432223006 | {'n_estimators': 2}  |        7        |
|  0.642764015645 | 0.0556036505635 | {'n_estimators': 3}  |        5        |
|  0.627118644068 | 0.0525603058049 | {'n_estimators': 5}  |        6        |
|  0.671447196871 | 0.0445822984328 | {'n_estimators': 10} |        4        |
|  0.710560625815 | 0.0469071710204 | {'n_estimators': 20} |        3        |
|  0.718383311604 | 0.0401529508522 | {'n_estimators': 40} |        2        |
|  0.719687092568 | 0.0362542536656 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.90      0.71      0.80        49
          1       0.69      0.89      0.78        35

avg / total       0.81      0.79      0.79        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.597117163941 | 0.0657982133655 | {'n_estimators': 2}  |        5        |
|  0.58418981848  | 0.0820525742389 | {'n_estimators': 3}  |        7        |
|  0.594006375209 | 0.0501183936233 | {'n_estimators': 5}  |        6        |
|  0.677155564639 | 0.0781825619968 | {'n_estimators': 10} |        3        |
|  0.705670444288 | 0.0895517264087 | {'n_estimators': 20} |        1        |
|  0.696357089622 | 0.0566378792386 | {'n_estimators': 40} |        2        |
|  0.675535303564 |  0.089184426029 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.82      0.81        49
          1       0.74      0.71      0.72        35

avg / total       0.77      0.77      0.77        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.369897905539 | 0.0726747946114 | {'n_estimators': 2}  |        7        |
|  0.589433854145 | 0.0946015142747 | {'n_estimators': 3}  |        1        |
|  0.491961769778 |  0.10110888701  | {'n_estimators': 5}  |        5        |
|  0.42618128864  | 0.0839074582882 | {'n_estimators': 10} |        6        |
|  0.50463551962  |  0.101757681836 | {'n_estimators': 20} |        4        |
|  0.551504605291 | 0.0826284458693 | {'n_estimators': 40} |        3        |
|  0.564029839761 |  0.113688447659 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.65      0.70        49
          1       0.60      0.71      0.65        35

avg / total       0.69      0.68      0.68        84

Evaluating MLPClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.606535947712 | 0.0249775213786 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.640522875817 | 0.0310194916334 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.660130718954 | 0.0559521722219 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.675816993464 | 0.0653963936862 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.657516339869 | 0.0607049951309 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.686274509804 | 0.0708372251851 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.690196078431 | 0.0732551986708 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.752941176471 | 0.0509325313922 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.755555555556 |  0.051194111963 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.762091503268 | 0.0566375156572 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        4        |
|  0.755555555556 | 0.0580182198862 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.764705882353 | 0.0493601172073 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.766013071895 |  0.037149707706 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.754248366013 |  0.065877080109 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.749019607843 | 0.0514886362043 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.750326797386 | 0.0496495668726 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.764705882353 | 0.0394413669798 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.762091503268 | 0.0290061595743 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.755555555556 | 0.0338227876805 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        8        |
|  0.758169934641 |  0.030142890037 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.762091503268 | 0.0332746172558 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        4        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.82      0.79        50
          1       0.72      0.64      0.68        36

avg / total       0.74      0.74      0.74        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.735424836601 |  0.392199835803 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        3        |
|  0.729749455338 |  0.275554917175 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        6        |
|  0.592178230266 |  0.393577178509 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.585342532075 |  0.389075713354 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.495517455506 |  0.412318664259 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        20       |
|  0.211312136234 |  0.327788834608 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.517437516414 |  0.344250384213 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.734713002859 | 0.0615478779718 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.725399723119 | 0.0726925784516 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.720301080655 | 0.0567031289833 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.732267569679 | 0.0598908375077 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.712601577492 | 0.0283066647752 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        14       |
|  0.724381668955 | 0.0628396406201 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.740019910156 | 0.0896571019485 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.751012928799 | 0.0717432589166 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        1        |
|  0.729718081338 | 0.0787321694448 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        7        |
|  0.71335699207  | 0.0523626478951 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        12       |
|  0.710194174687 | 0.0780927897881 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        16       |
|  0.710958431791 | 0.0647858651793 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        15       |
|  0.717072620533 | 0.0556287731045 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        11       |
|  0.712810177471 | 0.0495730854979 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        13       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.82      0.76        50
          1       0.68      0.53      0.59        36

avg / total       0.70      0.70      0.69        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
| 0.0911198081383 | 0.0966915126956 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|   0.2010871284  | 0.0919902379019 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.179062565887 |  0.156321078878 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        20       |
|  0.217034313725 |  0.225164740088 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.415155228758 |  0.17292860925  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.302132089395 |  0.264010975334 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|   0.3119794961  |  0.266284411933 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.622819154544 |  0.105488986316 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.663546278727 | 0.0861055831686 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.669700084335 |  0.127108097804 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.676243938436 | 0.0901340299968 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
|  0.70440649378  | 0.0751958327448 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        3        |
|  0.710819892473 |  0.073535632894 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.695055871811 |  0.124080760727 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|  0.569117647059 | 0.0742036244724 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.647668933165 | 0.0904600930978 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.691783944761 | 0.0996955531464 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.698347564832 | 0.0927119896687 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.698272454143 | 0.0716440152757 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.698225015813 | 0.0804795205502 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.713866487455 |  0.098207595247 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.80      0.78        50
          1       0.71      0.67      0.69        36

avg / total       0.74      0.74      0.74        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.61568627451  | 0.0225819724536 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.640522875817 | 0.0277765386768 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.650980392157 |  0.06727583075  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.679738562092 | 0.0548381193032 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|  0.630065359477 | 0.0593890271612 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        20       |
|  0.645751633987 | 0.0667056626398 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        18       |
|  0.671895424837 | 0.0865027433874 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.745098039216 |  0.049244950446 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        9        |
|  0.743790849673 | 0.0398157743321 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.747712418301 | 0.0404297584303 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.749019607843 | 0.0612218034658 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.743790849673 | 0.0390058374789 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.752941176471 | 0.0401908342288 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.752941176471 | 0.0299228670365 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.745098039216 | 0.0402846698763 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.739869281046 | 0.0362051621002 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.746405228758 | 0.0414649404367 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.747712418301 | 0.0602642813401 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.752941176471 | 0.0394257571556 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        1        |
|  0.749019607843 | 0.0410171941109 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.738562091503 |  0.062891881397 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        14       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.84      0.74      0.79        50
          1       0.69      0.81      0.74        36

avg / total       0.78      0.77      0.77        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.698474945534 |  0.38650698884  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|  0.734950561421 |  0.288307794767 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        7        |
|  0.67200823014  |  0.349949982506 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.457502400457 |  0.379847149908 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.551328814753 |  0.36346230466  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.380403610654 |  0.383546781168 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.572622449422 |  0.294593675429 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.760558930439 |  0.082881524797 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        1        |
|  0.714602870611 | 0.0548224657824 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.708398909542 | 0.0894673755336 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        13       |
|  0.733913727056 | 0.0623161897751 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.753206706562 | 0.0610806835616 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.741568077371 | 0.0812489432314 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.738377570893 | 0.0622294977418 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.751871729294 |  0.103856732525 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        3        |
|  0.731562935143 | 0.0595663845352 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.719786778338 | 0.0652931268897 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.723735911773 | 0.0638652082044 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        10       |
|  0.706043373204 |  0.05882432867  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        14       |
|  0.702179307783 | 0.0638891898735 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        15       |
|  0.737835357629 | 0.0802152405757 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        6        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.82      0.80        50
          1       0.73      0.67      0.70        36

avg / total       0.75      0.76      0.75        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
| 0.0880112797807 | 0.0698735295287 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.163419776513 | 0.0762840505276 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.213576586549 |  0.179772468421 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.352000316256 |  0.134429478394 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|  0.351723592663 |  0.194539073771 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.182897164242 |  0.228570268052 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        19       |
|  0.276803974278 |  0.239741082367 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.622580645161 | 0.0733763803738 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.613301180687 | 0.0749016226137 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.651230761122 |  0.103204991309 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.625790638836 | 0.0616737987601 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.644551180687 | 0.0744466758504 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        8        |
|  0.669796278727 | 0.0657749675464 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.651179369597 | 0.0896143167212 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|   0.5596919144  | 0.0533775191956 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.594418089817 | 0.0800157863476 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.641708834071 | 0.0834481911332 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.669775195024 | 0.0810504159441 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.685847564832 |  0.138343898273 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.688726807927 |  0.05481091375  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.691909129243 |  0.112472229027 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.88      0.76      0.82        50
          1       0.72      0.86      0.78        36

avg / total       0.82      0.80      0.80        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.613071895425 | 0.0313703449771 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.648366013072 | 0.0547447697263 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.675816993464 |  0.060040115903 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.687581699346 | 0.0584266602993 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|  0.674509803922 | 0.0649002460392 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.679738562092 | 0.0727869302194 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.658823529412 | 0.0656097193496 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.732026143791 | 0.0387877546039 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.739869281046 | 0.0338172629513 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.754248366013 | 0.0666324653381 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        1        |
|  0.733333333333 | 0.0426235511294 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.739869281046 | 0.0437782461848 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
|  0.745098039216 | 0.0454348949083 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
|  0.752941176471 | 0.0330089228759 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.730718954248 | 0.0474767000494 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.742483660131 | 0.0385659083739 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        7        |
|  0.738562091503 | 0.0477078489955 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.754248366013 | 0.0424344431083 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        1        |
|  0.742483660131 | 0.0573890708586 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.746405228758 | 0.0597034406644 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.754248366013 | 0.0471082279653 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.81      0.78      0.80        50
          1       0.71      0.75      0.73        36

avg / total       0.77      0.77      0.77        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.824945533769 |  0.299922067964 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.811775599129 |  0.159853517869 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.618040478671 |  0.335981640725 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.398410091935 |  0.401936512355 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.458682155215 |  0.37553254244  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.272310206134 |  0.336656199627 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.527705657572 |  0.358609146891 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.725061802636 | 0.0645137990683 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.703231966811 | 0.0468715096417 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.706169763046 | 0.0683004728479 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.719778519209 | 0.0570431871381 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.705821222773 | 0.0757880356555 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        10       |
|  0.689590847576 | 0.0797471896933 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        16       |
|  0.732351121286 | 0.0601906178539 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.712453421503 | 0.0692547330763 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        7        |
|  0.701579481261 | 0.0441335126454 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        14       |
|  0.703842441761 | 0.0791833196685 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.701545155099 | 0.0768504928489 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        15       |
|  0.701989238543 | 0.0466443658254 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        13       |
|  0.715867394095 | 0.0646026209307 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.707413776849 | 0.0716834866018 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        8        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      1.00      0.74        50
          1       1.00      0.03      0.05        36

avg / total       0.76      0.59      0.45        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
| 0.0817441492726 | 0.0489684137068 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.241895951929 | 0.0920229530884 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.286331172254 |  0.164740677025 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.308834071263 |  0.224306553813 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.386706725701 |  0.197044257479 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.226761806873 |  0.28143796402  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        20       |
|  0.443341503268 |  0.153543668916 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.644547227493 | 0.0579536583649 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.63820893949  | 0.0878797939771 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.68853969007  |  0.103870286258 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.676179369597 | 0.0583044048615 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.650913187856 |  0.115881884646 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        10       |
|  0.672975964579 | 0.0965878485678 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        7        |
|  0.675885515497 | 0.0939098044691 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.622744043854 | 0.0868325396106 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.631941808982 | 0.0600492491477 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.666725964579 |  0.049151281181 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.670024246258 | 0.0963613755407 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.67310905545  |  0.10076272509  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.713733396584 | 0.0880292415921 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.691913082437 | 0.0813592885764 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.76      0.79        50
          1       0.70      0.78      0.74        36

avg / total       0.77      0.77      0.77        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.611764705882 |  0.029382368779 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.649673202614 | 0.0368106330936 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.647058823529 | 0.0442059134369 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        20       |
|  0.662745098039 | 0.0749953716912 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.695424836601 | 0.0712449388014 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.675816993464 | 0.0700319417169 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.657516339869 | 0.0668440460969 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.741176470588 | 0.0487855077823 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.754248366013 |  0.054929579986 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        3        |
|  0.749019607843 | 0.0387161727894 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.751633986928 | 0.0499418754722 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.751633986928 | 0.0469748446652 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.760784313725 |  0.064712053973 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.752941176471 |  0.042750422226 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.721568627451 | 0.0457397035769 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.752941176471 | 0.0358713606052 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        4        |
|  0.76339869281  | 0.0232140889184 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.745098039216 | 0.0452110418503 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        12       |
|  0.749019607843 |  0.037897943498 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        9        |
|  0.746405228758 | 0.0400421900462 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        11       |
|  0.751633986928 | 0.0410501928538 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        6        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.84      0.80        50
          1       0.74      0.64      0.69        36

avg / total       0.75      0.76      0.75        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.821002178649 |  0.215453477942 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.801851851852 |  0.20895282588  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.543129332541 |  0.364838897334 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.447571154594 |  0.381069232215 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.54342605448  |  0.361295872324 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.44001037452  |  0.367500879449 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.646282781142 |  0.236351095164 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.757596064067 | 0.0651059233589 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.748989225096 | 0.0881588105216 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        4        |
|  0.725264339665 | 0.0601634552386 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.72285393607  | 0.0876414145566 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.734816441378 | 0.0770523954436 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.733287405289 | 0.0902758247117 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        7        |
|  0.723354517536 | 0.0571951399767 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.726117235425 | 0.0760127863563 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.73473712794  | 0.0531465213517 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        6        |
|  0.710921767956 | 0.0527979415544 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.731348755278 | 0.0953410055163 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.719900467595 | 0.0809249058889 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        14       |
|  0.722660496584 | 0.0738081539902 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        13       |
|  0.698964953436 | 0.0531005792903 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        16       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.98      0.75        50
          1       0.83      0.14      0.24        36

avg / total       0.70      0.63      0.54        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.103837233818 | 0.0548946915583 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.195065095931 | 0.0994757683805 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.264002213789 |  0.140543425895 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.207189542484 |  0.218110961121 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.301875131773 |  0.230856260036 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.211086074215 |  0.265447174122 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        18       |
|  0.32051839553  |  0.222760554385 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.622563514653 |  0.117909637152 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.613157547965 | 0.0607109543943 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.629119228336 |  0.143679193337 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.679348513599 |  0.109573712255 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.669609160869 | 0.0977268250121 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.635196605524 |  0.118423548546 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.673107737719 |  0.105366256716 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.565890522876 |  0.053660200121 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.613127240143 | 0.0906065628734 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.657204037529 | 0.0715889279516 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.694779148218 |  0.108286385511 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        1        |
|  0.672890312039 | 0.0580800341226 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.679419671094 | 0.0880144237737 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.682381931267 | 0.0643543027152 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.84      0.80        50
          1       0.74      0.64      0.69        36

avg / total       0.75      0.76      0.75        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.621409921671 | 0.0303915867894 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.634464751958 | 0.0335526890244 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.667101827676 | 0.0514604636733 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.625326370757 | 0.0587313713512 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.671018276762 | 0.0777803690761 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.691906005222 | 0.0698927427678 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.655352480418 | 0.0782850406428 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.738903394256 | 0.0566200556761 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.745430809399 | 0.0499219503133 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.742819843342 | 0.0472114346304 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
|  0.761096605744 | 0.0287930988953 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        2        |
|  0.751958224543 | 0.0506488233775 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.754569190601 | 0.0376953658649 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
|  0.742819843342 | 0.0443250348258 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.738903394256 | 0.0381857579314 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.753263707572 | 0.0597053708327 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        6        |
|  0.758485639687 | 0.0541433163491 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        3        |
|  0.751958224543 | 0.0435610109979 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.755874673629 | 0.0529886125317 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.746736292428 | 0.0527622098463 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        9        |
|  0.763707571802 | 0.0499545697513 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.92      0.85        50
          1       0.85      0.66      0.74        35

avg / total       0.82      0.81      0.81        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.592580504787 |  0.398398118408 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        19       |
|  0.704704202093 |  0.261534341186 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|  0.638181547139 |  0.331952846233 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.581821869589 |  0.308442136842 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.627878175293 |  0.322263726993 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.530520902216 |  0.358131158646 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.687537034414 |  0.231155546395 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.743077561361 | 0.0854496645048 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        2        |
|  0.745486259986 | 0.0735492582776 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        1        |
|  0.731095189831 | 0.0762728353625 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.730777943187 |   0.0956182012  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.728933579437 | 0.0803874840609 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        8        |
|  0.709779518422 |  0.115659779524 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.734087855638 | 0.0579150354168 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.741328859683 | 0.0691038529136 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        3        |
|  0.726101321408 | 0.0895440920856 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.73091042745  | 0.0476672592895 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.719533180227 | 0.0878107682232 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        10       |
|  0.706979231358 | 0.0763405448652 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        13       |
|  0.710006769967 | 0.0794388999739 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        11       |
|  0.705089676304 | 0.0406447802249 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        14       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.92      0.84        50
          1       0.85      0.63      0.72        35

avg / total       0.81      0.80      0.79        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.103289764592 | 0.0638944696998 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.166191147983 | 0.0946188524016 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.288176166512 |  0.138253286655 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.10666664912  |  0.170993329858 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.298019929672 |  0.276867177492 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|   0.2923650299  |  0.238749420197 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.332204634465 |  0.27477136469  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.602064558241 | 0.0657643090071 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.645869304304 | 0.0737427213418 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.658479322833 | 0.0944610185958 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.680107965552 | 0.0723506011177 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.673784532132 | 0.0611206588365 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.670905099806 | 0.0967861356268 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        7        |
|  0.642837214689 | 0.0923049523974 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.567591647014 | 0.0760026750881 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.589366366967 | 0.0550851761069 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.658112155731 |  0.106227114482 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.673937189421 |  0.062933100398 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.677170628737 | 0.0626539573789 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.73688331719  | 0.0695002113059 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.721135928156 |  0.108337039041 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.90      0.84        50
          1       0.82      0.66      0.73        35

avg / total       0.80      0.80      0.80        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.627937336815 | 0.0343220541859 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        20       |
|   0.6227154047  |  0.030153040064 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        21       |
|  0.651436031332 | 0.0541477922677 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.648825065274 | 0.0614418565633 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.677545691906 | 0.0756215470795 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.678851174935 | 0.0860966164501 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.671018276762 | 0.0659798830903 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.749347258486 | 0.0529939037046 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.76501305483  | 0.0467144499274 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        1        |
|  0.755874673629 |  0.04723051316  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.755874673629 | 0.0416320541947 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.750652741514 | 0.0454448769351 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.757180156658 | 0.0622086313069 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.76501305483  |  0.051176961632 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.751958224543 | 0.0438556764337 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.751958224543 | 0.0416612145559 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.757180156658 | 0.0514227626985 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.742819843342 |  0.046472298491 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        14       |
|  0.758485639687 | 0.0281191216926 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.750652741514 | 0.0432991108381 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        11       |
|  0.751958224543 | 0.0398793703749 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        8        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.72      0.74        50
          1       0.63      0.69      0.66        35

avg / total       0.71      0.71      0.71        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.723893447719 |  0.325603388577 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        7        |
|  0.78717502399  |  0.210269672359 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.400319436873 |  0.40215914102  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        21       |
|  0.537281459581 |  0.37162045108  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.54331737743  |  0.359392440514 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        17       |
|  0.436949119687 |  0.361017584151 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        20       |
|  0.541222025364 |  0.359109692743 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.742521961141 |  0.096866966751 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.733747549573 | 0.0833046058873 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        5        |
|  0.719941021335 | 0.0911887419936 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.719682529227 | 0.0517473060384 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.72590286234  | 0.0647187180179 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.716408380155 | 0.0782557566137 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.752690948607 | 0.0562042044118 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.750096259582 | 0.0651996879687 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        3        |
|  0.721029968967 | 0.0818976451524 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.717707255163 | 0.0683717976339 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.709609357276 | 0.0592775686409 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        13       |
|  0.705808726266 | 0.0499358697112 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        15       |
|  0.700367428422 | 0.0793626092243 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        16       |
|  0.706862598669 | 0.0922251517104 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        14       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.94      0.75        50
          1       0.70      0.20      0.31        35

avg / total       0.66      0.64      0.57        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
| 0.0814874084056 | 0.0561094384687 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.178606396867 |  0.125009985652 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.172093457846 |  0.154490879061 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        20       |
|  0.269011096606 |  0.220145754977 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.298179167018 |  0.248372350095 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.28510064853  |  0.250916500846 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.413731523204 |  0.223574104207 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.664564558241 | 0.0654024899239 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.664686947275 |  0.046039153448 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.695971163564 | 0.0787652256525 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.733312979028 | 0.0890857179822 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        1        |
|  0.711654068054 |  0.052930822978 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.720614787754 | 0.0978508818388 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.724062736882 | 0.0670102971444 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.595659532132 |  0.137541823664 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.639515602628 | 0.0871811956025 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.698891392234 | 0.0713395354782 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.696063284343 |  0.102739338141 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        9        |
|  0.705466183778 |  0.105524725429 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.714819074792 | 0.0887565722949 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.730484871136 | 0.0754331435787 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.74      0.74        50
          1       0.63      0.63      0.63        35

avg / total       0.69      0.69      0.69        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.604438642298 | 0.0235573543215 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.625326370757 | 0.0269604582896 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.634464751958 | 0.0537927871887 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.664490861619 | 0.0660213176998 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.656657963446 | 0.0852213980585 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.690600522193 | 0.0774517081022 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.695822454308 | 0.0664032438537 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.741514360313 | 0.0506929649277 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.731070496084 | 0.0294369855819 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        14       |
|  0.762402088773 | 0.0503942804582 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        1        |
|  0.749347258486 | 0.0307532210243 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.761096605744 | 0.0358999327513 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.757180156658 | 0.0480094228304 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.740208877285 | 0.0394385272241 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        12       |
|  0.738903394256 | 0.0450194358626 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.751958224543 | 0.0331632955422 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        6        |
|  0.744125326371 |  0.057003036284 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.753263707572 | 0.0538933042844 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.751958224543 | 0.0643163391934 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.744125326371 | 0.0446798352122 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        9        |
|  0.759791122715 |  0.04546033124  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.80      0.80        50
          1       0.71      0.71      0.71        35

avg / total       0.76      0.76      0.76        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.553111401218 |  0.409708791635 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        18       |
|  0.782915974365 |  0.272212510958 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.618353752427 |  0.34158666275  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.623070570639 |  0.314227133592 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
|  0.410373150566 |  0.415734324267 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        20       |
|  0.381497146002 |  0.385725671916 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.535060647264 |  0.35591545181  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.740228562773 | 0.0707060593315 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.71817669573  | 0.0373031070922 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.726909005853 |  0.111804257094 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.741494950596 | 0.0760375766637 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.726561309746 |  0.10981556226  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
|  0.754514476192 | 0.0818112497431 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.710048785159 |  0.075802339797 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        15       |
|  0.721723419641 | 0.0803241733816 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        10       |
|  0.734385197189 | 0.0579084931807 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.730898981217 | 0.0665648536975 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
|  0.720760248588 | 0.0870745582629 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        11       |
|  0.720121567288 | 0.0451604689517 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        12       |
|  0.732078495577 | 0.0699691052057 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.717435269859 | 0.0759016931464 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        14       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.98      0.79        50
          1       0.91      0.29      0.43        35

avg / total       0.76      0.69      0.64        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
| 0.0784790069907 | 0.0405487122888 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.18161216626  | 0.0720805246557 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        18       |
|  0.150512191527 |  0.157393417441 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        20       |
|  0.254063842331 |  0.217408837264 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.172201370757 |  0.213510237252 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.269053208962 |  0.230484035774 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.357499684157 |  0.244370496768 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.577052450939 | 0.0928002676813 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.648980354586 | 0.0663774040645 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.677003495326 | 0.0864711452221 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.664646150931 | 0.0790869453953 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.683065042533 |  0.118039453128 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        4        |
|  0.66124294618  | 0.0872479306002 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.680461972543 |  0.110709219291 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.56746925798  |  0.078526926114 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.589325570622 | 0.0649491044629 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.664482965552 | 0.0669728851103 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.67699691527  | 0.0780749669108 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.70235908153  | 0.0729266560574 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.686635380696 | 0.0524059334711 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.705422755411 | 0.0806673142333 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.78      0.78        50
          1       0.69      0.69      0.69        35

avg / total       0.74      0.74      0.74        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.623207301173 |  0.034084610576 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.634941329857 | 0.0370972911243 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.666232073012 | 0.0566055148805 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|  0.664928292047 | 0.0817907348078 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.654498044329 | 0.0761812720487 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.663624511082 | 0.0970222600709 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        18       |
|  0.697522816167 | 0.0771524787567 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.750977835724 | 0.0363418168853 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        6        |
|  0.761408083442 | 0.0311386332667 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        2        |
|  0.749674054759 |  0.042351515322 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        7        |
|  0.743155149935 | 0.0326116196346 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.761408083442 | 0.0424180772489 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.761408083442 | 0.0462995689005 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.767926988266 | 0.0316580922609 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.737940026076 | 0.0760219066661 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.753585397653 | 0.0302725781984 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.740547588005 | 0.0504769718313 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        13       |
|   0.7444589309  | 0.0646659697304 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        9        |
|  0.743155149935 | 0.0493709146064 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        11       |
|  0.745762711864 |  0.049170595995 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        8        |
|   0.7444589309  |  0.059488296176 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        9        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.76      0.78        49
          1       0.68      0.74      0.71        35

avg / total       0.75      0.75      0.75        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.759039548023 |  0.297766168035 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        2        |
|  0.843482488104 | 0.0828865671409 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.563924522529 |  0.374712576721 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.390863897459 |  0.396352123875 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.330176048552 |  0.414364657975 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        21       |
|  0.625442431141 |  0.320634315348 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.50892024189  |  0.339274674314 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.737311856203 | 0.0495998848294 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.716007458142 | 0.0723075528039 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.713062907367 | 0.0762177597121 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.723545351257 | 0.0955303624797 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.708070971683 | 0.0764288690304 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.734454344314 | 0.0597023800576 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
|  0.720565405519 | 0.0763694511615 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
|  0.734073603305 | 0.0561787280937 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        6        |
|  0.744138777475 | 0.0695539116963 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        3        |
|  0.705842571784 | 0.0682421754189 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        13       |
|   0.7047582473  | 0.0469925735485 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        14       |
|  0.71063673662  | 0.0431270774741 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        11       |
|  0.69654010646  | 0.0369169865598 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        16       |
|  0.696752200722 | 0.0812908404503 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        15       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.94      0.77        49
          1       0.77      0.29      0.42        35

avg / total       0.70      0.67      0.62        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.103392984817 | 0.0445467055085 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.141022574337 | 0.0672736360209 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.260037273415 |  0.137850257123 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.203652689574 |  0.211549733081 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.36976253312  |  0.190579836668 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.266868980527 |  0.221847822912 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.38569704967  |  0.20388592627  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.608334735248 | 0.0713922205887 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.642779787189 | 0.0700584933811 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.63300800143  |  0.136834488515 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
|  0.655274792867 |  0.104717510784 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
|  0.683278483408 |  0.092648022711 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.689685673129 | 0.0559292906425 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.664448574252 |  0.108894819805 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
|  0.595884415612 |  0.10806726336  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.648884688985 | 0.0940795632341 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
|  0.692683580771 | 0.0650031420945 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.689651501451 | 0.0985448691765 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.680362062077 | 0.0750582715565 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.680205660933 | 0.0693152821054 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.720929101653 | 0.0724269284525 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.78      0.78        49
          1       0.69      0.69      0.69        35

avg / total       0.74      0.74      0.74        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.631029986962 | 0.0280410529449 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        20       |
|  0.625814863103 | 0.0303466176798 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        21       |
|  0.64667535854  |  0.040290828514 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.638852672751 | 0.0647055895729 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.675358539765 | 0.0874592724065 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.662320730117 | 0.0823223744399 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.664928292047 | 0.0712535191422 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.74185136897  | 0.0521244856541 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.756192959583 | 0.0459306370579 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        3        |
|  0.761408083442 | 0.0409500427446 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        1        |
|  0.737940026076 |  0.033825415659 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.750977835724 | 0.0609871716207 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.726205997392 | 0.0419689440088 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        14       |
|  0.73924380704  | 0.0366859262088 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.737940026076 | 0.0322086423111 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.748370273794 | 0.0574494491041 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        6        |
|  0.756192959583 | 0.0508636612291 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        3        |
|  0.747066492829 | 0.0578579386544 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|   0.7444589309  | 0.0444870418509 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        9        |
|  0.748370273794 | 0.0464648446648 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.758800521512 | 0.0468703791531 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.84      0.82        49
          1       0.76      0.71      0.74        35

avg / total       0.78      0.79      0.78        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.873359408953 |  0.220113753566 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.849856358331 |  0.147720204331 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.564157698192 |  0.383055342118 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.562537306146 |  0.372785260239 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.373081716389 |  0.380120901311 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        20       |
|  0.546192502945 |  0.364452093605 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        19       |
|  0.36531130974  |  0.377140840742 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        21       |
|  0.719906074371 | 0.0774469677874 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        5        |
|  0.735994724984 |  0.104076246909 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        3        |
|  0.713802227176 | 0.0422961365701 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.71468671579  | 0.0526758182778 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.703480454983 | 0.0804128208262 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        13       |
|  0.711761233247 | 0.0519270978727 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.725409807985 |  0.105449543581 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.719187192027 |  0.103103455573 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        6        |
|  0.708371464348 | 0.0525468183489 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.710694056449 | 0.0742319639138 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.706961614841 |  0.072492149105 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        12       |
|  0.692921912279 | 0.0436095332391 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        15       |
|  0.703275272167 | 0.0551144705914 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        14       |
|  0.686070231261 | 0.0573159664678 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        16       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.98      0.76        49
          1       0.83      0.14      0.24        35

avg / total       0.71      0.63      0.54        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
| 0.0658514530849 | 0.0495636290422 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.19749653026  | 0.0494418591927 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.244402416201 |  0.181883333123 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.100391134289 |  0.163658149134 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.232444957312 |  0.23801118002  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.388347983345 |  0.212023737202 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.36012874837  |  0.204553987731 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.601903888211 | 0.0695650318257 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.636331854313 | 0.0490540284745 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.661497981242 | 0.0694181459794 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.67086233545  | 0.0924243876244 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.670885992766 | 0.0826410723521 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.69585103251  | 0.0917290400045 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.652045569248 | 0.0793762529991 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        10       |
|  0.580018242419 | 0.0695856776107 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.62074431173  | 0.0502203953771 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.677115752618 |  0.08583472302  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.692962211381 |  0.104821929946 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.708461696177 | 0.0661092981786 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.686606279177 | 0.0528360631391 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.714790028178 | 0.0667828073104 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.80      0.80        49
          1       0.71      0.71      0.71        35

avg / total       0.76      0.76      0.76        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.625814863103 | 0.0239588503441 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.632333767927 | 0.0251614518147 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.663624511082 | 0.0623977363863 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.662320730117 | 0.0665481671407 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.697522816167 | 0.0760948617388 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.680573663625 | 0.0739479156464 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.647979139505 |  0.077680365814 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.750977835724 | 0.0341809548085 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        8        |
|  0.747066492829 |  0.054912407437 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.754889178618 | 0.0500177615113 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.757496740548 | 0.0627008171007 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        1        |
|  0.757496740548 | 0.0376891092368 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.73924380704  | 0.0515282776486 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        14       |
|  0.756192959583 | 0.0297617629798 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.747066492829 | 0.0303125667889 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        11       |
|  0.749674054759 | 0.0206090831237 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.754889178618 | 0.0230157625153 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.757496740548 | 0.0283465548088 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        1        |
|  0.749674054759 | 0.0325597171894 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        9        |
|  0.756192959583 | 0.0322238775057 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.745762711864 | 0.0372213866665 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        13       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.78      0.78        49
          1       0.69      0.71      0.70        35

avg / total       0.75      0.75      0.75        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.864624076488 |  0.233897712677 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.830857542429 |   0.1362332603  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.642071746627 |  0.325412074427 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.654119988603 |  0.331891049702 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.540264217567 |  0.355500326555 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        20       |
|  0.39242327148  |  0.395298808363 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.546707147232 |  0.366060542699 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.721137239222 | 0.0444918038215 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        7        |
|  0.724010493603 | 0.0568493911107 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.732016947393 |  0.100552406776 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.712237240843 | 0.0616225234349 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.710886991631 | 0.0440700458723 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.71927512605  | 0.0805384208962 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.736744016455 |  0.100880111771 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.749838923345 | 0.0854023850142 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        3        |
|  0.71452022215  | 0.0543988206768 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
|  0.707938088937 | 0.0602711420423 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.703873857612 | 0.0502380657415 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        16       |
|  0.710283307013 | 0.0547361620768 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        13       |
|  0.719664345066 | 0.0863575193615 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        8        |
|  0.709086555189 | 0.0654485279335 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        14       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.98      0.76        49
          1       0.83      0.14      0.24        35

avg / total       0.71      0.63      0.54        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.115999705598 | 0.0469533302355 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.19081070993  |  0.123290054808 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.326156842747 |  0.137940055423 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.361054012281 |  0.187608284937 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
|  0.27009163267  |  0.227270580545 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.385510419733 |  0.210274068031 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.257474397527 |   0.2649821037  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.605092368676 |  0.115176613638 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.658174128359 | 0.0916090624084 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.667673854986 | 0.0600474643938 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.673948300879 | 0.0890658777227 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.648901774824 | 0.0790622282435 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
|  0.645869695504 |  0.134563264879 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.661589981915 | 0.0710779852795 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|  0.605075282836 | 0.0980414185642 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.617549259789 | 0.0636123679148 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.636335797199 | 0.0867655137752 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.677398326113 |  0.101935571873 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.683557114018 | 0.0714854043175 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.692771638558 | 0.0509749820406 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.692734838289 | 0.0752223790909 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.76      0.77        49
          1       0.68      0.71      0.69        35

avg / total       0.74      0.74      0.74        84

Evaluating SVC
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001}        |        6        |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01}         |        6        |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001} |        6        |
|  0.603921568627 | 0.0117022258392  |         {'C': 1.0}         |        5        |
|  0.715032679739 | 0.0508103465506  |        {'C': 10.0}         |        4        |
|  0.766013071895 | 0.0449078622068  |        {'C': 100.0}        |        2        |
|  0.76339869281  | 0.0376269331108  |       {'C': 1000.0}        |        3        |
|  0.786928104575 | 0.0450724636381  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.68      0.69        50
          1       0.58      0.61      0.59        36

avg / total       0.65      0.65      0.65        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|       1.0       |       0.0       |         {'C': 1.0}         |        1        |
|  0.809498977148 |  0.107642129303 |        {'C': 10.0}         |        2        |
|  0.750603566216 | 0.0829675815162 |        {'C': 100.0}        |        3        |
|  0.704403289036 | 0.0656187466373 |       {'C': 1000.0}        |        4        |
|  0.704215667983 | 0.0528419672041 |       {'C': 10000.0}       |        5        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.98      0.73        50
          1       0.00      0.00      0.00        36

avg / total       0.34      0.57      0.42        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0534998945815 |  0.020248239327 |         {'C': 1.0}         |        5        |
|  0.440215844402 | 0.0901587452818 |        {'C': 10.0}         |        4        |
|  0.650910552393 | 0.0948581847355 |        {'C': 100.0}        |        3        |
|  0.761202034577 | 0.0876261011349 |       {'C': 1000.0}        |        1        |
|  0.735574794434 | 0.0961754472643 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.70      0.73        50
          1       0.62      0.69      0.66        36

avg / total       0.70      0.70      0.70        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001}        |        6        |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01}         |        6        |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001} |        6        |
|  0.601307189542 | 0.0147209772267  |         {'C': 1.0}         |        5        |
|  0.718954248366 | 0.0493485639292  |        {'C': 10.0}         |        4        |
|  0.749019607843 | 0.0428577072764  |        {'C': 100.0}        |        3        |
|  0.764705882353 | 0.0419818468235  |       {'C': 1000.0}        |        1        |
|  0.752941176471 | 0.0652248668553  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.76      0.79        50
          1       0.70      0.78      0.74        36

avg / total       0.77      0.77      0.77        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.782483660131 |  0.392553698996 |         {'C': 1.0}         |        2        |
|  0.807676735412 |  0.11356616381  |        {'C': 10.0}         |        1        |
|  0.765702373809 | 0.0561556276808 |        {'C': 100.0}        |        3        |
|  0.699885339036 | 0.0580272255791 |       {'C': 1000.0}        |        5        |
|  0.710176206591 |   0.0692304804  |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.86      0.75        50
          1       0.67      0.39      0.49        36

avg / total       0.66      0.66      0.64        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0472156335653 |  0.031966389946 |         {'C': 1.0}         |        5        |
|  0.427501054185 | 0.0736891314907 |        {'C': 10.0}         |        4        |
|  0.610016076323 | 0.0864094939144 |        {'C': 100.0}        |        3        |
|  0.729501370441 | 0.0710684650431 |       {'C': 1000.0}        |        2        |
|  0.745082226439 | 0.0764426373304 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.86      0.76      0.81        50
          1       0.71      0.83      0.77        36

avg / total       0.80      0.79      0.79        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001}        |        6        |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01}         |        6        |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001} |        6        |
|  0.598692810458 | 0.0110538162225  |         {'C': 1.0}         |        5        |
|  0.700653594771 | 0.0226621535613  |        {'C': 10.0}         |        4        |
|  0.752941176471 |  0.045977811867  |        {'C': 100.0}        |        3        |
|  0.769934640523 |  0.040065232412  |       {'C': 1000.0}        |        1        |
|  0.759477124183 |  0.03460499902   |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.88      0.82        50
          1       0.79      0.64      0.71        36

avg / total       0.78      0.78      0.77        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.749673202614 |  0.40311275495  |         {'C': 1.0}         |        2        |
|  0.769595154157 | 0.0708814426426 |        {'C': 10.0}         |        1        |
|  0.739889108647 | 0.0749988949274 |        {'C': 100.0}        |        3        |
|  0.719631796438 | 0.0353899784515 |       {'C': 1000.0}        |        5        |
|  0.724308299702 | 0.0514739286835 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.92      0.78        50
          1       0.78      0.39      0.52        36

avg / total       0.72      0.70      0.67        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0470759540375 | 0.0375897118423 |         {'C': 1.0}         |        5        |
|  0.418341503268 |  0.076165614621 |        {'C': 10.0}         |        4        |
|  0.616483502003 | 0.0865237411036 |        {'C': 100.0}        |        3        |
|  0.760976702509 | 0.0703918850404 |       {'C': 1000.0}        |        2        |
|  0.764128716003 | 0.0506606043499 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.81      0.88      0.85        50
          1       0.81      0.72      0.76        36

avg / total       0.81      0.81      0.81        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001}        |        6        |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01}         |        6        |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001} |        6        |
|       0.6       | 0.00767673358264 |         {'C': 1.0}         |        5        |
|  0.715032679739 |  0.050436905165  |        {'C': 10.0}         |        4        |
|  0.754248366013 | 0.0393196471048  |        {'C': 100.0}        |        3        |
|  0.762091503268 | 0.0684094606631  |       {'C': 1000.0}        |        1        |
|  0.760784313725 | 0.0510926004398  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.78      0.79        50
          1       0.70      0.72      0.71        36

avg / total       0.76      0.76      0.76        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.767755991285 |  0.394891458031 |         {'C': 1.0}         |        2        |
|  0.790986829075 |  0.100025116133 |        {'C': 10.0}         |        1        |
|  0.736087393466 | 0.0907434738735 |        {'C': 100.0}        |        3        |
|  0.696483497758 | 0.0783489855596 |       {'C': 1000.0}        |        5        |
|  0.703771451032 | 0.0654515461815 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.94      0.80        50
          1       0.84      0.44      0.58        36

avg / total       0.76      0.73      0.71        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0534419144002 | 0.0399452093045 |         {'C': 1.0}         |        5        |
|  0.415120967742 | 0.0660624895004 |        {'C': 10.0}         |        4        |
|  0.619435220325 | 0.0538666552532 |        {'C': 100.0}        |        3        |
|  0.760877872654 | 0.0516233376765 |       {'C': 1000.0}        |        2        |
|  0.767257010331 | 0.0599115316409 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.80      0.80        50
          1       0.72      0.72      0.72        36

avg / total       0.77      0.77      0.77        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.583550913838 | 0.00238368027742 |        {'C': 0.001}        |        6        |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.01}         |        6        |
|  0.583550913838 | 0.00238368027742 | {'C': 0.10000000000000001} |        6        |
|  0.603133159269 | 0.0146657397353  |         {'C': 1.0}         |        5        |
|  0.729765013055 | 0.0427354952937  |        {'C': 10.0}         |        4        |
|  0.766318537859 | 0.0308112303443  |        {'C': 100.0}        |        1        |
|  0.758485639687 | 0.0339758042885  |       {'C': 1000.0}        |        2        |
|  0.748041775457 | 0.0432612791932  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.82      0.80        50
          1       0.72      0.66      0.69        35

avg / total       0.75      0.75      0.75        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.698433420366 |  0.400453594161 |         {'C': 1.0}         |        4        |
|  0.812433779208 |  0.108274095158 |        {'C': 10.0}         |        1        |
|  0.759483109662 | 0.0929877001789 |        {'C': 100.0}        |        2        |
|  0.69910473567  | 0.0493647689518 |       {'C': 1000.0}        |        3        |
|  0.689634037165 | 0.0685228149074 |       {'C': 10000.0}       |        5        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.82      0.75        50
          1       0.65      0.49      0.56        35

avg / total       0.68      0.68      0.67        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0563976564474 | 0.0305492159942 |         {'C': 1.0}         |        5        |
|  0.463797850164 |  0.116573560401 |        {'C': 10.0}         |        4        |
|  0.629962677925 | 0.0966020573755 |        {'C': 100.0}        |        3        |
|  0.752113513855 | 0.0543038314123 |       {'C': 1000.0}        |        1        |
|  0.745888781268 |  0.105471127796 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.88      0.76      0.82        50
          1       0.71      0.86      0.78        35

avg / total       0.81      0.80      0.80        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.583550913838 | 0.00238368027742 |        {'C': 0.001}        |        6        |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.01}         |        6        |
|  0.583550913838 | 0.00238368027742 | {'C': 0.10000000000000001} |        6        |
|  0.595300261097 | 0.0137224890148  |         {'C': 1.0}         |        5        |
|  0.712793733681 | 0.0324831480685  |        {'C': 10.0}         |        4        |
|  0.753263707572 | 0.0485509087078  |        {'C': 100.0}        |        2        |
|  0.755874673629 | 0.0409790972671  |       {'C': 1000.0}        |        1        |
|  0.748041775457 | 0.0462049289562  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.86      0.84      0.85        50
          1       0.78      0.80      0.79        35

avg / total       0.82      0.82      0.82        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.566144473455 |  0.472839032666 |         {'C': 1.0}         |        5        |
|  0.776229366988 | 0.0645167116954 |        {'C': 10.0}         |        1        |
|  0.73721525183  | 0.0537802899925 |        {'C': 100.0}        |        2        |
|  0.713550879987 | 0.0745864438958 |       {'C': 1000.0}        |        3        |
|  0.691097800425 | 0.0446782690571 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.90      0.81        50
          1       0.79      0.54      0.64        35

avg / total       0.76      0.75      0.74        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0250897519582 | 0.0272682291544 |         {'C': 1.0}         |        5        |
|  0.476594742272 |  0.116036360159 |        {'C': 10.0}         |        4        |
|  0.645777183526 |  0.105998233136 |        {'C': 100.0}        |        3        |
|  0.723906131559 | 0.0798563181107 |       {'C': 1000.0}        |        2        |
|  0.746300692748 | 0.0667234772223 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.88      0.86      0.87        50
          1       0.81      0.83      0.82        35

avg / total       0.85      0.85      0.85        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.583550913838 | 0.00238368027742 |        {'C': 0.001}        |        6        |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.01}         |        6        |
|  0.583550913838 | 0.00238368027742 | {'C': 0.10000000000000001} |        6        |
|  0.600522193211 | 0.0119462028807  |         {'C': 1.0}         |        5        |
|  0.706266318538 | 0.0571470262298  |        {'C': 10.0}         |        4        |
|  0.755874673629 | 0.0677876507611  |        {'C': 100.0}        |        1        |
|  0.733681462141 | 0.0586681922675  |       {'C': 1000.0}        |        3        |
|  0.745430809399 | 0.0356389723203  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.88      0.84      0.86        50
          1       0.78      0.83      0.81        35

avg / total       0.84      0.84      0.84        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.600522193211 |  0.489791066346 |         {'C': 1.0}         |        5        |
|  0.776706821088 | 0.0861335525651 |        {'C': 10.0}         |        1        |
|  0.701048139768 | 0.0447306658869 |        {'C': 100.0}        |        2        |
|  0.685781280432 | 0.0685357975473 |       {'C': 1000.0}        |        4        |
|  0.693524283363 | 0.0422438524983 |       {'C': 10000.0}       |        3        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      1.00      0.88        50
          1       1.00      0.60      0.75        35

avg / total       0.87      0.84      0.82        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0345479238609 | 0.0296905788278 |         {'C': 1.0}         |        5        |
|  0.426108607766 |  0.140363183451 |        {'C': 10.0}         |        4        |
|  0.689283195064 |  0.100496793016 |        {'C': 100.0}        |        3        |
|  0.748791901794 | 0.0997775137627 |       {'C': 1000.0}        |        2        |
|  0.774310673377 | 0.0615316689793 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.88      0.86      0.87        50
          1       0.81      0.83      0.82        35

avg / total       0.85      0.85      0.85        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.584093872229 | 0.00183162664133 |        {'C': 0.001}        |        6        |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.01}         |        6        |
|  0.584093872229 | 0.00183162664133 | {'C': 0.10000000000000001} |        6        |
|  0.604954367666 | 0.0175590688422  |         {'C': 1.0}         |        5        |
|  0.70925684485  | 0.0466598187779  |        {'C': 10.0}         |        4        |
|  0.760104302477 | 0.0395915463972  |        {'C': 100.0}        |        2        |
|  0.757496740548 | 0.0431817149429  |       {'C': 1000.0}        |        3        |
|  0.77444589309  | 0.0381182287141  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.80      0.78        49
          1       0.70      0.66      0.68        35

avg / total       0.74      0.74      0.74        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.579661016949 |  0.477065551987 |         {'C': 1.0}         |        5        |
|  0.750870946059 | 0.0784315931809 |        {'C': 10.0}         |        1        |
|  0.711394347326 | 0.0584286813145 |        {'C': 100.0}        |        2        |
|  0.691827397614 | 0.0667418740003 |       {'C': 1000.0}        |        3        |
|  0.689437351082 |  0.06242771466  |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.94      0.81        49
          1       0.84      0.46      0.59        35

avg / total       0.76      0.74      0.72        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
| 0.0501719098288 | 0.0318527194228 |         {'C': 1.0}         |        5        |
|  0.464039565547 | 0.0670186696357 |        {'C': 10.0}         |        4        |
|  0.68681656643  | 0.0943754013831 |        {'C': 100.0}        |        3        |
|  0.768201675989 | 0.0747448813589 |       {'C': 1000.0}        |        2        |
|  0.774257948858 | 0.0727336164296 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.80      0.78        49
          1       0.70      0.66      0.68        35

avg / total       0.74      0.74      0.74        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.584093872229 | 0.00183162664133 |        {'C': 0.001}        |        6        |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.01}         |        6        |
|  0.584093872229 | 0.00183162664133 | {'C': 0.10000000000000001} |        6        |
|  0.595827900913 | 0.0126911438621  |         {'C': 1.0}         |        5        |
|  0.707953063885 | 0.0281754816736  |        {'C': 10.0}         |        4        |
|  0.766623207301 | 0.0592077684984  |        {'C': 100.0}        |        2        |
|  0.769230769231 | 0.0580842046801  |       {'C': 1000.0}        |        1        |
|  0.760104302477 | 0.0367642985614  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.69      0.76        49
          1       0.65      0.80      0.72        35

avg / total       0.76      0.74      0.74        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.774119947849 |  0.395012552348 |         {'C': 1.0}         |        3        |
|  0.79456741353  | 0.0890440624967 |        {'C': 10.0}         |        1        |
|  0.777925969382 |  0.073342079986 |        {'C': 100.0}        |        2        |
|  0.718843739828 | 0.0802174460518 |       {'C': 1000.0}        |        4        |
|  0.695185926473 | 0.0533531117962 |       {'C': 10000.0}       |        5        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.84      0.76        49
          1       0.68      0.49      0.57        35

avg / total       0.69      0.69      0.68        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.028211349203 | 0.0168813690102 |         {'C': 1.0}         |        5        |
|  0.426453347773 | 0.0821502501923 |        {'C': 10.0}         |        4        |
|  0.576853419271 |  0.092361289679 |        {'C': 100.0}        |        3        |
|  0.68316282542  |  0.103368521291 |       {'C': 1000.0}        |        2        |
|  0.758751892585 | 0.0680719847523 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.87      0.69      0.77        49
          1       0.67      0.86      0.75        35

avg / total       0.79      0.76      0.76        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.584093872229 | 0.00183162664133 |        {'C': 0.001}        |        6        |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.01}         |        6        |
|  0.584093872229 | 0.00183162664133 | {'C': 0.10000000000000001} |        6        |
|  0.595827900913 | 0.00997869919759 |         {'C': 1.0}         |        5        |
|  0.726205997392 | 0.0417048109676  |        {'C': 10.0}         |        4        |
|  0.752281616688 | 0.0433441677063  |        {'C': 100.0}        |        2        |
|  0.749674054759 | 0.0382284442825  |       {'C': 1000.0}        |        3        |
|  0.758800521512 | 0.0551111956772  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.71      0.75        49
          1       0.65      0.74      0.69        35

avg / total       0.73      0.73      0.73        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.765754019991 |  0.396315101788 |         {'C': 1.0}         |        2        |
|  0.786888423797 | 0.0915206464981 |        {'C': 10.0}         |        1        |
|  0.729778489349 | 0.0654593989101 |        {'C': 100.0}        |        3        |
|  0.698721553944 | 0.0717587888098 |       {'C': 1000.0}        |        5        |
|  0.710839609371 | 0.0468145736099 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.90      0.79        49
          1       0.76      0.46      0.57        35

avg / total       0.72      0.71      0.70        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        6        |
|       0.0       |       0.0       |        {'C': 0.01}         |        6        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        6        |
|  0.040719497834 | 0.0244012760694 |         {'C': 1.0}         |        5        |
|  0.457778262607 | 0.0610036393147 |        {'C': 10.0}         |        4        |
|  0.674057387391 |  0.075821945489 |        {'C': 100.0}        |        3        |
|  0.771137811751 | 0.0752096420881 |       {'C': 1000.0}        |        1        |
|  0.765118339151 | 0.0989784765246 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.71      0.75        49
          1       0.65      0.74      0.69        35

avg / total       0.73      0.73      0.73        84

Evaluating SVC
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.001}               |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.01}                |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.001, 'gamma': 1.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 10.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 100.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 1000.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 10000.0}              |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 0.001}                |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 0.01}                |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 1.0}                 |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 10.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 100.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 1000.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.01, 'gamma': 10000.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        32       |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        32       |
|  0.58431372549  | 0.00198842203817 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        32       |
|  0.58431372549  | 0.00198842203817 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        32       |
|  0.58431372549  | 0.00198842203817 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.001}                |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.01}                 |        32       |
|  0.58431372549  | 0.00198842203817 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        32       |
|  0.623529411765 | 0.0172710342667  |                 {'C': 1.0, 'gamma': 1.0}                 |        20       |
|  0.732026143791 | 0.0422759464126  |                {'C': 1.0, 'gamma': 10.0}                 |        7        |
|  0.63660130719  | 0.0401479213871  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.581699346405 | 0.0175908808103  |               {'C': 1.0, 'gamma': 1000.0}                |        63       |
|  0.571241830065 |  0.023351643699  |               {'C': 1.0, 'gamma': 10000.0}               |        64       |
|  0.58431372549  | 0.00198842203817 |               {'C': 10.0, 'gamma': 0.001}                |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 10.0, 'gamma': 0.01}                |        32       |
|  0.619607843137 | 0.0191161094335  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.747712418301 |  0.045555284204  |                {'C': 10.0, 'gamma': 1.0}                 |        5        |
|  0.729411764706 | 0.0601396668787  |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.648366013072 | 0.0373046452868  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.58954248366  | 0.0194251229639  |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
|  0.585620915033 | 0.0146310694727  |              {'C': 10.0, 'gamma': 10000.0}               |        29       |
|  0.58431372549  | 0.00198842203817 |               {'C': 100.0, 'gamma': 0.001}               |        32       |
|  0.622222222222 | 0.0213989819622  |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.720261437908 | 0.0370161384106  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        11       |
|  0.751633986928 | 0.0459738291438  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.690196078431 |  0.034333866075  |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.643137254902 | 0.0552851394676  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.593464052288 | 0.0275395290869  |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
|  0.583006535948 | 0.0188378174966  |              {'C': 100.0, 'gamma': 10000.0}              |        62       |
|  0.623529411765 | 0.0254881409471  |              {'C': 1000.0, 'gamma': 0.001}               |        20       |
|  0.739869281046 | 0.0305138884638  |               {'C': 1000.0, 'gamma': 0.01}               |        6        |
|  0.766013071895 | 0.0390808995948  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.725490196078 | 0.0527885171074  |               {'C': 1000.0, 'gamma': 1.0}                |        10       |
|  0.665359477124 | 0.0504503808032  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.63660130719  | 0.0322051502764  |              {'C': 1000.0, 'gamma': 100.0}               |        18       |
|  0.588235294118 | 0.0195567398602  |              {'C': 1000.0, 'gamma': 1000.0}              |        28       |
|  0.585620915033 | 0.0169305690223  |             {'C': 1000.0, 'gamma': 10000.0}              |        29       |
|  0.728104575163 | 0.0242652497413  |              {'C': 10000.0, 'gamma': 0.001}              |        9        |
|  0.759477124183 | 0.0348273689196  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.755555555556 | 0.0394167502428  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.687581699346 | 0.0498280638854  |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.661437908497 | 0.0657738769373  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.62091503268  | 0.0450554062677  |              {'C': 10000.0, 'gamma': 100.0}              |        23       |
|  0.59477124183  |  0.034560714784  |             {'C': 10000.0, 'gamma': 1000.0}              |        25       |
|  0.585620915033 | 0.0110157518354  |             {'C': 10000.0, 'gamma': 10000.0}             |        29       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.88      0.82        50
          1       0.79      0.64      0.71        36

avg / total       0.78      0.78      0.77        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.811690009337 |  0.178556483999 |                 {'C': 1.0, 'gamma': 1.0}                 |        3        |
|  0.719630399132 |  0.114664684973 |                {'C': 1.0, 'gamma': 10.0}                 |        10       |
|  0.650389321161 |  0.107930050687 |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.637167755991 |  0.310443842203 |               {'C': 1.0, 'gamma': 1000.0}                |        19       |
|  0.220784313725 |  0.271523249553 |               {'C': 1.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.815816993464 |  0.21677988882  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.721248403099 | 0.0692081175079 |                {'C': 10.0, 'gamma': 1.0}                 |        9        |
|  0.688173279801 | 0.0559017472607 |                {'C': 10.0, 'gamma': 10.0}                |        13       |
|  0.622247425151 | 0.0887560515037 |               {'C': 10.0, 'gamma': 100.0}                |        20       |
|  0.443432928727 |  0.153972110549 |               {'C': 10.0, 'gamma': 1000.0}               |        29       |
|  0.332026143791 |  0.447211685061 |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.803188090051 |  0.115493699375 |               {'C': 100.0, 'gamma': 0.01}                |        4        |
|  0.732110071301 |  0.067053526267 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.67013633598  | 0.0789637813664 |                {'C': 100.0, 'gamma': 1.0}                |        14       |
|  0.619052885356 | 0.0397746937641 |               {'C': 100.0, 'gamma': 10.0}                |        21       |
|  0.639792925446 | 0.0792746028749 |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.422142338417 |  0.177662490118 |              {'C': 100.0, 'gamma': 1000.0}               |        30       |
|  0.308605664488 |  0.353805458892 |              {'C': 100.0, 'gamma': 10000.0}              |        33       |
|  0.833605664488 |  0.12792228265  |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.749051866195 | 0.0678965923149 |               {'C': 1000.0, 'gamma': 0.01}               |        5        |
|  0.717648072299 | 0.0590861516841 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        11       |
|  0.65653008511  | 0.0477645907101 |               {'C': 1000.0, 'gamma': 1.0}                |        15       |
|  0.600031049503 | 0.0724956413197 |               {'C': 1000.0, 'gamma': 10.0}               |        22       |
|  0.58848503248  | 0.0787142965964 |              {'C': 1000.0, 'gamma': 100.0}               |        23       |
|  0.46788671024  |  0.208930864797 |              {'C': 1000.0, 'gamma': 1000.0}              |        28       |
|  0.334204793028 |  0.44737510418  |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.745080733891 | 0.0519724668245 |              {'C': 10000.0, 'gamma': 0.001}              |        6        |
|  0.726517778569 | 0.0558726723391 |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|  0.708085249392 | 0.0629909564141 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        12       |
|  0.643700964756 | 0.0538616514954 |               {'C': 10000.0, 'gamma': 1.0}               |        17       |
|  0.578147625062 | 0.0320393542077 |              {'C': 10000.0, 'gamma': 10.0}               |        24       |
|  0.553823940587 | 0.0818856849879 |              {'C': 10000.0, 'gamma': 100.0}              |        25       |
|  0.495610021786 |  0.317940435063 |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.552287581699 |  0.471277635908 |             {'C': 10000.0, 'gamma': 10000.0}             |        26       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.96      0.74        50
          1       0.71      0.14      0.23        36

avg / total       0.65      0.62      0.53        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.116313514653 | 0.0545988421738 |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.566208096142 |  0.113795725514 |                {'C': 1.0, 'gamma': 10.0}                 |        14       |
|  0.326553605313 |  0.130579023884 |                {'C': 1.0, 'gamma': 100.0}                |        20       |
|  0.06287818891  | 0.0278923169737 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
| 0.0188725490196 | 0.0207408558804 |               {'C': 1.0, 'gamma': 10000.0}               |        33       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.122819154544 | 0.0700956397571 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.600780096985 | 0.0761117003473 |                {'C': 10.0, 'gamma': 1.0}                 |        11       |
|  0.685717109424 |  0.119791471485 |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.40570182374  | 0.0735792754066 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
| 0.0974541429475 | 0.0403518229036 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|      0.0125     | 0.0206980904364 |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.128833280624 | 0.0578169227011 |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.584910657812 | 0.0916319366606 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        12       |
|   0.6885871284  | 0.0722720361012 |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.628785842294 | 0.0751975844312 |               {'C': 100.0, 'gamma': 10.0}                |        10       |
|  0.374342452035 | 0.0654272433118 |               {'C': 100.0, 'gamma': 100.0}               |        18       |
| 0.0912041429475 | 0.0474740624834 |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
| 0.0220351043643 | 0.0244830012751 |              {'C': 100.0, 'gamma': 10000.0}              |        30       |
|  0.125691808982 | 0.0656937962349 |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.57226702509  |  0.050270883017 |               {'C': 1000.0, 'gamma': 0.01}               |        13       |
|  0.666770767447 |  0.12238871826  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.694772559561 | 0.0741131916657 |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.644731709888 | 0.0773322933813 |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.383372865275 | 0.0991465329595 |              {'C': 1000.0, 'gamma': 100.0}               |        17       |
| 0.0723144634198 | 0.0241558720532 |              {'C': 1000.0, 'gamma': 1000.0}              |        28       |
| 0.0220351043643 |  0.02007058293  |             {'C': 1000.0, 'gamma': 10000.0}              |        30       |
|  0.525167351887 |  0.105246357594 |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|  0.707401697238 | 0.0791553958152 |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.751714368543 | 0.0911298051806 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.647662344508 |  0.10235839535  |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.629079696395 | 0.0906541836808 |              {'C': 10000.0, 'gamma': 10.0}               |        9        |
|  0.367843400801 |  0.06633258618  |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
| 0.0818021294539 | 0.0351267488787 |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
| 0.0219942546911 | 0.0200835836391 |             {'C': 10000.0, 'gamma': 10000.0}             |        32       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.84      0.86      0.85        50
          1       0.80      0.78      0.79        36

avg / total       0.83      0.83      0.83        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.58431372549  | 0.00198842203817 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.585620915033 | 0.00905325009866 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        33       |
|  0.581699346405 | 0.00501066339145 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        64       |
|  0.58431372549  | 0.00198842203817 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.58431372549  | 0.00198842203817 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.616993464052 | 0.0197518541881  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.730718954248 | 0.0504357918746  |                {'C': 1.0, 'gamma': 10.0}                 |        12       |
|  0.667973856209 | 0.0320423002012  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.602614379085 | 0.0388725413602  |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.58954248366  | 0.0245816482552  |               {'C': 1.0, 'gamma': 10000.0}               |        31       |
|  0.58431372549  | 0.00198842203817 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.58431372549  | 0.00198842203817 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.61568627451  | 0.0194022612776  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.746405228758 |  0.061403549067  |                {'C': 10.0, 'gamma': 1.0}                 |        5        |
|  0.750326797386 | 0.0401350549567  |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.674509803922 | 0.0365855622592  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|       0.6       | 0.0364291341682  |               {'C': 10.0, 'gamma': 1000.0}               |        26       |
|  0.592156862745 | 0.0170121433868  |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|  0.58431372549  | 0.00198842203817 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.623529411765 | 0.0215005938954  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.743790849673 | 0.0467318838397  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.741176470588 |  0.045925251021  |                {'C': 100.0, 'gamma': 1.0}                |        9        |
|  0.711111111111 | 0.0553145564164  |               {'C': 100.0, 'gamma': 10.0}                |        14       |
|  0.665359477124 | 0.0324842962259  |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.59477124183  | 0.0349550506551  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.585620915033 | 0.0189725008557  |              {'C': 100.0, 'gamma': 10000.0}              |        33       |
|  0.623529411765 | 0.0146316522075  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.746405228758 | 0.0538516425678  |               {'C': 1000.0, 'gamma': 0.01}               |        5        |
|  0.750326797386 | 0.0383009178318  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.734640522876 | 0.0389972734338  |               {'C': 1000.0, 'gamma': 1.0}                |        10       |
|  0.715032679739 | 0.0697212081457  |               {'C': 1000.0, 'gamma': 10.0}               |        13       |
|  0.645751633987 | 0.0445306597194  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.590849673203 | 0.0242396484322  |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.588235294118 | 0.0122983450781  |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.742483660131 | 0.0537885565174  |              {'C': 10000.0, 'gamma': 0.001}              |        8        |
|  0.758169934641 |  0.054247744866  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.760784313725 | 0.0474362191115  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.734640522876 | 0.0517021814935  |               {'C': 10000.0, 'gamma': 1.0}               |        10       |
|  0.666666666667 | 0.0423022063555  |              {'C': 10000.0, 'gamma': 10.0}               |        17       |
|  0.630065359477 | 0.0537757023737  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.590849673203 | 0.0204039556593  |             {'C': 10000.0, 'gamma': 1000.0}              |        29       |
|  0.58431372549  | 0.0165993645942  |             {'C': 10000.0, 'gamma': 10000.0}             |        35       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.85      0.70      0.77        50
          1       0.67      0.83      0.74        36

avg / total       0.78      0.76      0.76        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        36       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        36       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        36       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        36       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        36       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        36       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        36       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        36       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        36       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        36       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        36       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        36       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        36       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        36       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        36       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        36       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        36       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        36       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        36       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        36       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        36       |
|  0.113790849673 |  0.241460714232 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        36       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        36       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        36       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        36       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        36       |
|  0.796896981015 |  0.233872602977 |                 {'C': 1.0, 'gamma': 1.0}                 |        3        |
|  0.654001318663 | 0.0530079570914 |                {'C': 1.0, 'gamma': 10.0}                 |        17       |
|  0.689903584141 | 0.0917838949201 |                {'C': 1.0, 'gamma': 100.0}                |        12       |
|  0.605128683952 | 0.0978513357551 |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.524226579521 |  0.320252942546 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        36       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        36       |
|  0.81211328976  |  0.160898521091 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.687687367975 | 0.0596088071008 |                {'C': 10.0, 'gamma': 1.0}                 |        13       |
|  0.679313412413 | 0.0419333275699 |                {'C': 10.0, 'gamma': 10.0}                |        14       |
|  0.640281490892 |  0.126816873194 |               {'C': 10.0, 'gamma': 100.0}                |        20       |
|  0.610196078431 |  0.210305496565 |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.607843137255 |  0.37630666755  |              {'C': 10.0, 'gamma': 10000.0}               |        24       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        36       |
|  0.784684095861 |  0.147847021916 |               {'C': 100.0, 'gamma': 0.01}                |        4        |
|  0.718427045368 | 0.0787078361832 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.695976887781 | 0.0751698706024 |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.640086898604 | 0.0592679770464 |               {'C': 100.0, 'gamma': 10.0}                |        21       |
|  0.663974705294 |  0.065906307881 |               {'C': 100.0, 'gamma': 100.0}               |        15       |
|  0.538517528223 |  0.289182127645 |              {'C': 100.0, 'gamma': 1000.0}               |        28       |
|   0.3825708061  |  0.381357224736 |              {'C': 100.0, 'gamma': 10000.0}              |        34       |
|  0.812803195352 |  0.147462821912 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.737964735394 |  0.069403752292 |               {'C': 1000.0, 'gamma': 0.01}               |        6        |
|  0.701372642448 | 0.0450742128714 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.663220716132 | 0.0807451636709 |               {'C': 1000.0, 'gamma': 1.0}                |        16       |
|  0.648858434319 | 0.0586962206709 |               {'C': 1000.0, 'gamma': 10.0}               |        18       |
|  0.631883344033 | 0.0798529944001 |              {'C': 1000.0, 'gamma': 100.0}               |        22       |
|  0.530653594771 |  0.24885509857  |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.445577342048 |  0.354048651118 |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.766617727888 | 0.0890992325717 |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.696847373236 | 0.0420583509223 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.699649329772 |  0.048926347851 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        9        |
|  0.643520709689 | 0.0558383137027 |               {'C': 10000.0, 'gamma': 1.0}               |        19       |
|  0.587042623121 | 0.0331946821123 |              {'C': 10000.0, 'gamma': 10.0}               |        27       |
|  0.604057411781 | 0.0744046380252 |              {'C': 10000.0, 'gamma': 100.0}              |        26       |
|  0.426099379923 |  0.23331472869  |             {'C': 10000.0, 'gamma': 1000.0}              |        32       |
|  0.412026143791 |  0.378074515388 |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        50
          1       1.00      0.06      0.11        36

avg / total       0.76      0.60      0.48        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        37       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        37       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        37       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        37       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        37       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        37       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        37       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        37       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        37       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        37       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        37       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        37       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        37       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        37       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        37       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        37       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        37       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        37       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        37       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        37       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        37       |
| 0.00947053552604 | 0.0204126220848 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
| 0.0062908496732  |  0.012530533216 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        36       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        37       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        37       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        37       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        37       |
|  0.113191808982  | 0.0599337896398 |                 {'C': 1.0, 'gamma': 1.0}                 |        25       |
|  0.701222854733  | 0.0659490361692 |                {'C': 1.0, 'gamma': 10.0}                 |        11       |
|  0.433924994729  | 0.0673788609233 |                {'C': 1.0, 'gamma': 100.0}                |        17       |
|  0.122750632511  | 0.0493671454629 |               {'C': 1.0, 'gamma': 1000.0}                |        21       |
| 0.0503136200717  |  0.032122009167 |               {'C': 1.0, 'gamma': 10000.0}               |        31       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        37       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        37       |
|  0.106999789163  | 0.0569426405015 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        27       |
|  0.75792351887   | 0.0633232403271 |                {'C': 10.0, 'gamma': 1.0}                 |        1        |
|  0.729597564832  | 0.0784920650678 |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.452971484293  | 0.0939749665669 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.119540638836  | 0.0275402086479 |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
| 0.0503478810879  |  0.04558882491  |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        37       |
|  0.113191808982  | 0.0287214006579 |               {'C': 100.0, 'gamma': 0.01}                |        25       |
|  0.644588077166  |  0.100298448846 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.751506166983  |  0.066986514836 |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.716971062619  | 0.0507550922646 |               {'C': 100.0, 'gamma': 10.0}                |        10       |
|  0.430953510436  |  0.076053174024 |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.12257010331   | 0.0403843862117 |              {'C': 100.0, 'gamma': 1000.0}               |        22       |
| 0.0157442546911  | 0.0157262348686 |              {'C': 100.0, 'gamma': 10000.0}              |        34       |
|  0.113290638836  |  0.047117314644 |              {'C': 1000.0, 'gamma': 0.001}               |        24       |
|  0.572185325743  | 0.0939501053678 |               {'C': 1000.0, 'gamma': 0.01}               |        14       |
|  0.739023297491  | 0.0673841043823 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        5        |
|  0.738894159814  | 0.0493690657236 |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.720038741303  |  0.101356039889 |               {'C': 1000.0, 'gamma': 10.0}               |        9        |
|  0.389738825638  |  0.098238656747 |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
| 0.0785407442547  | 0.0319947018401 |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
| 0.0378070314147  | 0.0466366353003 |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.559681372549  |  0.114501986838 |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|  0.742192441493  | 0.0466775484965 |              {'C': 10000.0, 'gamma': 0.01}               |        4        |
|  0.751622127346  | 0.0404050215364 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.723214473962  | 0.0810879337072 |               {'C': 10000.0, 'gamma': 1.0}               |        8        |
|  0.663645108581  |  0.083354791485 |              {'C': 10000.0, 'gamma': 10.0}               |        12       |
|  0.383675943496  | 0.0846889531689 |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
| 0.0881272401434  | 0.0466592367319 |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
| 0.0251396795277  | 0.0365559006459 |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.82      0.64      0.72        50
          1       0.62      0.81      0.70        36

avg / total       0.74      0.71      0.71        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.001}               |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.01}                |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.001, 'gamma': 1.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 10.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 100.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 1000.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 10000.0}              |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 0.001}                |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 0.01}                |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 1.0}                 |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 10.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 100.0}                |        32       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 1000.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.01, 'gamma': 10000.0}               |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        32       |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        32       |
|  0.58431372549  | 0.00198842203817 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        32       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        32       |
|  0.58431372549  | 0.00198842203817 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        32       |
|  0.58431372549  | 0.00198842203817 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.001}                |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.01}                 |        32       |
|  0.58431372549  | 0.00198842203817 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        32       |
|  0.616993464052 |  0.035506197011  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.687581699346 | 0.0440680705281  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.656209150327 | 0.0442165169718  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.576470588235 | 0.0229289733314  |               {'C': 1.0, 'gamma': 1000.0}                |        64       |
|  0.57908496732  | 0.0148174705474  |               {'C': 1.0, 'gamma': 10000.0}               |        63       |
|  0.58431372549  | 0.00198842203817 |               {'C': 10.0, 'gamma': 0.001}                |        32       |
|  0.58431372549  | 0.00198842203817 |                {'C': 10.0, 'gamma': 0.01}                |        32       |
|  0.614379084967 | 0.0151910400132  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.742483660131 | 0.0611832600428  |                {'C': 10.0, 'gamma': 1.0}                 |        5        |
|  0.724183006536 | 0.0620639237531  |                {'C': 10.0, 'gamma': 10.0}                |        9        |
|  0.682352941176 | 0.0562915661297  |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.590849673203 | 0.0269706146019  |               {'C': 10.0, 'gamma': 1000.0}               |        29       |
|  0.581699346405 | 0.0170957027329  |              {'C': 10.0, 'gamma': 10000.0}               |        62       |
|  0.58431372549  | 0.00198842203817 |               {'C': 100.0, 'gamma': 0.001}               |        32       |
|  0.62614379085  | 0.0189356991782  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.720261437908 | 0.0291741996985  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.751633986928 | 0.0397877970583  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.700653594771 | 0.0403034935257  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.650980392157 | 0.0366605692212  |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.59477124183  | 0.0262246748479  |              {'C': 100.0, 'gamma': 1000.0}               |        25       |
|  0.590849673203 | 0.0149516521189  |              {'C': 100.0, 'gamma': 10000.0}              |        29       |
|  0.622222222222 | 0.0321036840746  |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.728104575163 | 0.0542615865777  |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.750326797386 | 0.0493856723634  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.738562091503 | 0.0576343819967  |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.674509803922 | 0.0333303347198  |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.648366013072 |  0.059518912508  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.593464052288 | 0.0375427235353  |              {'C': 1000.0, 'gamma': 1000.0}              |        27       |
|  0.59477124183  | 0.0132667120035  |             {'C': 1000.0, 'gamma': 10000.0}              |        25       |
|  0.728104575163 | 0.0496622824993  |              {'C': 10000.0, 'gamma': 0.001}              |        7        |
|  0.743790849673 | 0.0357681661504  |              {'C': 10000.0, 'gamma': 0.01}               |        4        |
|  0.747712418301 | 0.0727887053381  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.691503267974 | 0.0441674373424  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.644444444444 | 0.0348332062214  |              {'C': 10000.0, 'gamma': 10.0}               |        20       |
|  0.653594771242 | 0.0487299690003  |              {'C': 10000.0, 'gamma': 100.0}              |        17       |
|  0.593464052288 |  0.022727265223  |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.58954248366  | 0.0126895692314  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.88      0.84        50
          1       0.81      0.69      0.75        36

avg / total       0.80      0.80      0.80        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.822178649237 |  0.167298723196 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.702696004779 | 0.0829351869955 |                {'C': 1.0, 'gamma': 10.0}                 |        12       |
|  0.618754086837 | 0.0981307003728 |                {'C': 1.0, 'gamma': 100.0}                |        21       |
|  0.499496835771 |  0.181289824102 |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
|  0.292265795207 |  0.221469527091 |               {'C': 1.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.796873638344 |  0.213006178617 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        3        |
|  0.719847175193 | 0.0795653952665 |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.677890775398 | 0.0475683993969 |                {'C': 10.0, 'gamma': 10.0}                |        15       |
|  0.68477254223  |  0.112130457061 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.565577900676 |  0.215976448201 |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
|  0.448583877996 |  0.421946709699 |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.774281045752 |  0.216003322138 |               {'C': 100.0, 'gamma': 0.01}                |        4        |
|  0.744688739244 | 0.0760269694545 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.688402971562 | 0.0624440885133 |                {'C': 100.0, 'gamma': 1.0}                |        13       |
|  0.621461213551 | 0.0553242799799 |               {'C': 100.0, 'gamma': 10.0}                |        20       |
|  0.671870431343 | 0.0936732420371 |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.566492374728 |  0.306148852262 |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
|  0.426470588235 |  0.447836441006 |              {'C': 100.0, 'gamma': 10000.0}              |        33       |
|  0.800297748729 |  0.123535690538 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.758781579687 |  0.108143473712 |               {'C': 1000.0, 'gamma': 0.01}               |        5        |
|  0.716626413071 | 0.0601855426759 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.66322794266  | 0.0368767372441 |               {'C': 1000.0, 'gamma': 1.0}                |        17       |
|  0.629330181299 | 0.0840214172671 |               {'C': 1000.0, 'gamma': 10.0}               |        18       |
|  0.595691506488 |  0.037624369613 |              {'C': 1000.0, 'gamma': 100.0}               |        24       |
|  0.518823529412 |  0.264318689513 |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.483224400871 |  0.424437329835 |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.757008902976 | 0.0662177045806 |              {'C': 10000.0, 'gamma': 0.001}              |        6        |
|  0.713799634956 | 0.0870799908017 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.70630785862  | 0.0739555994297 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        11       |
|  0.61271494948  | 0.0461294184221 |               {'C': 10000.0, 'gamma': 1.0}               |        23       |
|  0.572225485918 | 0.0661185904824 |              {'C': 10000.0, 'gamma': 10.0}               |        25       |
|  0.62528703501  |  0.108146912342 |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
|  0.617130407719 |  0.267834023681 |             {'C': 10000.0, 'gamma': 1000.0}              |        22       |
|  0.564705882353 |  0.416773150561 |             {'C': 10000.0, 'gamma': 10000.0}             |        28       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.98      0.73        50
          1       0.50      0.03      0.05        36

avg / total       0.55      0.58      0.45        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.106866698292 | 0.0282136358517 |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.578636938646 |  0.115263771983 |                {'C': 1.0, 'gamma': 10.0}                 |        12       |
|  0.374325321526 | 0.0908945192633 |                {'C': 1.0, 'gamma': 100.0}                |        19       |
| 0.0723658549441 | 0.0492297007443 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
| 0.0283022348724 | 0.0262110357274 |               {'C': 1.0, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.110186063673 | 0.0405868100849 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.588123286949 | 0.0846903144437 |                {'C': 10.0, 'gamma': 1.0}                 |        11       |
|  0.704395951929 | 0.0554659000756 |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.468535209783 | 0.0714167076717 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.10382010331  | 0.0313105339825 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.021977124183 | 0.0244329541386 |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.125616698292 | 0.0637321926168 |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.515901064727 | 0.0877206867111 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        15       |
|  0.729617330803 | 0.0500969121771 |                {'C': 100.0, 'gamma': 1.0}                |        2        |
|  0.644581488509 | 0.0748866366093 |               {'C': 100.0, 'gamma': 10.0}                |        10       |
|  0.434006694075 | 0.0687893248903 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
| 0.0912384039637 | 0.0495884920794 |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
| 0.0314713788741 | 0.0242071914576 |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.128994043854 | 0.0497247437561 |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.534627345562 | 0.0639537046266 |               {'C': 1000.0, 'gamma': 0.01}               |        13       |
|  0.660568205777 |  0.118124853022 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.69177340291  | 0.0689079908987 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.663518606367 | 0.0796245199226 |               {'C': 1000.0, 'gamma': 10.0}               |        6        |
|  0.396029675311 | 0.0894707516036 |              {'C': 1000.0, 'gamma': 100.0}               |        18       |
| 0.0943021294539 | 0.0545787025712 |              {'C': 1000.0, 'gamma': 1000.0}              |        26       |
| 0.0314885093822 | 0.0242617594496 |             {'C': 1000.0, 'gamma': 10000.0}              |        30       |
|  0.515911606578 | 0.0755235209234 |              {'C': 10000.0, 'gamma': 0.001}              |        14       |
|  0.688569997892 | 0.0483935218313 |              {'C': 10000.0, 'gamma': 0.01}               |        5        |
|  0.760895003163 | 0.0730737303679 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.657466266076 |  0.112634166642 |               {'C': 10000.0, 'gamma': 1.0}               |        8        |
|  0.644656599199 | 0.0360236967082 |              {'C': 10000.0, 'gamma': 10.0}               |        9        |
|  0.361569681636 |  0.112681825451 |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
| 0.0817678684377 | 0.0446773059246 |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
| 0.0282442546911 | 0.0295277191879 |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.82      0.81        50
          1       0.74      0.72      0.73        36

avg / total       0.78      0.78      0.78        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|  0.58431372549  | 0.00198842203817 |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|  0.58431372549  | 0.00198842203817 |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|  0.58431372549  | 0.00198842203817 |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|  0.58431372549  | 0.00198842203817 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|  0.58431372549  | 0.00198842203817 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|  0.58431372549  | 0.00198842203817 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|  0.58431372549  | 0.00198842203817 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|  0.58431372549  | 0.00198842203817 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|  0.58431372549  | 0.00198842203817 |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|  0.58431372549  | 0.00198842203817 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.624836601307 | 0.0206478450378  |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.725490196078 | 0.0411520793414  |                {'C': 1.0, 'gamma': 10.0}                 |        11       |
|  0.658823529412 | 0.0352400691913  |                {'C': 1.0, 'gamma': 100.0}                |        17       |
|  0.590849673203 | 0.0125481782011  |               {'C': 1.0, 'gamma': 1000.0}                |        26       |
|  0.586928104575 | 0.0213589381525  |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.58431372549  | 0.00198842203817 |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|  0.58431372549  | 0.00198842203817 |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|  0.623529411765 | 0.0188756886979  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.738562091503 | 0.0470478148262  |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.746405228758 | 0.0528779677816  |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.669281045752 | 0.0360156362364  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.59477124183  | 0.0298862973124  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.580392156863 | 0.0112870463023  |              {'C': 10.0, 'gamma': 10000.0}               |        63       |
|  0.58431372549  | 0.00198842203817 |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|  0.627450980392 | 0.0342385784095  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.747712418301 | 0.0422834465769  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.743790849673 | 0.0465231404228  |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.709803921569 | 0.0425658629572  |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.660130718954 | 0.0331721074123  |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.581699346405 |  0.026099016113  |              {'C': 100.0, 'gamma': 1000.0}               |        60       |
|  0.580392156863 | 0.0153945141404  |              {'C': 100.0, 'gamma': 10000.0}              |        63       |
|  0.622222222222 |  0.020147252636  |              {'C': 1000.0, 'gamma': 0.001}               |        24       |
|  0.732026143791 | 0.0339080927467  |               {'C': 1000.0, 'gamma': 0.01}               |        8        |
|  0.764705882353 | 0.0534870928337  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.730718954248 | 0.0384739621828  |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.688888888889 | 0.0567489004781  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.640522875817 | 0.0551977128986  |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
|  0.583006535948 | 0.0320906496554  |              {'C': 1000.0, 'gamma': 1000.0}              |        59       |
|  0.588235294118 | 0.0166996921081  |             {'C': 1000.0, 'gamma': 10000.0}              |        27       |
|  0.730718954248 | 0.0556952063749  |              {'C': 10000.0, 'gamma': 0.001}              |        9        |
|  0.764705882353 | 0.0529725554723  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.739869281046 | 0.0347048667187  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        6        |
|  0.716339869281 | 0.0618818282129  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.649673202614 |  0.064646674019  |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.644444444444 | 0.0462044144428  |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
|  0.581699346405 |  0.024171442614  |             {'C': 10000.0, 'gamma': 1000.0}              |        60       |
|  0.581699346405 |  0.019562873869  |             {'C': 10000.0, 'gamma': 10000.0}             |        60       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.90      0.78        50
          1       0.76      0.44      0.56        36

avg / total       0.72      0.71      0.69        86

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.769047619048 |  0.16990572265  |                 {'C': 1.0, 'gamma': 1.0}                 |        6        |
|  0.723659696389 |  0.083559998577 |                {'C': 1.0, 'gamma': 10.0}                 |        10       |
|  0.594545243429 |  0.129781528302 |                {'C': 1.0, 'gamma': 100.0}                |        22       |
|  0.582376283847 |  0.220837063675 |               {'C': 1.0, 'gamma': 1000.0}                |        24       |
|  0.493355119826 |  0.258903474226 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.853685548293 |  0.139707660807 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.760738904555 | 0.0283489165452 |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.705868146862 | 0.0648532346388 |                {'C': 10.0, 'gamma': 10.0}                |        12       |
|  0.636275107574 |  0.092303118645 |               {'C': 10.0, 'gamma': 100.0}                |        19       |
|  0.602309368192 |  0.154213653183 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.339869281046 |  0.387945799947 |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.841677559913 |  0.174268102945 |               {'C': 100.0, 'gamma': 0.01}                |        2        |
|  0.762470334253 | 0.0633071829607 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.69662050679  | 0.0741881689721 |                {'C': 100.0, 'gamma': 1.0}                |        13       |
|  0.652196960828 | 0.0617943180793 |               {'C': 100.0, 'gamma': 10.0}                |        17       |
|  0.65983545465  |  0.129034852021 |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.545627139745 |  0.182523617512 |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.43311546841  |  0.416080140248 |              {'C': 100.0, 'gamma': 10000.0}              |        33       |
|  0.785239651416 |  0.163493555822 |              {'C': 1000.0, 'gamma': 0.001}               |        3        |
|  0.781687867593 |  0.12000704899  |               {'C': 1000.0, 'gamma': 0.01}               |        4        |
|  0.717102056613 | 0.0815836632799 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        11       |
|  0.664435783754 | 0.0690541246992 |               {'C': 1000.0, 'gamma': 1.0}                |        15       |
|  0.584363562561 |  0.06621461957  |               {'C': 1000.0, 'gamma': 10.0}               |        23       |
|  0.612916442126 |  0.138703574617 |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
|  0.494422657952 |  0.217903449441 |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.483224400871 |  0.450016124669 |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.77355792133  | 0.0717977113814 |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.749194396379 | 0.0693612376044 |              {'C': 10000.0, 'gamma': 0.01}               |        9        |
|  0.690479304694 | 0.0533803910035 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        14       |
|  0.642611024717 | 0.0423394560497 |               {'C': 10000.0, 'gamma': 1.0}               |        18       |
|  0.576191323323 | 0.0460296417997 |              {'C': 10000.0, 'gamma': 10.0}               |        26       |
|  0.580085187149 | 0.0814855389992 |              {'C': 10000.0, 'gamma': 100.0}              |        25       |
|  0.497422969188 |  0.225642378372 |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.478711484594 |  0.451783824236 |             {'C': 10000.0, 'gamma': 10000.0}             |        32       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.94      0.72        50
          1       0.50      0.08      0.14        36

avg / total       0.55      0.58      0.48        86

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.106825848619  | 0.0627588590136 |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.487534261016  | 0.0956688762678 |                {'C': 1.0, 'gamma': 10.0}                 |        15       |
|  0.393222907443  |  0.120615683324 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
| 0.0849370124394  | 0.0368058158598 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.047151064727  | 0.0210770024637 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.125906599199  | 0.0254063539101 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.550453299599  |  0.118452878718 |                {'C': 10.0, 'gamma': 1.0}                 |        13       |
|  0.656982658655  |  0.137526851955 |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.452883196289  | 0.0961016199925 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
| 0.0879256272401  | 0.0620575274322 |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
| 0.00945340501792 | 0.0144651339503 |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.13507010331   | 0.0668881112975 |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.553343084546  |  0.078436226707 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.735601149062  |  0.10707813147  |                {'C': 100.0, 'gamma': 1.0}                |        2        |
|  0.685602466793  | 0.0733333524958 |               {'C': 100.0, 'gamma': 10.0}                |        4        |
|  0.412001897533  | 0.0887178890779 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
| 0.0880929791271  | 0.0564000059436 |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
| 0.0283430845456  | 0.0261912390582 |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.138372338183  |  0.042311454173 |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.559629981025  | 0.0922195241246 |               {'C': 1000.0, 'gamma': 0.01}               |        11       |
|  0.647774351676  | 0.0503894240135 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.69815649378   | 0.0816026675686 |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.663338077166  | 0.0748171619427 |               {'C': 1000.0, 'gamma': 10.0}               |        6        |
|  0.389732236981  |  0.100702846043 |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
| 0.0849646847987  | 0.0351981406895 |              {'C': 1000.0, 'gamma': 1000.0}              |        28       |
| 0.0283022348724  | 0.0219768643171 |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.541139574109  |  0.107490775066 |              {'C': 10000.0, 'gamma': 0.001}              |        14       |
|  0.657319997892  |  0.125285473553 |              {'C': 10000.0, 'gamma': 0.01}               |        7        |
|  0.748470113852  | 0.0669844106985 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.66988456673   | 0.0754950337007 |               {'C': 10000.0, 'gamma': 1.0}               |        5        |
|  0.638365749526  | 0.0926425994808 |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.377470746363  | 0.0751458095179 |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
| 0.0911909656336  | 0.0480405292068 |             {'C': 10000.0, 'gamma': 1000.0}              |        25       |
|  0.018923940544  | 0.0211390071775 |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.84      0.81        50
          1       0.75      0.67      0.71        36

avg / total       0.77      0.77      0.77        86

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|  0.583550913838 | 0.00238368027742 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|  0.583550913838 | 0.00238368027742 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|  0.583550913838 | 0.00238368027742 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|  0.583550913838 | 0.00238368027742 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|  0.583550913838 | 0.00238368027742 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.620104438642 | 0.0118230127271  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.711488250653 | 0.0470726481997  |                {'C': 1.0, 'gamma': 10.0}                 |        12       |
|  0.674934725849 | 0.0520854214205  |                {'C': 1.0, 'gamma': 100.0}                |        15       |
|  0.592689295039 |  0.031151458792  |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.583550913838 | 0.0242198177351  |               {'C': 1.0, 'gamma': 10000.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|   0.6227154047  | 0.0153755533772  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.729765013055 | 0.0476290567677  |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.732375979112 | 0.0535612474874  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.651436031332 | 0.0436554758947  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.590078328982 | 0.0154056293503  |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
|  0.584856396867 | 0.0188532172777  |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|  0.583550913838 | 0.00238368027742 |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|   0.6227154047  |  0.02822356494   |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.729765013055 | 0.0366154502875  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.757180156658 | 0.0395564352258  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.702349869452 | 0.0332847500872  |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.659268929504 | 0.0316957467906  |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.582245430809 | 0.0208382766924  |              {'C': 100.0, 'gamma': 1000.0}               |        63       |
|  0.590078328982 | 0.0166311774436  |              {'C': 100.0, 'gamma': 10000.0}              |        27       |
|   0.6227154047  | 0.0368983028619  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.742819843342 | 0.0550306235279  |               {'C': 1000.0, 'gamma': 0.01}               |        3        |
|  0.746736292428 | 0.0515149810063  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.728459530026 | 0.0433773661524  |               {'C': 1000.0, 'gamma': 1.0}                |        10       |
|  0.695822454308 | 0.0370342095744  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.630548302872 | 0.0441711983582  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.590078328982 | 0.0225195529967  |              {'C': 1000.0, 'gamma': 1000.0}              |        27       |
|  0.580939947781 | 0.0145705815606  |             {'C': 1000.0, 'gamma': 10000.0}              |        64       |
|  0.733681462141 | 0.0392446878777  |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.732375979112 |  0.029491617196  |              {'C': 10000.0, 'gamma': 0.01}               |        6        |
|  0.741514360313 | 0.0346900258444  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.715404699739 | 0.0610804331206  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.643603133159 | 0.0545627820785  |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.627937336815 | 0.0365361112416  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.59138381201  |  0.034391593938  |             {'C': 10000.0, 'gamma': 1000.0}              |        26       |
|  0.583550913838 | 0.0191439491692  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.88      0.83        50
          1       0.79      0.66      0.72        35

avg / total       0.79      0.79      0.78        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.860400348129 |  0.121773291047 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.685021455418 | 0.0978854386692 |                {'C': 1.0, 'gamma': 10.0}                 |        14       |
|  0.632328944397 |  0.119526111913 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.588082167325 |   0.2328852371  |               {'C': 1.0, 'gamma': 1000.0}                |        24       |
|  0.480874673629 |  0.329084439059 |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.755287206266 |  0.27588105068  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        5        |
|  0.738119692917 | 0.0703422319056 |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.697705167058 | 0.0788114077979 |                {'C': 10.0, 'gamma': 10.0}                |        11       |
|  0.63395536078  | 0.0958912939003 |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.457981578184 |  0.264970383089 |               {'C': 10.0, 'gamma': 1000.0}               |        31       |
|  0.451479547433 |  0.422396616633 |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.777197563098 |  0.178901203135 |               {'C': 100.0, 'gamma': 0.01}                |        3        |
|  0.711595271366 | 0.0995877201632 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.69316336321  | 0.0507724142356 |                {'C': 100.0, 'gamma': 1.0}                |        12       |
|  0.634951305912 | 0.0458258264184 |               {'C': 100.0, 'gamma': 10.0}                |        16       |
|  0.629570964553 | 0.0770608392176 |               {'C': 100.0, 'gamma': 100.0}               |        19       |
|  0.41567201293  |  0.148865085202 |              {'C': 100.0, 'gamma': 1000.0}               |        33       |
|  0.461096605744 |  0.417253044254 |              {'C': 100.0, 'gamma': 10000.0}              |        30       |
|  0.849227589208 |  0.190559583912 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.762174493178 | 0.0608099347064 |               {'C': 1000.0, 'gamma': 0.01}               |        4        |
|  0.707416725676 |  0.069609019071 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.662333680636 | 0.0516002140165 |               {'C': 1000.0, 'gamma': 1.0}                |        15       |
|  0.620554914801 | 0.0589111559017 |               {'C': 1000.0, 'gamma': 10.0}               |        21       |
|  0.592136669823 | 0.0882026314426 |              {'C': 1000.0, 'gamma': 100.0}               |        23       |
|  0.560106614447 |  0.243651526321 |              {'C': 1000.0, 'gamma': 1000.0}              |        26       |
|  0.365970409051 |  0.433854653603 |             {'C': 1000.0, 'gamma': 10000.0}              |        34       |
|  0.754447126239 | 0.0592245611288 |              {'C': 10000.0, 'gamma': 0.001}              |        6        |
|  0.690430713535 |  0.059774668871 |              {'C': 10000.0, 'gamma': 0.01}               |        13       |
|  0.701664250824 | 0.0534888471044 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        10       |
|  0.627893553442 | 0.0712667947067 |               {'C': 10000.0, 'gamma': 1.0}               |        20       |
|  0.594206881586 | 0.0554797848576 |              {'C': 10000.0, 'gamma': 10.0}               |        22       |
|  0.574949357288 | 0.0923280095885 |              {'C': 10000.0, 'gamma': 100.0}              |        25       |
|   0.5363794604  |   0.2434390102  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.55863794604  |  0.45318364368  |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.96      0.75        50
          1       0.71      0.14      0.24        35

avg / total       0.66      0.62      0.54        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.112829529184 |  0.03500355236  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.567819316938 |  0.147954443747 |                {'C': 1.0, 'gamma': 10.0}                 |        14       |
|  0.407254116483 | 0.0818755482593 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.106703497431 | 0.0570539727032 |               {'C': 1.0, 'gamma': 1000.0}                |        26       |
| 0.0408476690811 | 0.0318456795755 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.109759275246 | 0.0643231701691 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.64272140571  |  0.123764306134 |                {'C': 10.0, 'gamma': 1.0}                 |        11       |
|  0.733190589994 | 0.0770848160486 |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.476802672029 |  0.122575752956 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.109694790702 | 0.0611515749803 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
| 0.0219247452202 | 0.0200990084741 |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.131786669334 | 0.0535190907335 |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.633385622842 |  0.11686100499  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.733463004295 | 0.0961698651233 |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.68032905542  | 0.0806695459119 |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|  0.429567084983 | 0.0890229551051 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
| 0.0971703128948 | 0.0492485269559 |              {'C': 100.0, 'gamma': 1000.0}               |        28       |
| 0.0313894971785 | 0.0280024067901 |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.128658510907 | 0.0381356248493 |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.589342678767 | 0.0999432356997 |               {'C': 1000.0, 'gamma': 0.01}               |        13       |
|  0.708264023414 | 0.0816649403624 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.733469584351 | 0.0519051264213 |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.686530099806 | 0.0872124617274 |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.39190811084  |  0.120104707485 |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
| 0.0939645098122 |  0.041985016271 |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
| 0.0282310704961 | 0.0259658398188 |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.548967457677 |  0.110998728702 |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|  0.708604870294 | 0.0970425336138 |              {'C': 10000.0, 'gamma': 0.01}               |        5        |
|  0.761734871136 |  0.058277521579 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.686577476207 | 0.0472340138784 |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.661498252337 |  0.11298567793  |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.401471563632 | 0.0583228841007 |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
|  0.100311631433 | 0.0436260234152 |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
| 0.0250489556136 | 0.0233547582151 |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.80      0.80        50
          1       0.71      0.71      0.71        35

avg / total       0.76      0.76      0.76        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 0.001}               |        34       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 0.01}                |        34       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        34       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.001, 'gamma': 1.0}                |        34       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 10.0}                |        34       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 100.0}               |        34       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.001, 'gamma': 1000.0}               |        34       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.001, 'gamma': 10000.0}              |        34       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 0.001}                |        34       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 0.01}                |        34       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        34       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 1.0}                 |        34       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 10.0}                |        34       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 100.0}                |        34       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 1000.0}               |        34       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.01, 'gamma': 10000.0}               |        34       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        34       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        34       |
|  0.583550913838 | 0.00238368027742 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        34       |
|  0.583550913838 | 0.00238368027742 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        34       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        34       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        34       |
|  0.583550913838 | 0.00238368027742 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        34       |
|  0.583550913838 | 0.00238368027742 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        34       |
|  0.583550913838 | 0.00238368027742 |                {'C': 1.0, 'gamma': 0.001}                |        34       |
|  0.583550913838 | 0.00238368027742 |                {'C': 1.0, 'gamma': 0.01}                 |        34       |
|  0.583550913838 | 0.00238368027742 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        34       |
|  0.610966057441 |  0.01801171388   |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.706266318538 | 0.0425079101505  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.680156657963 | 0.0694047315105  |                {'C': 1.0, 'gamma': 100.0}                |        15       |
|  0.590078328982 |  0.038063147857  |               {'C': 1.0, 'gamma': 1000.0}                |        27       |
|  0.59138381201  | 0.0231234777341  |               {'C': 1.0, 'gamma': 10000.0}               |        26       |
|  0.583550913838 | 0.00238368027742 |               {'C': 10.0, 'gamma': 0.001}                |        34       |
|  0.583550913838 | 0.00238368027742 |                {'C': 10.0, 'gamma': 0.01}                |        34       |
|  0.610966057441 |  0.01292857934   |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.746736292428 | 0.0397023239198  |                {'C': 10.0, 'gamma': 1.0}                 |        6        |
|  0.746736292428 | 0.0703298986052  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.671018276762 | 0.0259430696794  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.595300261097 | 0.0369106179081  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.584856396867 | 0.0136017726175  |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|  0.583550913838 | 0.00238368027742 |               {'C': 100.0, 'gamma': 0.001}               |        34       |
|  0.610966057441 | 0.0214328338422  |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.761096605744 | 0.0427211568525  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.754569190601 | 0.0374408191585  |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.718015665796 | 0.0479731154504  |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.672323759791 | 0.0492502305631  |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.590078328982 | 0.0286720785189  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.590078328982 | 0.0121531303024  |              {'C': 100.0, 'gamma': 10000.0}              |        27       |
|  0.614882506527 | 0.0216488794419  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.742819843342 | 0.0453941466478  |               {'C': 1000.0, 'gamma': 0.01}               |        8        |
|  0.758485639687 |  0.043004055089  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.742819843342 | 0.0417681590434  |               {'C': 1000.0, 'gamma': 1.0}                |        8        |
|  0.689295039164 | 0.0560527187957  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.665796344648 | 0.0495404338403  |              {'C': 1000.0, 'gamma': 100.0}               |        18       |
|  0.583550913838 | 0.0255526627409  |              {'C': 1000.0, 'gamma': 1000.0}              |        34       |
|  0.587467362924 | 0.0144843996074  |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.741514360313 |  0.037140536889  |              {'C': 10000.0, 'gamma': 0.001}              |        10       |
|  0.762402088773 |  0.030260211551  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.763707571802 | 0.0421948212938  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.732375979112 | 0.0547191552691  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.661879895561 | 0.0365208285951  |              {'C': 10000.0, 'gamma': 10.0}               |        19       |
|  0.63315926893  | 0.0579589952915  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.584856396867 | 0.0262675722859  |             {'C': 10000.0, 'gamma': 1000.0}              |        32       |
|  0.590078328982 | 0.0123748073898  |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.72      0.74        50
          1       0.63      0.69      0.66        35

avg / total       0.71      0.71      0.71        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.785683202785 |  0.243070528947 |                 {'C': 1.0, 'gamma': 1.0}                 |        2        |
|  0.688934549223 | 0.0934643437352 |                {'C': 1.0, 'gamma': 10.0}                 |        14       |
|  0.646631255269 | 0.0508905598896 |                {'C': 1.0, 'gamma': 100.0}                |        20       |
|  0.545735422106 |  0.262905818323 |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
|  0.612228024369 |  0.323389356031 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.778245057814 | 0.0948256879219 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        3        |
|  0.700952477607 | 0.0676343182299 |                {'C': 10.0, 'gamma': 1.0}                 |        13       |
|  0.680378215854 |  0.049965189313 |                {'C': 10.0, 'gamma': 10.0}                |        16       |
|  0.701322059979 |  0.10274288299  |               {'C': 10.0, 'gamma': 100.0}                |        12       |
|  0.575769302499 |  0.217521932962 |               {'C': 10.0, 'gamma': 1000.0}               |        29       |
|       0.5       |  0.387466835101 |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.760987815492 |  0.200086299237 |               {'C': 100.0, 'gamma': 0.01}                |        5        |
|  0.743084712955 | 0.0963375824938 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.706951266233 | 0.0815913241162 |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.644614990456 | 0.0511181613554 |               {'C': 100.0, 'gamma': 10.0}                |        21       |
|  0.671045344557 |  0.102648222766 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.489204380621 |  0.26106039756  |              {'C': 100.0, 'gamma': 1000.0}               |        34       |
|  0.723999129678 |  0.293817901249 |              {'C': 100.0, 'gamma': 10000.0}              |        8        |
|  0.724216710183 |  0.225267632543 |              {'C': 1000.0, 'gamma': 0.001}               |        7        |
|  0.766675563456 | 0.0780570349933 |               {'C': 1000.0, 'gamma': 0.01}               |        4        |
|  0.716971049122 | 0.0466506389899 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.670777461764 | 0.0353277954261 |               {'C': 1000.0, 'gamma': 1.0}                |        18       |
|  0.637155365118 | 0.0565163490241 |               {'C': 1000.0, 'gamma': 10.0}               |        23       |
|  0.610486358884 |  0.070017549409 |              {'C': 1000.0, 'gamma': 100.0}               |        26       |
|  0.637212482904 |  0.25771378523  |              {'C': 1000.0, 'gamma': 1000.0}              |        22       |
|  0.527415143603 |  0.35806631143  |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.786742775896 | 0.0639809840943 |              {'C': 10000.0, 'gamma': 0.001}              |        1        |
|  0.707198394376 | 0.0515809149021 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.68649882542  | 0.0604022517458 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        15       |
|  0.670117583144 |  0.051743551915 |               {'C': 10000.0, 'gamma': 1.0}               |        19       |
|  0.607425698623 | 0.0594109542846 |              {'C': 10000.0, 'gamma': 10.0}               |        27       |
|  0.627546031041 |  0.095191590638 |              {'C': 10000.0, 'gamma': 100.0}              |        24       |
|  0.580163910647 |  0.208740265298 |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.491623150566 |  0.428500996155 |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.82      0.77        50
          1       0.68      0.54      0.60        35

avg / total       0.70      0.71      0.70        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.103347669081 | 0.0626268362939 |                 {'C': 1.0, 'gamma': 1.0}                 |        27       |
|  0.633314558241 |  0.130961019742 |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.442237640024 | 0.0740295951938 |                {'C': 1.0, 'gamma': 100.0}                |        19       |
|  0.106611376653 | 0.0613154047744 |               {'C': 1.0, 'gamma': 1000.0}                |        23       |
| 0.0595968794744 | 0.0407372122993 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.10351085446  | 0.0505453640015 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.677228533227 |  0.105122467349 |                {'C': 10.0, 'gamma': 1.0}                 |        9        |
|  0.730392750358 | 0.0560425624376 |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.49526630801  | 0.0825130590343 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.125452707824 | 0.0467317748517 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
| 0.0344900193717 | 0.0295050476785 |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.106512675819 | 0.0398059901506 |               {'C': 100.0, 'gamma': 0.01}                |        24       |
|  0.658217436621 |  0.090499207672 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        11       |
|  0.72387191527  |  0.094273618955 |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.696181725343 | 0.0817468513629 |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.467108934136 | 0.0771348712502 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.10353454266  | 0.0441153497526 |              {'C': 100.0, 'gamma': 1000.0}               |        25       |
| 0.0282481786406 | 0.0219236105855 |              {'C': 100.0, 'gamma': 10000.0}              |        33       |
|  0.109636886212 | 0.0559954381023 |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.57989108692  | 0.0811433969423 |               {'C': 1000.0, 'gamma': 0.01}               |        14       |
|  0.739943043039 | 0.0869003559975 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.724093005138 | 0.0896418169263 |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.695790870041 | 0.0790041570588 |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.429668417839 | 0.0758942293147 |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
| 0.0814229238609 | 0.0507526659113 |              {'C': 1000.0, 'gamma': 1000.0}              |        28       |
| 0.0345650320054 | 0.0299823400288 |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.539343468374 | 0.0985897183998 |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|  0.742985660743 | 0.0734212294115 |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.755550934894 | 0.0568692349279 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.677146940537 | 0.0479133032946 |               {'C': 10000.0, 'gamma': 1.0}               |        10       |
|  0.636316379601 | 0.0505680358456 |              {'C': 10000.0, 'gamma': 10.0}               |        12       |
|  0.444967047082 | 0.0778624384076 |              {'C': 10000.0, 'gamma': 100.0}              |        18       |
| 0.0784276825571 | 0.0399558919875 |             {'C': 10000.0, 'gamma': 1000.0}              |        29       |
|  0.028207382296 | 0.0218888835786 |             {'C': 10000.0, 'gamma': 10000.0}             |        34       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.72      0.74        50
          1       0.63      0.69      0.66        35

avg / total       0.71      0.71      0.71        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|  0.583550913838 | 0.00238368027742 |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|  0.583550913838 | 0.00238368027742 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|  0.583550913838 | 0.00238368027742 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|  0.583550913838 | 0.00238368027742 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|  0.583550913838 | 0.00238368027742 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|  0.583550913838 | 0.00238368027742 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|  0.583550913838 | 0.00238368027742 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.603133159269 |  0.023734296601  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.731070496084 | 0.0334608502553  |                {'C': 1.0, 'gamma': 10.0}                 |        9        |
|  0.677545691906 | 0.0373944386757  |                {'C': 1.0, 'gamma': 100.0}                |        15       |
|  0.579634464752 | 0.0272953624384  |               {'C': 1.0, 'gamma': 1000.0}                |        63       |
|  0.575718015666 | 0.0167282917282  |               {'C': 1.0, 'gamma': 10000.0}               |        64       |
|  0.583550913838 | 0.00238368027742 |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|  0.583550913838 | 0.00238368027742 |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|  0.618798955614 | 0.0257550072133  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.750652741514 | 0.0406582715371  |                {'C': 10.0, 'gamma': 1.0}                 |        6        |
|  0.759791122715 | 0.0528202204304  |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.659268929504 | 0.0581519002817  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.593994778068 | 0.0203856262805  |               {'C': 10.0, 'gamma': 1000.0}               |        26       |
|  0.582245430809 | 0.0112574379954  |              {'C': 10.0, 'gamma': 10000.0}               |        61       |
|  0.583550913838 | 0.00238368027742 |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|  0.610966057441 | 0.0227933405576  |               {'C': 100.0, 'gamma': 0.01}                |        23       |
|  0.720626631854 | 0.0639130685374  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.754569190601 | 0.0383381103607  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.721932114883 | 0.0476751918707  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.659268929504 | 0.0373026583206  |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.590078328982 | 0.0322440306834  |              {'C': 100.0, 'gamma': 1000.0}               |        28       |
|  0.582245430809 | 0.0174462766506  |              {'C': 100.0, 'gamma': 10000.0}              |        61       |
|  0.620104438642 | 0.0202248629587  |              {'C': 1000.0, 'gamma': 0.001}               |        20       |
|  0.725848563969 | 0.0334927522421  |               {'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.762402088773 | 0.0510558112275  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.755874673629 | 0.0547795193515  |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.682767624021 |  0.046553309401  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.644908616188 | 0.0425769150626  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.596605744125 | 0.0326189510925  |              {'C': 1000.0, 'gamma': 1000.0}              |        25       |
|  0.586161879896 | 0.0212060883758  |             {'C': 1000.0, 'gamma': 10000.0}              |        29       |
|  0.736292428198 | 0.0406126172409  |              {'C': 10000.0, 'gamma': 0.001}              |        7        |
|  0.73498694517  | 0.0617873837945  |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|  0.751958224543 | 0.0378678480762  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.715404699739 | 0.0402104796855  |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.656657963446 | 0.0586189541231  |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.620104438642 |  0.059988206487  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.59138381201  | 0.0249933820951  |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.586161879896 | 0.0178456089681  |             {'C': 10000.0, 'gamma': 10000.0}             |        29       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.87      0.78      0.82        50
          1       0.72      0.83      0.77        35

avg / total       0.81      0.80      0.80        85

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.793943491235 |  0.224139202893 |                 {'C': 1.0, 'gamma': 1.0}                 |        3        |
|  0.713273407175 | 0.0897443862906 |                {'C': 1.0, 'gamma': 10.0}                 |        11       |
|  0.666531972914 | 0.0369553234535 |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.430215715529 |  0.181411634772 |               {'C': 1.0, 'gamma': 1000.0}                |        32       |
|  0.469930374238 |  0.286414305546 |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.801131418625 |  0.220882258874 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.713106283764 | 0.0896963691556 |                {'C': 10.0, 'gamma': 1.0}                 |        12       |
|  0.691372845271 | 0.0735540272544 |                {'C': 10.0, 'gamma': 10.0}                |        14       |
|  0.655897217868 | 0.0833426860447 |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.560498259356 |  0.188645759896 |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
|  0.271409921671 |  0.395641854299 |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.823281114012 |  0.214567179997 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.738743182601 | 0.0891989055881 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.709804360783 |  0.07471157486  |                {'C': 100.0, 'gamma': 1.0}                |        13       |
|  0.648070218105 | 0.0527441028965 |               {'C': 100.0, 'gamma': 10.0}                |        20       |
|  0.634624798895 | 0.0748631703403 |               {'C': 100.0, 'gamma': 100.0}               |        22       |
|  0.440796344648 |  0.165072237648 |              {'C': 100.0, 'gamma': 1000.0}               |        31       |
|  0.389469103568 |  0.443668257391 |              {'C': 100.0, 'gamma': 10000.0}              |        33       |
|  0.786335944299 |  0.248411169131 |              {'C': 1000.0, 'gamma': 0.001}               |        4        |
|  0.736040937153 | 0.0687764061479 |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.726986538213 | 0.0538480840624 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.677094301565 | 0.0677709986432 |               {'C': 1000.0, 'gamma': 1.0}                |        15       |
|  0.623953899354 | 0.0654410482413 |               {'C': 1000.0, 'gamma': 10.0}               |        23       |
|  0.619909005519 | 0.0956820980815 |              {'C': 1000.0, 'gamma': 100.0}               |        24       |
|  0.637386547308 |  0.246466448184 |              {'C': 1000.0, 'gamma': 1000.0}              |        21       |
|  0.467145343777 |  0.420294635414 |             {'C': 1000.0, 'gamma': 10000.0}              |        30       |
|  0.765121124608 | 0.0873490196257 |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.723472576523 | 0.0385980004355 |              {'C': 10000.0, 'gamma': 0.01}               |        9        |
|  0.713742264361 | 0.0440178662643 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        10       |
|  0.654816275949 | 0.0671416886183 |               {'C': 10000.0, 'gamma': 1.0}               |        18       |
|  0.599531094683 | 0.0621757519547 |              {'C': 10000.0, 'gamma': 10.0}               |        26       |
|  0.610105711445 |  0.061088453807 |              {'C': 10000.0, 'gamma': 100.0}              |        25       |
|  0.531922168345 |  0.118415170686 |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.651436031332 |  0.39697156139  |             {'C': 10000.0, 'gamma': 10000.0}             |        19       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.98      0.78        50
          1       0.89      0.23      0.36        35

avg / total       0.75      0.67      0.61        85

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
| 0.0940697907016 | 0.0340899972323 |                 {'C': 1.0, 'gamma': 1.0}                 |        27       |
|  0.60172107934  |  0.124658646804 |                {'C': 1.0, 'gamma': 10.0}                 |        11       |
|  0.369932041186 | 0.0625563765206 |                {'C': 1.0, 'gamma': 100.0}                |        20       |
| 0.0878687463152 | 0.0499686736838 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
| 0.0125244778068 | 0.0207571625167 |               {'C': 1.0, 'gamma': 10000.0}               |        34       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.100253726943 | 0.0517449865595 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.595185768129 |  0.133606035083 |                {'C': 10.0, 'gamma': 1.0}                 |        12       |
|  0.730450654847 | 0.0588199926285 |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.454605512507 | 0.0913785049809 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.11911216626  | 0.0235238775946 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
| 0.0156657963446 |  0.015624946741 |              {'C': 10.0, 'gamma': 10000.0}               |        33       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.112870325529 | 0.0320325298563 |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.561111608271 |  0.107831904648 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.730240093068 | 0.0686599014633 |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.689620093911 |  0.101273166135 |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.423495009686 | 0.0771848540842 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
| 0.0940461025015 | 0.0464533585204 |              {'C': 100.0, 'gamma': 1000.0}               |        28       |
| 0.0344084266824 | 0.0259757097365 |              {'C': 100.0, 'gamma': 10000.0}              |        30       |
|  0.103470058115 | 0.0464116316718 |              {'C': 1000.0, 'gamma': 0.001}               |        23       |
|  0.558034774278 | 0.0641771438369 |               {'C': 1000.0, 'gamma': 0.01}               |        14       |
|  0.677061399815 | 0.0635397600995 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.739846974227 |  0.119706210488 |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.683324296724 |  0.130591031808 |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.39190811084  | 0.0845463942674 |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
| 0.0972453255285 | 0.0534036101905 |              {'C': 1000.0, 'gamma': 1000.0}              |        25       |
| 0.0282652867851 | 0.0221547611749 |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.548164690895 | 0.0973503016093 |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|   0.7053029984  | 0.0500777220763 |              {'C': 10000.0, 'gamma': 0.01}               |        5        |
|  0.758610660743 | 0.0815603711814 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.696046176198 | 0.0527595925864 |               {'C': 10000.0, 'gamma': 1.0}               |        6        |
|  0.623805061905 |  0.08453381851  |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.395236302956 | 0.0698864905228 |              {'C': 10000.0, 'gamma': 100.0}              |        18       |
| 0.0971466246947 |  0.025985514356 |             {'C': 10000.0, 'gamma': 1000.0}              |        26       |
| 0.0313894971785 | 0.0197856000366 |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.85      0.78      0.81        50
          1       0.72      0.80      0.76        35

avg / total       0.79      0.79      0.79        85

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.584093872229 | 0.00183162664133 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.584093872229 | 0.00183162664133 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.582790091265 | 0.00421287873339 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        63       |
|  0.582790091265 | 0.00999437037407 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        63       |
|  0.584093872229 | 0.00183162664133 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.584093872229 | 0.00183162664133 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.584093872229 | 0.00183162664133 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.584093872229 | 0.00183162664133 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.61147327249  | 0.0103758315052  |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.717079530639 |  0.04089059815   |                {'C': 1.0, 'gamma': 10.0}                 |        12       |
|  0.672750977836 | 0.0456808173374  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.599739243807 | 0.0364482592257  |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.593220338983 | 0.0220627612899  |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.584093872229 | 0.00183162664133 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.584093872229 | 0.00183162664133 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.610169491525 | 0.0257526331503  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.745762711864 | 0.0720464412973  |                {'C': 10.0, 'gamma': 1.0}                 |        5        |
|  0.74185136897  | 0.0300417255663  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.675358539765 | 0.0417597751087  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.598435462842 | 0.0401207905211  |               {'C': 10.0, 'gamma': 1000.0}               |        26       |
|  0.591916558018 | 0.0265836970395  |              {'C': 10.0, 'gamma': 10000.0}               |        31       |
|  0.584093872229 | 0.00183162664133 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.61408083442  |  0.022594071142  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.736636245111 | 0.0443874387353  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.754889178618 | 0.0353399347108  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.713168187744 | 0.0602865493818  |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.663624511082 | 0.0225569452876  |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.589308996089 | 0.0352032678745  |              {'C': 100.0, 'gamma': 1000.0}               |        33       |
|  0.593220338983 | 0.0114898910613  |              {'C': 100.0, 'gamma': 10000.0}              |        28       |
|  0.61147327249  | 0.0246676941193  |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.736636245111 | 0.0389393258376  |               {'C': 1000.0, 'gamma': 0.01}               |        8        |
|  0.77183833116  |  0.030124897369  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.734028683181 | 0.0510625924443  |               {'C': 1000.0, 'gamma': 1.0}                |        10       |
|  0.685788787484 | 0.0556675026408  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.64667535854  | 0.0713925198577  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.589308996089 | 0.0342456141711  |              {'C': 1000.0, 'gamma': 1000.0}              |        33       |
|  0.590612777053 | 0.0125517237171  |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.740547588005 | 0.0492307117767  |              {'C': 10000.0, 'gamma': 0.001}              |        7        |
|  0.764015645372 | 0.0384227389712  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.758800521512 | 0.0387980014592  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.728813559322 | 0.0433353638993  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.664928292047 | 0.0355816234533  |              {'C': 10000.0, 'gamma': 10.0}               |        17       |
|  0.64406779661  | 0.0294459480981  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.593220338983 | 0.0372150150068  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.594524119948 | 0.0182701679091  |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.84      0.73      0.78        49
          1       0.68      0.80      0.74        35

avg / total       0.77      0.76      0.76        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        37       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        37       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        37       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        37       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        37       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        37       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        37       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        37       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        37       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        37       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        37       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        37       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        37       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        37       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        37       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        37       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        37       |
|  0.107083876575 |  0.164026722875 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        36       |
|  0.193220338983 |  0.244677578592 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        37       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        37       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        37       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        37       |
|  0.875162972621 |  0.171954024482 |                 {'C': 1.0, 'gamma': 1.0}                 |        2        |
|  0.639459737399 | 0.0473629419356 |                {'C': 1.0, 'gamma': 10.0}                 |        20       |
|  0.642958529684 | 0.0949705880016 |                {'C': 1.0, 'gamma': 100.0}                |        19       |
|  0.621818153598 |  0.183694248013 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.682333767927 |  0.276451066882 |               {'C': 1.0, 'gamma': 10000.0}               |        14       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        37       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        37       |
|  0.801553672316 |  0.220681352567 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        3        |
|  0.699386865089 | 0.0633735862494 |                {'C': 10.0, 'gamma': 1.0}                 |        10       |
|  0.691529125912 | 0.0690688907351 |                {'C': 10.0, 'gamma': 10.0}                |        11       |
|  0.647414026403 | 0.0735664659905 |               {'C': 10.0, 'gamma': 100.0}                |        18       |
|  0.600130378096 |  0.23774243476  |               {'C': 10.0, 'gamma': 1000.0}               |        26       |
|  0.597044763146 |  0.288577190031 |              {'C': 10.0, 'gamma': 10000.0}               |        27       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        37       |
|  0.764178617992 |  0.304023288173 |               {'C': 100.0, 'gamma': 0.01}                |        4        |
|  0.722625147906 |  0.062791288723 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.687795049723 | 0.0472673270289 |                {'C': 100.0, 'gamma': 1.0}                |        13       |
|  0.639229127814 | 0.0539901377928 |               {'C': 100.0, 'gamma': 10.0}                |        21       |
|  0.652226191866 | 0.0732445277979 |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.601837710312 |  0.223625258706 |              {'C': 100.0, 'gamma': 1000.0}               |        25       |
|  0.575945241199 |  0.361379486978 |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.87603215993  |  0.171265124428 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.735999426652 | 0.0855684662953 |               {'C': 1000.0, 'gamma': 0.01}               |        5        |
|  0.722854077714 | 0.0830562993453 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.665487454641 |  0.044337489974 |               {'C': 1000.0, 'gamma': 1.0}                |        15       |
|  0.619111470493 | 0.0713130327232 |               {'C': 1000.0, 'gamma': 10.0}               |        23       |
|  0.618980927597 |  0.119600830297 |              {'C': 1000.0, 'gamma': 100.0}               |        24       |
|  0.559713168188 |  0.163076983203 |              {'C': 1000.0, 'gamma': 1000.0}              |        32       |
|  0.584245980009 |  0.361329584408 |             {'C': 1000.0, 'gamma': 10000.0}              |        29       |
|  0.729977689637 | 0.0648632430659 |              {'C': 10000.0, 'gamma': 0.001}              |        6        |
|  0.712430958872 | 0.0608797929665 |              {'C': 10000.0, 'gamma': 0.01}               |        9        |
|  0.69145968429  | 0.0561164100633 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        12       |
|  0.651145795679 | 0.0433279926389 |               {'C': 10000.0, 'gamma': 1.0}               |        17       |
|  0.578175868353 | 0.0352529598546 |              {'C': 10000.0, 'gamma': 10.0}               |        30       |
|  0.584464810928 | 0.0466654353856 |              {'C': 10000.0, 'gamma': 100.0}              |        28       |
|  0.529331967468 |  0.272659616488 |             {'C': 10000.0, 'gamma': 1000.0}              |        33       |
|  0.434159061278 |  0.326377954117 |             {'C': 10000.0, 'gamma': 10000.0}             |        34       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.98      0.77        49
          1       0.89      0.23      0.36        35

avg / total       0.74      0.67      0.60        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        37       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        37       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        37       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        37       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        37       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        37       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        37       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        37       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        37       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        37       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        37       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        37       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        37       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        37       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        37       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        37       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        37       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        37       |
| 0.0125488917862 | 0.0375651006682 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        36       |
| 0.0219776464651 | 0.0314844404633 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        37       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        37       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        37       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        37       |
| 0.0846169617698 | 0.0396076609445 |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.683428313076 |  0.111727017256 |                {'C': 1.0, 'gamma': 10.0}                 |        10       |
|  0.432438648694 |  0.11474195906  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.119062013711 | 0.0555027532679 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
| 0.0563070404172 | 0.0413649184196 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        37       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        37       |
| 0.0909255793414 | 0.0587115551599 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        27       |
|  0.714738770661 | 0.0670139526345 |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.721034245279 | 0.0610467464914 |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.460677598099 | 0.0622384373701 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.125411374437 | 0.0644063460779 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
| 0.0533262186146 | 0.0525173711751 |              {'C': 10.0, 'gamma': 10000.0}               |        31       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        37       |
|  0.090867750347 | 0.0382346305502 |               {'C': 100.0, 'gamma': 0.01}                |        28       |
|  0.601890745258 | 0.0930383184538 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.765186682508 |  0.101333713441 |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.699056598814 | 0.0573772530738 |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|  0.454688354292 |  0.101974227503 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.109748917021 |  0.032283400375 |              {'C': 100.0, 'gamma': 1000.0}               |        23       |
| 0.0470110295664 |  0.03508650053  |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
| 0.0909663224965 | 0.0359048910535 |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.582866320394 | 0.0752933862541 |               {'C': 1000.0, 'gamma': 0.01}               |        14       |
|  0.749170679648 | 0.0524353752337 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.736910932834 | 0.0877055316233 |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.664767948017 | 0.0939423456591 |               {'C': 1000.0, 'gamma': 10.0}               |        11       |
|  0.388605585229 | 0.0680968673674 |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
| 0.0970843672457 | 0.0511502733549 |              {'C': 1000.0, 'gamma': 1000.0}              |        25       |
| 0.0439552929301 |  0.028772504559 |             {'C': 1000.0, 'gamma': 10000.0}              |        33       |
|  0.57040942928  | 0.0743884146794 |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|  0.742977720066 |   0.0538230468  |              {'C': 10000.0, 'gamma': 0.01}               |        4        |
|  0.752307902595 | 0.0664189703632 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.717736678303 | 0.0979814282622 |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.642657557724 | 0.0507056780354 |              {'C': 10000.0, 'gamma': 10.0}               |        12       |
|  0.401385792993 | 0.0780814621323 |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
|  0.103195840518 | 0.0737471892573 |             {'C': 10000.0, 'gamma': 1000.0}              |        24       |
| 0.0439552929301 | 0.0319989601824 |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.65      0.72        49
          1       0.61      0.77      0.68        35

avg / total       0.72      0.70      0.70        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 0.001}               |        33       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 0.01}                |        33       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        33       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.001, 'gamma': 1.0}                |        33       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 10.0}                |        33       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 100.0}               |        33       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.001, 'gamma': 1000.0}               |        33       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.001, 'gamma': 10000.0}              |        33       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 0.001}                |        33       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 0.01}                |        33       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        33       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 1.0}                 |        33       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 10.0}                |        33       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 100.0}                |        33       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 1000.0}               |        33       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.01, 'gamma': 10000.0}               |        33       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        33       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        33       |
|  0.584093872229 | 0.00183162664133 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        33       |
|  0.584093872229 | 0.00183162664133 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        33       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        33       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        33       |
|  0.584093872229 | 0.00183162664133 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        33       |
|  0.584093872229 | 0.00183162664133 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        33       |
|  0.584093872229 | 0.00183162664133 |                {'C': 1.0, 'gamma': 0.001}                |        33       |
|  0.584093872229 | 0.00183162664133 |                {'C': 1.0, 'gamma': 0.01}                 |        33       |
|  0.584093872229 | 0.00183162664133 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        33       |
|  0.615384615385 | 0.0356318353981  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.74185136897  | 0.0386438953431  |                {'C': 1.0, 'gamma': 10.0}                 |        7        |
|  0.677966101695 | 0.0593226971793  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.593220338983 |  0.026142469641  |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.586701434159 | 0.0271282758424  |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.584093872229 | 0.00183162664133 |               {'C': 10.0, 'gamma': 0.001}                |        33       |
|  0.584093872229 | 0.00183162664133 |                {'C': 10.0, 'gamma': 0.01}                |        33       |
|  0.620599739244 | 0.0335364050459  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.753585397653 | 0.0303344822658  |                {'C': 10.0, 'gamma': 1.0}                 |        5        |
|   0.7444589309  | 0.0437368575133  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.681877444589 | 0.0471931624974  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.588005215124 | 0.0336730169303  |               {'C': 10.0, 'gamma': 1000.0}               |        26       |
|  0.585397653194 | 0.0110008835123  |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|  0.584093872229 | 0.00183162664133 |               {'C': 100.0, 'gamma': 0.001}               |        33       |
|  0.620599739244 | 0.0248339254598  |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.726205997392 | 0.0282762111726  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        11       |
|  0.760104302477 | 0.0398160010038  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.719687092568 | 0.0689777717564  |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.672750977836 | 0.0561136152237  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.584093872229 | 0.0191293004049  |              {'C': 100.0, 'gamma': 1000.0}               |        33       |
|  0.586701434159 | 0.0189354401662  |              {'C': 100.0, 'gamma': 10000.0}              |        28       |
|  0.624511082138 | 0.0192594439884  |              {'C': 1000.0, 'gamma': 0.001}               |        20       |
|  0.73924380704  |  0.053926040904  |               {'C': 1000.0, 'gamma': 0.01}               |        8        |
|  0.770534550196 | 0.0454288394138  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.736636245111 | 0.0410684568108  |               {'C': 1000.0, 'gamma': 1.0}                |        10       |
|  0.700130378096 | 0.0481151644022  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.638852672751 | 0.0302644365075  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.584093872229 | 0.0202982375953  |              {'C': 1000.0, 'gamma': 1000.0}              |        33       |
|  0.588005215124 | 0.0182239845684  |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
|  0.73924380704  | 0.0318375438074  |              {'C': 10000.0, 'gamma': 0.001}              |        8        |
|  0.757496740548 | 0.0522332619386  |              {'C': 10000.0, 'gamma': 0.01}               |        4        |
|  0.762711864407 | 0.0514004203648  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.724902216428 | 0.0353333438498  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.661016949153 | 0.0639793152776  |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.624511082138 |  0.040409664736  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.586701434159 | 0.0168392096504  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.586701434159 | 0.0123902998179  |             {'C': 10000.0, 'gamma': 10000.0}             |        28       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.82      0.81        49
          1       0.74      0.71      0.72        35

avg / total       0.77      0.77      0.77        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.832681442851 |  0.141312255247 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.678807260353 | 0.0769321360032 |                {'C': 1.0, 'gamma': 10.0}                 |        15       |
|  0.651646060124 | 0.0704966911027 |                {'C': 1.0, 'gamma': 100.0}                |        17       |
|  0.541131702572 |  0.142456085495 |               {'C': 1.0, 'gamma': 1000.0}                |        26       |
|  0.437461973055 |  0.342291205425 |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.812809647979 |  0.199746482766 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.729929858605 | 0.0812180983802 |                {'C': 10.0, 'gamma': 1.0}                 |        9        |
|  0.692758530887 | 0.0578766037821 |                {'C': 10.0, 'gamma': 10.0}                |        13       |
|  0.656098741427 | 0.0798225972032 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.549985513545 |  0.216364282579 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.432637983485 |  0.368903269489 |              {'C': 10.0, 'gamma': 10000.0}               |        31       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.753766478343 |  0.169083721841 |               {'C': 100.0, 'gamma': 0.01}                |        6        |
|  0.754046892257 | 0.0873801077246 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        5        |
|  0.707207393708 | 0.0478538844257 |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.630656281799 | 0.0532746530221 |               {'C': 100.0, 'gamma': 10.0}                |        20       |
|  0.634047744124 | 0.0844197706508 |               {'C': 100.0, 'gamma': 100.0}               |        19       |
|  0.452542372881 |  0.240718099272 |              {'C': 100.0, 'gamma': 1000.0}               |        28       |
|  0.310278139939 |  0.362922542871 |              {'C': 100.0, 'gamma': 10000.0}              |        33       |
|  0.808264522671 |  0.147973390242 |              {'C': 1000.0, 'gamma': 0.001}               |        3        |
|  0.761405544801 | 0.0589735786853 |               {'C': 1000.0, 'gamma': 0.01}               |        4        |
|  0.731467597312 | 0.0863706219362 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.681092629712 | 0.0818138110655 |               {'C': 1000.0, 'gamma': 1.0}                |        14       |
|  0.61218993863  | 0.0689747339368 |               {'C': 1000.0, 'gamma': 10.0}               |        21       |
|  0.591971294095 | 0.0920271396314 |              {'C': 1000.0, 'gamma': 100.0}               |        23       |
|  0.418138076613 |  0.328677327645 |              {'C': 1000.0, 'gamma': 1000.0}              |        32       |
|  0.234245980009 |  0.367091976148 |             {'C': 1000.0, 'gamma': 10000.0}              |        34       |
|  0.75114254042  | 0.0730432992866 |              {'C': 10000.0, 'gamma': 0.001}              |        7        |
|  0.724583137163 | 0.0802533371115 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.694643323458 | 0.0520104765861 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        12       |
|  0.642439281097 | 0.0641896968873 |               {'C': 10000.0, 'gamma': 1.0}               |        18       |
|  0.579062408325 | 0.0523275951322 |              {'C': 10000.0, 'gamma': 10.0}               |        24       |
|  0.601845011352 | 0.0556136783089 |              {'C': 10000.0, 'gamma': 100.0}              |        22       |
|  0.536744893525 |  0.243753743748 |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.43591916558  |  0.422127422244 |             {'C': 10000.0, 'gamma': 10000.0}             |        30       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.96      0.75        49
          1       0.71      0.14      0.24        35

avg / total       0.65      0.62      0.53        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.128589340539 | 0.0359316261756 |                 {'C': 1.0, 'gamma': 1.0}                 |        21       |
|  0.661403351979 |  0.167188766742 |                {'C': 1.0, 'gamma': 10.0}                 |        9        |
|  0.397967310847 | 0.0868945864215 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.103358813139 | 0.0625113927087 |               {'C': 1.0, 'gamma': 1000.0}                |        26       |
| 0.0439316356142 | 0.0323002754504 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.119154014384 | 0.0644263153377 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|   0.6361386529  |  0.145410227642 |                {'C': 10.0, 'gamma': 1.0}                 |        12       |
|  0.73972483913  | 0.0534716957613 |                {'C': 10.0, 'gamma': 10.0}                |        1        |
|  0.470279839761 | 0.0682150940608 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.103474471128 | 0.0596366930405 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
| 0.0219605606258 | 0.0281465912507 |              {'C': 10.0, 'gamma': 10000.0}               |        33       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.122274151491 | 0.0386508024858 |               {'C': 100.0, 'gamma': 0.01}                |        23       |
|  0.570576344787 | 0.0994719337706 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.717740621189 | 0.0874216895754 |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.68976715944  | 0.0655674341227 |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.442006718678 | 0.0690229358143 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
| 0.0720509841443 | 0.0395669979803 |              {'C': 100.0, 'gamma': 1000.0}               |        29       |
| 0.0281535202086 | 0.0259395385784 |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
|  0.128531511545 | 0.0493971024107 |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.564362356479 |  0.135758763059 |               {'C': 1000.0, 'gamma': 0.01}               |        14       |
|  0.658377844135 | 0.0803102040653 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.714705913278 | 0.0900209050076 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.677085523826 | 0.0832436028877 |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.388650271271 | 0.0940340471935 |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.072190299449 | 0.0542271832203 |              {'C': 1000.0, 'gamma': 1000.0}              |        28       |
| 0.0313893153047 | 0.0279841467865 |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.548594755436 | 0.0985972372604 |              {'C': 10000.0, 'gamma': 0.001}              |        15       |
|   0.6803554906  | 0.0674336641896 |              {'C': 10000.0, 'gamma': 0.01}               |        7        |
|  0.736546873029 | 0.0621161433949 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.686681194011 | 0.0906108566605 |               {'C': 10000.0, 'gamma': 1.0}               |        6        |
|  0.645927524498 | 0.0886269865738 |              {'C': 10000.0, 'gamma': 10.0}               |        11       |
|  0.38240605417  | 0.0711196477126 |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
| 0.0938893153047 | 0.0623509608719 |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
| 0.0219539891492 | 0.0246986688237 |             {'C': 10000.0, 'gamma': 10000.0}             |        34       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.81      0.71      0.76        49
          1       0.66      0.77      0.71        35

avg / total       0.75      0.74      0.74        84

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.584093872229 | 0.00183162664133 |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|  0.584093872229 | 0.00183162664133 |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|  0.584093872229 | 0.00183162664133 |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|  0.584093872229 | 0.00183162664133 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|  0.584093872229 | 0.00183162664133 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|  0.584093872229 | 0.00183162664133 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|  0.584093872229 | 0.00183162664133 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|  0.584093872229 | 0.00183162664133 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.584093872229 | 0.00183162664133 |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|  0.584093872229 | 0.00183162664133 |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|  0.584093872229 | 0.00183162664133 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.608865710561 | 0.0212617238783  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.707953063885 | 0.0559428379708  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.664928292047 | 0.0371719311113  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.599739243807 | 0.0343311149067  |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.589308996089 | 0.0189299520977  |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.584093872229 | 0.00183162664133 |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|  0.584093872229 | 0.00183162664133 |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|  0.607561929596 | 0.0295607313928  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.752281616688 | 0.0497126199815  |                {'C': 10.0, 'gamma': 1.0}                 |        3        |
|  0.734028683181 | 0.0607487350132  |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.667535853977 | 0.0400789735682  |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.590612777053 | 0.0228061624589  |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
|  0.585397653194 | 0.0258683561637  |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|  0.584093872229 | 0.00183162664133 |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|  0.61408083442  | 0.0206572534149  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.736636245111 |  0.035164793462  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.743155149935 | 0.0415557164411  |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.70925684485  | 0.0559844149861  |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.663624511082 | 0.0415711250301  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.593220338983 | 0.0226434362012  |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
|  0.57887874837  | 0.0213967473409  |              {'C': 100.0, 'gamma': 10000.0}              |        64       |
|  0.61408083442  | 0.0289811475247  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.73924380704  | 0.0343363611158  |               {'C': 1000.0, 'gamma': 0.01}               |        6        |
|   0.7444589309  | 0.0566541703573  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.730117340287 | 0.0465228579984  |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.666232073012 |  0.070414121166  |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.655801825293 | 0.0559594514093  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.584093872229 | 0.0310203504134  |              {'C': 1000.0, 'gamma': 1000.0}              |        31       |
|  0.582790091265 | 0.0166969971677  |             {'C': 1000.0, 'gamma': 10000.0}              |        62       |
|  0.730117340287 | 0.0318230902318  |              {'C': 10000.0, 'gamma': 0.001}              |        9        |
|  0.761408083442 | 0.0525368116231  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.758800521512 | 0.0500669650123  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.710560625815 | 0.0395778812883  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.659713168188 | 0.0425654860551  |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.640156453716 | 0.0431233337315  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.589308996089 |  0.024869286316  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|   0.5814863103  | 0.0173644230724  |             {'C': 10000.0, 'gamma': 10000.0}             |        63       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.82      0.84      0.83        49
          1       0.76      0.74      0.75        35

avg / total       0.80      0.80      0.80        84

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.775325945241 |  0.20888518164  |                 {'C': 1.0, 'gamma': 1.0}                 |        3        |
|  0.669102449575 | 0.0759365119494 |                {'C': 1.0, 'gamma': 10.0}                 |        16       |
|  0.670268199002 | 0.0685339622765 |                {'C': 1.0, 'gamma': 100.0}                |        15       |
|  0.559777322489 |  0.27672833115  |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
|  0.56186440678  |  0.31263491773  |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.733601332754 |  0.151453588382 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        6        |
|  0.726174579398 | 0.0500304514311 |                {'C': 10.0, 'gamma': 1.0}                 |        9        |
|  0.675887387856 | 0.0425355977558 |                {'C': 10.0, 'gamma': 10.0}                |        14       |
|  0.654868384191 |  0.103208255012 |               {'C': 10.0, 'gamma': 100.0}                |        18       |
|  0.595480225989 |  0.187063116227 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.542590178183 |  0.305848275853 |              {'C': 10.0, 'gamma': 10000.0}               |        31       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.741596821258 |  0.178190693014 |               {'C': 100.0, 'gamma': 0.01}                |        4        |
|  0.736291081283 | 0.0908403963569 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        5        |
|  0.698396787542 | 0.0666998892618 |                {'C': 100.0, 'gamma': 1.0}                |        12       |
|  0.625857522068 | 0.0488043067472 |               {'C': 100.0, 'gamma': 10.0}                |        20       |
|  0.666162017624 |  0.11078788855  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.488593986052 |  0.254391596155 |              {'C': 100.0, 'gamma': 1000.0}               |        33       |
|  0.633637548892 |  0.34052846446  |              {'C': 100.0, 'gamma': 10000.0}              |        19       |
|  0.781877444589 |  0.139953685811 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.729203072246 | 0.0781261055051 |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.726457641138 | 0.0945469251552 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.677393284677 | 0.0694939173602 |               {'C': 1000.0, 'gamma': 1.0}                |        13       |
|  0.62115938329  | 0.0694712521101 |               {'C': 1000.0, 'gamma': 10.0}               |        22       |
|  0.608269138779 | 0.0638735564024 |              {'C': 1000.0, 'gamma': 100.0}               |        23       |
|  0.494390120238 |  0.218822978156 |              {'C': 1000.0, 'gamma': 1000.0}              |        32       |
|  0.473489787049 |  0.391982637863 |             {'C': 1000.0, 'gamma': 10000.0}              |        34       |
|  0.779348819842 | 0.0916208720017 |              {'C': 10000.0, 'gamma': 0.001}              |        2        |
|  0.725260262584 | 0.0560592571731 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.698739320688 | 0.0630616799913 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        11       |
|  0.623364230101 |  0.049579079563 |               {'C': 10000.0, 'gamma': 1.0}               |        21       |
|  0.58982826939  | 0.0763430553622 |              {'C': 10000.0, 'gamma': 10.0}               |        26       |
|  0.577481608192 | 0.0925600512166 |              {'C': 10000.0, 'gamma': 100.0}              |        27       |
|  0.575756917282 |  0.224594625178 |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.601043024772 |  0.373361986356 |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      1.00      0.77        49
          1       1.00      0.17      0.29        35

avg / total       0.78      0.65      0.57        84

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
| 0.0971829393952 | 0.0382057912767 |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.536001177609 |  0.158359934791 |                {'C': 1.0, 'gamma': 10.0}                 |        15       |
|  0.416827448795 | 0.0717037484723 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.119143500021 | 0.0537162943186 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
| 0.0533262186146 | 0.0421626861615 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.106523636287 | 0.0515945553371 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.642691729402 |  0.106162041084 |                {'C': 10.0, 'gamma': 1.0}                 |        11       |
|  0.71491620053  | 0.0944982697868 |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.473406548345 | 0.0834272997343 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.119201329015 | 0.0337539775249 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
| 0.0376979328763 | 0.0340775969524 |              {'C': 10.0, 'gamma': 10000.0}               |        31       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.109714745342 | 0.0507322846314 |               {'C': 100.0, 'gamma': 0.01}                |        24       |
|  0.558034024477 |  0.100298894262 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.736628359339 | 0.0681909066711 |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.677177524498 | 0.0617198649655 |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.435851873659 |  0.069589917936 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.103481042604 | 0.0766152356294 |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.028211349203 |  0.021933012876 |              {'C': 100.0, 'gamma': 10000.0}              |        34       |
|  0.112933454599 |  0.070046380349 |              {'C': 1000.0, 'gamma': 0.001}               |        23       |
|  0.539033256929 | 0.0798624150174 |               {'C': 1000.0, 'gamma': 0.01}               |        13       |
|  0.652120484081 | 0.0891876064075 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.733385992766 | 0.0745501152236 |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.67393121504  |  0.068364492176 |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.404271985532 | 0.0868928316898 |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.10653677924  | 0.0486800595684 |              {'C': 1000.0, 'gamma': 1000.0}              |        25       |
| 0.0313485721496 | 0.0280070595967 |             {'C': 1000.0, 'gamma': 10000.0}              |        33       |
|  0.538989885183 |  0.114433812166 |              {'C': 10000.0, 'gamma': 0.001}              |        14       |
|  0.730428828279 |  0.078054966752 |              {'C': 10000.0, 'gamma': 0.01}               |        3        |
|  0.714678313076 | 0.0739928335199 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.708397295706 | 0.0714981837241 |               {'C': 10000.0, 'gamma': 1.0}               |        6        |
|  0.652035054885 | 0.0931508072526 |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.395135004416 |  0.122232499979 |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
| 0.0972815115448 | 0.0432301760336 |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.031406401144 | 0.0281634619953 |             {'C': 10000.0, 'gamma': 10000.0}             |        32       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.84      0.82        49
          1       0.76      0.71      0.74        35

avg / total       0.78      0.79      0.78        84


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.437072996652 | 0.00452095546162 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      1.00      0.72       121
          1       0.00      0.00      0.00        92

avg / total       0.32      0.57      0.41       213


Accuracy on test set (using best parameters): 0.57

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.616498602972 | 0.0379290046484 |  {'n_neighbors': 3} |        5        |
|  0.647117310026 | 0.0447017423157 |  {'n_neighbors': 5} |        1        |
|  0.639522992695 | 0.0509136760196 | {'n_neighbors': 11} |        3        |
|  0.636086711381 |  0.045995826899 | {'n_neighbors': 21} |        4        |
|  0.639849985773 | 0.0563635205847 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.76      0.69       119
          1       0.58      0.41      0.48        94

avg / total       0.61      0.61      0.60       213


Accuracy on test set (using best parameters): 0.61

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.578320290755 | 0.0463658829368 | {'n_estimators': 2}  |        7        |
|  0.597177106482 | 0.0596060032304 | {'n_estimators': 3}  |        6        |
|  0.613934802391 | 0.0386689166137 | {'n_estimators': 5}  |        5        |
|  0.64140373968  | 0.0956782061896 | {'n_estimators': 10} |        4        |
|  0.693721513642 | 0.0416052047129 | {'n_estimators': 20} |        1        |
|  0.675550288049 | 0.0199163913047 | {'n_estimators': 40} |        3        |
|  0.685506240538 | 0.0557526393873 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.85      0.81       123
          1       0.76      0.68      0.72        90

avg / total       0.77      0.77      0.77       213


Accuracy on test set (using best parameters): 0.77

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.447094477305 | 0.0174649804676 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|   0.4641752455  | 0.0328198805745 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.492218928113 | 0.0663826367813 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.54744009975  | 0.0954046659485 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.476066724058 | 0.0863544890975 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.549534976533 |  0.11529670497  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.580659830565 |  0.123907686029 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.716421183083 | 0.0600853131285 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.715796764168 | 0.0566088335011 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.732483599158 | 0.0568542174473 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.736565670573 | 0.0572162293059 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.74184281724  | 0.0629490754911 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.738803709827 |  0.063196281657 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
|  0.742247589347 | 0.0596107004876 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.70036145049  | 0.0576576336086 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.719378787996 | 0.0622062613472 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.735336666078 | 0.0661546076682 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.736310312852 | 0.0608857621092 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.750090893826 | 0.0578763261591 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        1        |
|  0.748149587767 | 0.0646757430122 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.745478803173 | 0.0620890029326 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.78      0.88      0.83       123
          1       0.80      0.67      0.73        90

avg / total       0.79      0.79      0.79       213


Accuracy on test set (using best parameters): 0.79

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|   0.4427587697  | 0.00108755466128 |        {'C': 0.001}        |        6        |
|   0.4427587697  | 0.00108755466128 |        {'C': 0.01}         |        6        |
|   0.4427587697  | 0.00108755466128 | {'C': 0.10000000000000001} |        6        |
|  0.446216857226 | 0.0102940102597  |         {'C': 1.0}         |        5        |
|  0.684238408962 | 0.0656433502709  |        {'C': 10.0}         |        4        |
|  0.739931153401 | 0.0517924213592  |        {'C': 100.0}        |        3        |
|  0.750166257525 | 0.0413098260985  |       {'C': 1000.0}        |        2        |
|  0.758601995796 |  0.041438815241  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.79      0.79       118
          1       0.74      0.76      0.75        95

avg / total       0.78      0.77      0.77       213


Accuracy on test set (using best parameters): 0.77

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.437072996652 | 0.00452095546162 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.437072996652 | 0.00452095546162 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.437072996652 | 0.00452095546162 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.437072996652 | 0.00452095546162 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.437072996652 | 0.00452095546162 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.437072996652 | 0.00452095546162 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.437072996652 | 0.00452095546162 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.437072996652 | 0.00452095546162 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.437072996652 | 0.00452095546162 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.437072996652 | 0.00452095546162 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.437072996652 | 0.00452095546162 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.437072996652 | 0.00452095546162 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.437072996652 | 0.00452095546162 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.437072996652 | 0.00452095546162 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.437072996652 | 0.00452095546162 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.437072996652 | 0.00452095546162 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.437072996652 | 0.00452095546162 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.437072996652 | 0.00452095546162 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.437072996652 | 0.00452095546162 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.437072996652 | 0.00452095546162 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.437072996652 | 0.00452095546162 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.437072996652 | 0.00452095546162 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.437072996652 | 0.00452095546162 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.437072996652 | 0.00452095546162 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.437072996652 | 0.00452095546162 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.437072996652 | 0.00452095546162 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.437072996652 | 0.00452095546162 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.504744176549 | 0.0321117438387  |                 {'C': 1.0, 'gamma': 1.0}                 |        26       |
|  0.675355555437 | 0.0722812606939  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.616253828323 | 0.0541477598196  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.474295210358 | 0.0366373356246  |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.43864617256  | 0.0169765480873  |               {'C': 1.0, 'gamma': 10000.0}               |        34       |
|  0.437072996652 | 0.00452095546162 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.437072996652 | 0.00452095546162 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.510929782651 | 0.0449946814773  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.699944154731 | 0.0767371861626  |                {'C': 10.0, 'gamma': 1.0}                 |        10       |
|   0.714341434   | 0.0602962931306  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.613216788346 | 0.0577643696636  |               {'C': 10.0, 'gamma': 100.0}                |        19       |
|  0.485842631435 | 0.0434372746642  |               {'C': 10.0, 'gamma': 1000.0}               |        28       |
|  0.448537892694 | 0.0292856782251  |              {'C': 10.0, 'gamma': 10000.0}               |        33       |
|  0.437072996652 | 0.00452095546162 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.511507538087 |  0.051686902439  |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.704931480108 | 0.0609250351528  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.722374305226 | 0.0651983724812  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.690459615473 | 0.0329838031512  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.622528307476 | 0.0427113880408  |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.497486474187 | 0.0503998455533  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.457672651081 | 0.0406408499758  |              {'C': 100.0, 'gamma': 10000.0}              |        30       |
|  0.516597201739 | 0.0475129425265  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.71023366714  | 0.0693108774796  |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.728203943482 | 0.0550071793536  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.721626596522 | 0.0474195679607  |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.67439545026  | 0.0547785925313  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.602841686758 |  0.063748950085  |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
|  0.510475887868 | 0.0492777125282  |              {'C': 1000.0, 'gamma': 1000.0}              |        24       |
|  0.457672651081 | 0.0406408499758  |             {'C': 1000.0, 'gamma': 10000.0}              |        30       |
|  0.706114357232 | 0.0675965240599  |              {'C': 10000.0, 'gamma': 0.001}              |        8        |
|  0.748988221216 | 0.0485293971831  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.741980623974 | 0.0616070923058  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.680334100195 | 0.0503448122735  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.644241759278 | 0.0735221400959  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.618521350936 | 0.0444073382223  |              {'C': 10000.0, 'gamma': 100.0}              |        17       |
|  0.510475887868 | 0.0492777125282  |             {'C': 10000.0, 'gamma': 1000.0}              |        24       |
|  0.457672651081 | 0.0406408499758  |             {'C': 10000.0, 'gamma': 10000.0}             |        30       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.83      0.81       121
          1       0.76      0.71      0.73        92

avg / total       0.78      0.78      0.78       213


Accuracy on test set (using best parameters): 0.78


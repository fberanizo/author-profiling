Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.435178614161 | 0.00388236617942 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      1.00      0.73       122
          1       0.00      0.00      0.00        91

avg / total       0.33      0.57      0.42       213


Accuracy on test set (using best parameters): 0.57

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.633207933275 | 0.0741955901577 |  {'n_neighbors': 3} |        4        |
|  0.640964680799 | 0.0564449592847 |  {'n_neighbors': 5} |        1        |
|  0.63808256943  | 0.0309842153538 | {'n_neighbors': 11} |        3        |
|  0.628303141387 | 0.0476145390086 | {'n_neighbors': 21} |        5        |
|  0.640089505586 | 0.0378027065594 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.77      0.69       121
          1       0.58      0.41      0.48        92

avg / total       0.61      0.62      0.60       213


Accuracy on test set (using best parameters): 0.62

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.622621387135 | 0.0458268691317 | {'n_estimators': 2}  |        7        |
|  0.650621139165 | 0.0720543713361 | {'n_estimators': 3}  |        4        |
|  0.656498706436 | 0.0508533112712 | {'n_estimators': 5}  |        3        |
|  0.625252113245 |  0.048311111637 | {'n_estimators': 10} |        6        |
|  0.647170564179 | 0.0518195563988 | {'n_estimators': 20} |        5        |
|  0.719121898703 | 0.0624320880349 | {'n_estimators': 40} |        1        |
|  0.694073041879 | 0.0502804396279 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.87      0.79       127
          1       0.72      0.51      0.60        86

avg / total       0.72      0.72      0.71       213


Accuracy on test set (using best parameters): 0.72

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.461184808048 | 0.0262753644446 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.470008527284 | 0.0327042006911 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.557579941496 | 0.0793065753975 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.56683766382  |  0.108072997937 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|  0.557866302641 |  0.122230006278 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.517116093998 | 0.0964565924811 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        18       |
|  0.514257995817 |  0.113549418409 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.739940344737 | 0.0625414817944 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.763596882778 | 0.0634159039136 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        7        |
|  0.762388800831 | 0.0731366820704 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.763103819335 | 0.0758895169648 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.765963502262 | 0.0748342001079 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.768980920818 | 0.0781604989194 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.770172003898 | 0.0775184373659 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.739384061936 | 0.0608650208818 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.750038800574 |  0.049342707424 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.758232070627 | 0.0711027207661 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.766089128231 | 0.0698178051352 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|   0.7623102666  |  0.063247812226 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        10       |
|  0.772034498069 | 0.0650180218323 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.781551071875 | 0.0759482456709 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.74      0.72       119
          1       0.64      0.60      0.62        94

avg / total       0.67      0.68      0.67       213


Accuracy on test set (using best parameters): 0.68

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.435178614161 | 0.00388236617942 |        {'C': 0.001}        |        6        |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.01}         |        6        |
|  0.435178614161 | 0.00388236617942 | {'C': 0.10000000000000001} |        6        |
|  0.454751697657 | 0.0230702020433  |         {'C': 1.0}         |        5        |
|  0.684607007459 | 0.0389191489111  |        {'C': 10.0}         |        4        |
|  0.758091853954 | 0.0339024191745  |        {'C': 100.0}        |        3        |
|  0.765417285926 |  0.043509651279  |       {'C': 1000.0}        |        2        |
|  0.779284213936 | 0.0379539052358  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.80      0.78       122
          1       0.71      0.68      0.70        91

avg / total       0.75      0.75      0.75       213


Accuracy on test set (using best parameters): 0.75

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.452295229523 | 0.00190356142574 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.452295229523 | 0.00190356142574 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.452295229523 | 0.00190356142574 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.452295229523 | 0.00190356142574 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.452295229523 | 0.00190356142574 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.452295229523 | 0.00190356142574 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.452295229523 | 0.00190356142574 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.452295229523 | 0.00190356142574 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.452295229523 | 0.00190356142574 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.452295229523 | 0.00190356142574 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.452295229523 | 0.00190356142574 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.452295229523 | 0.00190356142574 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.452295229523 | 0.00190356142574 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.452295229523 | 0.00190356142574 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.452295229523 | 0.00190356142574 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.452295229523 | 0.00190356142574 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.452295229523 | 0.00190356142574 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.452295229523 | 0.00190356142574 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.452295229523 | 0.00190356142574 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.452295229523 | 0.00190356142574 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.452295229523 | 0.00190356142574 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.452295229523 | 0.00190356142574 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.452295229523 | 0.00190356142574 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.452295229523 | 0.00190356142574 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.452295229523 | 0.00190356142574 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.452295229523 | 0.00190356142574 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.452295229523 | 0.00190356142574 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.541142733596 |  0.026435262069  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.724989491668 | 0.0313040042168  |                {'C': 1.0, 'gamma': 10.0}                 |        14       |
|  0.658670353107 | 0.0403785495415  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.521295625147 | 0.0358082567999  |               {'C': 1.0, 'gamma': 1000.0}                |        26       |
|  0.48764431245  | 0.0325676364175  |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.452295229523 | 0.00190356142574 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.452295229523 | 0.00190356142574 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.539068656361 | 0.0208287914866  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.746476189605 | 0.0352370788289  |                {'C': 10.0, 'gamma': 1.0}                 |        9        |
|  0.76437196072  | 0.0381542967493  |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.685854943443 | 0.0622112205256  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.52982996375  | 0.0353825968326  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.47334615702  | 0.0310095610136  |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|  0.452295229523 | 0.00190356142574 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|   0.5477463128  | 0.0252637563459  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.750474916967 | 0.0465695011386  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.784724935876 | 0.0232528407859  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.750565436643 | 0.0425332655032  |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.667553939089 | 0.0643185239815  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.51476765435  |  0.044535521334  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.47573029962  | 0.0293340669887  |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.547680235276 |  0.023842769123  |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.743121977118 | 0.0382749503828  |               {'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.767098890531 | 0.0551565808198  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.762611150744 | 0.0218368448149  |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.738585736736 | 0.0451494326566  |               {'C': 1000.0, 'gamma': 10.0}               |        11       |
|  0.653503276839 |  0.057191048716  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.509791259718 | 0.0355237467007  |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.472482111607 | 0.0256376540504  |             {'C': 1000.0, 'gamma': 10000.0}              |        33       |
|  0.73721667448  | 0.0406995262733  |              {'C': 10000.0, 'gamma': 0.001}              |        12       |
|  0.767491968454 | 0.0573501734819  |              {'C': 10000.0, 'gamma': 0.01}               |        3        |
|  0.777411404781 | 0.0451628647651  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.733641221636 | 0.0390566480996  |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.72224095625  | 0.0522378331056  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|   0.643160028   | 0.0715124159993  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.512717925986 | 0.0331481462335  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.472482111607 | 0.0256376540504  |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.77      0.74       113
          1       0.71      0.65      0.68       100

avg / total       0.71      0.71      0.71       213


Accuracy on test set (using best parameters): 0.71


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.444667590491 | 0.00456708020392 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.55      1.00      0.71       117
          1       0.00      0.00      0.00        96

avg / total       0.30      0.55      0.39       213


Accuracy on test set (using best parameters): 0.55

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.577071089959 | 0.0568298003192 |  {'n_neighbors': 3} |        5        |
|  0.608567053401 | 0.0707747524992 |  {'n_neighbors': 5} |        1        |
|  0.607151258316 | 0.0549225391676 | {'n_neighbors': 11} |        2        |
|  0.588756737891 | 0.0354000508918 | {'n_neighbors': 21} |        3        |
|  0.587014251197 | 0.0561579363109 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.78      0.73       126
          1       0.60      0.48      0.54        87

avg / total       0.65      0.66      0.65       213


Accuracy on test set (using best parameters): 0.66

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.598884767875 | 0.0387110693383 | {'n_estimators': 2}  |        7        |
|  0.672860975116 | 0.0479546794862 | {'n_estimators': 3}  |        6        |
|  0.689134042374 | 0.0580687963946 | {'n_estimators': 5}  |        5        |
|  0.701505237741 | 0.0310197213077 | {'n_estimators': 10} |        4        |
|  0.719315424539 |  0.033476630648 | {'n_estimators': 20} |        3        |
|  0.749204557959 | 0.0411761457907 | {'n_estimators': 40} |        1        |
|  0.734276263704 | 0.0449545101955 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.83      0.74       121
          1       0.68      0.48      0.56        92

avg / total       0.68      0.68      0.66       213


Accuracy on test set (using best parameters): 0.68

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.481127142644 | 0.0393879742678 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.495543848193 | 0.0460447994667 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.557421914664 | 0.0749807712257 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|  0.509011956126 | 0.0969179546181 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.519714718295 |  0.109203888463 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.543901603499 |  0.118644698667 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.610454875761 |  0.12886716559  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.728805509243 | 0.0535765348136 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.735741251584 | 0.0685606925591 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.740430649307 | 0.0604146242434 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.752705920979 |  0.057531735213 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        1        |
|  0.739101552015 | 0.0625815024882 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
|  0.750981707519 |  0.056201001472 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.742752195445 | 0.0581068011841 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.724856314495 | 0.0627416017935 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.726560344697 | 0.0644774492618 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.736488281346 | 0.0649063193518 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.74192152122  | 0.0562521503763 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.743756419496 | 0.0632792111208 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.741073285575 |  0.060050529126 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.743691948663 | 0.0671831581929 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        4        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.86      0.80       123
          1       0.76      0.61      0.68        90

avg / total       0.76      0.76      0.75       213


Accuracy on test set (using best parameters): 0.76

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.444667590491 | 0.00456708020392 |        {'C': 0.001}        |        6        |
|  0.444667590491 | 0.00456708020392 |        {'C': 0.01}         |        6        |
|  0.444667590491 | 0.00456708020392 | {'C': 0.10000000000000001} |        6        |
|  0.461755517489 | 0.0232259289282  |         {'C': 1.0}         |        5        |
|   0.6786978346  | 0.0546416856189  |        {'C': 10.0}         |        4        |
|  0.742133691338 | 0.0860508195343  |        {'C': 100.0}        |        3        |
|  0.759735199328 | 0.0694911126222  |       {'C': 1000.0}        |        1        |
|  0.749675874167 | 0.0752469105929  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.83      0.80       117
          1       0.77      0.69      0.73        96

avg / total       0.77      0.77      0.76       213


Accuracy on test set (using best parameters): 0.77

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.431401765888 | 0.00416476243201 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.431401765888 | 0.00416476243201 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.431401765888 | 0.00416476243201 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.431401765888 | 0.00416476243201 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.431401765888 | 0.00416476243201 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.431401765888 | 0.00416476243201 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.431401765888 | 0.00416476243201 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.431401765888 | 0.00416476243201 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.431401765888 | 0.00416476243201 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.431401765888 | 0.00416476243201 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.431401765888 | 0.00416476243201 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.431401765888 | 0.00416476243201 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.431401765888 | 0.00416476243201 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.431401765888 | 0.00416476243201 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.431401765888 | 0.00416476243201 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.431401765888 | 0.00416476243201 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.431401765888 | 0.00416476243201 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.431401765888 | 0.00416476243201 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.431401765888 | 0.00416476243201 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.431401765888 | 0.00416476243201 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.431401765888 | 0.00416476243201 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.431401765888 | 0.00416476243201 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.431401765888 | 0.00416476243201 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.431401765888 | 0.00416476243201 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.431401765888 | 0.00416476243201 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.431401765888 | 0.00416476243201 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.431401765888 | 0.00416476243201 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.529902662943 | 0.0631532387835  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.69266944136  | 0.0637407235491  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.590231846061 | 0.0537047808155  |                {'C': 1.0, 'gamma': 100.0}                |        20       |
|  0.451215725753 | 0.0284335438408  |               {'C': 1.0, 'gamma': 1000.0}                |        34       |
|  0.461345446527 | 0.0348846930465  |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|  0.431401765888 | 0.00416476243201 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.431401765888 | 0.00416476243201 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.539214718284 | 0.0609761904175  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.706796513731 |  0.069508000425  |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.721037734807 | 0.0607694713904  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.624761618567 | 0.0411895005784  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.464278439584 | 0.0325559477686  |               {'C': 10.0, 'gamma': 1000.0}               |        28       |
|   0.4586658053  | 0.0354783379609  |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|  0.431401765888 | 0.00416476243201 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.541431732663 | 0.0582267817079  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.693857351743 | 0.0640002246353  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.737990368188 | 0.0490728172525  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.69481661345  | 0.0434140820098  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.615141069392 | 0.0375882714022  |               {'C': 100.0, 'gamma': 100.0}               |        19       |
|  0.473153854005 | 0.0440242932677  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.455204796315 | 0.0287697874983  |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.538636754416 |  0.058846322609  |              {'C': 1000.0, 'gamma': 0.001}               |        23       |
|  0.696800783701 | 0.0642994918331  |               {'C': 1000.0, 'gamma': 0.01}               |        9        |
|  0.746141948398 | 0.0452181880258  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.726495211663 | 0.0576141569243  |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.650933810797 | 0.0575598865204  |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.618923695924 |  0.036289598389  |              {'C': 1000.0, 'gamma': 100.0}               |        18       |
|  0.476022034726 | 0.0422742657099  |              {'C': 1000.0, 'gamma': 1000.0}              |        25       |
|  0.454259754306 | 0.0273238592239  |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.696016617582 | 0.0634618074596  |              {'C': 10000.0, 'gamma': 0.001}              |        10       |
|  0.746525609137 | 0.0466069577962  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.744111107609 | 0.0507866442094  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.710397668268 | 0.0488487042035  |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.652216337935 | 0.0397612676235  |              {'C': 10000.0, 'gamma': 10.0}               |        14       |
|  0.629025051514 | 0.0443232560112  |              {'C': 10000.0, 'gamma': 100.0}              |        16       |
|  0.474057724246 | 0.0414519219382  |             {'C': 10000.0, 'gamma': 1000.0}              |        26       |
|  0.454259754306 | 0.0273238592239  |             {'C': 10000.0, 'gamma': 10000.0}             |        32       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.85      0.79       124
          1       0.74      0.60      0.66        89

avg / total       0.74      0.74      0.74       213


Accuracy on test set (using best parameters): 0.74


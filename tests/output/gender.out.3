Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.427636834323 | 0.00507103755249 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      1.00      0.74       126
          1       0.00      0.00      0.00        87

avg / total       0.35      0.59      0.44       213


Accuracy on test set (using best parameters): 0.59

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.614740254563 | 0.0419449731938 |  {'n_neighbors': 3} |        1        |
|  0.612658763284 | 0.0549818207214 |  {'n_neighbors': 5} |        2        |
|  0.607572230018 | 0.0243659220735 | {'n_neighbors': 11} |        3        |
|  0.607175373475 | 0.0265260561765 | {'n_neighbors': 21} |        4        |
|  0.599899604413 | 0.0313267755685 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.79      0.75       131
          1       0.59      0.50      0.54        82

avg / total       0.67      0.68      0.67       213


Accuracy on test set (using best parameters): 0.68

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.606241999977 | 0.0351474821012 | {'n_estimators': 2}  |        7        |
|  0.612164843285 | 0.0540244391347 | {'n_estimators': 3}  |        6        |
|  0.643971220235 | 0.0357165438449 | {'n_estimators': 5}  |        5        |
|  0.686520979966 |  0.032201855597 | {'n_estimators': 10} |        3        |
|  0.674517864607 | 0.0444711493172 | {'n_estimators': 20} |        4        |
|  0.696103437475 | 0.0311065769542 | {'n_estimators': 40} |        2        |
|  0.727497943994 |  0.055359368173 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.82      0.77       126
          1       0.67      0.54      0.60        87

avg / total       0.70      0.70      0.70       213


Accuracy on test set (using best parameters): 0.70

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.458450576863 | 0.0377776106226 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.496494502177 | 0.0294454668225 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.515593523264 | 0.0726644430377 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.519191470708 | 0.0801269323303 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.566481197831 |  0.114863996859 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.498049594956 | 0.0881945652648 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        19       |
|  0.523200748916 | 0.0963191548841 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.711664412913 | 0.0503808397964 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.729999368521 | 0.0555203133312 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.734255501728 | 0.0605509615363 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.738550643927 | 0.0548221295699 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.743912328643 |  0.060238530291 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.747138928252 | 0.0512840538043 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.742855878135 | 0.0566046664165 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.694210445656 | 0.0562234222456 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.726475954108 | 0.0532045278345 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.723826166381 | 0.0571102689488 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        12       |
|  0.735462211939 | 0.0528869778722 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.742313745136 | 0.0503430844607 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.732898737142 | 0.0484531169065 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        9        |
|  0.734520780061 | 0.0383627085686 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        7        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.76      0.79       123
          1       0.70      0.79      0.74        90

avg / total       0.78      0.77      0.77       213


Accuracy on test set (using best parameters): 0.77

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.435178614161 | 0.00388236617942 |        {'C': 0.001}        |        6        |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.01}         |        6        |
|  0.435178614161 | 0.00388236617942 | {'C': 0.10000000000000001} |        6        |
|  0.445538199611 | 0.0143514314288  |         {'C': 1.0}         |        5        |
|  0.702910083002 | 0.0539239867766  |        {'C': 10.0}         |        4        |
|  0.74963237943  | 0.0478170670572  |        {'C': 100.0}        |        2        |
|  0.748761298421 | 0.0654340470444  |       {'C': 1000.0}        |        3        |
|  0.753301820132 | 0.0501491574161  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.84      0.82       122
          1       0.76      0.71      0.74        91

avg / total       0.78      0.78      0.78       213


Accuracy on test set (using best parameters): 0.78

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 0.001}               |        37       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 0.01}                |        37       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        37       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.001, 'gamma': 1.0}                |        37       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 10.0}                |        37       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 100.0}               |        37       |
|  0.433284231671 | 0.00159032260113 |              {'C': 0.001, 'gamma': 1000.0}               |        37       |
|  0.433284231671 | 0.00159032260113 |              {'C': 0.001, 'gamma': 10000.0}              |        37       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.01, 'gamma': 0.001}                |        37       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.01, 'gamma': 0.01}                |        37       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        37       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.01, 'gamma': 1.0}                 |        37       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.01, 'gamma': 10.0}                |        37       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.01, 'gamma': 100.0}                |        37       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.01, 'gamma': 1000.0}               |        37       |
|  0.433284231671 | 0.00159032260113 |              {'C': 0.01, 'gamma': 10000.0}               |        37       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        37       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        37       |
|  0.433284231671 | 0.00159032260113 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        37       |
|  0.433284231671 | 0.00159032260113 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        37       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        37       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        37       |
|  0.443482674167 | 0.0157188573473  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.433284231671 | 0.00159032260113 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        37       |
|  0.433284231671 | 0.00159032260113 |                {'C': 1.0, 'gamma': 0.001}                |        37       |
|  0.433284231671 | 0.00159032260113 |                {'C': 1.0, 'gamma': 0.01}                 |        37       |
|  0.436736412834 |  0.010973008669  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        36       |
|  0.499359871797 |  0.036787924019  |                 {'C': 1.0, 'gamma': 1.0}                 |        23       |
|  0.715560819759 | 0.0682794628119  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.644039204513 | 0.0664885509409  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.513707553738 | 0.0586227565411  |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.478551129602 | 0.0372312835709  |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.433284231671 | 0.00159032260113 |               {'C': 10.0, 'gamma': 0.001}                |        37       |
|  0.433284231671 | 0.00159032260113 |                {'C': 10.0, 'gamma': 0.01}                |        37       |
|  0.493734787683 | 0.0379191512597  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.74056083358  |  0.067758789052  |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.743845552037 | 0.0565740694666  |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.64771222819  | 0.0573136414088  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.517053958266 | 0.0588559584644  |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.462531189744 | 0.0294261819925  |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|  0.433284231671 | 0.00159032260113 |               {'C': 100.0, 'gamma': 0.001}               |        37       |
|  0.490383935546 | 0.0416981425738  |               {'C': 100.0, 'gamma': 0.01}                |        27       |
|  0.743073961747 | 0.0604641219325  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.744234304039 | 0.0633048938896  |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.718800286113 | 0.0427956933358  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.646770881533 | 0.0466382197525  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.496887323801 | 0.0481159203178  |              {'C': 100.0, 'gamma': 1000.0}               |        24       |
|  0.463388058004 | 0.0292411873928  |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.491141597487 |  0.044295205714  |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.723025227544 | 0.0472549907497  |               {'C': 1000.0, 'gamma': 0.01}               |        9        |
|  0.75790061567  | 0.0594003011713  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.750391295587 | 0.0570523409829  |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.720589781769 | 0.0395167835081  |               {'C': 1000.0, 'gamma': 10.0}               |        10       |
|  0.631332871935 |  0.052252707196  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.485090591229 | 0.0417468385532  |              {'C': 1000.0, 'gamma': 1000.0}              |        29       |
|  0.463388058004 | 0.0292411873928  |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.708203426678 | 0.0487493111655  |              {'C': 10000.0, 'gamma': 0.001}              |        14       |
|  0.758008037414 | 0.0669958221359  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.750373612557 | 0.0581740585785  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.715792109827 | 0.0472846156049  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.693661176872 | 0.0499422898393  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.60492218171  | 0.0516013051931  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.488064545099 | 0.0397020703408  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.463388058004 | 0.0292411873928  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.74      0.77       123
          1       0.68      0.74      0.71        90

avg / total       0.75      0.74      0.74       213


Accuracy on test set (using best parameters): 0.74


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.444667590491 | 0.00456708020392 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.55      1.00      0.71       117
          1       0.00      0.00      0.00        96

avg / total       0.30      0.55      0.39       213


Accuracy on test set (using best parameters): 0.55

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.606729476146 | 0.0416360633878 |  {'n_neighbors': 3} |        5        |
|  0.614764415972 |  0.057560498131 |  {'n_neighbors': 5} |        3        |
|  0.609669755973 | 0.0415781006345 | {'n_neighbors': 11} |        4        |
|  0.62491237075  | 0.0533483193597 | {'n_neighbors': 21} |        2        |
|  0.646805505293 | 0.0694387746999 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.86      0.76       127
          1       0.66      0.41      0.50        86

avg / total       0.67      0.68      0.66       213


Accuracy on test set (using best parameters): 0.68

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.602144604172 |  0.064487304728 | {'n_estimators': 2}  |        7        |
|  0.61420556859  | 0.0760306650206 | {'n_estimators': 3}  |        6        |
|  0.640021532581 | 0.0647946984203 | {'n_estimators': 5}  |        5        |
|  0.681441926907 | 0.0521808247584 | {'n_estimators': 10} |        4        |
|  0.709909541149 | 0.0649374051792 | {'n_estimators': 20} |        2        |
|  0.697597108816 | 0.0361865606322 | {'n_estimators': 40} |        3        |
|  0.727630751609 | 0.0355990685123 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.81      0.75       129
          1       0.62      0.48      0.54        84

avg / total       0.67      0.68      0.67       213


Accuracy on test set (using best parameters): 0.68

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.472869964304 |  0.034083769964 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.499869511725 | 0.0446448602943 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        18       |
|  0.493209885307 | 0.0802893482336 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.475975601593 | 0.0679824887424 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.566232363779 |  0.106389887071 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.576921566618 |  0.111838885971 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.522389299597 |  0.123324964165 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.722638712677 | 0.0536142972043 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.726456322518 |  0.046902112786 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.737569746423 | 0.0379191895316 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.743592065379 | 0.0379426315459 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.741990779204 | 0.0477505276898 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.749096660059 |  0.05040767873  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.750509036528 | 0.0611749740994 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|  0.713915594598 | 0.0525913248309 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.717217065441 | 0.0537980036772 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.735713766977 | 0.0596942398595 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.735936826452 | 0.0555899681818 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        9        |
|  0.739028105328 | 0.0577645526703 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.739999782753 | 0.0527061775352 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.752017330173 | 0.0598825515594 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.74      0.75       118
          1       0.68      0.71      0.69        95

avg / total       0.72      0.72      0.72       213


Accuracy on test set (using best parameters): 0.72

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.452295229523 | 0.00190356142574 |        {'C': 0.001}        |        6        |
|  0.452295229523 | 0.00190356142574 |        {'C': 0.01}         |        6        |
|  0.452295229523 | 0.00190356142574 | {'C': 0.10000000000000001} |        6        |
|  0.481478247464 | 0.0338200604303  |         {'C': 1.0}         |        5        |
|  0.654918902755 | 0.0417385355142  |        {'C': 10.0}         |        4        |
|  0.732234324735 |  0.057225386087  |        {'C': 100.0}        |        2        |
|  0.728948767044 | 0.0499625220049  |       {'C': 1000.0}        |        3        |
|  0.736666586626 |  0.025648705257  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.74      0.90      0.81       113
          1       0.85      0.64      0.73       100

avg / total       0.79      0.78      0.77       213


Accuracy on test set (using best parameters): 0.78

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 0.001}               |        36       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 0.01}                |        36       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        36       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.001, 'gamma': 1.0}                |        36       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 10.0}                |        36       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.001, 'gamma': 100.0}               |        36       |
|  0.433284231671 | 0.00159032260113 |              {'C': 0.001, 'gamma': 1000.0}               |        36       |
|  0.433284231671 | 0.00159032260113 |              {'C': 0.001, 'gamma': 10000.0}              |        36       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.01, 'gamma': 0.001}                |        36       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.01, 'gamma': 0.01}                |        36       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        36       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.01, 'gamma': 1.0}                 |        36       |
|  0.433284231671 | 0.00159032260113 |                {'C': 0.01, 'gamma': 10.0}                |        36       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.01, 'gamma': 100.0}                |        36       |
|  0.433284231671 | 0.00159032260113 |               {'C': 0.01, 'gamma': 1000.0}               |        36       |
|  0.433284231671 | 0.00159032260113 |              {'C': 0.01, 'gamma': 10000.0}               |        36       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        36       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        36       |
|  0.433284231671 | 0.00159032260113 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        36       |
|  0.433284231671 | 0.00159032260113 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        36       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        36       |
|  0.433284231671 | 0.00159032260113 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        36       |
|  0.433284231671 | 0.00159032260113 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        36       |
|  0.433284231671 | 0.00159032260113 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        36       |
|  0.433284231671 | 0.00159032260113 |                {'C': 1.0, 'gamma': 0.001}                |        36       |
|  0.433284231671 | 0.00159032260113 |                {'C': 1.0, 'gamma': 0.01}                 |        36       |
|  0.436736412834 |  0.010973008669  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.508637890469 | 0.0370420216321  |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.702730392291 | 0.0552502072543  |                {'C': 1.0, 'gamma': 10.0}                 |        9        |
|  0.634700370576 | 0.0392678313505  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.494495141459 | 0.0296587524674  |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.473700407738 | 0.0243689955455  |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.433284231671 | 0.00159032260113 |               {'C': 10.0, 'gamma': 0.001}                |        36       |
|  0.433284231671 | 0.00159032260113 |                {'C': 10.0, 'gamma': 0.01}                |        36       |
|  0.501197677264 | 0.0280097912656  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.718212878737 | 0.0389412402782  |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.732306555733 | 0.0457496144086  |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.627220764934 |  0.042219486204  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.515523591239 | 0.0309972039341  |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.467640957108 | 0.0205962158357  |              {'C': 10.0, 'gamma': 10000.0}               |        31       |
|  0.433284231671 | 0.00159032260113 |               {'C': 100.0, 'gamma': 0.001}               |        36       |
|  0.497856414854 |  0.033989645108  |               {'C': 100.0, 'gamma': 0.01}                |        28       |
|  0.709813751989 | 0.0528586677438  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.729816553489 | 0.0497775222232  |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.696313082917 | 0.0541933367984  |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.626497559591 | 0.0398438712051  |               {'C': 100.0, 'gamma': 100.0}               |        19       |
|  0.507078005226 | 0.0330501807685  |              {'C': 100.0, 'gamma': 1000.0}               |        23       |
|  0.467636205601 | 0.0204262900105  |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
|  0.501197677264 | 0.0280097912656  |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.70257446656  | 0.0396847514514  |               {'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.736247477829 | 0.0484149564854  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.726987261363 | 0.0416109072603  |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.688156507721 | 0.0488393663646  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.626651109057 |  0.028403626827  |              {'C': 1000.0, 'gamma': 100.0}               |        18       |
|  0.504251880973 | 0.0385038908597  |              {'C': 1000.0, 'gamma': 1000.0}              |        24       |
|  0.467636205601 | 0.0204262900105  |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.692432876686 | 0.0452635050768  |              {'C': 10000.0, 'gamma': 0.001}              |        13       |
|  0.743985321876 | 0.0444418673173  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.760468055309 | 0.0402133736731  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.693213527409 | 0.0550077962233  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.67826296436  | 0.0437205399727  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.601748517099 | 0.0523572840879  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.504251880973 | 0.0385038908597  |             {'C': 10000.0, 'gamma': 1000.0}              |        24       |
|  0.467636205601 | 0.0204262900105  |             {'C': 10000.0, 'gamma': 10000.0}             |        32       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.84      0.72      0.77       123
          1       0.68      0.81      0.74        90

avg / total       0.77      0.76      0.76       213


Accuracy on test set (using best parameters): 0.76


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-------------------+--------+-----------------+
| test_mean_score |   test_std_score  | params | test_rank_score |
+-----------------+-------------------+--------+-----------------+
|  0.423870184344 | 0.000894441587632 |   {}   |        1        |
+-----------------+-------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75       128
          1       0.00      0.00      0.00        85

avg / total       0.36      0.60      0.45       213


Accuracy on test set (using best parameters): 0.60

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.583735630843 | 0.0242542300123 |  {'n_neighbors': 3} |        5        |
|  0.606593346961 | 0.0670694085753 |  {'n_neighbors': 5} |        3        |
|  0.603065023659 | 0.0361340477114 | {'n_neighbors': 11} |        4        |
|  0.613333030684 | 0.0352430096393 | {'n_neighbors': 21} |        1        |
|  0.607702217212 | 0.0273760022927 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.80      0.76       132
          1       0.61      0.52      0.56        81

avg / total       0.68      0.69      0.68       213


Accuracy on test set (using best parameters): 0.69

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.593869190959 | 0.0595224917215 | {'n_estimators': 2}  |        7        |
|  0.647014792607 | 0.0664852171675 | {'n_estimators': 3}  |        6        |
|  0.666413320202 | 0.0529541789007 | {'n_estimators': 5}  |        5        |
|  0.673657375293 | 0.0472951155404 | {'n_estimators': 10} |        4        |
|  0.681807689687 | 0.0261975856515 | {'n_estimators': 20} |        3        |
|  0.715604006907 | 0.0252457536403 | {'n_estimators': 40} |        1        |
|  0.70590451857  | 0.0393277608857 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.86      0.78       124
          1       0.73      0.53      0.61        89

avg / total       0.72      0.72      0.71       213


Accuracy on test set (using best parameters): 0.72

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.48271668768  | 0.0374770989341 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        19       |
|  0.475085181966 | 0.0497954025109 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.528340824619 | 0.0857518564273 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.47061076431  | 0.0681364390855 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        21       |
|  0.531883972333 |  0.122830887614 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        17       |
|  0.545953181289 |  0.133123125623 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.540526002793 |  0.126215622873 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.725874319817 | 0.0410617557793 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.736554681924 | 0.0438432076888 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.744813725356 | 0.0521694324795 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.75759191379  | 0.0456998821498 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        2        |
|  0.762879389479 | 0.0480754535835 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.750150058875 | 0.0493722182834 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.756602392419 | 0.0546646158918 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.724319232876 | 0.0439136340085 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.73916087525  | 0.0516078819761 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.753503459659 | 0.0410914942613 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
|  0.751527447101 | 0.0366851440027 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.754356920188 |  0.035080475046 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.754716886546 |  0.03526828577  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.756409872779 | 0.0373427991503 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        4        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.80      0.79       121
          1       0.72      0.68      0.70        92

avg / total       0.75      0.75      0.75       213


Accuracy on test set (using best parameters): 0.75

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.437072996652 | 0.00452095546162 |        {'C': 0.001}        |        6        |
|  0.437072996652 | 0.00452095546162 |        {'C': 0.01}         |        6        |
|  0.437072996652 | 0.00452095546162 | {'C': 0.10000000000000001} |        6        |
|  0.47077245492  | 0.00557229350733 |         {'C': 1.0}         |        5        |
|  0.692370837488 | 0.0552889814652  |        {'C': 10.0}         |        4        |
|  0.761434807752 | 0.0591906488449  |        {'C': 100.0}        |        2        |
|  0.759123831262 | 0.0409794353563  |       {'C': 1000.0}        |        3        |
|   0.7776148061  |  0.037524091196  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.74      0.75       121
          1       0.67      0.68      0.68        92

avg / total       0.72      0.72      0.72       213


Accuracy on test set (using best parameters): 0.72

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.42575436854  | 0.00438970129541 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.42575436854  | 0.00438970129541 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.42575436854  | 0.00438970129541 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.42575436854  | 0.00438970129541 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.42575436854  | 0.00438970129541 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.42575436854  | 0.00438970129541 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.42575436854  | 0.00438970129541 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.42575436854  | 0.00438970129541 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.42575436854  | 0.00438970129541 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.42575436854  | 0.00438970129541 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.42575436854  | 0.00438970129541 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.42575436854  | 0.00438970129541 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.42575436854  | 0.00438970129541 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.42575436854  | 0.00438970129541 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.42575436854  | 0.00438970129541 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.42575436854  | 0.00438970129541 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.42575436854  | 0.00438970129541 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.42575436854  | 0.00438970129541 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.42575436854  | 0.00438970129541 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.42575436854  | 0.00438970129541 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.42575436854  | 0.00438970129541 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.42575436854  | 0.00438970129541 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.42575436854  | 0.00438970129541 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.42575436854  | 0.00438970129541 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.42575436854  | 0.00438970129541 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.42575436854  | 0.00438970129541 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.42575436854  | 0.00438970129541 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.491232561462 | 0.0382156969118  |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.706370401383 | 0.0428567907046  |                {'C': 1.0, 'gamma': 10.0}                 |        11       |
|  0.669347195411 | 0.0552891717449  |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.510882771957 | 0.0301137941838  |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.463178640853 | 0.0274990831003  |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.42575436854  | 0.00438970129541 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.42575436854  | 0.00438970129541 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.495634312962 | 0.0325278682481  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.707795506439 | 0.0417926767207  |                {'C': 10.0, 'gamma': 1.0}                 |        10       |
|  0.746555611077 |  0.055722288096  |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.671176801316 |  0.055962028924  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.522448374811 | 0.0383297697924  |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.453518881491 | 0.0247067873992  |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|  0.42575436854  | 0.00438970129541 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.505797320753 | 0.0283287714152  |               {'C': 100.0, 'gamma': 0.01}                |        23       |
|  0.731658656028 | 0.0518987472214  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.747964624944 | 0.0582982222132  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.702499247455 | 0.0714757673116  |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.663908966101 | 0.0591107221208  |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.50347926858  | 0.0278535837542  |              {'C': 100.0, 'gamma': 1000.0}               |        25       |
|  0.458307705303 | 0.0276248181863  |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.505797320753 | 0.0283287714152  |              {'C': 1000.0, 'gamma': 0.001}               |        23       |
|  0.734312587136 | 0.0530074226837  |               {'C': 1000.0, 'gamma': 0.01}               |        5        |
|  0.740649746836 |  0.07138527308   |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.727536401807 | 0.0552513114259  |               {'C': 1000.0, 'gamma': 1.0}                |        8        |
|  0.680760787989 | 0.0476766730066  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.624080430009 | 0.0556061195142  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.493024024485 | 0.0268194475584  |              {'C': 1000.0, 'gamma': 1000.0}              |        27       |
|  0.458307705303 | 0.0276248181863  |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.715499029358 | 0.0557452916444  |              {'C': 10000.0, 'gamma': 0.001}              |        9        |
|  0.742546662594 | 0.0675575659801  |              {'C': 10000.0, 'gamma': 0.01}               |        3        |
|  0.732148886984 | 0.0580774767707  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        6        |
|  0.697507104738 | 0.0729916780727  |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.664430050803 | 0.0468317150642  |              {'C': 10000.0, 'gamma': 10.0}               |        17       |
|  0.622677869269 | 0.0589762409097  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.493024024485 | 0.0268194475584  |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.458307705303 | 0.0276248181863  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.73      0.78       127
          1       0.66      0.78      0.72        86

avg / total       0.76      0.75      0.75       213


Accuracy on test set (using best parameters): 0.75


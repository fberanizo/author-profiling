Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.414519526819 | 0.00128399540987 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.77       133
          1       0.00      0.00      0.00        80

avg / total       0.39      0.62      0.48       213


Accuracy on test set (using best parameters): 0.62

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.621309842295 | 0.0638999381049 |  {'n_neighbors': 3} |        4        |
|  0.634201558345 | 0.0818994938916 |  {'n_neighbors': 5} |        2        |
|  0.637106723525 | 0.0619102293247 | {'n_neighbors': 11} |        1        |
|  0.623474870605 | 0.0737792433685 | {'n_neighbors': 21} |        3        |
|  0.597197729915 |  0.062536685821 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.84      0.71       116
          1       0.66      0.36      0.47        97

avg / total       0.63      0.62      0.60       213


Accuracy on test set (using best parameters): 0.62

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.607219179959 | 0.0555883818584 | {'n_estimators': 2}  |        7        |
|  0.633445619288 | 0.0492564298013 | {'n_estimators': 3}  |        5        |
|  0.628963934762 | 0.0552180386751 | {'n_estimators': 5}  |        6        |
|  0.675247841865 | 0.0413892335914 | {'n_estimators': 10} |        4        |
|  0.688268641859 | 0.0492448817023 | {'n_estimators': 20} |        3        |
|  0.711041620767 | 0.0403479843223 | {'n_estimators': 40} |        1        |
|  0.704125017035 | 0.0257090128092 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.83      0.75       121
          1       0.69      0.51      0.59        92

avg / total       0.69      0.69      0.68       213


Accuracy on test set (using best parameters): 0.69

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.466969991994 | 0.0211174013698 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.496986452133 | 0.0358715033957 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.512565964666 | 0.0616360453862 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.563318418732 | 0.0986600631879 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.528718067574 | 0.0927661690228 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.588721267351 |  0.110458780517 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.604604667336 |  0.108552441063 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.717091455734 | 0.0494542181556 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.744533023268 | 0.0455968175399 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.75303778579  | 0.0517380838978 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.75472193973  | 0.0490356123611 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.757891303715 | 0.0531918652226 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.714384114873 | 0.0978666071046 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        14       |
|   0.7508647178  | 0.0443344270994 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        6        |
|  0.719022668666 | 0.0464829538181 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.73435516122  |  0.055218371132 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.743058321305 | 0.0438028614007 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.745061730823 | 0.0427076591623 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.75560471351  | 0.0483664162063 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.746991578798 | 0.0386608362265 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.755438502501 | 0.0413161623202 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.91      0.79       117
          1       0.83      0.50      0.62        96

avg / total       0.75      0.73      0.71       213


Accuracy on test set (using best parameters): 0.73

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|   0.4427587697  | 0.00108755466128 |        {'C': 0.001}        |        6        |
|   0.4427587697  | 0.00108755466128 |        {'C': 0.01}         |        6        |
|   0.4427587697  | 0.00108755466128 | {'C': 0.10000000000000001} |        6        |
|  0.449674944752 | 0.0136687153981  |         {'C': 1.0}         |        5        |
|  0.647001984499 | 0.0548289228069  |        {'C': 10.0}         |        4        |
|  0.730723917553 | 0.0642919124599  |        {'C': 100.0}        |        3        |
|  0.747047287796 | 0.0529966273062  |       {'C': 1000.0}        |        1        |
|  0.740401927065 | 0.0312020941183  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.79      0.82      0.80       118
          1       0.77      0.73      0.75        95

avg / total       0.78      0.78      0.78       213


Accuracy on test set (using best parameters): 0.78

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.410804932973 | 0.00484770870926 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.410804932973 | 0.00484770870926 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.410804932973 | 0.00484770870926 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.410804932973 | 0.00484770870926 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.410804932973 | 0.00484770870926 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.410804932973 | 0.00484770870926 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.410804932973 | 0.00484770870926 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.410804932973 | 0.00484770870926 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.410804932973 | 0.00484770870926 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.410804932973 | 0.00484770870926 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.410804932973 | 0.00484770870926 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.410804932973 | 0.00484770870926 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.410804932973 | 0.00484770870926 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.410804932973 | 0.00484770870926 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.410804932973 | 0.00484770870926 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.410804932973 | 0.00484770870926 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.410804932973 | 0.00484770870926 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.410804932973 | 0.00484770870926 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.410804932973 | 0.00484770870926 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.410804932973 | 0.00484770870926 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.410804932973 | 0.00484770870926 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.410804932973 | 0.00484770870926 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.410804932973 | 0.00484770870926 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.410804932973 | 0.00484770870926 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.410804932973 | 0.00484770870926 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.410804932973 | 0.00484770870926 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.410804932973 | 0.00484770870926 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.493753742186 | 0.0354759888012  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.70725408726  | 0.0563866763109  |                {'C': 1.0, 'gamma': 10.0}                 |        11       |
|  0.613593466983 | 0.0407394041909  |                {'C': 1.0, 'gamma': 100.0}                |        19       |
|  0.444644277165 | 0.0258467439223  |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.432846671503 | 0.0176251969805  |               {'C': 1.0, 'gamma': 10000.0}               |        31       |
|  0.410804932973 | 0.00484770870926 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.410804932973 | 0.00484770870926 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.506263154243 | 0.0407531556142  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.730567688387 | 0.0465562069865  |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.737882886653 |  0.04101007218   |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.63572718014  | 0.0423336438296  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.451332372798 | 0.0185670003115  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.432195642867 | 0.0181603373701  |              {'C': 10.0, 'gamma': 10000.0}               |        32       |
|  0.410804932973 | 0.00484770870926 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.50719659357  |  0.039396193171  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.739144371329 | 0.0541803896052  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        5        |
|  0.746652525368 | 0.0432966245786  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.696979021527 | 0.0597671266928  |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.642510234305 | 0.0492506935692  |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.450829419445 | 0.0207347512582  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.432943561851 | 0.0169595125792  |              {'C': 100.0, 'gamma': 10000.0}              |        30       |
|  0.50719659357  |  0.039396193171  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.725511426604 | 0.0549846955077  |               {'C': 1000.0, 'gamma': 0.01}               |        8        |
|  0.753912584183 | 0.0535230868797  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.718700586449 | 0.0388612351384  |               {'C': 1000.0, 'gamma': 1.0}                |        10       |
|  0.663345314381 | 0.0597298131374  |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.610575464658 | 0.0521459892113  |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
|  0.450908366063 | 0.0259447221326  |              {'C': 1000.0, 'gamma': 1000.0}              |        26       |
|  0.429952003331 | 0.0160284547815  |             {'C': 1000.0, 'gamma': 10000.0}              |        33       |
|  0.722216020084 |  0.053069881722  |              {'C': 10000.0, 'gamma': 0.001}              |        9        |
|  0.755243983903 | 0.0555977196655  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.753013591337 | 0.0535864896899  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.702136949656 | 0.0536915787006  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.666449500612 | 0.0614470353347  |              {'C': 10000.0, 'gamma': 10.0}               |        14       |
|  0.617336560884 | 0.0557301815589  |              {'C': 10000.0, 'gamma': 100.0}              |        18       |
|  0.447179608432 | 0.0196344598698  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.429952003331 | 0.0160284547815  |             {'C': 10000.0, 'gamma': 10000.0}             |        33       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.76      0.80       135
          1       0.64      0.73      0.68        78

avg / total       0.76      0.75      0.75       213


Accuracy on test set (using best parameters): 0.75


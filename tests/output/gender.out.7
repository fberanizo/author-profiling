Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.414519526819 | 0.00128399540987 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.77       133
          1       0.00      0.00      0.00        80

avg / total       0.39      0.62      0.48       213


Accuracy on test set (using best parameters): 0.62

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.59856218731  | 0.0406759367478 |  {'n_neighbors': 3} |        5        |
|  0.632011240513 | 0.0271772500738 |  {'n_neighbors': 5} |        1        |
|  0.630591579618 | 0.0398999207055 | {'n_neighbors': 11} |        3        |
|  0.63141290438  | 0.0501718441413 | {'n_neighbors': 21} |        2        |
|  0.600654839995 |  0.05390535619  | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.77      0.73       127
          1       0.59      0.48      0.53        86

avg / total       0.65      0.65      0.65       213


Accuracy on test set (using best parameters): 0.65

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.600009830532 | 0.0708149089812 | {'n_estimators': 2}  |        7        |
|  0.650852334636 | 0.0243510470912 | {'n_estimators': 3}  |        4        |
|  0.642893260611 | 0.0394445956734 | {'n_estimators': 5}  |        5        |
|  0.63495694091  | 0.0401350347104 | {'n_estimators': 10} |        6        |
|  0.67437862214  | 0.0446681851035 | {'n_estimators': 20} |        3        |
|  0.681940055093 | 0.0491143826931 | {'n_estimators': 40} |        2        |
|  0.690255816329 | 0.0274150815121 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.84      0.77       122
          1       0.72      0.56      0.63        91

avg / total       0.72      0.72      0.71       213


Accuracy on test set (using best parameters): 0.72

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.469905904556 | 0.0286590736773 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.510904884012 | 0.0453296471268 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.509417233311 | 0.0836052768381 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        20       |
|  0.51639831916  | 0.0937067584567 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.572150778197 |  0.111421791342 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.546475528896 |  0.106970182445 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.583819772244 |  0.118662227645 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.719550248938 | 0.0334409790934 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.725828466647 | 0.0360696923812 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.741114597735 | 0.0409050749672 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.746564998364 |  0.046318210585 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.751812607323 |  0.046175577429 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        4        |
|  0.75522837884  | 0.0526691099809 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.744954189164 | 0.0345868699177 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|  0.704006212428 | 0.0418398563945 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.719858232898 | 0.0448716170139 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.734609226536 | 0.0410273815305 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.739368241964 | 0.0434609813685 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        9        |
|  0.745461250899 | 0.0348466090392 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.753989189764 | 0.0240209174682 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.762549684477 | 0.0335089850094 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.85      0.78       117
          1       0.77      0.61      0.68        96

avg / total       0.75      0.74      0.74       213


Accuracy on test set (using best parameters): 0.74

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.412662229896 | 0.00400300060336 |        {'C': 0.001}        |        6        |
|  0.412662229896 | 0.00400300060336 |        {'C': 0.01}         |        6        |
|  0.412662229896 | 0.00400300060336 | {'C': 0.10000000000000001} |        6        |
|  0.432181947442 |  0.029684627202  |         {'C': 1.0}         |        5        |
|  0.712550588116 | 0.0427393173195  |        {'C': 10.0}         |        4        |
|  0.733905219075 | 0.0550621614363  |        {'C': 100.0}        |        3        |
|  0.741015430044 | 0.0623604183959  |       {'C': 1000.0}        |        2        |
|  0.74241760378  | 0.0483979165693  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.88      0.78      0.83       134
          1       0.69      0.82      0.75        79

avg / total       0.81      0.80      0.80       213


Accuracy on test set (using best parameters): 0.80

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.407090339128 | 0.00421372761018 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.407090339128 | 0.00421372761018 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.407090339128 | 0.00421372761018 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.407090339128 | 0.00421372761018 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.407090339128 | 0.00421372761018 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.407090339128 | 0.00421372761018 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.407090339128 | 0.00421372761018 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.407090339128 | 0.00421372761018 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.407090339128 | 0.00421372761018 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.407090339128 | 0.00421372761018 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.407090339128 | 0.00421372761018 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.407090339128 | 0.00421372761018 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.407090339128 | 0.00421372761018 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.407090339128 | 0.00421372761018 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.407090339128 | 0.00421372761018 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.407090339128 | 0.00421372761018 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.407090339128 | 0.00421372761018 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.407090339128 | 0.00421372761018 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.407090339128 | 0.00421372761018 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.407090339128 | 0.00421372761018 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.407090339128 | 0.00421372761018 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.407090339128 | 0.00421372761018 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.404880058054 | 0.00427494632394 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        64       |
|  0.407090339128 | 0.00421372761018 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.407090339128 | 0.00421372761018 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.407090339128 | 0.00421372761018 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.407090339128 | 0.00421372761018 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.516589709816 | 0.0549100016053  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.704254990094 | 0.0454545604838  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|   0.6261355954  | 0.0659728156914  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.490659361114 | 0.0618881029136  |               {'C': 1.0, 'gamma': 1000.0}                |        26       |
|  0.449298635784 | 0.0544498897919  |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.407090339128 | 0.00421372761018 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.407090339128 | 0.00421372761018 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.52630754793  | 0.0534531932655  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.730782143764 | 0.0411114491951  |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.743052285882 | 0.0357354324525  |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.645675780075 | 0.0686011248497  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.491542475919 | 0.0683828670082  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.449298635784 | 0.0544498897919  |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|  0.407090339128 | 0.00421372761018 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.526096676455 | 0.0594480706372  |               {'C': 100.0, 'gamma': 0.01}                |        22       |
|  0.718080433152 | 0.0336943321886  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.74738239811  | 0.0503192777298  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.708954521487 | 0.0716413945603  |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.643567751538 | 0.0597579258594  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.483116094193 | 0.0587948148099  |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.432294047862 | 0.0429551864761  |              {'C': 100.0, 'gamma': 10000.0}              |        32       |
|  0.524506842908 | 0.0593654700067  |              {'C': 1000.0, 'gamma': 0.001}               |        23       |
|  0.727248463293 | 0.0287315107668  |               {'C': 1000.0, 'gamma': 0.01}               |        9        |
|  0.752792678689 | 0.0511903777679  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.729386938411 | 0.0481422630926  |               {'C': 1000.0, 'gamma': 1.0}                |        8        |
|  0.662123459495 | 0.0630141602456  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.60851698593  | 0.0541308912433  |              {'C': 1000.0, 'gamma': 100.0}               |        19       |
|  0.46405908534  | 0.0514762311473  |              {'C': 1000.0, 'gamma': 1000.0}              |        28       |
|  0.432294047862 | 0.0429551864761  |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.731944233043 | 0.0271458053219  |              {'C': 10000.0, 'gamma': 0.001}              |        6        |
|  0.762264329073 | 0.0491118745762  |              {'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.74208446827  | 0.0315250257932  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.715280768641 | 0.0640186222302  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.648118258366 | 0.0546893211886  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.589733489412 | 0.0524802373963  |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.46405908534  | 0.0514762311473  |             {'C': 10000.0, 'gamma': 1000.0}              |        28       |
|  0.432294047862 | 0.0429551864761  |             {'C': 10000.0, 'gamma': 10000.0}             |        32       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.82      0.77      0.79       137
          1       0.62      0.70      0.66        76

avg / total       0.75      0.74      0.74       213


Accuracy on test set (using best parameters): 0.74


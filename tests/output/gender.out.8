Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.427636834323 | 0.00507103755249 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      1.00      0.74       126
          1       0.00      0.00      0.00        87

avg / total       0.35      0.59      0.44       213


Accuracy on test set (using best parameters): 0.59

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.614948876941 | 0.0370818052405 |  {'n_neighbors': 3} |        1        |
|  0.597081870941 | 0.0519033283562 |  {'n_neighbors': 5} |        4        |
|  0.595127786374 | 0.0343754635383 | {'n_neighbors': 11} |        5        |
|  0.606723827849 |  0.03232784049  | {'n_neighbors': 21} |        2        |
|  0.598812826989 | 0.0416018118712 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.74      0.69       120
          1       0.59      0.47      0.52        93

avg / total       0.62      0.62      0.62       213


Accuracy on test set (using best parameters): 0.62

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.57311311117  |  0.038373743759 | {'n_estimators': 2}  |        7        |
|  0.665058115922 | 0.0713571355177 | {'n_estimators': 3}  |        6        |
|  0.666829282508 | 0.0434281959989 | {'n_estimators': 5}  |        5        |
|  0.679649195115 | 0.0495727794649 | {'n_estimators': 10} |        4        |
|  0.705901841005 | 0.0389023711597 | {'n_estimators': 20} |        3        |
|  0.719230550718 | 0.0442855913193 | {'n_estimators': 40} |        2        |
|  0.720525992059 |  0.054343549079 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.87      0.79       118
          1       0.78      0.57      0.66        95

avg / total       0.75      0.74      0.73       213


Accuracy on test set (using best parameters): 0.74

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.463260532055 | 0.0305622229631 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.484386568111 | 0.0397401862295 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.492987812767 |  0.067755554433 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.472189432399 | 0.0809774978213 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.586196714805 |  0.133894612208 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.500692252671 |  0.103692626514 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.520094361225 |  0.132307409554 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.729091542008 | 0.0537370673801 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.738586351593 | 0.0516944687116 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.738438486861 | 0.0460109616303 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
|  0.745556084995 | 0.0518495374618 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.756294922587 | 0.0593468181032 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.754808614243 | 0.0578983111047 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.762254322506 | 0.0536710381196 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.719213250617 | 0.0530467797016 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.732619813084 | 0.0521150477969 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.738780300151 | 0.0514878307724 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.741856991091 |  0.053812029315 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.741792766549 | 0.0556173162869 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        8        |
|  0.75551233378  | 0.0578414783369 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.747238546105 | 0.0622214906038 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        5        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.90      0.77       123
          1       0.75      0.40      0.52        90

avg / total       0.71      0.69      0.67       213


Accuracy on test set (using best parameters): 0.69

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.42575436854  | 0.00438970129541 |        {'C': 0.001}        |        6        |
|  0.42575436854  | 0.00438970129541 |        {'C': 0.01}         |        6        |
|  0.42575436854  | 0.00438970129541 | {'C': 0.10000000000000001} |        6        |
|  0.432658730868 |  0.018307587528  |         {'C': 1.0}         |        5        |
|  0.66932050347  | 0.0399726455246  |        {'C': 10.0}         |        4        |
|  0.751206800062 | 0.0489861567979  |        {'C': 100.0}        |        2        |
|  0.740319397628 | 0.0410431360893  |       {'C': 1000.0}        |        3        |
|  0.753763709662 | 0.0393330191415  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.84      0.75      0.79       127
          1       0.68      0.79      0.73        86

avg / total       0.78      0.77      0.77       213


Accuracy on test set (using best parameters): 0.77

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.440861761633 | 0.0031047496572 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.440861761633 | 0.0031047496572 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.440861761633 | 0.0031047496572 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.440861761633 | 0.0031047496572 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.440861761633 | 0.0031047496572 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.440861761633 | 0.0031047496572 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.440861761633 | 0.0031047496572 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.440861761633 | 0.0031047496572 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.440861761633 | 0.0031047496572 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.440861761633 | 0.0031047496572 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.440861761633 | 0.0031047496572 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.440861761633 | 0.0031047496572 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.440861761633 | 0.0031047496572 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.440861761633 | 0.0031047496572 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.440861761633 | 0.0031047496572 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.440861761633 | 0.0031047496572 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.440861761633 | 0.0031047496572 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.440861761633 | 0.0031047496572 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.440861761633 | 0.0031047496572 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.440861761633 | 0.0031047496572 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.440861761633 | 0.0031047496572 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.440861761633 | 0.0031047496572 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.440861761633 | 0.0031047496572 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.440861761633 | 0.0031047496572 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.440861761633 | 0.0031047496572 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.440861761633 | 0.0031047496572 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.440861761633 | 0.0031047496572 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.490699409671 | 0.0297173460009 |                 {'C': 1.0, 'gamma': 1.0}                 |        28       |
|  0.694816101138 | 0.0733015230088 |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.634775988186 | 0.0565822433475 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.513290746992 | 0.0367093283322 |               {'C': 1.0, 'gamma': 1000.0}                |        21       |
|  0.474561846533 | 0.0243528696838 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.440861761633 | 0.0031047496572 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.440861761633 | 0.0031047496572 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.505655401638 | 0.0397486050736 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        23       |
|  0.731882200052 | 0.0517768059681 |                {'C': 10.0, 'gamma': 1.0}                 |        7        |
|  0.74692351288  | 0.0534327559372 |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.644180006889 | 0.0504936902292 |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.494199803139 | 0.0369106295193 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.462202981849 | 0.0145500309907 |              {'C': 10.0, 'gamma': 10000.0}               |        31       |
|  0.440861761633 | 0.0031047496572 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.505655401638 | 0.0397486050736 |               {'C': 100.0, 'gamma': 0.01}                |        23       |
|  0.722256196506 | 0.0432430714284 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.771987007872 | 0.0591911875187 |                {'C': 100.0, 'gamma': 1.0}                |        2        |
|  0.705149863246 | 0.0417505837029 |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.624485507175 | 0.0504610841482 |               {'C': 100.0, 'gamma': 100.0}               |        19       |
|  0.486094557178 | 0.0414401428276 |              {'C': 100.0, 'gamma': 1000.0}               |        29       |
|  0.457095781131 | 0.0183199693557 |              {'C': 100.0, 'gamma': 10000.0}              |        34       |
|  0.506757835725 | 0.0413016904195 |              {'C': 1000.0, 'gamma': 0.001}               |        22       |
|  0.721221804918 | 0.0402410329564 |               {'C': 1000.0, 'gamma': 0.01}               |        9        |
|  0.772967156326 | 0.0678491152735 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.746052299819 | 0.0472565349352 |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.685887864758 | 0.0372433081974 |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.638568443778 | 0.0348741959715 |              {'C': 1000.0, 'gamma': 100.0}               |        17       |
|  0.49148721801  | 0.0329596007364 |              {'C': 1000.0, 'gamma': 1000.0}              |        27       |
|  0.457954207107 | 0.0186261607813 |             {'C': 1000.0, 'gamma': 10000.0}              |        32       |
|  0.710446164406 | 0.0352283530821 |              {'C': 10000.0, 'gamma': 0.001}              |        11       |
|  0.768110446572 | 0.0532826431408 |              {'C': 10000.0, 'gamma': 0.01}               |        3        |
|  0.751399683673 | 0.0508953909786 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.717690681725 | 0.0336224673384 |               {'C': 10000.0, 'gamma': 1.0}               |        10       |
|  0.666647965999 | 0.0385463055793 |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.612553912608 | 0.0380429272723 |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.492915888548 | 0.0333397842439 |             {'C': 10000.0, 'gamma': 1000.0}              |        26       |
|  0.457954207107 | 0.0186261607813 |             {'C': 10000.0, 'gamma': 10000.0}             |        32       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.83      0.77       119
          1       0.74      0.60      0.66        94

avg / total       0.73      0.73      0.72       213


Accuracy on test set (using best parameters): 0.73


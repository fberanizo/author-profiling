Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.444667590491 | 0.00456708020392 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.55      1.00      0.71       117
          1       0.00      0.00      0.00        96

avg / total       0.30      0.55      0.39       213


Accuracy on test set (using best parameters): 0.55

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.600449226125 | 0.0506709755136 |  {'n_neighbors': 3} |        5        |
|  0.606310236448 | 0.0517248882171 |  {'n_neighbors': 5} |        4        |
|  0.611141854401 | 0.0484336583984 | {'n_neighbors': 11} |        3        |
|  0.615914367173 | 0.0281212026854 | {'n_neighbors': 21} |        1        |
|  0.612331839259 |  0.050329144985 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.89      0.73       123
          1       0.62      0.26      0.36        90

avg / total       0.62      0.62      0.57       213


Accuracy on test set (using best parameters): 0.62

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.604367829695 | 0.0463231720587 | {'n_estimators': 2}  |        7        |
|  0.625902666607 | 0.0394124956442 | {'n_estimators': 3}  |        6        |
|  0.649950966029 | 0.0439731922238 | {'n_estimators': 5}  |        5        |
|  0.65703408359  | 0.0483740439965 | {'n_estimators': 10} |        4        |
|  0.692693414564 | 0.0490075279458 | {'n_estimators': 20} |        3        |
|  0.726612946331 | 0.0489900184376 | {'n_estimators': 40} |        1        |
|  0.719570341681 | 0.0374238818451 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.77      0.72       119
          1       0.64      0.51      0.57        94

avg / total       0.65      0.66      0.65       213


Accuracy on test set (using best parameters): 0.66

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.471826061774 | 0.0429462332706 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        20       |
|  0.516878249362 | 0.0465350372441 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        16       |
|  0.452011837249 | 0.0410913709129 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        21       |
|  0.510516270047 |  0.106394148602 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.511388301986 |  0.13353008234  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        17       |
|  0.55730447643  |  0.137666071083 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.490620412141 | 0.0942847829194 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        19       |
|  0.704346316593 | 0.0632470171143 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.717655109548 | 0.0579219068456 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.72024023576  | 0.0537016495743 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.723930697573 | 0.0497219943901 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.728178446927 | 0.0544046574869 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        3        |
|  0.733297609552 | 0.0467890081525 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.729271470074 | 0.0498812427989 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
|   0.6985469284  | 0.0616368305724 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.699941912618 | 0.0592539144909 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.713078283985 | 0.0591636737022 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.722070969678 | 0.0588936398958 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.719898569216 | 0.0508198068905 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        9        |
|  0.724242223745 |  0.05531416508  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.720272749537 | 0.0572772101784 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        7        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.87      0.79       126
          1       0.73      0.54      0.62        87

avg / total       0.73      0.73      0.72       213


Accuracy on test set (using best parameters): 0.73

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.444667590491 | 0.00456708020392 |        {'C': 0.001}        |        6        |
|  0.444667590491 | 0.00456708020392 |        {'C': 0.01}         |        6        |
|  0.444667590491 | 0.00456708020392 | {'C': 0.10000000000000001} |        6        |
|  0.454835020061 | 0.0209610665363  |         {'C': 1.0}         |        5        |
|  0.660649856837 | 0.0425187142927  |        {'C': 10.0}         |        4        |
|  0.749890743232 | 0.0631722923273  |        {'C': 100.0}        |        1        |
|  0.745801870647 | 0.0588612916495  |       {'C': 1000.0}        |        2        |
|  0.730427161879 | 0.0596806869653  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.90      0.79       117
          1       0.82      0.55      0.66        96

avg / total       0.76      0.74      0.73       213


Accuracy on test set (using best parameters): 0.74

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.435178614161 | 0.00388236617942 |               {'C': 0.001, 'gamma': 0.001}               |        35       |
|  0.435178614161 | 0.00388236617942 |               {'C': 0.001, 'gamma': 0.01}                |        35       |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        35       |
|  0.435178614161 | 0.00388236617942 |                {'C': 0.001, 'gamma': 1.0}                |        35       |
|  0.435178614161 | 0.00388236617942 |               {'C': 0.001, 'gamma': 10.0}                |        35       |
|  0.435178614161 | 0.00388236617942 |               {'C': 0.001, 'gamma': 100.0}               |        35       |
|  0.435178614161 | 0.00388236617942 |              {'C': 0.001, 'gamma': 1000.0}               |        35       |
|  0.435178614161 | 0.00388236617942 |              {'C': 0.001, 'gamma': 10000.0}              |        35       |
|  0.435178614161 | 0.00388236617942 |               {'C': 0.01, 'gamma': 0.001}                |        35       |
|  0.435178614161 | 0.00388236617942 |                {'C': 0.01, 'gamma': 0.01}                |        35       |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        35       |
|  0.435178614161 | 0.00388236617942 |                {'C': 0.01, 'gamma': 1.0}                 |        35       |
|  0.435178614161 | 0.00388236617942 |                {'C': 0.01, 'gamma': 10.0}                |        35       |
|  0.435178614161 | 0.00388236617942 |               {'C': 0.01, 'gamma': 100.0}                |        35       |
|  0.435178614161 | 0.00388236617942 |               {'C': 0.01, 'gamma': 1000.0}               |        35       |
|  0.435178614161 | 0.00388236617942 |              {'C': 0.01, 'gamma': 10000.0}               |        35       |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        35       |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        35       |
|  0.435178614161 | 0.00388236617942 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        35       |
|  0.435178614161 | 0.00388236617942 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        35       |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        35       |
|  0.435178614161 | 0.00388236617942 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        35       |
|  0.435178614161 | 0.00388236617942 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        35       |
|  0.435178614161 | 0.00388236617942 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        35       |
|  0.435178614161 | 0.00388236617942 |                {'C': 1.0, 'gamma': 0.001}                |        35       |
|  0.435178614161 | 0.00388236617942 |                {'C': 1.0, 'gamma': 0.01}                 |        35       |
|  0.435178614161 | 0.00388236617942 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.506619579455 | 0.0353198331399  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.718596595219 | 0.0607795611524  |                {'C': 1.0, 'gamma': 10.0}                 |        8        |
|  0.629363808713 |  0.051828195183  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.476182624055 | 0.0413454052149  |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.444833850401 | 0.0209110550431  |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|  0.435178614161 | 0.00388236617942 |               {'C': 10.0, 'gamma': 0.001}                |        35       |
|  0.435178614161 | 0.00388236617942 |                {'C': 10.0, 'gamma': 0.01}                |        35       |
|  0.508371348329 | 0.0210307107093  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        21       |
|  0.721471768189 | 0.0491471323003  |                {'C': 10.0, 'gamma': 1.0}                 |        6        |
|  0.727340166018 | 0.0616338481482  |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.646055741353 | 0.0504201153949  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.494260562157 | 0.0510930339843  |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.440030664621 | 0.0148372730653  |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|  0.435178614161 | 0.00388236617942 |               {'C': 100.0, 'gamma': 0.001}               |        35       |
|  0.508371348329 | 0.0210307107093  |               {'C': 100.0, 'gamma': 0.01}                |        21       |
|  0.718000751939 | 0.0530240032131  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.741710111393 | 0.0411400663123  |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.693359644581 | 0.0614996331692  |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.642830817377 | 0.0566741880703  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.47936057463  | 0.0476159000694  |              {'C': 100.0, 'gamma': 1000.0}               |        28       |
|  0.442518035965 | 0.0157335285402  |              {'C': 100.0, 'gamma': 10000.0}              |        31       |
|  0.508371348329 | 0.0210307107093  |              {'C': 1000.0, 'gamma': 0.001}               |        21       |
|  0.716328596079 | 0.0524092928835  |               {'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.762283104747 | 0.0585233635786  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.718805783481 | 0.0484485490452  |               {'C': 1000.0, 'gamma': 1.0}                |        7        |
|  0.673113157413 | 0.0683108731684  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.623809797283 | 0.0611166458531  |              {'C': 1000.0, 'gamma': 100.0}               |        20       |
|  0.487012975982 | 0.0488051914686  |              {'C': 1000.0, 'gamma': 1000.0}              |        26       |
|  0.442518035965 | 0.0157335285402  |             {'C': 1000.0, 'gamma': 10000.0}              |        31       |
|  0.714889845469 | 0.0637405422943  |              {'C': 10000.0, 'gamma': 0.001}              |        11       |
|  0.760894484791 |  0.047617892223  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.741740565354 | 0.0501864466199  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.699780595984 | 0.0439769888917  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.647744335534 |  0.080994608776  |              {'C': 10000.0, 'gamma': 10.0}               |        15       |
|  0.627874301989 | 0.0666070854779  |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
|  0.479379365888 | 0.0448045804613  |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.442518035965 | 0.0157335285402  |             {'C': 10000.0, 'gamma': 10000.0}             |        31       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.78      0.79       122
          1       0.71      0.74      0.72        91

avg / total       0.76      0.76      0.76       213


Accuracy on test set (using best parameters): 0.76


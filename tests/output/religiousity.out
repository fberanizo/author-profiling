Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.557119835499 | 0.0310965574195 |  {'n_neighbors': 3} |        2        |
|  0.520266356555 |  0.030971443848 |  {'n_neighbors': 5} |        3        |
|  0.598335674336 | 0.0648251553787 | {'n_neighbors': 11} |        1        |
|  0.515398895386 | 0.0384305429526 | {'n_neighbors': 21} |        4        |
|  0.492837481146 | 0.0339867728149 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.73      0.66        26
          1       0.22      0.13      0.17        15

avg / total       0.46      0.51      0.48        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.562051563533 | 0.0211082902854 |  {'n_neighbors': 3} |        3        |
|  0.574661378297 |  0.045260091395 |  {'n_neighbors': 5} |        1        |
|  0.57055726227  | 0.0968509336112 | {'n_neighbors': 11} |        2        |
|  0.541497074228 | 0.0470979882752 | {'n_neighbors': 21} |        4        |
|  0.489072128852 | 0.0231996927812 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.77      0.67        26
          1       0.14      0.07      0.09        15

avg / total       0.43      0.51      0.46        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.50265480761  | 0.0484924744263 |  {'n_neighbors': 3} |        2        |
|  0.476789295323 | 0.0645583187568 |  {'n_neighbors': 5} |        5        |
|  0.493937150545 | 0.0722371701028 | {'n_neighbors': 11} |        3        |
|  0.50953729987  |  0.034709221851 | {'n_neighbors': 21} |        1        |
|  0.491442061775 | 0.0095488511589 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      1.00      0.78        25
          1       1.00      0.07      0.12        15

avg / total       0.78      0.65      0.54        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.534036463425 |  0.102726664727 |  {'n_neighbors': 3} |        2        |
|  0.506996316313 | 0.0791006817172 |  {'n_neighbors': 5} |        5        |
|  0.523491871493 |  0.055448727819 | {'n_neighbors': 11} |        3        |
|  0.537717943021 | 0.0460317630165 | {'n_neighbors': 21} |        1        |
|  0.510151354552 | 0.0236054875614 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.84      0.71        25
          1       0.33      0.13      0.19        15

avg / total       0.51      0.57      0.52        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+------------------+---------------------+-----------------+
| test_mean_score |  test_std_score  |        params       | test_rank_score |
+-----------------+------------------+---------------------+-----------------+
|  0.516247486719 | 0.0731971246766  |  {'n_neighbors': 3} |        2        |
|  0.482654997184 | 0.0528431405153  |  {'n_neighbors': 5} |        5        |
|  0.548192379004 | 0.0589232395375  | {'n_neighbors': 11} |        1        |
|  0.513744151341 | 0.0489256634872  | {'n_neighbors': 21} |        3        |
|  0.483557012907 | 0.00576531519867 | {'n_neighbors': 31} |        4        |
+-----------------+------------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.84      0.72        25
          1       0.33      0.14      0.20        14

avg / total       0.53      0.59      0.54        39

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.573778014667 |  0.070197045707 | {'n_estimators': 2}  |        4        |
|  0.587450213604 | 0.0653515241701 | {'n_estimators': 3}  |        2        |
|  0.602514591427 | 0.0794970772592 | {'n_estimators': 5}  |        1        |
|  0.587067872483 | 0.0810108221762 | {'n_estimators': 10} |        3        |
|  0.509224444323 | 0.0790794385782 | {'n_estimators': 20} |        7        |
|  0.548779286306 |  0.092031198686 | {'n_estimators': 40} |        6        |
|  0.553965222941 | 0.0394104816512 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.65      0.64        26
          1       0.36      0.33      0.34        15

avg / total       0.53      0.54      0.53        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.488059564251 | 0.0420889270423 | {'n_estimators': 2}  |        7        |
|  0.560033949534 | 0.0875587979176 | {'n_estimators': 3}  |        2        |
|  0.529987518731 | 0.0732951208801 | {'n_estimators': 5}  |        4        |
|  0.59149247171  | 0.0193351793911 | {'n_estimators': 10} |        1        |
|  0.532984229876 | 0.0357783511902 | {'n_estimators': 20} |        3        |
|  0.509015278434 | 0.0447545700259 | {'n_estimators': 40} |        6        |
|  0.520894146665 | 0.0722766484106 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.85      0.71        26
          1       0.20      0.07      0.10        15

avg / total       0.46      0.56      0.49        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.564204853127 | 0.0532237963415 | {'n_estimators': 2}  |        2        |
|  0.575436560769 |  0.109645934977 | {'n_estimators': 3}  |        1        |
|  0.491293099754 |  0.085905237611 | {'n_estimators': 5}  |        7        |
|   0.5316165501  | 0.0242095458713 | {'n_estimators': 10} |        4        |
|  0.523082779612 |  0.078987000667 | {'n_estimators': 20} |        5        |
|  0.49922294766  | 0.0497902450647 | {'n_estimators': 40} |        6        |
|  0.534113795563 | 0.0956983052138 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.83      0.76      0.79        25
          1       0.65      0.73      0.69        15

avg / total       0.76      0.75      0.75        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.540798674689 | 0.0500071727589 | {'n_estimators': 2}  |        2        |
|  0.539208491571 | 0.0364012479124 | {'n_estimators': 3}  |        3        |
|  0.472702519001 | 0.0491391029272 | {'n_estimators': 5}  |        7        |
|  0.528376358533 | 0.0857066380219 | {'n_estimators': 10} |        6        |
|  0.607199192855 |  0.117343181078 | {'n_estimators': 20} |        1        |
|  0.538813609503 | 0.0470274350864 | {'n_estimators': 40} |        4        |
|  0.530726095206 | 0.0462519145566 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.88      0.79        25
          1       0.67      0.40      0.50        15

avg / total       0.69      0.70      0.68        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.506822395905 | 0.0681908237539 | {'n_estimators': 2}  |        7        |
|  0.528326885347 | 0.0471464408435 | {'n_estimators': 3}  |        4        |
|  0.518948531289 | 0.0424856571199 | {'n_estimators': 5}  |        6        |
|  0.56346212858  | 0.0878658518534 | {'n_estimators': 10} |        1        |
|  0.54350839806  | 0.0534513496217 | {'n_estimators': 20} |        2        |
|  0.518959032868 |  0.067866231812 | {'n_estimators': 40} |        5        |
|  0.53393732587  | 0.0360401845802 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.80      0.68        25
          1       0.00      0.00      0.00        14

avg / total       0.38      0.51      0.43        39

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.488584087481 | 0.0101895524276 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|  0.482430241327 |  0.01874804311  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.488584087481 | 0.0101895524276 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|  0.482430241327 |  0.01874804311  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        20       |
|  0.488584087481 | 0.0101895524276 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.488584087481 | 0.0101895524276 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.526791027369 | 0.0372438032145 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        4        |
|  0.504768503555 | 0.0604962625269 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.510305774519 | 0.0398911050183 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.56739674585  | 0.0817039862682 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        1        |
|  0.517691336441 | 0.0681452798185 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.522162900299 | 0.0444733138626 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.508234193343 | 0.0615464940726 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.494114193243 | 0.0257023118267 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        14       |
|  0.499518974605 | 0.0249133624895 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.513360024779 | 0.0229591359229 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        7        |
|  0.492157895921 | 0.0266072102816 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.543258277333 | 0.0234828408426 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.505555312551 | 0.0642271213173 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        10       |
|  0.500393053071 | 0.0383986764043 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        12       |
|  0.529564522004 | 0.0458570453144 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      1.00      0.78        26
          1       0.00      0.00      0.00        15

avg / total       0.40      0.63      0.49        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.502007918552 |  0.024795429185 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|  0.505003340743 | 0.0304231205863 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        13       |
|  0.507540131437 |  0.028043524095 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        12       |
|   0.4989913273  | 0.0279168314664 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.503770739065 | 0.0235024140064 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.494266976021 | 0.0120077453341 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        19       |
|  0.497559793148 |  0.031078428487 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.546776383993 | 0.0471593314713 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.514191250246 | 0.0270033935048 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.550885248121 | 0.0655825188905 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        2        |
|  0.504079516974 | 0.0550236693056 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        14       |
|  0.460899749098 | 0.0328338428423 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        21       |
|  0.517389676018 | 0.0543702965596 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.551203399354 | 0.0297355971343 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.544084903192 |  0.057523695816 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        4        |
|  0.539832317542 | 0.0678336393829 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.517830115448 | 0.0567690864623 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
|  0.537755668701 |  0.066585372248 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.515798128069 | 0.0295118160451 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        10       |
|  0.517774741468 | 0.0544966876255 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        8        |
|  0.462484719489 | 0.0770098679169 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        20       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.88      0.77        26
          1       0.57      0.27      0.36        15

avg / total       0.64      0.66      0.62        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.491442061775 | 0.0095488511589 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|  0.491442061775 | 0.0095488511589 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        16       |
|  0.48208141355  | 0.0253813890804 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        20       |
|  0.498707369614 | 0.0363939560779 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        12       |
|  0.498662207358 | 0.0408646395611 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        13       |
|  0.491442061775 | 0.0095488511589 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.472569629859 | 0.0310500899741 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        21       |
|  0.510106249858 | 0.0741641735364 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        7        |
|  0.502731125895 | 0.0345951081886 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.545255549612 | 0.0356598803023 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|   0.5556808093  | 0.0496095976063 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        1        |
|  0.546952816734 | 0.0659567027528 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.487672577769 |  0.012967425907 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        19       |
|  0.505347480607 | 0.0443409960817 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        9        |
|  0.493512476221 | 0.0247581444847 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        15       |
|  0.508288490905 | 0.0299436402408 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.493862854337 | 0.0497785721973 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        14       |
|  0.524718368661 | 0.0624339283808 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.519792722764 |  0.059298902927 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.513479627451 | 0.0676626814228 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.501932881166 |  0.109811874976 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        11       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.92      0.78        25
          1       0.67      0.27      0.38        15

avg / total       0.67      0.68      0.63        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.491442061775 | 0.0095488511589  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        17       |
|  0.500943119723 | 0.0158831840632  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        13       |
|  0.491442061775 | 0.0095488511589  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.491442061775 | 0.0095488511589  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.491442061775 | 0.0095488511589  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        17       |
|  0.498691443511 | 0.0338592167849  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|  0.491442061775 | 0.0095488511589  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.509035208707 | 0.0490202087751  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.53929715699  | 0.0569140062528  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.56586506058  | 0.0687895743514  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.556789730579 | 0.0613746304552  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.517564390589 | 0.0524029528451  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        10       |
|  0.506574864438 | 0.0284189070453  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.493113268415 | 0.00817108022322 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        16       |
|  0.497935189726 |  0.017984054909  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        15       |
|  0.541063313046 | 0.0499294565252  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.557989232335 | 0.0666787051404  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.56873451892  | 0.0328586024277  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|  0.566655276597 | 0.0508482922968  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.571871449219 | 0.0403636057464  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.590372407004 | 0.0466635041885  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.64      0.60        25
          1       0.25      0.20      0.22        15

avg / total       0.45      0.47      0.46        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.486546375435 | 0.0069674986243  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        18       |
|  0.486546375435 | 0.0069674986243  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        18       |
|  0.499804480197 | 0.0246871122247  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|  0.496865359056 | 0.0333627436497  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
|  0.526792690768 | 0.0632046049302  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        11       |
|  0.483557012907 | 0.00576531519867 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        21       |
|  0.486546375435 | 0.0069674986243  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.503371061625 | 0.0157316974399  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.575615554864 | 0.0372479493429  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        2        |
|  0.497892526219 | 0.0435029258528  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        16       |
|  0.575626882545 | 0.0924820263737  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        1        |
|  0.526783311104 | 0.0714743706421  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.528195289648 | 0.0768912011195  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.534261352024 |  0.048046723949  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        6        |
|  0.529997773088 | 0.0661708231779  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.566092020854 | 0.0450681250322  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        3        |
|  0.554066113625 | 0.0537330575477  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.530432663044 | 0.0659688632821  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.530046132785 | 0.0451391663954  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        8        |
|  0.539098551777 |  0.105496115043  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.514096448819 | 0.0709521964775  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        13       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.76      0.69        25
          1       0.33      0.21      0.26        14

avg / total       0.53      0.56      0.54        39

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.488584087481 | 0.0101895524276 |        {'C': 0.001}        |        3        |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.01}         |        3        |
|  0.488584087481 | 0.0101895524276 | {'C': 0.10000000000000001} |        3        |
|  0.488584087481 | 0.0101895524276 |         {'C': 1.0}         |        3        |
|  0.525375983372 | 0.0521640329485 |        {'C': 10.0}         |        2        |
|  0.525994090224 | 0.0461941352108 |        {'C': 100.0}        |        1        |
|  0.485346903097 | 0.0943293828108 |       {'C': 1000.0}        |        7        |
|  0.484481042251 | 0.0461531193404 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.73      0.64        26
          1       0.12      0.07      0.09        15

avg / total       0.41      0.49      0.44        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.488584087481 | 0.0101895524276 |        {'C': 0.001}        |        5        |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.01}         |        5        |
|  0.488584087481 | 0.0101895524276 | {'C': 0.10000000000000001} |        5        |
|  0.485567496229 | 0.0136884888349 |         {'C': 1.0}         |        8        |
|  0.53482169116  | 0.0469314293286 |        {'C': 10.0}         |        3        |
|  0.549975121105 | 0.0707731298937 |        {'C': 100.0}        |        2        |
|  0.568770668396 | 0.0374098259706 |       {'C': 1000.0}        |        1        |
|  0.502320564389 | 0.0635008382834 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.54      0.56        26
          1       0.29      0.33      0.31        15

avg / total       0.48      0.46      0.47        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.491442061775 | 0.0095488511589 |        {'C': 0.001}        |        3        |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.01}         |        3        |
|  0.491442061775 | 0.0095488511589 | {'C': 0.10000000000000001} |        3        |
|  0.491442061775 | 0.0095488511589 |         {'C': 1.0}         |        3        |
|  0.564231405221 | 0.0557544914296 |        {'C': 10.0}         |        1        |
|  0.529757023893 | 0.0838500267887 |        {'C': 100.0}        |        2        |
|  0.484573876794 | 0.0688595388958 |       {'C': 1000.0}        |        7        |
|  0.482355408567 | 0.0361883065277 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.77        25
          1       0.00      0.00      0.00        15

avg / total       0.39      0.62      0.48        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.491442061775 | 0.0095488511589 |        {'C': 0.001}        |        5        |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.01}         |        5        |
|  0.491442061775 | 0.0095488511589 | {'C': 0.10000000000000001} |        5        |
|  0.491442061775 | 0.0095488511589 |         {'C': 1.0}         |        5        |
|  0.511942330234 | 0.0279731991522 |        {'C': 10.0}         |        3        |
|  0.572648155836 | 0.0706210526419 |        {'C': 100.0}        |        2        |
|  0.586512364488 | 0.0536255963436 |       {'C': 1000.0}        |        1        |
|  0.497495210922 | 0.0413620670103 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.50      0.48      0.49        25
          1       0.19      0.20      0.19        15

avg / total       0.38      0.38      0.38        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.486546375435 | 0.0069674986243 |        {'C': 0.001}        |        3        |
|  0.486546375435 | 0.0069674986243 |        {'C': 0.01}         |        3        |
|  0.486546375435 | 0.0069674986243 | {'C': 0.10000000000000001} |        3        |
|  0.486546375435 | 0.0069674986243 |         {'C': 1.0}         |        3        |
|  0.518609761093 | 0.0349349267234 |        {'C': 10.0}         |        1        |
|  0.476981219329 | 0.0513233749455 |        {'C': 100.0}        |        7        |
|  0.51797967466  | 0.0582933778223 |       {'C': 1000.0}        |        2        |
|  0.44510343606  | 0.0602491720761 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.96      0.76        25
          1       0.00      0.00      0.00        14

avg / total       0.40      0.62      0.49        39

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.488584087481 | 0.0101895524276 |               {'C': 0.001, 'gamma': 0.001}               |        24       |
|  0.488584087481 | 0.0101895524276 |               {'C': 0.001, 'gamma': 0.01}                |        24       |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        24       |
|  0.488584087481 | 0.0101895524276 |                {'C': 0.001, 'gamma': 1.0}                |        24       |
|  0.488584087481 | 0.0101895524276 |               {'C': 0.001, 'gamma': 10.0}                |        24       |
|  0.488584087481 | 0.0101895524276 |               {'C': 0.001, 'gamma': 100.0}               |        24       |
|  0.488584087481 | 0.0101895524276 |              {'C': 0.001, 'gamma': 1000.0}               |        24       |
|  0.488584087481 | 0.0101895524276 |              {'C': 0.001, 'gamma': 10000.0}              |        24       |
|  0.488584087481 | 0.0101895524276 |               {'C': 0.01, 'gamma': 0.001}                |        24       |
|  0.488584087481 | 0.0101895524276 |                {'C': 0.01, 'gamma': 0.01}                |        24       |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        24       |
|  0.488584087481 | 0.0101895524276 |                {'C': 0.01, 'gamma': 1.0}                 |        24       |
|  0.488584087481 | 0.0101895524276 |                {'C': 0.01, 'gamma': 10.0}                |        24       |
|  0.488584087481 | 0.0101895524276 |               {'C': 0.01, 'gamma': 100.0}                |        24       |
|  0.488584087481 | 0.0101895524276 |               {'C': 0.01, 'gamma': 1000.0}               |        24       |
|  0.488584087481 | 0.0101895524276 |              {'C': 0.01, 'gamma': 10000.0}               |        24       |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        24       |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        24       |
|  0.488584087481 | 0.0101895524276 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        24       |
|  0.488584087481 | 0.0101895524276 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        24       |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        24       |
|  0.488584087481 | 0.0101895524276 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        24       |
|  0.488584087481 | 0.0101895524276 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        24       |
|  0.488584087481 | 0.0101895524276 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        24       |
|  0.488584087481 | 0.0101895524276 |                {'C': 1.0, 'gamma': 0.001}                |        24       |
|  0.488584087481 | 0.0101895524276 |                {'C': 1.0, 'gamma': 0.01}                 |        24       |
|  0.488584087481 | 0.0101895524276 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        24       |
|  0.482381606489 | 0.0069109654108 |                 {'C': 1.0, 'gamma': 1.0}                 |        62       |
|  0.512266025641 | 0.0523572365924 |                {'C': 1.0, 'gamma': 10.0}                 |        15       |
|  0.485557357921 | 0.0100274906074 |                {'C': 1.0, 'gamma': 100.0}                |        56       |
|  0.479164935205 | 0.0246155915603 |               {'C': 1.0, 'gamma': 1000.0}                |        63       |
|  0.482430241327 |  0.01874804311  |               {'C': 1.0, 'gamma': 10000.0}               |        61       |
|  0.488584087481 | 0.0101895524276 |               {'C': 10.0, 'gamma': 0.001}                |        24       |
|  0.488584087481 | 0.0101895524276 |                {'C': 10.0, 'gamma': 0.01}                |        24       |
|  0.49512793579  | 0.0214763984664 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        20       |
|  0.517644237579 | 0.0228023795641 |                {'C': 10.0, 'gamma': 1.0}                 |        12       |
|  0.48303008768  | 0.0473946081531 |                {'C': 10.0, 'gamma': 10.0}                |        59       |
|  0.52525248561  |  0.043148100512 |               {'C': 10.0, 'gamma': 100.0}                |        10       |
|  0.512433265033 | 0.0349056752335 |               {'C': 10.0, 'gamma': 1000.0}               |        14       |
|  0.494294871795 | 0.0173793203113 |              {'C': 10.0, 'gamma': 10000.0}               |        21       |
|  0.488584087481 | 0.0101895524276 |               {'C': 100.0, 'gamma': 0.001}               |        24       |
|  0.507731538189 | 0.0293304358787 |               {'C': 100.0, 'gamma': 0.01}                |        17       |
|  0.548908163265 | 0.0237684514669 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        5        |
|  0.49298882454  | 0.0627599145902 |                {'C': 100.0, 'gamma': 1.0}                |        22       |
|  0.485369698241 | 0.0351401429634 |               {'C': 100.0, 'gamma': 10.0}                |        58       |
|  0.573926262813 | 0.0498276963851 |               {'C': 100.0, 'gamma': 100.0}               |        1        |
|  0.499032058397 | 0.0337302923257 |              {'C': 100.0, 'gamma': 1000.0}               |        19       |
|  0.48254076667  | 0.0128777911136 |              {'C': 100.0, 'gamma': 10000.0}              |        60       |
|  0.515467767296 | 0.0427617878405 |              {'C': 1000.0, 'gamma': 0.001}               |        13       |
|  0.511959774329 | 0.0657815441666 |               {'C': 1000.0, 'gamma': 0.01}               |        16       |
|  0.469150014639 | 0.0840326363376 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        64       |
|  0.53177735732  | 0.0986957893763 |               {'C': 1000.0, 'gamma': 1.0}                |        7        |
|  0.526602684256 |  0.102243255737 |               {'C': 1000.0, 'gamma': 10.0}               |        9        |
|  0.552071363872 | 0.0308138110154 |              {'C': 1000.0, 'gamma': 100.0}               |        4        |
|  0.492588766276 | 0.0370107537836 |              {'C': 1000.0, 'gamma': 1000.0}              |        23       |
|  0.485567496229 | 0.0136884888349 |             {'C': 1000.0, 'gamma': 10000.0}              |        54       |
|  0.571396024813 | 0.0681670277888 |              {'C': 10000.0, 'gamma': 0.001}              |        2        |
|  0.500021338311 | 0.0896959083486 |              {'C': 10000.0, 'gamma': 0.01}               |        18       |
|  0.518544644278 | 0.0642354723097 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        11       |
|  0.534486392735 | 0.0417198326515 |               {'C': 10000.0, 'gamma': 1.0}               |        6        |
|  0.560639157457 | 0.0676958646906 |              {'C': 10000.0, 'gamma': 10.0}               |        3        |
|  0.527900313972 | 0.0436508470448 |              {'C': 10000.0, 'gamma': 100.0}              |        8        |
|  0.485567496229 | 0.0136884888349 |             {'C': 10000.0, 'gamma': 1000.0}              |        54       |
|  0.485557357921 | 0.0100274906074 |             {'C': 10000.0, 'gamma': 10000.0}             |        56       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.96      0.77        26
          1       0.50      0.07      0.12        15

avg / total       0.59      0.63      0.53        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.488584087481 | 0.0101895524276  |               {'C': 0.001, 'gamma': 0.001}               |        22       |
|  0.488584087481 | 0.0101895524276  |               {'C': 0.001, 'gamma': 0.01}                |        22       |
|  0.488584087481 | 0.0101895524276  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        22       |
|  0.488584087481 | 0.0101895524276  |                {'C': 0.001, 'gamma': 1.0}                |        22       |
|  0.488584087481 | 0.0101895524276  |               {'C': 0.001, 'gamma': 10.0}                |        22       |
|  0.488584087481 | 0.0101895524276  |               {'C': 0.001, 'gamma': 100.0}               |        22       |
|  0.488584087481 | 0.0101895524276  |              {'C': 0.001, 'gamma': 1000.0}               |        22       |
|  0.488584087481 | 0.0101895524276  |              {'C': 0.001, 'gamma': 10000.0}              |        22       |
|  0.488584087481 | 0.0101895524276  |               {'C': 0.01, 'gamma': 0.001}                |        22       |
|  0.488584087481 | 0.0101895524276  |                {'C': 0.01, 'gamma': 0.01}                |        22       |
|  0.488584087481 | 0.0101895524276  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        22       |
|  0.488584087481 | 0.0101895524276  |                {'C': 0.01, 'gamma': 1.0}                 |        22       |
|  0.488584087481 | 0.0101895524276  |                {'C': 0.01, 'gamma': 10.0}                |        22       |
|  0.488584087481 | 0.0101895524276  |               {'C': 0.01, 'gamma': 100.0}                |        22       |
|  0.488584087481 | 0.0101895524276  |               {'C': 0.01, 'gamma': 1000.0}               |        22       |
|  0.488584087481 | 0.0101895524276  |              {'C': 0.01, 'gamma': 10000.0}               |        22       |
|  0.488584087481 | 0.0101895524276  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        22       |
|  0.488584087481 | 0.0101895524276  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        22       |
|  0.488584087481 | 0.0101895524276  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        22       |
|  0.488584087481 | 0.0101895524276  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        22       |
|  0.488584087481 | 0.0101895524276  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        22       |
|  0.488584087481 | 0.0101895524276  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        22       |
|  0.488584087481 | 0.0101895524276  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        22       |
|  0.488584087481 | 0.0101895524276  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        22       |
|  0.488584087481 | 0.0101895524276  |                {'C': 1.0, 'gamma': 0.001}                |        22       |
|  0.488584087481 | 0.0101895524276  |                {'C': 1.0, 'gamma': 0.01}                 |        22       |
|  0.488584087481 | 0.0101895524276  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.488584087481 | 0.0101895524276  |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.485557357921 | 0.0100274906074  |                {'C': 1.0, 'gamma': 10.0}                 |        56       |
|  0.493026700173 | 0.0158803822907  |                {'C': 1.0, 'gamma': 100.0}                |        21       |
|  0.488584087481 | 0.0101895524276  |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.498176578324 | 0.0240846201245  |               {'C': 1.0, 'gamma': 10000.0}               |        16       |
|  0.488584087481 | 0.0101895524276  |               {'C': 10.0, 'gamma': 0.001}                |        22       |
|  0.488584087481 | 0.0101895524276  |                {'C': 10.0, 'gamma': 0.01}                |        22       |
|  0.485567496229 | 0.0136884888349  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        54       |
|  0.522669952596 | 0.0794103166334  |                {'C': 10.0, 'gamma': 1.0}                 |        6        |
|  0.498040280875 | 0.0864162406886  |                {'C': 10.0, 'gamma': 10.0}                |        20       |
|  0.505368131868 |  0.043274640245  |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.525879720538 | 0.0351894815578  |               {'C': 10.0, 'gamma': 1000.0}               |        5        |
|  0.498144527042 |  0.017888769284  |              {'C': 10.0, 'gamma': 10000.0}               |        17       |
|  0.488584087481 | 0.0101895524276  |               {'C': 100.0, 'gamma': 0.001}               |        22       |
|  0.485544871795 | 0.00602900188662 |               {'C': 100.0, 'gamma': 0.01}                |        57       |
|  0.505707701183 | 0.0661974068498  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.431965686443 | 0.0571295987236  |                {'C': 100.0, 'gamma': 1.0}                |        62       |
|  0.46664479452  | 0.0802221143199  |               {'C': 100.0, 'gamma': 10.0}                |        61       |
|  0.529102304383 | 0.0556172897277  |               {'C': 100.0, 'gamma': 100.0}               |        4        |
|  0.479391025641 | 0.0157036707176  |              {'C': 100.0, 'gamma': 1000.0}               |        59       |
|  0.498144527042 |  0.017888769284  |              {'C': 100.0, 'gamma': 10000.0}              |        17       |
|  0.511568358112 | 0.0239649524314  |              {'C': 1000.0, 'gamma': 0.001}               |        10       |
|  0.501803471389 | 0.0257430624533  |               {'C': 1000.0, 'gamma': 0.01}               |        15       |
|  0.480128002622 | 0.0524373985926  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        58       |
|  0.473987821031 | 0.0735567902511  |               {'C': 1000.0, 'gamma': 1.0}                |        60       |
|  0.422930505429 |  0.059292939465  |               {'C': 1000.0, 'gamma': 10.0}               |        64       |
|  0.544629963688 | 0.0640068299568  |              {'C': 1000.0, 'gamma': 100.0}               |        3        |
|  0.514996809682 | 0.0470303838108  |              {'C': 1000.0, 'gamma': 1000.0}              |        8        |
|  0.498144527042 |  0.017888769284  |             {'C': 1000.0, 'gamma': 10000.0}              |        17       |
|  0.558312957916 | 0.0473801478439  |              {'C': 10000.0, 'gamma': 0.001}              |        1        |
|  0.518320612611 | 0.0624553244992  |              {'C': 10000.0, 'gamma': 0.01}               |        7        |
|  0.42438425124  |  0.023036680577  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.509651479878 | 0.0422830593144  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.509165387522 |  0.097184819446  |              {'C': 10000.0, 'gamma': 10.0}               |        12       |
|  0.554517999507 | 0.0706078125555  |              {'C': 10000.0, 'gamma': 100.0}              |        2        |
|  0.512455889468 | 0.0369893951959  |             {'C': 10000.0, 'gamma': 1000.0}              |        9        |
|  0.485567496229 | 0.0136884888349  |             {'C': 10000.0, 'gamma': 10000.0}             |        54       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.96      0.78        26
          1       0.67      0.13      0.22        15

avg / total       0.66      0.66      0.58        41

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.491442061775 | 0.0095488511589  |               {'C': 0.001, 'gamma': 0.001}               |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 0.001, 'gamma': 0.01}                |        18       |
|  0.491442061775 | 0.0095488511589  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 0.001, 'gamma': 1.0}                |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 0.001, 'gamma': 10.0}                |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 0.001, 'gamma': 100.0}               |        18       |
|  0.491442061775 | 0.0095488511589  |              {'C': 0.001, 'gamma': 1000.0}               |        18       |
|  0.491442061775 | 0.0095488511589  |              {'C': 0.001, 'gamma': 10000.0}              |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 0.01, 'gamma': 0.001}                |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 0.01, 'gamma': 0.01}                |        18       |
|  0.491442061775 | 0.0095488511589  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 0.01, 'gamma': 1.0}                 |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 0.01, 'gamma': 10.0}                |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 0.01, 'gamma': 100.0}                |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 0.01, 'gamma': 1000.0}               |        18       |
|  0.491442061775 | 0.0095488511589  |              {'C': 0.01, 'gamma': 10000.0}               |        18       |
|  0.491442061775 | 0.0095488511589  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        18       |
|  0.491442061775 | 0.0095488511589  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        18       |
|  0.491442061775 | 0.0095488511589  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        18       |
|  0.491442061775 | 0.0095488511589  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        18       |
|  0.491442061775 | 0.0095488511589  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        18       |
|  0.491442061775 | 0.0095488511589  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        18       |
|  0.491442061775 | 0.0095488511589  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        18       |
|  0.491442061775 | 0.0095488511589  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 1.0, 'gamma': 0.001}                |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 1.0, 'gamma': 0.01}                 |        18       |
|  0.491442061775 | 0.0095488511589  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.491442061775 | 0.0095488511589  |                 {'C': 1.0, 'gamma': 1.0}                 |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.471514525543 | 0.0386223278779  |                {'C': 1.0, 'gamma': 100.0}                |        62       |
|  0.491442061775 | 0.0095488511589  |               {'C': 1.0, 'gamma': 1000.0}                |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 1.0, 'gamma': 10000.0}               |        18       |
|  0.491442061775 | 0.0095488511589  |               {'C': 10.0, 'gamma': 0.001}                |        18       |
|  0.491442061775 | 0.0095488511589  |                {'C': 10.0, 'gamma': 0.01}                |        18       |
|  0.504777830865 | 0.0350070202692  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        13       |
|  0.51511529026  |  0.055878207692  |                {'C': 10.0, 'gamma': 1.0}                 |        12       |
|  0.498894195664 | 0.0581026764511  |                {'C': 10.0, 'gamma': 10.0}                |        14       |
|  0.517606035436 | 0.0333211119575  |               {'C': 10.0, 'gamma': 100.0}                |        11       |
|  0.497117375378 | 0.0159976473053  |               {'C': 10.0, 'gamma': 1000.0}               |        15       |
|  0.488444207114 | 0.0138347796852  |              {'C': 10.0, 'gamma': 10000.0}               |        53       |
|  0.491442061775 | 0.0095488511589  |               {'C': 100.0, 'gamma': 0.001}               |        18       |
|  0.518118284103 | 0.0360881215242  |               {'C': 100.0, 'gamma': 0.01}                |        10       |
|  0.552305985696 | 0.0372662367489  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.48555139364  | 0.0725147376595  |                {'C': 100.0, 'gamma': 1.0}                |        60       |
|  0.454192935733 | 0.0733499749686  |               {'C': 100.0, 'gamma': 10.0}                |        63       |
|  0.492640496597 | 0.0409213561483  |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.488444207114 | 0.0138347796852  |              {'C': 100.0, 'gamma': 1000.0}               |        53       |
|  0.488444207114 | 0.0138347796852  |              {'C': 100.0, 'gamma': 10000.0}              |        53       |
|  0.491442061775 | 0.0095488511589  |              {'C': 1000.0, 'gamma': 0.001}               |        18       |
|  0.528507938957 | 0.0612948408931  |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.494221605836 | 0.0576006756603  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.55548849828  |  0.117451029837  |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.452196192433 | 0.0394696265415  |               {'C': 1000.0, 'gamma': 10.0}               |        64       |
|  0.519977087825 |  0.017026498714  |              {'C': 1000.0, 'gamma': 100.0}               |        9        |
|  0.485326438268 | 0.0193001235986  |              {'C': 1000.0, 'gamma': 1000.0}              |        61       |
|  0.488444207114 | 0.0138347796852  |             {'C': 1000.0, 'gamma': 10000.0}              |        53       |
|  0.528879211788 | 0.0391164558921  |              {'C': 10000.0, 'gamma': 0.001}              |        6        |
|  0.488222287481 | 0.0624363325038  |              {'C': 10000.0, 'gamma': 0.01}               |        59       |
|  0.532941366183 | 0.0581491019347  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.582773704447 | 0.0554875357894  |               {'C': 10000.0, 'gamma': 1.0}               |        1        |
|  0.531954931822 | 0.0818693475807  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.525533863808 | 0.0626810460508  |              {'C': 10000.0, 'gamma': 100.0}              |        8        |
|  0.488421723204 | 0.00643759873856 |             {'C': 10000.0, 'gamma': 1000.0}              |        57       |
|  0.488421723204 | 0.00643759873856 |             {'C': 10000.0, 'gamma': 10000.0}             |        57       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.64      0.62        25
          1       0.31      0.27      0.29        15

avg / total       0.49      0.50      0.49        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.491442061775 | 0.0095488511589 |               {'C': 0.001, 'gamma': 0.001}               |        20       |
|  0.491442061775 | 0.0095488511589 |               {'C': 0.001, 'gamma': 0.01}                |        20       |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 0.001, 'gamma': 1.0}                |        20       |
|  0.491442061775 | 0.0095488511589 |               {'C': 0.001, 'gamma': 10.0}                |        20       |
|  0.491442061775 | 0.0095488511589 |               {'C': 0.001, 'gamma': 100.0}               |        20       |
|  0.491442061775 | 0.0095488511589 |              {'C': 0.001, 'gamma': 1000.0}               |        20       |
|  0.491442061775 | 0.0095488511589 |              {'C': 0.001, 'gamma': 10000.0}              |        20       |
|  0.491442061775 | 0.0095488511589 |               {'C': 0.01, 'gamma': 0.001}                |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 0.01, 'gamma': 0.01}                |        20       |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 0.01, 'gamma': 1.0}                 |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 0.01, 'gamma': 10.0}                |        20       |
|  0.491442061775 | 0.0095488511589 |               {'C': 0.01, 'gamma': 100.0}                |        20       |
|  0.491442061775 | 0.0095488511589 |               {'C': 0.01, 'gamma': 1000.0}               |        20       |
|  0.491442061775 | 0.0095488511589 |              {'C': 0.01, 'gamma': 10000.0}               |        20       |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        20       |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        20       |
|  0.491442061775 | 0.0095488511589 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        20       |
|  0.491442061775 | 0.0095488511589 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        20       |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        20       |
|  0.491442061775 | 0.0095488511589 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        20       |
|  0.491442061775 | 0.0095488511589 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        20       |
|  0.491442061775 | 0.0095488511589 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 1.0, 'gamma': 0.001}                |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 1.0, 'gamma': 0.01}                 |        20       |
|  0.491442061775 | 0.0095488511589 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        20       |
|  0.491442061775 | 0.0095488511589 |                 {'C': 1.0, 'gamma': 1.0}                 |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 1.0, 'gamma': 10.0}                 |        20       |
|  0.489987544153 | 0.0159876840225 |                {'C': 1.0, 'gamma': 100.0}                |        53       |
|  0.482290173595 | 0.0103546360888 |               {'C': 1.0, 'gamma': 1000.0}                |        60       |
|  0.491442061775 | 0.0095488511589 |               {'C': 1.0, 'gamma': 10000.0}               |        20       |
|  0.491442061775 | 0.0095488511589 |               {'C': 10.0, 'gamma': 0.001}                |        20       |
|  0.491442061775 | 0.0095488511589 |                {'C': 10.0, 'gamma': 0.01}                |        20       |
|  0.504782515013 |  0.022887813643 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.52936493564  | 0.0587018004327 |                {'C': 10.0, 'gamma': 1.0}                 |        6        |
|  0.473593582493 |  0.023938300535 |                {'C': 10.0, 'gamma': 10.0}                |        61       |
|  0.497423829704 | 0.0380857940871 |               {'C': 10.0, 'gamma': 100.0}                |        19       |
|  0.508337710045 | 0.0367689769066 |               {'C': 10.0, 'gamma': 1000.0}               |        17       |
|  0.485423868544 | 0.0111154926065 |              {'C': 10.0, 'gamma': 10000.0}               |        58       |
|  0.491442061775 | 0.0095488511589 |               {'C': 100.0, 'gamma': 0.001}               |        20       |
|  0.488444207114 | 0.0138347796852 |               {'C': 100.0, 'gamma': 0.01}                |        54       |
|  0.512500742045 | 0.0566625033266 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.459225136829 | 0.0329941087658 |                {'C': 100.0, 'gamma': 1.0}                |        63       |
|  0.484506876052 | 0.0298634835297 |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.576356711983 | 0.0412675388329 |               {'C': 100.0, 'gamma': 100.0}               |        1        |
|  0.512088300961 | 0.0438000760236 |              {'C': 100.0, 'gamma': 1000.0}               |        14       |
|  0.488434131777 | 0.0102554482605 |              {'C': 100.0, 'gamma': 10000.0}              |        56       |
|  0.518163446359 | 0.0309062522321 |              {'C': 1000.0, 'gamma': 0.001}               |        9        |
|  0.533542166193 | 0.0341923010814 |               {'C': 1000.0, 'gamma': 0.01}               |        5        |
|  0.459446056073 | 0.0587944820434 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        62       |
|  0.410906784099 | 0.0556360470647 |               {'C': 1000.0, 'gamma': 1.0}                |        64       |
|  0.525552377306 | 0.0506771454876 |               {'C': 1000.0, 'gamma': 10.0}               |        7        |
|  0.514988393829 | 0.0548855852129 |              {'C': 1000.0, 'gamma': 100.0}               |        11       |
|  0.520840905303 | 0.0333331346976 |              {'C': 1000.0, 'gamma': 1000.0}              |        8        |
|  0.488444207114 | 0.0138347796852 |             {'C': 1000.0, 'gamma': 10000.0}              |        54       |
|  0.546492040124 | 0.0521184694404 |              {'C': 10000.0, 'gamma': 0.001}              |        4        |
|  0.516867580786 | 0.0420359129553 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.513718117046 | 0.0317015097104 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        12       |
|  0.509120079138 | 0.0216706373556 |               {'C': 10000.0, 'gamma': 1.0}               |        16       |
|  0.557605558693 |  0.10777452488  |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.550214073207 | 0.0436092407604 |              {'C': 10000.0, 'gamma': 100.0}              |        3        |
|  0.511270958816 | 0.0358406951745 |             {'C': 10000.0, 'gamma': 1000.0}              |        15       |
|  0.485436277117 | 0.0136879551281 |             {'C': 10000.0, 'gamma': 10000.0}             |        57       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      1.00      0.79        25
          1       1.00      0.13      0.24        15

avg / total       0.79      0.68      0.58        40

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.486546375435 | 0.0069674986243  |               {'C': 0.001, 'gamma': 0.001}               |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 0.001, 'gamma': 0.01}                |        13       |
|  0.486546375435 | 0.0069674986243  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 0.001, 'gamma': 1.0}                |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 0.001, 'gamma': 10.0}                |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 0.001, 'gamma': 100.0}               |        13       |
|  0.486546375435 | 0.0069674986243  |              {'C': 0.001, 'gamma': 1000.0}               |        13       |
|  0.486546375435 | 0.0069674986243  |              {'C': 0.001, 'gamma': 10000.0}              |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 0.01, 'gamma': 0.001}                |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 0.01, 'gamma': 0.01}                |        13       |
|  0.486546375435 | 0.0069674986243  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 0.01, 'gamma': 1.0}                 |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 0.01, 'gamma': 10.0}                |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 0.01, 'gamma': 100.0}                |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 0.01, 'gamma': 1000.0}               |        13       |
|  0.486546375435 | 0.0069674986243  |              {'C': 0.01, 'gamma': 10000.0}               |        13       |
|  0.486546375435 | 0.0069674986243  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        13       |
|  0.486546375435 | 0.0069674986243  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        13       |
|  0.486546375435 | 0.0069674986243  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        13       |
|  0.486546375435 | 0.0069674986243  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        13       |
|  0.486546375435 | 0.0069674986243  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        13       |
|  0.486546375435 | 0.0069674986243  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        13       |
|  0.486546375435 | 0.0069674986243  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        13       |
|  0.486546375435 | 0.0069674986243  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 1.0, 'gamma': 0.001}                |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 1.0, 'gamma': 0.01}                 |        13       |
|  0.486546375435 | 0.0069674986243  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        13       |
|  0.486546375435 | 0.0069674986243  |                 {'C': 1.0, 'gamma': 1.0}                 |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.499804480197 | 0.0246871122247  |                {'C': 1.0, 'gamma': 100.0}                |        11       |
|  0.486546375435 | 0.0069674986243  |               {'C': 1.0, 'gamma': 1000.0}                |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 1.0, 'gamma': 10000.0}               |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 10.0, 'gamma': 0.001}                |        13       |
|  0.486546375435 | 0.0069674986243  |                {'C': 10.0, 'gamma': 0.01}                |        13       |
|  0.483557012907 | 0.00576531519867 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        53       |
|  0.523727706568 |  0.023141910133  |                {'C': 10.0, 'gamma': 1.0}                 |        5        |
|  0.454837733073 | 0.0624351894153  |                {'C': 10.0, 'gamma': 10.0}                |        63       |
|  0.50969806762  | 0.0386912718897  |               {'C': 10.0, 'gamma': 100.0}                |        10       |
|  0.477226598142 |  0.015213560496  |               {'C': 10.0, 'gamma': 1000.0}               |        60       |
|  0.486546375435 | 0.0069674986243  |              {'C': 10.0, 'gamma': 10000.0}               |        13       |
|  0.486546375435 | 0.0069674986243  |               {'C': 100.0, 'gamma': 0.001}               |        13       |
|  0.483557012907 | 0.00576531519867 |               {'C': 100.0, 'gamma': 0.01}                |        53       |
|  0.530655270655 | 0.0610514669674  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.478989584795 | 0.0707352960918  |                {'C': 100.0, 'gamma': 1.0}                |        58       |
|  0.518881119712 | 0.0905058176085  |               {'C': 100.0, 'gamma': 10.0}                |        8        |
|  0.491907950265 | 0.0464233341871  |               {'C': 100.0, 'gamma': 100.0}               |        12       |
|  0.486546375435 | 0.0069674986243  |              {'C': 100.0, 'gamma': 1000.0}               |        13       |
|  0.486546375435 | 0.0069674986243  |              {'C': 100.0, 'gamma': 10000.0}              |        13       |
|  0.483557012907 | 0.00576531519867 |              {'C': 1000.0, 'gamma': 0.001}               |        53       |
|  0.511595594123 | 0.0415355102536  |               {'C': 1000.0, 'gamma': 0.01}               |        9        |
|  0.469373588773 | 0.0335665727454  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        61       |
|  0.478020723271 |  0.106596196698  |               {'C': 1000.0, 'gamma': 1.0}                |        59       |
|  0.58705761444  | 0.0811244462926  |               {'C': 1000.0, 'gamma': 10.0}               |        1        |
|  0.520517988772 | 0.0165376939813  |              {'C': 1000.0, 'gamma': 100.0}               |        6        |
|  0.483557012907 | 0.00576531519867 |              {'C': 1000.0, 'gamma': 1000.0}              |        53       |
|  0.486546375435 | 0.0069674986243  |             {'C': 1000.0, 'gamma': 10000.0}              |        13       |
|  0.480056067733 | 0.0337078628545  |              {'C': 10000.0, 'gamma': 0.001}              |        57       |
|  0.520044102729 | 0.0648512196344  |              {'C': 10000.0, 'gamma': 0.01}               |        7        |
|  0.429278631115 | 0.0835092069535  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        64       |
|  0.456383748348 | 0.0695358662884  |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.559848421215 | 0.0799002347467  |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.524739704407 | 0.0347749904613  |              {'C': 10000.0, 'gamma': 100.0}              |        4        |
|  0.486546375435 | 0.0069674986243  |             {'C': 10000.0, 'gamma': 1000.0}              |        13       |
|  0.483567026051 | 0.0109101409516  |             {'C': 10000.0, 'gamma': 10000.0}             |        52       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.64      0.64        25
          1       0.36      0.36      0.36        14

avg / total       0.54      0.54      0.54        39


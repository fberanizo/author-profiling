Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.499620958751 | 0.0195823941617 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        31
          1       0.00      0.00      0.00        20

avg / total       0.37      0.61      0.46        51


Accuracy on test set (using best parameters): 0.61

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.567212592476 |  0.117013434638 |  {'n_neighbors': 3} |        1        |
|  0.487299754348 |  0.109265594043 |  {'n_neighbors': 5} |        5        |
|  0.555605617741 |  0.118084333342 | {'n_neighbors': 11} |        2        |
|  0.532943656514 |  0.106312097505 | {'n_neighbors': 21} |        3        |
|  0.495814330597 | 0.0500207234289 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.58      0.60        31
          1       0.41      0.45      0.43        20

avg / total       0.54      0.53      0.53        51


Accuracy on test set (using best parameters): 0.53

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.523774679427 |  0.109878417815 | {'n_estimators': 2}  |        5        |
|  0.585024124482 |  0.110943325789 | {'n_estimators': 3}  |        1        |
|  0.555663659317 | 0.0893857615119 | {'n_estimators': 5}  |        4        |
|  0.508188716276 | 0.0680013366714 | {'n_estimators': 10} |        6        |
|  0.559597193467 |  0.110588880168 | {'n_estimators': 20} |        3        |
|  0.495648974214 | 0.0834650492244 | {'n_estimators': 40} |        7        |
|  0.574639956993 | 0.0813206709733 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.61      0.59        31
          1       0.33      0.30      0.32        20

avg / total       0.48      0.49      0.48        51


Accuracy on test set (using best parameters): 0.49

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.482954292085 | 0.0192570883785 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|  0.482954292085 | 0.0192570883785 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        16       |
|  0.482954292085 | 0.0192570883785 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|  0.531049052397 | 0.0691698272851 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        6        |
|  0.482954292085 | 0.0192570883785 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.482954292085 | 0.0192570883785 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|  0.482954292085 | 0.0192570883785 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.54089408659  | 0.0893282836399 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.498838509317 | 0.0640581675689 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.544529867793 |  0.10268902085  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        1        |
|  0.533094894765 | 0.0943734854033 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.487252594765 | 0.0907744793289 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        15       |
|  0.504258876389 | 0.0628609850841 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.52448015202  |  0.109646453397 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
|  0.527882943144 | 0.0759857630461 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        7        |
|  0.542810315289 | 0.0899086026611 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        2        |
|  0.534290834769 | 0.0896590510127 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.503607793173 | 0.0962449161143 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        11       |
|  0.502393972499 | 0.0875067622087 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        12       |
|  0.518533133533 |  0.102768212202 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        9        |
|  0.494815885869 | 0.0984991525002 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        14       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.91      0.75        33
          1       0.25      0.06      0.09        18

avg / total       0.50      0.61      0.52        51


Accuracy on test set (using best parameters): 0.61

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.491192865106 | 0.0111433338322 |        {'C': 0.001}        |        3        |
|  0.491192865106 | 0.0111433338322 |        {'C': 0.01}         |        3        |
|  0.491192865106 | 0.0111433338322 | {'C': 0.10000000000000001} |        3        |
|  0.491192865106 | 0.0111433338322 |         {'C': 1.0}         |        3        |
|  0.537113031896 | 0.0683128039307 |        {'C': 10.0}         |        1        |
|  0.502827028044 | 0.0818863878707 |        {'C': 100.0}        |        2        |
|  0.477634612378 |  0.104640687739 |       {'C': 1000.0}        |        8        |
|  0.487882870942 |  0.119017952433 |       {'C': 10000.0}       |        7        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.97      0.78        32
          1       0.75      0.16      0.26        19

avg / total       0.69      0.67      0.59        51


Accuracy on test set (using best parameters): 0.67

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.001}               |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.01}                |        19       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        19       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.001, 'gamma': 1.0}                |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 10.0}                |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 100.0}               |        19       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 1000.0}               |        19       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 10000.0}              |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 0.001}                |        19       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 0.01}                |        19       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        19       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 1.0}                 |        19       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 10.0}                |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 100.0}                |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 1000.0}               |        19       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.01, 'gamma': 10000.0}               |        19       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        19       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        19       |
|  0.516477146042 | 0.0218143560652 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        19       |
|  0.516477146042 | 0.0218143560652 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        19       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        19       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        19       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        19       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        19       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.001}                |        19       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.01}                 |        19       |
|  0.516477146042 | 0.0218143560652 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        19       |
|  0.516477146042 | 0.0218143560652 |                 {'C': 1.0, 'gamma': 1.0}                 |        19       |
|  0.51315698794  | 0.0259179943589 |                {'C': 1.0, 'gamma': 10.0}                 |        53       |
|  0.513143812709 | 0.0215288538618 |                {'C': 1.0, 'gamma': 100.0}                |        54       |
|  0.516477146042 | 0.0218143560652 |               {'C': 1.0, 'gamma': 1000.0}                |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 1.0, 'gamma': 10000.0}               |        19       |
|  0.516477146042 | 0.0218143560652 |               {'C': 10.0, 'gamma': 0.001}                |        19       |
|  0.516477146042 | 0.0218143560652 |                {'C': 10.0, 'gamma': 0.01}                |        19       |
|  0.513143812709 | 0.0215288538618 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        54       |
|  0.531528193563 | 0.0717632502487 |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.535963162187 |  0.121855224781 |                {'C': 10.0, 'gamma': 10.0}                |        15       |
|  0.563290332856 | 0.0755282469095 |               {'C': 10.0, 'gamma': 100.0}                |        4        |
|  0.513143812709 | 0.0215288538618 |               {'C': 10.0, 'gamma': 1000.0}               |        54       |
|  0.513143812709 | 0.0215288538618 |              {'C': 10.0, 'gamma': 10000.0}               |        54       |
|  0.516477146042 | 0.0218143560652 |               {'C': 100.0, 'gamma': 0.001}               |        19       |
|  0.513143812709 | 0.0215288538618 |               {'C': 100.0, 'gamma': 0.01}                |        54       |
|  0.539880293619 | 0.0928079652969 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.526309497943 |  0.127031359563 |                {'C': 100.0, 'gamma': 1.0}                |        18       |
|  0.55463920341  |  0.110722076823 |               {'C': 100.0, 'gamma': 10.0}                |        8        |
|  0.566200176635 | 0.0758365510755 |               {'C': 100.0, 'gamma': 100.0}               |        3        |
|  0.513143812709 | 0.0215288538618 |              {'C': 100.0, 'gamma': 1000.0}               |        54       |
|  0.513143812709 | 0.0215288538618 |              {'C': 100.0, 'gamma': 10000.0}              |        54       |
|  0.516477146042 | 0.0218143560652 |              {'C': 1000.0, 'gamma': 0.001}               |        19       |
|  0.539880293619 | 0.0928079652969 |               {'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.537937818985 |  0.134038628828 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        14       |
|  0.540911318701 |  0.112191782467 |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.566692879542 | 0.0945940653131 |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.561320635886 | 0.0739590047292 |              {'C': 1000.0, 'gamma': 100.0}               |        5        |
|  0.513143812709 | 0.0215288538618 |              {'C': 1000.0, 'gamma': 1000.0}              |        54       |
|  0.513143812709 | 0.0215288538618 |             {'C': 1000.0, 'gamma': 10000.0}              |        54       |
|  0.539880293619 | 0.0928079652969 |              {'C': 10000.0, 'gamma': 0.001}              |        10       |
|  0.555105513143 |  0.120251889836 |              {'C': 10000.0, 'gamma': 0.01}               |        7        |
|  0.538913509014 |  0.137751519802 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        13       |
|  0.531799498747 |  0.128539464898 |               {'C': 10000.0, 'gamma': 1.0}               |        16       |
|  0.577599565449 |  0.104487373597 |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.561320635886 | 0.0739590047292 |              {'C': 10000.0, 'gamma': 100.0}              |        5        |
|  0.513143812709 | 0.0215288538618 |             {'C': 10000.0, 'gamma': 1000.0}              |        54       |
|  0.513143812709 | 0.0215288538618 |             {'C': 10000.0, 'gamma': 10000.0}             |        54       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.52      0.76      0.62        29
          1       0.22      0.09      0.13        22

avg / total       0.39      0.47      0.41        51


Accuracy on test set (using best parameters): 0.47


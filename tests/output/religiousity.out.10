Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.482954292085 | 0.0192570883785 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      1.00      0.79        33
          1       0.00      0.00      0.00        18

avg / total       0.42      0.65      0.51        51


Accuracy on test set (using best parameters): 0.65

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.504360197308 |  0.14618906897  |  {'n_neighbors': 3} |        3        |
|  0.513349737981 |  0.137496231994 |  {'n_neighbors': 5} |        2        |
|  0.527627982613 |  0.115781417755 | {'n_neighbors': 11} |        1        |
|  0.485679755028 | 0.0850250629027 | {'n_neighbors': 21} |        4        |
|  0.482954292085 | 0.0192570883785 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.79      0.69        33
          1       0.22      0.11      0.15        18

avg / total       0.48      0.55      0.50        51


Accuracy on test set (using best parameters): 0.55

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.577378876484 | 0.0657181652136 | {'n_estimators': 2}  |        1        |
|  0.55052530756  | 0.0911484912437 | {'n_estimators': 3}  |        5        |
|  0.564039193284 |  0.120124424334 | {'n_estimators': 5}  |        2        |
|  0.560736238928 | 0.0733415095977 | {'n_estimators': 10} |        3        |
|  0.549613460613 | 0.0641393898985 | {'n_estimators': 20} |        6        |
|  0.546585245672 | 0.0679203927236 | {'n_estimators': 40} |        7        |
|  0.554655788656 | 0.0962993299278 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.84      0.70        31
          1       0.38      0.15      0.21        20

avg / total       0.51      0.57      0.51        51


Accuracy on test set (using best parameters): 0.57

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.458238573021 | 0.0172142708089 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        9        |
|  0.458238573021 | 0.0172142708089 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        9        |
|  0.458238573021 | 0.0172142708089 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        9        |
|  0.454977703456 | 0.0211130380671 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        13       |
|  0.476730636513 | 0.0554007436633 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        4        |
|  0.452324487107 |  0.017965580436 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.444602209385 |  0.035564323802 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.473923960098 | 0.0566189247673 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        5        |
|  0.483116506682 | 0.0735408489351 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        2        |
|  0.453106305459 | 0.0730319873977 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.439304285087 | 0.0998639827922 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        20       |
|  0.473122466905 |  0.119549599988 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.507408181191 |  0.10676650718  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.477180186963 | 0.0903207722509 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.470149608845 | 0.0570049627152 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        7        |
|  0.457713783801 | 0.0614222726093 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.46647826087  | 0.0549908125781 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.44282345191  |  0.053508709615 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.439355292051 | 0.0776312999948 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        19       |
|  0.422748092233 | 0.0784387525008 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        21       |
|  0.452314650262 | 0.0917491001444 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        16       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      1.00      0.83        36
          1       0.00      0.00      0.00        15

avg / total       0.50      0.71      0.58        51


Accuracy on test set (using best parameters): 0.71

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.499620958751 | 0.0195823941617 |        {'C': 0.001}        |        3        |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.01}         |        3        |
|  0.499620958751 | 0.0195823941617 | {'C': 0.10000000000000001} |        3        |
|  0.499620958751 | 0.0195823941617 |         {'C': 1.0}         |        3        |
|  0.525992297558 | 0.0843570976844 |        {'C': 10.0}         |        2        |
|  0.540453460769 | 0.0777597984814 |        {'C': 100.0}        |        1        |
|  0.481976431721 |  0.110645514358 |       {'C': 1000.0}        |        8        |
|  0.482251694699 | 0.0859133788842 |       {'C': 10000.0}       |        7        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.71      0.64        31
          1       0.31      0.20      0.24        20

avg / total       0.47      0.51      0.48        51


Accuracy on test set (using best parameters): 0.51

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.499620958751 | 0.0195823941617 |               {'C': 0.001, 'gamma': 0.001}               |        26       |
|  0.499620958751 | 0.0195823941617 |               {'C': 0.001, 'gamma': 0.01}                |        26       |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        26       |
|  0.499620958751 | 0.0195823941617 |                {'C': 0.001, 'gamma': 1.0}                |        26       |
|  0.499620958751 | 0.0195823941617 |               {'C': 0.001, 'gamma': 10.0}                |        26       |
|  0.499620958751 | 0.0195823941617 |               {'C': 0.001, 'gamma': 100.0}               |        26       |
|  0.499620958751 | 0.0195823941617 |              {'C': 0.001, 'gamma': 1000.0}               |        26       |
|  0.499620958751 | 0.0195823941617 |              {'C': 0.001, 'gamma': 10000.0}              |        26       |
|  0.499620958751 | 0.0195823941617 |               {'C': 0.01, 'gamma': 0.001}                |        26       |
|  0.499620958751 | 0.0195823941617 |                {'C': 0.01, 'gamma': 0.01}                |        26       |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        26       |
|  0.499620958751 | 0.0195823941617 |                {'C': 0.01, 'gamma': 1.0}                 |        26       |
|  0.499620958751 | 0.0195823941617 |                {'C': 0.01, 'gamma': 10.0}                |        26       |
|  0.499620958751 | 0.0195823941617 |               {'C': 0.01, 'gamma': 100.0}                |        26       |
|  0.499620958751 | 0.0195823941617 |               {'C': 0.01, 'gamma': 1000.0}               |        26       |
|  0.499620958751 | 0.0195823941617 |              {'C': 0.01, 'gamma': 10000.0}               |        26       |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        26       |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        26       |
|  0.499620958751 | 0.0195823941617 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        26       |
|  0.499620958751 | 0.0195823941617 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        26       |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        26       |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        26       |
|  0.499620958751 | 0.0195823941617 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        26       |
|  0.499620958751 | 0.0195823941617 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        26       |
|  0.499620958751 | 0.0195823941617 |                {'C': 1.0, 'gamma': 0.001}                |        26       |
|  0.499620958751 | 0.0195823941617 |                {'C': 1.0, 'gamma': 0.01}                 |        26       |
|  0.499620958751 | 0.0195823941617 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.485945745076 | 0.0398582208569 |                 {'C': 1.0, 'gamma': 1.0}                 |        64       |
|  0.502589777372 | 0.0539601940999 |                {'C': 1.0, 'gamma': 10.0}                 |        25       |
|  0.562389296694 | 0.0573238738302 |                {'C': 1.0, 'gamma': 100.0}                |        3        |
|  0.518498602846 |  0.041245155063 |               {'C': 1.0, 'gamma': 1000.0}                |        20       |
|  0.496300800649 | 0.0216198068567 |               {'C': 1.0, 'gamma': 10000.0}               |        57       |
|  0.499620958751 | 0.0195823941617 |               {'C': 10.0, 'gamma': 0.001}                |        26       |
|  0.499620958751 | 0.0195823941617 |                {'C': 10.0, 'gamma': 0.01}                |        26       |
|  0.489501300632 | 0.0346684739907 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        63       |
|  0.545163696546 |  0.091642514071 |                {'C': 10.0, 'gamma': 1.0}                 |        10       |
|  0.523646105434 |  0.105857734273 |                {'C': 10.0, 'gamma': 10.0}                |        17       |
|  0.57090049564  | 0.0610895213608 |               {'C': 10.0, 'gamma': 100.0}                |        1        |
|  0.514982196547 | 0.0531327662127 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.496300800649 | 0.0216198068567 |              {'C': 10.0, 'gamma': 10000.0}               |        57       |
|  0.499620958751 | 0.0195823941617 |               {'C': 100.0, 'gamma': 0.001}               |        26       |
|  0.493056856187 | 0.0281041715265 |               {'C': 100.0, 'gamma': 0.01}                |        62       |
|  0.529724550812 | 0.0851245371901 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.529964725333 |  0.114567589257 |                {'C': 100.0, 'gamma': 1.0}                |        15       |
|  0.550221277444 | 0.0927761030959 |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|  0.556965155617 | 0.0578428627164 |               {'C': 100.0, 'gamma': 100.0}               |        5        |
|  0.514982196547 | 0.0531327662127 |              {'C': 100.0, 'gamma': 1000.0}               |        21       |
|  0.496300800649 | 0.0216198068567 |              {'C': 100.0, 'gamma': 10000.0}              |        57       |
|  0.496338907469 | 0.0244423642426 |              {'C': 1000.0, 'gamma': 0.001}               |        56       |
|  0.544899342204 | 0.0757450313459 |               {'C': 1000.0, 'gamma': 0.01}               |        11       |
|  0.532499196692 |  0.113714761919 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        14       |
|  0.563989644343 | 0.0680671424611 |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.522800167965 | 0.0722314865913 |               {'C': 1000.0, 'gamma': 10.0}               |        18       |
|  0.553683104335 | 0.0627388951574 |              {'C': 1000.0, 'gamma': 100.0}               |        6        |
|  0.514982196547 | 0.0531327662127 |              {'C': 1000.0, 'gamma': 1000.0}              |        21       |
|  0.496300800649 | 0.0216198068567 |             {'C': 1000.0, 'gamma': 10000.0}              |        57       |
|  0.544899342204 | 0.0757450313459 |              {'C': 10000.0, 'gamma': 0.001}              |        11       |
|  0.541417373533 |  0.105996964365 |              {'C': 10000.0, 'gamma': 0.01}               |        13       |
|  0.550579166448 |  0.109298404806 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        8        |
|  0.559758379506 | 0.0631652000084 |               {'C': 10000.0, 'gamma': 1.0}               |        4        |
|  0.522800167965 | 0.0722314865913 |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.553683104335 | 0.0627388951574 |              {'C': 10000.0, 'gamma': 100.0}              |        6        |
|  0.514982196547 | 0.0531327662127 |             {'C': 10000.0, 'gamma': 1000.0}              |        21       |
|  0.496300800649 | 0.0216198068567 |             {'C': 10000.0, 'gamma': 10000.0}             |        57       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.90      0.72        31
          1       0.25      0.05      0.08        20

avg / total       0.46      0.57      0.47        51


Accuracy on test set (using best parameters): 0.57


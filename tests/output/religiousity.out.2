Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.516477146042 | 0.0218143560652 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      1.00      0.72        29
          1       0.00      0.00      0.00        22

avg / total       0.32      0.57      0.41        51


Accuracy on test set (using best parameters): 0.57

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.468462612035 |  0.121559050311 |  {'n_neighbors': 3} |        3        |
|  0.464565230092 |  0.125851927237 |  {'n_neighbors': 5} |        4        |
|  0.485907961604 |  0.127833259072 | {'n_neighbors': 11} |        1        |
|  0.475497183975 | 0.0577418458268 | {'n_neighbors': 21} |        2        |
|  0.448455964326 | 0.0260925136463 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.89      0.79        36
          1       0.33      0.13      0.19        15

avg / total       0.60      0.67      0.61        51


Accuracy on test set (using best parameters): 0.67

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.50067021867  | 0.0591181680288 | {'n_estimators': 2}  |        7        |
|  0.525037593985 |  0.127690943504 | {'n_estimators': 3}  |        6        |
|  0.542313362587 |  0.119779144153 | {'n_estimators': 5}  |        4        |
|  0.573280062255 |  0.118022240073 | {'n_estimators': 10} |        2        |
|  0.539457927868 | 0.0691428270044 | {'n_estimators': 20} |        5        |
|  0.591239200413 | 0.0750312538538 | {'n_estimators': 40} |        1        |
|  0.555610930133 | 0.0531893302664 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.97      0.76        30
          1       0.80      0.19      0.31        21

avg / total       0.70      0.65      0.58        51


Accuracy on test set (using best parameters): 0.65

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.499620958751 | 0.0195823941617 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|  0.499620958751 | 0.0195823941617 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|  0.52138238573  | 0.0435628433261 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        10       |
|  0.496338907469 | 0.0244423642426 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.508338907469 |  0.026292496848 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        12       |
|  0.499620958751 | 0.0195823941617 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.499620958751 | 0.0195823941617 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.535214206084 | 0.0908788654703 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.523110326406 | 0.0748440054626 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.529778498813 | 0.0968764834178 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        7        |
|  0.495363670146 | 0.0664172424568 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        20       |
|  0.502054763272 | 0.0788357343419 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        14       |
|  0.47485079172  |  0.063475962979 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        21       |
|  0.545109061631 | 0.0818520202449 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.54077210712  | 0.0858879145041 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        3        |
|  0.530227381314 | 0.0905574809279 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        6        |
|  0.528814205119 | 0.0639860620111 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.53219509476  | 0.0904973859139 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.506312250977 | 0.0950659707033 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        13       |
|  0.542551704334 | 0.0851929701837 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.520022395905 |  0.113533574345 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        11       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.74      0.68        31
          1       0.43      0.30      0.35        20

avg / total       0.55      0.57      0.55        51


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.482954292085 | 0.0192570883785 |        {'C': 0.001}        |        5        |
|  0.482954292085 | 0.0192570883785 |        {'C': 0.01}         |        5        |
|  0.482954292085 | 0.0192570883785 | {'C': 0.10000000000000001} |        5        |
|  0.482954292085 | 0.0192570883785 |         {'C': 1.0}         |        5        |
|  0.512437142568 | 0.0867588260346 |        {'C': 10.0}         |        2        |
|  0.50935118293  | 0.0965967206512 |        {'C': 100.0}        |        3        |
|  0.518284490134 |  0.100547687721 |       {'C': 1000.0}        |        1        |
|  0.497782138226 |  0.122312398119 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.48      0.55        33
          1       0.35      0.50      0.41        18

avg / total       0.54      0.49      0.50        51


Accuracy on test set (using best parameters): 0.49

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.001}               |        16       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.01}                |        16       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.001, 'gamma': 1.0}                |        16       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 10.0}                |        16       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 100.0}               |        16       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 1000.0}               |        16       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 10000.0}              |        16       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 0.001}                |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 0.01}                |        16       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 1.0}                 |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 10.0}                |        16       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 100.0}                |        16       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 1000.0}               |        16       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.01, 'gamma': 10000.0}               |        16       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        16       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        16       |
|  0.516477146042 | 0.0218143560652 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        16       |
|  0.516477146042 | 0.0218143560652 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        16       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        16       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        16       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        16       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.001}                |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.01}                 |        16       |
|  0.516477146042 | 0.0218143560652 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        16       |
|  0.516477146042 | 0.0218143560652 |                 {'C': 1.0, 'gamma': 1.0}                 |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 10.0}                 |        16       |
|  0.509810479376 | 0.0207097741282 |                {'C': 1.0, 'gamma': 100.0}                |        53       |
|  0.516477146042 | 0.0218143560652 |               {'C': 1.0, 'gamma': 1000.0}                |        16       |
|  0.509520624303 | 0.0260169947582 |               {'C': 1.0, 'gamma': 10000.0}               |        54       |
|  0.516477146042 | 0.0218143560652 |               {'C': 10.0, 'gamma': 0.001}                |        16       |
|  0.516477146042 | 0.0218143560652 |                {'C': 10.0, 'gamma': 0.01}                |        16       |
|  0.516477146042 | 0.0218143560652 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        16       |
|  0.50061434218  | 0.0517234554511 |                {'C': 10.0, 'gamma': 1.0}                 |        57       |
|  0.487859045946 | 0.0823874942071 |                {'C': 10.0, 'gamma': 10.0}                |        60       |
|  0.555134575569 | 0.0605657868123 |               {'C': 10.0, 'gamma': 100.0}                |        4        |
|  0.519961994527 | 0.0265074738269 |               {'C': 10.0, 'gamma': 1000.0}               |        7        |
|  0.519961994527 | 0.0265074738269 |              {'C': 10.0, 'gamma': 10000.0}               |        7        |
|  0.516477146042 | 0.0218143560652 |               {'C': 100.0, 'gamma': 0.001}               |        16       |
|  0.516477146042 | 0.0218143560652 |               {'C': 100.0, 'gamma': 0.01}                |        16       |
|  0.505265700483 | 0.0282737874012 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.431546199711 | 0.0524211093973 |                {'C': 100.0, 'gamma': 1.0}                |        64       |
|  0.493208461426 | 0.0735647930468 |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.600015684798 |  0.075045879401 |               {'C': 100.0, 'gamma': 100.0}               |        1        |
|  0.519961994527 | 0.0265074738269 |              {'C': 100.0, 'gamma': 1000.0}               |        7        |
|  0.519961994527 | 0.0265074738269 |              {'C': 100.0, 'gamma': 10000.0}              |        7        |
|  0.516477146042 | 0.0218143560652 |              {'C': 1000.0, 'gamma': 0.001}               |        16       |
|  0.51696342305  | 0.0436777296412 |               {'C': 1000.0, 'gamma': 0.01}               |        15       |
|  0.453420495684 |  0.118488103112 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        62       |
|  0.505935581123 |  0.11820616804  |               {'C': 1000.0, 'gamma': 1.0}                |        55       |
|  0.527043478261 |  0.103248451253 |               {'C': 1000.0, 'gamma': 10.0}               |        5        |
|  0.600015684798 |  0.075045879401 |              {'C': 1000.0, 'gamma': 100.0}               |        1        |
|  0.519961994527 | 0.0265074738269 |              {'C': 1000.0, 'gamma': 1000.0}              |        7        |
|  0.519961994527 | 0.0265074738269 |             {'C': 1000.0, 'gamma': 10000.0}              |        7        |
|  0.513340234645 | 0.0463553111311 |              {'C': 10000.0, 'gamma': 0.001}              |        52       |
|  0.48018034326  | 0.0875643559942 |              {'C': 10000.0, 'gamma': 0.01}               |        61       |
|  0.499090023037 |  0.122073177084 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        58       |
|  0.437731958855 |  0.127028441706 |               {'C': 10000.0, 'gamma': 1.0}               |        63       |
|  0.52164377992  |  0.100671579638 |              {'C': 10000.0, 'gamma': 10.0}               |        6        |
|  0.600015684798 |  0.075045879401 |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.519961994527 | 0.0265074738269 |             {'C': 10000.0, 'gamma': 1000.0}              |        7        |
|  0.519961994527 | 0.0265074738269 |             {'C': 10000.0, 'gamma': 10000.0}             |        7        |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.56      0.93      0.70        29
          1       0.33      0.05      0.08        22

avg / total       0.46      0.55      0.43        51


Accuracy on test set (using best parameters): 0.55


Evaluating DummyClassifier
# Tuning hyper-parameters for f1

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+----------------+--------+-----------------+
| test_mean_score | test_std_score | params | test_rank_score |
+-----------------+----------------+--------+-----------------+
|       0.0       |      0.0       |   {}   |        1        |
+-----------------+----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      1.00      0.77        32
          1       0.00      0.00      0.00        19

avg / total       0.39      0.63      0.48        51


Average accuracy on test set (using best parameters): 0.63

===================================================================
[ 0.62745098  0.        ]
===================================================================
Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+----------------+---------------------+-----------------+
| test_mean_score | test_std_score |        params       | test_rank_score |
+-----------------+----------------+---------------------+-----------------+
|  0.349216117216 | 0.173161757205 |  {'n_neighbors': 3} |        2        |
|  0.399087024087 | 0.189728112364 |  {'n_neighbors': 5} |        1        |
|  0.302786842787 | 0.161732409957 | {'n_neighbors': 11} |        3        |
|  0.276955266955 | 0.149289972408 | {'n_neighbors': 21} |        4        |
|  0.105904761905 | 0.166975387544 | {'n_neighbors': 31} |        5        |
+-----------------+----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      0.67      0.71        39
          1       0.24      0.33      0.28        12

avg / total       0.64      0.59      0.61        51


Average accuracy on test set (using best parameters): 0.59

===================================================================
[ 0.76470588  0.23529412]
===================================================================
Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.128476190476 |  0.181045690228 | {'n_estimators': 2}  |        5        |
|  0.328292374292 |  0.135802722395 | {'n_estimators': 3}  |        1        |
|  0.212027972028 |  0.145635858395 | {'n_estimators': 5}  |        3        |
|  0.227505827506 |  0.200939895232 | {'n_estimators': 10} |        2        |
|      0.048      | 0.0978862313388 | {'n_estimators': 20} |        7        |
|  0.138846560847 |  0.151339357508 | {'n_estimators': 40} |        4        |
| 0.0975420875421 |  0.124430323364 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.76      0.72        33
          1       0.47      0.39      0.42        18

avg / total       0.61      0.63      0.62        51


Average accuracy on test set (using best parameters): 0.63

===================================================================
[ 0.69444444  0.46666667]
===================================================================
Evaluating MLPClassifier
# Tuning hyper-parameters for f1

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        18       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        18       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
| 0.0266666666667 | 0.0771722460186 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        17       |
| 0.0285714285714 | 0.0857142857143 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
| 0.0571428571429 |  0.110040190555 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        18       |
|  0.103492063492 |  0.160975860033 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.184126984127 |  0.159173982689 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.242349206349 |  0.187241566924 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.112121212121 |  0.177576791806 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.372390572391 |  0.150797702804 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.165137085137 |  0.167583147623 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.137912457912 |  0.18675303243  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        10       |
| 0.0804761904762 |  0.165018380066 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.109047619048 |  0.173145502625 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.186084656085 |  0.163696221908 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
|  0.214603174603 |  0.147959668464 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.27063011063  |  0.121820045714 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.284603174603 |  0.129136780408 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.298941798942 |  0.143319059423 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.94      0.77        33
          1       0.33      0.06      0.10        18

avg / total       0.54      0.63      0.53        51


Average accuracy on test set (using best parameters): 0.63

===================================================================
[ 0.64583333  0.33333333]
===================================================================
Evaluating SVC
# Tuning hyper-parameters for f1

Fitting 10 folds for each of 128 candidates, totalling 1280 fits
Grid scores on validation set:

+-----------------+-----------------+------------------------------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                                    params                                    | test_rank_score |
+-----------------+-----------------+------------------------------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 0.001, 'gamma': 0.001}               |        63       |
|       0.0       |       0.0       |                {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.001}                 |        63       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 0.001, 'gamma': 0.01}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.01}                 |        63       |
|       0.0       |       0.0       |        {'kernel': 'linear', 'C': 0.001, 'gamma': 0.10000000000000001}        |        63       |
|       0.0       |       0.0       |         {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.10000000000000001}          |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 0.001, 'gamma': 1.0}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 0.001, 'gamma': 1.0}                  |        63       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 0.001, 'gamma': 10.0}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 0.001, 'gamma': 10.0}                 |        63       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 0.001, 'gamma': 100.0}               |        63       |
|       0.0       |       0.0       |                {'kernel': 'rbf', 'C': 0.001, 'gamma': 100.0}                 |        63       |
|       0.0       |       0.0       |              {'kernel': 'linear', 'C': 0.001, 'gamma': 1000.0}               |        63       |
|       0.0       |       0.0       |                {'kernel': 'rbf', 'C': 0.001, 'gamma': 1000.0}                |        63       |
|       0.0       |       0.0       |              {'kernel': 'linear', 'C': 0.001, 'gamma': 10000.0}              |        63       |
|       0.0       |       0.0       |               {'kernel': 'rbf', 'C': 0.001, 'gamma': 10000.0}                |        63       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 0.01, 'gamma': 0.001}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.001}                 |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 0.01, 'gamma': 0.01}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.01}                  |        63       |
|       0.0       |       0.0       |        {'kernel': 'linear', 'C': 0.01, 'gamma': 0.10000000000000001}         |        63       |
|       0.0       |       0.0       |          {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.10000000000000001}          |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 0.01, 'gamma': 1.0}                 |        63       |
|       0.0       |       0.0       |                  {'kernel': 'rbf', 'C': 0.01, 'gamma': 1.0}                  |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 0.01, 'gamma': 10.0}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 10.0}                  |        63       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 0.01, 'gamma': 100.0}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 0.01, 'gamma': 100.0}                 |        63       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 0.01, 'gamma': 1000.0}               |        63       |
|       0.0       |       0.0       |                {'kernel': 'rbf', 'C': 0.01, 'gamma': 1000.0}                 |        63       |
|       0.0       |       0.0       |              {'kernel': 'linear', 'C': 0.01, 'gamma': 10000.0}               |        63       |
|       0.0       |       0.0       |                {'kernel': 'rbf', 'C': 0.01, 'gamma': 10000.0}                |        63       |
|       0.0       |       0.0       |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 0.001}        |        63       |
|       0.0       |       0.0       |         {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.001}          |        63       |
|       0.0       |       0.0       |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 0.01}         |        63       |
|       0.0       |       0.0       |          {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.01}          |        63       |
|       0.0       |       0.0       | {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        63       |
|       0.0       |       0.0       |  {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}   |        63       |
|       0.0       |       0.0       |         {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 1.0}         |        63       |
|       0.0       |       0.0       |          {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 1.0}           |        63       |
|       0.0       |       0.0       |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 10.0}         |        63       |
|       0.0       |       0.0       |          {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 10.0}          |        63       |
|       0.0       |       0.0       |        {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 100.0}        |        63       |
|       0.0       |       0.0       |         {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 100.0}          |        63       |
|       0.0       |       0.0       |       {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 1000.0}        |        63       |
|       0.0       |       0.0       |         {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 1000.0}         |        63       |
|       0.0       |       0.0       |       {'kernel': 'linear', 'C': 0.10000000000000001, 'gamma': 10000.0}       |        63       |
|       0.0       |       0.0       |        {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 10000.0}         |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 1.0, 'gamma': 0.001}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}                  |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 1.0, 'gamma': 0.01}                 |        63       |
|       0.0       |       0.0       |                  {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}                  |        63       |
|       0.0       |       0.0       |         {'kernel': 'linear', 'C': 1.0, 'gamma': 0.10000000000000001}         |        63       |
|       0.0       |       0.0       |          {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.10000000000000001}           |        63       |
|       0.0       |       0.0       |                 {'kernel': 'linear', 'C': 1.0, 'gamma': 1.0}                 |        63       |
|       0.0       |       0.0       |                  {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}                   |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 1.0, 'gamma': 10.0}                 |        63       |
|       0.0       |       0.0       |                  {'kernel': 'rbf', 'C': 1.0, 'gamma': 10.0}                  |        63       |
|       0.0       |       0.0       |                {'kernel': 'linear', 'C': 1.0, 'gamma': 100.0}                |        63       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 100.0}                  |        63       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 1.0, 'gamma': 1000.0}                |        63       |
|      0.025      |      0.075      |                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 1000.0}                 |        61       |
|       0.0       |       0.0       |               {'kernel': 'linear', 'C': 1.0, 'gamma': 10000.0}               |        63       |
|       0.0       |       0.0       |                {'kernel': 'rbf', 'C': 1.0, 'gamma': 10000.0}                 |        63       |
|  0.162751322751 |  0.13276126542  |               {'kernel': 'linear', 'C': 10.0, 'gamma': 0.001}                |        36       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}                 |        63       |
|  0.162751322751 |  0.13276126542  |                {'kernel': 'linear', 'C': 10.0, 'gamma': 0.01}                |        36       |
|       0.0       |       0.0       |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}                  |        63       |
|  0.162751322751 |  0.13276126542  |        {'kernel': 'linear', 'C': 10.0, 'gamma': 0.10000000000000001}         |        36       |
| 0.0590476190476 |  0.115689787726 |          {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.10000000000000001}          |        47       |
|  0.162751322751 |  0.13276126542  |                {'kernel': 'linear', 'C': 10.0, 'gamma': 1.0}                 |        36       |
|  0.162666666667 |  0.171758522368 |                  {'kernel': 'rbf', 'C': 10.0, 'gamma': 1.0}                  |        44       |
|  0.162751322751 |  0.13276126542  |                {'kernel': 'linear', 'C': 10.0, 'gamma': 10.0}                |        36       |
| 0.0779120879121 |  0.121993536507 |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 10.0}                  |        46       |
|  0.162751322751 |  0.13276126542  |               {'kernel': 'linear', 'C': 10.0, 'gamma': 100.0}                |        36       |
| 0.0222222222222 | 0.0666666666667 |                 {'kernel': 'rbf', 'C': 10.0, 'gamma': 100.0}                 |        62       |
|  0.162751322751 |  0.13276126542  |               {'kernel': 'linear', 'C': 10.0, 'gamma': 1000.0}               |        36       |
| 0.0554761904762 |  0.108994840628 |                {'kernel': 'rbf', 'C': 10.0, 'gamma': 1000.0}                 |        52       |
|  0.162751322751 |  0.13276126542  |              {'kernel': 'linear', 'C': 10.0, 'gamma': 10000.0}               |        36       |
| 0.0590476190476 |  0.115689787726 |                {'kernel': 'rbf', 'C': 10.0, 'gamma': 10000.0}                |        47       |
|  0.25912975913  |  0.196515662687 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 0.001}               |        24       |
|       0.0       |       0.0       |                {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}                 |        63       |
|  0.25912975913  |  0.196515662687 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 0.01}                |        24       |
| 0.0304761904762 | 0.0881968525927 |                 {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}                 |        59       |
|  0.25912975913  |  0.196515662687 |        {'kernel': 'linear', 'C': 100.0, 'gamma': 0.10000000000000001}        |        24       |
|  0.164713804714 |  0.185263769237 |         {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.10000000000000001}          |        35       |
|  0.25912975913  |  0.196515662687 |                {'kernel': 'linear', 'C': 100.0, 'gamma': 1.0}                |        24       |
|  0.263760683761 |  0.130350579185 |                 {'kernel': 'rbf', 'C': 100.0, 'gamma': 1.0}                  |        22       |
|  0.25912975913  |  0.196515662687 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 10.0}                |        24       |
|  0.152705627706 |  0.144340853745 |                 {'kernel': 'rbf', 'C': 100.0, 'gamma': 10.0}                 |        45       |
|  0.25912975913  |  0.196515662687 |               {'kernel': 'linear', 'C': 100.0, 'gamma': 100.0}               |        24       |
| 0.0526984126984 |  0.104252730886 |                {'kernel': 'rbf', 'C': 100.0, 'gamma': 100.0}                 |        56       |
|  0.25912975913  |  0.196515662687 |              {'kernel': 'linear', 'C': 100.0, 'gamma': 1000.0}               |        24       |
| 0.0554761904762 |  0.108994840628 |                {'kernel': 'rbf', 'C': 100.0, 'gamma': 1000.0}                |        52       |
|  0.25912975913  |  0.196515662687 |              {'kernel': 'linear', 'C': 100.0, 'gamma': 10000.0}              |        24       |
| 0.0590476190476 |  0.115689787726 |               {'kernel': 'rbf', 'C': 100.0, 'gamma': 10000.0}                |        47       |
|  0.327121064121 |  0.121898597252 |              {'kernel': 'linear', 'C': 1000.0, 'gamma': 0.001}               |        10       |
| 0.0304761904762 | 0.0881968525927 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}                |        59       |
|  0.327121064121 |  0.121898597252 |               {'kernel': 'linear', 'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.204713804714 |  0.188535301243 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}                 |        33       |
|  0.327121064121 |  0.121898597252 |       {'kernel': 'linear', 'C': 1000.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.266411366411 |  0.121502054489 |         {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.10000000000000001}         |        20       |
|  0.327121064121 |  0.121898597252 |               {'kernel': 'linear', 'C': 1000.0, 'gamma': 1.0}                |        10       |
|  0.280060680061 |  0.114894874199 |                 {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1.0}                 |        19       |
|  0.327121064121 |  0.121898597252 |               {'kernel': 'linear', 'C': 1000.0, 'gamma': 10.0}               |        10       |
|  0.262856402856 |  0.163796308042 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 10.0}                 |        23       |
|  0.327121064121 |  0.121898597252 |              {'kernel': 'linear', 'C': 1000.0, 'gamma': 100.0}               |        10       |
| 0.0526984126984 |  0.104252730886 |                {'kernel': 'rbf', 'C': 1000.0, 'gamma': 100.0}                |        56       |
|  0.327121064121 |  0.121898597252 |              {'kernel': 'linear', 'C': 1000.0, 'gamma': 1000.0}              |        10       |
| 0.0554761904762 |  0.108994840628 |               {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1000.0}                |        52       |
|  0.327121064121 |  0.121898597252 |             {'kernel': 'linear', 'C': 1000.0, 'gamma': 10000.0}              |        10       |
| 0.0590476190476 |  0.115689787726 |               {'kernel': 'rbf', 'C': 1000.0, 'gamma': 10000.0}               |        47       |
|  0.351074074074 |  0.126092083209 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 0.001}              |        1        |
|  0.197037037037 |  0.179655096507 |               {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}                |        34       |
|  0.351074074074 |  0.126092083209 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 0.01}               |        1        |
|  0.254841103341 |  0.164339216058 |                {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}                |        32       |
|  0.351074074074 |  0.126092083209 |       {'kernel': 'linear', 'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.28900997151  |  0.108106777859 |        {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.351074074074 |  0.126092083209 |               {'kernel': 'linear', 'C': 10000.0, 'gamma': 1.0}               |        1        |
|  0.330472120472 |   0.1243990363  |                {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1.0}                 |        9        |
|  0.351074074074 |  0.126092083209 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.265634180634 |  0.163318491068 |                {'kernel': 'rbf', 'C': 10000.0, 'gamma': 10.0}                |        21       |
|  0.351074074074 |  0.126092083209 |              {'kernel': 'linear', 'C': 10000.0, 'gamma': 100.0}              |        1        |
| 0.0526984126984 |  0.104252730886 |               {'kernel': 'rbf', 'C': 10000.0, 'gamma': 100.0}                |        56       |
|  0.351074074074 |  0.126092083209 |             {'kernel': 'linear', 'C': 10000.0, 'gamma': 1000.0}              |        1        |
| 0.0554761904762 |  0.108994840628 |               {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1000.0}               |        52       |
|  0.351074074074 |  0.126092083209 |             {'kernel': 'linear', 'C': 10000.0, 'gamma': 10000.0}             |        1        |
| 0.0590476190476 |  0.115689787726 |              {'kernel': 'rbf', 'C': 10000.0, 'gamma': 10000.0}               |        47       |
+-----------------+-----------------+------------------------------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'kernel': 'linear', 'C': 10000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.68      0.70        34
          1       0.42      0.47      0.44        17

avg / total       0.62      0.61      0.61        51


Average accuracy on test set (using best parameters): 0.61

===================================================================
[ 0.71875     0.42105263]
===================================================================

Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.516477146042 | 0.0218143560652 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      1.00      0.72        29
          1       0.00      0.00      0.00        22

avg / total       0.32      0.57      0.41        51


Accuracy on test set (using best parameters): 0.57

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.478059142096 | 0.0845827618783 |  {'n_neighbors': 3} |        4        |
|  0.498759399296 |  0.103541074492 |  {'n_neighbors': 5} |        2        |
|  0.518204479387 | 0.0864733159138 | {'n_neighbors': 11} |        1        |
|  0.495828827669 | 0.0952162017674 | {'n_neighbors': 21} |        3        |
|  0.470606687998 | 0.0628765592786 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.81      0.76        37
          1       0.22      0.14      0.17        14

avg / total       0.58      0.63      0.60        51


Accuracy on test set (using best parameters): 0.63

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.520965542975 | 0.0753628023137 | {'n_estimators': 2}  |        5        |
|  0.488329999893 |  0.114890714819 | {'n_estimators': 3}  |        7        |
|  0.520679501785 |  0.114739562972 | {'n_estimators': 5}  |        6        |
|  0.527138528139 | 0.0739098222809 | {'n_estimators': 10} |        4        |
|  0.583618190183 |  0.120265706958 | {'n_estimators': 20} |        2        |
|  0.568171680849 | 0.0832498605627 | {'n_estimators': 40} |        3        |
|  0.598312856734 |  0.117461341422 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.86      0.78        36
          1       0.38      0.20      0.26        15

avg / total       0.62      0.67      0.63        51


Accuracy on test set (using best parameters): 0.67

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.427157575758 | 0.0244170789663 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        18       |
|  0.423896706192 | 0.0233006619245 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        19       |
|  0.440542668925 | 0.0531049542937 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        12       |
|  0.43283475333  | 0.0331673918807 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|  0.423896706192 | 0.0233006619245 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.427454018445 | 0.0189060355342 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        17       |
|  0.44564963925  | 0.0672205963511 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        9        |
|  0.444820084907 |  0.047871070956 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.496033093552 | 0.0858705260166 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        1        |
|  0.474085411664 | 0.0644032574766 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.416647862079 | 0.0818706401937 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        21       |
|  0.451903273335 | 0.0761293511784 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        8        |
|  0.491165096342 | 0.0983201290312 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.463965208648 | 0.0872956019418 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        6        |
|  0.459961499048 | 0.0987481555284 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        7        |
|  0.44409745488  | 0.0766536281382 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.475223240747 | 0.0732937684443 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.431449618777 | 0.0536802584412 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        16       |
|  0.439042481426 | 0.0696803450476 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        13       |
|  0.432542919069 | 0.0714832174896 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        15       |
|  0.485989133673 | 0.0518296180572 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.80      0.90      0.84        39
          1       0.43      0.25      0.32        12

avg / total       0.71      0.75      0.72        51


Accuracy on test set (using best parameters): 0.75

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.499620958751 | 0.0195823941617 |        {'C': 0.001}        |        5        |
|  0.499620958751 | 0.0195823941617 |        {'C': 0.01}         |        5        |
|  0.499620958751 | 0.0195823941617 | {'C': 0.10000000000000001} |        5        |
|  0.499620958751 | 0.0195823941617 |         {'C': 1.0}         |        5        |
|  0.531506947159 | 0.0803899367319 |        {'C': 10.0}         |        3        |
|  0.586092054145 |  0.123573166032 |        {'C': 100.0}        |        1        |
|  0.511080213904 |  0.116715817031 |       {'C': 1000.0}        |        4        |
|  0.552147026005 |  0.136201441967 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.77      0.70        31
          1       0.46      0.30      0.36        20

avg / total       0.56      0.59      0.57        51


Accuracy on test set (using best parameters): 0.59

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.474715719064 | 0.0219487777767 |               {'C': 0.001, 'gamma': 0.001}               |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 0.001, 'gamma': 0.01}                |        22       |
|  0.474715719064 | 0.0219487777767 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        22       |
|  0.474715719064 | 0.0219487777767 |                {'C': 0.001, 'gamma': 1.0}                |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 0.001, 'gamma': 10.0}                |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 0.001, 'gamma': 100.0}               |        22       |
|  0.474715719064 | 0.0219487777767 |              {'C': 0.001, 'gamma': 1000.0}               |        22       |
|  0.474715719064 | 0.0219487777767 |              {'C': 0.001, 'gamma': 10000.0}              |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 0.01, 'gamma': 0.001}                |        22       |
|  0.474715719064 | 0.0219487777767 |                {'C': 0.01, 'gamma': 0.01}                |        22       |
|  0.474715719064 | 0.0219487777767 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        22       |
|  0.474715719064 | 0.0219487777767 |                {'C': 0.01, 'gamma': 1.0}                 |        22       |
|  0.474715719064 | 0.0219487777767 |                {'C': 0.01, 'gamma': 10.0}                |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 0.01, 'gamma': 100.0}                |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 0.01, 'gamma': 1000.0}               |        22       |
|  0.474715719064 | 0.0219487777767 |              {'C': 0.01, 'gamma': 10000.0}               |        22       |
|  0.474715719064 | 0.0219487777767 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        22       |
|  0.474715719064 | 0.0219487777767 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        22       |
|  0.474715719064 | 0.0219487777767 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        22       |
|  0.474715719064 | 0.0219487777767 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        22       |
|  0.474715719064 | 0.0219487777767 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        22       |
|  0.474715719064 | 0.0219487777767 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        22       |
|  0.474715719064 | 0.0219487777767 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        22       |
|  0.474715719064 | 0.0219487777767 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        22       |
|  0.474715719064 | 0.0219487777767 |                {'C': 1.0, 'gamma': 0.001}                |        22       |
|  0.474715719064 | 0.0219487777767 |                {'C': 1.0, 'gamma': 0.01}                 |        22       |
|  0.474715719064 | 0.0219487777767 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        22       |
|  0.474715719064 | 0.0219487777767 |                 {'C': 1.0, 'gamma': 1.0}                 |        22       |
|  0.467878112226 | 0.0281162060595 |                {'C': 1.0, 'gamma': 10.0}                 |        63       |
|  0.471454849498 | 0.0271778908478 |                {'C': 1.0, 'gamma': 100.0}                |        59       |
|  0.474715719064 | 0.0219487777767 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 1.0, 'gamma': 10000.0}               |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 10.0, 'gamma': 0.001}                |        22       |
|  0.474715719064 | 0.0219487777767 |                {'C': 10.0, 'gamma': 0.01}                |        22       |
|  0.471433667781 | 0.0230700521642 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        60       |
|  0.530376528802 |  0.103659915229 |                {'C': 10.0, 'gamma': 1.0}                 |        4        |
|  0.455165231532 |  0.104201229261 |                {'C': 10.0, 'gamma': 10.0}                |        64       |
|  0.498205948641 | 0.0819544756518 |               {'C': 10.0, 'gamma': 100.0}                |        8        |
|  0.480113509679 | 0.0346450059456 |               {'C': 10.0, 'gamma': 1000.0}               |        18       |
|  0.474715719064 | 0.0219487777767 |              {'C': 10.0, 'gamma': 10000.0}               |        22       |
|  0.474715719064 | 0.0219487777767 |               {'C': 100.0, 'gamma': 0.001}               |        22       |
|  0.471433667781 | 0.0230700521642 |               {'C': 100.0, 'gamma': 0.01}                |        60       |
|  0.511298903995 |  0.087373806465 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.490501724177 |  0.117160837448 |                {'C': 100.0, 'gamma': 1.0}                |        15       |
|  0.487953379276 | 0.0937283063413 |               {'C': 100.0, 'gamma': 10.0}                |        16       |
|  0.493453116931 | 0.0909096823158 |               {'C': 100.0, 'gamma': 100.0}               |        11       |
|  0.480113509679 | 0.0346450059456 |              {'C': 100.0, 'gamma': 1000.0}               |        18       |
|  0.474715719064 | 0.0219487777767 |              {'C': 100.0, 'gamma': 10000.0}              |        22       |
|  0.471433667781 | 0.0230700521642 |              {'C': 1000.0, 'gamma': 0.001}               |        60       |
|  0.535389813085 | 0.0995190259026 |               {'C': 1000.0, 'gamma': 0.01}               |        2        |
|  0.487773150988 |  0.13868793052  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.540244932914 |  0.132199619449 |               {'C': 1000.0, 'gamma': 1.0}                |        1        |
|  0.496333455121 | 0.0720545742435 |               {'C': 1000.0, 'gamma': 10.0}               |        9        |
|  0.493453116931 | 0.0909096823158 |              {'C': 1000.0, 'gamma': 100.0}               |        11       |
|  0.480113509679 | 0.0346450059456 |              {'C': 1000.0, 'gamma': 1000.0}              |        18       |
|  0.474715719064 | 0.0219487777767 |             {'C': 1000.0, 'gamma': 10000.0}              |        22       |
|  0.527224181615 |  0.101017892422 |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.492293141125 |  0.133519380299 |              {'C': 10000.0, 'gamma': 0.01}               |        14       |
|  0.510992039723 |  0.10650652182  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        7        |
|  0.534263011842 |  0.141244567018 |               {'C': 10000.0, 'gamma': 1.0}               |        3        |
|  0.496333455121 | 0.0720545742435 |              {'C': 10000.0, 'gamma': 10.0}               |        9        |
|  0.493453116931 | 0.0909096823158 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
|  0.480113509679 | 0.0346450059456 |             {'C': 10000.0, 'gamma': 1000.0}              |        18       |
|  0.474715719064 | 0.0219487777767 |             {'C': 10000.0, 'gamma': 10000.0}             |        22       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.71      0.68        34
          1       0.29      0.24      0.26        17

avg / total       0.53      0.55      0.54        51


Accuracy on test set (using best parameters): 0.55


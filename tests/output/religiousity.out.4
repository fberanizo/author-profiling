Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.499620958751 | 0.0195823941617 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        31
          1       0.00      0.00      0.00        20

avg / total       0.37      0.61      0.46        51


Accuracy on test set (using best parameters): 0.61

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.48006675368  | 0.0763835708853 |  {'n_neighbors': 3} |        3        |
|  0.49028454168  | 0.0730709868712 |  {'n_neighbors': 5} |        2        |
|  0.517207792208 |  0.12049592902  | {'n_neighbors': 11} |        1        |
|  0.469533900882 | 0.0347074611063 | {'n_neighbors': 21} |        5        |
|  0.479672240803 | 0.0218035032066 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.85      0.72        33
          1       0.17      0.06      0.08        18

avg / total       0.46      0.57      0.49        51


Accuracy on test set (using best parameters): 0.57

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.535707384403 | 0.0916776147165 | {'n_estimators': 2}  |        2        |
|  0.523681417654 |  0.131657083025 | {'n_estimators': 3}  |        4        |
|  0.483841695807 |  0.154004133362 | {'n_estimators': 5}  |        7        |
|  0.536655809484 |  0.115702847092 | {'n_estimators': 10} |        1        |
|  0.487737499216 |  0.078187341493 | {'n_estimators': 20} |        6        |
|  0.488754117397 |  0.109128056204 | {'n_estimators': 40} |        5        |
|  0.533407992973 |  0.143349436231 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.83      0.73        35
          1       0.14      0.06      0.09        16

avg / total       0.50      0.59      0.53        51


Accuracy on test set (using best parameters): 0.59

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.474715719064 | 0.0219487777767 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|  0.474715719064 | 0.0219487777767 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        16       |
|  0.474715719064 | 0.0219487777767 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|  0.474715719064 | 0.0219487777767 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
|  0.467878112226 | 0.0281162060595 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        21       |
|  0.478604607952 | 0.0206307194859 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.474715719064 | 0.0219487777767 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.510785760134 | 0.0488355853875 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        9        |
|  0.520802047939 | 0.0799963442555 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        7        |
|  0.494020679803 | 0.0578286408225 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
|  0.521972886762 | 0.0824475234799 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.505761092708 | 0.0533234861851 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.510109014471 |  0.107963350464 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.488040770823 | 0.0420541430256 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        14       |
|  0.493511778077 | 0.0473677785499 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.511345943911 |  0.059678852446 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.560595771378 |  0.107428943901 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.539665641548 |  0.115283175987 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.585464141249 |  0.12945999577  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        1        |
|  0.583204777424 |  0.102689347596 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.570614174325 |  0.135439557244 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.74      0.69        34
          1       0.31      0.24      0.27        17

avg / total       0.54      0.57      0.55        51


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.508049052397 | 0.0223763470728 |        {'C': 0.001}        |        1        |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.01}         |        1        |
|  0.508049052397 | 0.0223763470728 | {'C': 0.10000000000000001} |        1        |
|  0.508049052397 | 0.0223763470728 |         {'C': 1.0}         |        1        |
|  0.484541603324 | 0.0260075353454 |        {'C': 10.0}         |        5        |
|  0.481255490505 |  0.10687652546  |        {'C': 100.0}        |        6        |
|  0.432868612869 |  0.141605383783 |       {'C': 1000.0}        |        8        |
|  0.447438888368 | 0.0840361875113 |       {'C': 10000.0}       |        7        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      1.00      0.74        30
          1       0.00      0.00      0.00        21

avg / total       0.35      0.59      0.44        51


Accuracy on test set (using best parameters): 0.59

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.001}               |        15       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.01}                |        15       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.001, 'gamma': 1.0}                |        15       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 10.0}                |        15       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 100.0}               |        15       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 1000.0}               |        15       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 10000.0}              |        15       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 0.001}                |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 0.01}                |        15       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 1.0}                 |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 10.0}                |        15       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 100.0}                |        15       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 1000.0}               |        15       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.01, 'gamma': 10000.0}               |        15       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        15       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        15       |
|  0.516477146042 | 0.0218143560652 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        15       |
|  0.516477146042 | 0.0218143560652 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        15       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        15       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        15       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        15       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.001}                |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.01}                 |        15       |
|  0.516477146042 | 0.0218143560652 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        15       |
|  0.513143812709 | 0.0215288538618 |                 {'C': 1.0, 'gamma': 1.0}                 |        53       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 10.0}                 |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 100.0}                |        15       |
|  0.516477146042 | 0.0218143560652 |               {'C': 1.0, 'gamma': 1000.0}                |        15       |
|  0.51319509476  | 0.0282925941091 |               {'C': 1.0, 'gamma': 10000.0}               |        48       |
|  0.516477146042 | 0.0218143560652 |               {'C': 10.0, 'gamma': 0.001}                |        15       |
|  0.516477146042 | 0.0218143560652 |                {'C': 10.0, 'gamma': 0.01}                |        15       |
|  0.548334563987 | 0.0601463501783 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        7        |
|  0.563993997951 | 0.0826112774766 |                {'C': 10.0, 'gamma': 1.0}                 |        4        |
|  0.489434525048 |  0.132346784138 |                {'C': 10.0, 'gamma': 10.0}                |        63       |
|  0.518606060606 | 0.0748693920126 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.506306205871 |  0.036024660132 |               {'C': 10.0, 'gamma': 1000.0}               |        55       |
|  0.51319509476  | 0.0282925941091 |              {'C': 10.0, 'gamma': 10000.0}               |        48       |
|  0.516477146042 | 0.0218143560652 |               {'C': 100.0, 'gamma': 0.001}               |        15       |
|  0.56166789732  | 0.0694085774408 |               {'C': 100.0, 'gamma': 0.01}                |        5        |
|  0.567276049233 | 0.0785275060393 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.518619479935 |  0.10960385768  |                {'C': 100.0, 'gamma': 1.0}                |        13       |
|  0.49605304874  | 0.0970978970999 |               {'C': 100.0, 'gamma': 10.0}                |        61       |
|  0.543732354602 | 0.0790833210186 |               {'C': 100.0, 'gamma': 100.0}               |        9        |
|  0.506306205871 |  0.036024660132 |              {'C': 100.0, 'gamma': 1000.0}               |        55       |
|  0.51319509476  | 0.0282925941091 |              {'C': 100.0, 'gamma': 10000.0}              |        48       |
|  0.553303508086 | 0.0672455216832 |              {'C': 1000.0, 'gamma': 0.001}               |        6        |
|  0.594007128138 | 0.0891975989149 |               {'C': 1000.0, 'gamma': 0.01}               |        1        |
|  0.525781973599 | 0.0902431851834 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.500461469502 | 0.0793481755544 |               {'C': 1000.0, 'gamma': 1.0}                |        59       |
|  0.478321044156 | 0.0965320892469 |               {'C': 1000.0, 'gamma': 10.0}               |        64       |
|  0.543732354602 | 0.0790833210186 |              {'C': 1000.0, 'gamma': 100.0}               |        9        |
|  0.506306205871 |  0.036024660132 |              {'C': 1000.0, 'gamma': 1000.0}              |        55       |
|  0.51319509476  | 0.0282925941091 |             {'C': 1000.0, 'gamma': 10000.0}              |        48       |
|  0.594007128138 | 0.0891975989149 |              {'C': 10000.0, 'gamma': 0.001}              |        1        |
|  0.54525801218  |  0.11316120128  |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|  0.509195463406 |  0.102646760801 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        54       |
|  0.497920733091 |  0.138912347577 |               {'C': 10000.0, 'gamma': 1.0}               |        60       |
|  0.49321733627  | 0.0814530783629 |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.543732354602 | 0.0790833210186 |              {'C': 10000.0, 'gamma': 100.0}              |        9        |
|  0.506306205871 |  0.036024660132 |             {'C': 10000.0, 'gamma': 1000.0}              |        55       |
|  0.51319509476  | 0.0282925941091 |             {'C': 10000.0, 'gamma': 10000.0}             |        48       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.53      0.79      0.64        29
          1       0.25      0.09      0.13        22

avg / total       0.41      0.49      0.42        51


Accuracy on test set (using best parameters): 0.49


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.482954292085 | 0.0192570883785 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      1.00      0.79        33
          1       0.00      0.00      0.00        18

avg / total       0.42      0.65      0.51        51


Accuracy on test set (using best parameters): 0.65

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.513945976051 |  0.138245704125 |  {'n_neighbors': 3} |        5        |
|  0.579385576708 |  0.112469470602 |  {'n_neighbors': 5} |        1        |
|  0.536067507372 | 0.0881621670632 | {'n_neighbors': 11} |        3        |
|  0.546245976246 | 0.0658137726373 | {'n_neighbors': 21} |        2        |
|  0.516477146042 | 0.0218143560652 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.93      0.76        29
          1       0.78      0.32      0.45        22

avg / total       0.70      0.67      0.63        51


Accuracy on test set (using best parameters): 0.67

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.443584352845 | 0.0622564138529 | {'n_estimators': 2}  |        5        |
|  0.435743504517 |  0.145567180517 | {'n_estimators': 3}  |        6        |
|  0.460808283335 | 0.0862488867274 | {'n_estimators': 5}  |        3        |
|  0.507811594203 | 0.0772029750702 | {'n_estimators': 10} |        1        |
|  0.494671923172 |  0.111275113844 | {'n_estimators': 20} |        2        |
|  0.447308543647 |  0.10890855834  | {'n_estimators': 40} |        4        |
|  0.418149372113 | 0.0745400454742 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.77      0.75      0.76        36
          1       0.44      0.47      0.45        15

avg / total       0.67      0.67      0.67        51


Accuracy on test set (using best parameters): 0.67

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.431273593074 | 0.0335235424147 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        21       |
|  0.43990995671  | 0.0460278720712 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.458402020202 |  0.074628038695 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        17       |
|  0.471260606061 | 0.0553739035635 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
|  0.444273593074 | 0.0559617233126 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.450624242424 | 0.0327417946777 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        18       |
|  0.472391919192 | 0.0655396312812 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.513255536734 | 0.0683624201169 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        8        |
|  0.526388216919 | 0.0931634986222 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        4        |
|  0.523004605888 |  0.119196990884 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.530297632192 | 0.0893742190276 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.495310011626 |  0.14958913391  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        13       |
|  0.544678027625 |  0.127534950834 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        1        |
|  0.481139809279 |  0.109790199841 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        14       |
|  0.524280632411 | 0.0836151259761 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        5        |
|  0.513154526633 | 0.0885346962248 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.517579072847 |  0.106859565581 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
|  0.533915064341 |  0.103692865487 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.511692842118 |  0.105964796268 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        10       |
|  0.496066615815 |  0.130988040782 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        12       |
|  0.501728383871 |  0.112459742125 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        11       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.71      0.71        38
          1       0.15      0.15      0.15        13

avg / total       0.57      0.57      0.57        51


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.508049052397 | 0.0223763470728 |        {'C': 0.001}        |        3        |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.01}         |        3        |
|  0.508049052397 | 0.0223763470728 | {'C': 0.10000000000000001} |        3        |
|  0.508049052397 | 0.0223763470728 |         {'C': 1.0}         |        3        |
|  0.521048661483 | 0.0582335308939 |        {'C': 10.0}         |        2        |
|  0.526391340671 | 0.0785896450661 |        {'C': 100.0}        |        1        |
|  0.496123746681 |  0.124711213113 |       {'C': 1000.0}        |        7        |
|  0.468846868531 |  0.118491752443 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.63      0.60        30
          1       0.39      0.33      0.36        21

avg / total       0.50      0.51      0.50        51


Accuracy on test set (using best parameters): 0.51

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.533333333333 |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        26       |
|  0.533333333333 |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        26       |
|  0.533333333333 |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        26       |
|  0.533333333333 |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        26       |
|  0.533333333333 |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        26       |
|  0.533333333333 |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        26       |
|  0.533333333333 |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        26       |
|  0.533333333333 |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        26       |
|  0.533333333333 |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        26       |
|  0.533333333333 |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        26       |
|  0.533333333333 |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        26       |
|  0.533333333333 |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        26       |
|  0.533333333333 |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        26       |
|  0.533333333333 |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        26       |
|  0.533333333333 |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        26       |
|  0.533333333333 |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        26       |
|  0.533333333333 |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        26       |
|  0.533333333333 |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        26       |
|  0.533333333333 |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        26       |
|  0.533333333333 |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        26       |
|  0.533333333333 |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        26       |
|  0.533333333333 |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        26       |
|  0.533333333333 |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        26       |
|  0.533333333333 |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        26       |
|  0.533333333333 |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        26       |
|  0.533333333333 |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        26       |
|  0.533333333333 |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.533333333333 |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        26       |
|       0.53      |       0.01      |                {'C': 1.0, 'gamma': 10.0}                 |        58       |
|  0.544741200828 | 0.0542430776021 |                {'C': 1.0, 'gamma': 100.0}                |        24       |
|  0.565031055901 | 0.0579788851504 |               {'C': 1.0, 'gamma': 1000.0}                |        21       |
|  0.546666666667 |       0.04      |               {'C': 1.0, 'gamma': 10000.0}               |        23       |
|  0.533333333333 |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        26       |
|  0.533333333333 |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        26       |
|  0.543333333333 | 0.0422952584682 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        25       |
|  0.570717108978 | 0.0786629813524 |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.52592069766  | 0.0994101245527 |                {'C': 10.0, 'gamma': 10.0}                |        60       |
|  0.584741200828 | 0.0759145269464 |               {'C': 10.0, 'gamma': 100.0}                |        6        |
|  0.568364389234 | 0.0550273636531 |               {'C': 10.0, 'gamma': 1000.0}               |        17       |
|  0.573333333333 | 0.0611010092661 |              {'C': 10.0, 'gamma': 10000.0}               |        10       |
|  0.533333333333 |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        26       |
|       0.53      |       0.01      |               {'C': 100.0, 'gamma': 0.01}                |        58       |
|  0.582971955581 | 0.0695083301429 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.508661145618 |  0.104450197684 |                {'C': 100.0, 'gamma': 1.0}                |        62       |
|  0.586122717862 | 0.0845967975826 |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.605031055901 | 0.0675208608597 |               {'C': 100.0, 'gamma': 100.0}               |        1        |
|  0.568364389234 | 0.0550273636531 |              {'C': 100.0, 'gamma': 1000.0}               |        17       |
|  0.573333333333 | 0.0611010092661 |              {'C': 100.0, 'gamma': 10000.0}              |        10       |
|  0.533333333333 |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.582971955581 | 0.0695083301429 |               {'C': 1000.0, 'gamma': 0.01}               |        7        |
|  0.499631709929 | 0.0858649978719 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        64       |
|  0.588111225433 |  0.130790119898 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.573097643098 |  0.103253407377 |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.605031055901 | 0.0675208608597 |              {'C': 1000.0, 'gamma': 100.0}               |        1        |
|  0.568364389234 | 0.0550273636531 |              {'C': 1000.0, 'gamma': 1000.0}              |        17       |
|  0.573333333333 | 0.0611010092661 |             {'C': 1000.0, 'gamma': 10000.0}              |        10       |
|  0.582971955581 | 0.0695083301429 |              {'C': 10000.0, 'gamma': 0.001}              |        7        |
|  0.507119693172 |  0.122923165476 |              {'C': 10000.0, 'gamma': 0.01}               |        63       |
|  0.547363777147 |  0.125849329609 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        22       |
|  0.522018050176 |  0.137606577582 |               {'C': 10000.0, 'gamma': 1.0}               |        61       |
|  0.573097643098 |  0.103253407377 |              {'C': 10000.0, 'gamma': 10.0}               |        14       |
|  0.605031055901 | 0.0675208608597 |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.568364389234 | 0.0550273636531 |             {'C': 10000.0, 'gamma': 1000.0}              |        17       |
|  0.573333333333 | 0.0611010092661 |             {'C': 10000.0, 'gamma': 10000.0}             |        10       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.48      0.78      0.59        27
          1       0.14      0.04      0.06        24

avg / total       0.32      0.43      0.34        51


Accuracy on test set (using best parameters): 0.43


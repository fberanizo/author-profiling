Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.516477146042 | 0.0218143560652 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      1.00      0.72        29
          1       0.00      0.00      0.00        22

avg / total       0.32      0.57      0.41        51


Accuracy on test set (using best parameters): 0.57

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.585496637636 | 0.0977466694134 |  {'n_neighbors': 3} |        1        |
|  0.522590816514 |  0.10940713774  |  {'n_neighbors': 5} |        3        |
|  0.486051687563 |  0.130272974609 | {'n_neighbors': 11} |        5        |
|  0.552943219167 | 0.0926416720606 | {'n_neighbors': 21} |        2        |
|  0.489582108713 |  0.056749434349 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.72      0.72        32
          1       0.53      0.53      0.53        19

avg / total       0.65      0.65      0.65        51


Accuracy on test set (using best parameters): 0.65

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.558401154401 | 0.0937095379298 | {'n_estimators': 2}  |        2        |
|  0.383287819851 | 0.0959159873209 | {'n_estimators': 3}  |        7        |
|  0.507953665415 |  0.152908723659 | {'n_estimators': 5}  |        5        |
|  0.540801054018 |  0.12101413184  | {'n_estimators': 10} |        3        |
|  0.539345755694 |  0.116849083984 | {'n_estimators': 20} |        4        |
|  0.583231193927 |  0.118574662307 | {'n_estimators': 40} |        1        |
|  0.487614844093 | 0.0720551231603 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.91      0.77        34
          1       0.25      0.06      0.10        17

avg / total       0.52      0.63      0.54        51


Accuracy on test set (using best parameters): 0.63

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.493207782556 | 0.0514321617598 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        14       |
|  0.471433667781 | 0.0230700521642 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        20       |
|  0.501441071006 | 0.0653148386777 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        11       |
|  0.474715719064 | 0.0219487777767 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        18       |
|  0.486547751765 | 0.0647380717236 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.501206715989 | 0.0710184882556 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        13       |
|  0.482997292563 | 0.0402271486535 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.50212911726  | 0.0703044579669 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.526233578016 |  0.069519767607 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        7        |
|  0.545011956769 | 0.0987784542659 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.501295510684 | 0.0751291242827 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.472395560961 |  0.038202323315 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.492229929491 | 0.0760894129526 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        15       |
|  0.469885703668 |  0.035489602497 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.520525542091 | 0.0686934636074 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.536046113307 | 0.0893486753837 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        6        |
|  0.503778141005 | 0.0762611552447 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.547229249012 |  0.106607993612 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.574254192794 | 0.0983952428286 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        1        |
|  0.567718651041 | 0.0966161743916 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.569331738437 | 0.0905500883568 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.76      0.70        34
          1       0.27      0.18      0.21        17

avg / total       0.52      0.57      0.54        51


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.466477146042 | 0.0213755483698 |        {'C': 0.001}        |        3        |
|  0.466477146042 | 0.0213755483698 |        {'C': 0.01}         |        3        |
|  0.466477146042 | 0.0213755483698 | {'C': 0.10000000000000001} |        3        |
|  0.466477146042 | 0.0213755483698 |         {'C': 1.0}         |        3        |
|  0.492315365794 | 0.0558714424166 |        {'C': 10.0}         |        1        |
|  0.469123564841 |  0.117007569826 |        {'C': 100.0}        |        2        |
|  0.459729787183 |  0.121111862072 |       {'C': 1000.0}        |        8        |
|  0.463367622402 |  0.10042678564  |       {'C': 10000.0}       |        7        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.73      0.91      0.81        35
          1       0.57      0.25      0.35        16

avg / total       0.68      0.71      0.67        51


Accuracy on test set (using best parameters): 0.71

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.508049052397 | 0.0223763470728 |               {'C': 0.001, 'gamma': 0.001}               |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 0.001, 'gamma': 0.01}                |        18       |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 0.001, 'gamma': 1.0}                |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 0.001, 'gamma': 10.0}                |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 0.001, 'gamma': 100.0}               |        18       |
|  0.508049052397 | 0.0223763470728 |              {'C': 0.001, 'gamma': 1000.0}               |        18       |
|  0.508049052397 | 0.0223763470728 |              {'C': 0.001, 'gamma': 10000.0}              |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 0.01, 'gamma': 0.001}                |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 0.01, 'gamma': 0.01}                |        18       |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 0.01, 'gamma': 1.0}                 |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 0.01, 'gamma': 10.0}                |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 0.01, 'gamma': 100.0}                |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 0.01, 'gamma': 1000.0}               |        18       |
|  0.508049052397 | 0.0223763470728 |              {'C': 0.01, 'gamma': 10000.0}               |        18       |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        18       |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        18       |
|  0.508049052397 | 0.0223763470728 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        18       |
|  0.508049052397 | 0.0223763470728 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        18       |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        18       |
|  0.508049052397 | 0.0223763470728 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        18       |
|  0.508049052397 | 0.0223763470728 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        18       |
|  0.508049052397 | 0.0223763470728 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 1.0, 'gamma': 0.001}                |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 1.0, 'gamma': 0.01}                 |        18       |
|  0.508049052397 | 0.0223763470728 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.508049052397 | 0.0223763470728 |                 {'C': 1.0, 'gamma': 1.0}                 |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.513446843012 | 0.0293151120025 |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|  0.508049052397 | 0.0223763470728 |               {'C': 1.0, 'gamma': 1000.0}                |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 1.0, 'gamma': 10000.0}               |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 10.0, 'gamma': 0.001}                |        18       |
|  0.508049052397 | 0.0223763470728 |                {'C': 10.0, 'gamma': 0.01}                |        18       |
|  0.504715719064 | 0.0207879540939 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        54       |
|  0.553255408038 | 0.0825988464222 |                {'C': 10.0, 'gamma': 1.0}                 |        2        |
|  0.514188419005 | 0.0847045532568 |                {'C': 10.0, 'gamma': 10.0}                |        15       |
|  0.547733522516 |  0.078205108928 |               {'C': 10.0, 'gamma': 100.0}                |        3        |
|  0.501433667781 | 0.0260679990276 |               {'C': 10.0, 'gamma': 1000.0}               |        60       |
|  0.504715719064 | 0.0207879540939 |              {'C': 10.0, 'gamma': 10000.0}               |        54       |
|  0.508049052397 | 0.0223763470728 |               {'C': 100.0, 'gamma': 0.001}               |        18       |
|  0.508049052397 | 0.0223763470728 |               {'C': 100.0, 'gamma': 0.01}                |        18       |
|  0.539333178221 |  0.102213496441 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.521228518071 |  0.110123947522 |                {'C': 100.0, 'gamma': 1.0}                |        14       |
|  0.528372349407 | 0.0719071718434 |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.538921175443 |  0.089403368547 |               {'C': 100.0, 'gamma': 100.0}               |        8        |
|  0.501433667781 | 0.0260679990276 |              {'C': 100.0, 'gamma': 1000.0}               |        60       |
|  0.504715719064 | 0.0207879540939 |              {'C': 100.0, 'gamma': 10000.0}              |        54       |
|  0.508049052397 | 0.0223763470728 |              {'C': 1000.0, 'gamma': 0.001}               |        18       |
|  0.54366218255  | 0.0961509180768 |               {'C': 1000.0, 'gamma': 0.01}               |        4        |
|  0.560238818791 | 0.0995362772815 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.538511897001 |   0.1218889622  |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.512522082674 | 0.0902252170341 |               {'C': 1000.0, 'gamma': 10.0}               |        17       |
|  0.53558784211  | 0.0901677025785 |              {'C': 1000.0, 'gamma': 100.0}               |        10       |
|  0.501433667781 | 0.0260679990276 |              {'C': 1000.0, 'gamma': 1000.0}              |        60       |
|  0.504715719064 | 0.0207879540939 |             {'C': 1000.0, 'gamma': 10000.0}              |        54       |
|  0.54366218255  | 0.0961509180768 |              {'C': 10000.0, 'gamma': 0.001}              |        4        |
|  0.539986772487 |  0.106478243818 |              {'C': 10000.0, 'gamma': 0.01}               |        6        |
|  0.495804149067 | 0.0753306747313 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        64       |
|  0.527633814529 |  0.100692533071 |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.503852049004 | 0.0886113513133 |              {'C': 10000.0, 'gamma': 10.0}               |        59       |
|  0.53558784211  | 0.0901677025785 |              {'C': 10000.0, 'gamma': 100.0}              |        10       |
|  0.501433667781 | 0.0260679990276 |             {'C': 10000.0, 'gamma': 1000.0}              |        60       |
|  0.504715719064 | 0.0207879540939 |             {'C': 10000.0, 'gamma': 10000.0}             |        54       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.56      0.73      0.64        30
          1       0.33      0.19      0.24        21

avg / total       0.47      0.51      0.47        51


Accuracy on test set (using best parameters): 0.51


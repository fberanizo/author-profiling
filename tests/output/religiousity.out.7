Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.482954292085 | 0.0192570883785 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      1.00      0.79        33
          1       0.00      0.00      0.00        18

avg / total       0.42      0.65      0.51        51


Accuracy on test set (using best parameters): 0.65

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.500394116605 | 0.0911965654006 |  {'n_neighbors': 3} |        3        |
|  0.512973519658 |  0.100647017689 |  {'n_neighbors': 5} |        2        |
|   0.5462081004  |  0.113543268791 | {'n_neighbors': 11} |        1        |
|  0.467274734927 | 0.0702220771471 | {'n_neighbors': 21} |        5        |
|  0.478628762542 | 0.0363507738596 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.77      0.71        31
          1       0.50      0.35      0.41        20

avg / total       0.59      0.61      0.59        51


Accuracy on test set (using best parameters): 0.61

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.586688834515 | 0.0956074785189 | {'n_estimators': 2}  |        3        |
|  0.527718593806 | 0.0987926299449 | {'n_estimators': 3}  |        7        |
|  0.530248777262 | 0.0993631530256 | {'n_estimators': 5}  |        6        |
|  0.569620581978 | 0.0936679004355 | {'n_estimators': 10} |        4        |
|  0.589988288684 | 0.0737742110911 | {'n_estimators': 20} |        2        |
|  0.612536859276 | 0.0975773343736 | {'n_estimators': 40} |        1        |
|  0.539712076634 | 0.0749626445016 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.52      0.93      0.67        27
          1       0.33      0.04      0.07        24

avg / total       0.43      0.51      0.39        51


Accuracy on test set (using best parameters): 0.51

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.508049052397 | 0.0223763470728 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        13       |
|  0.508049052397 | 0.0223763470728 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        13       |
|  0.508049052397 | 0.0223763470728 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        13       |
|  0.508049052397 | 0.0223763470728 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        13       |
|  0.508049052397 | 0.0223763470728 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        13       |
|  0.511533900882 | 0.0280396541563 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        10       |
|  0.52138238573  | 0.0526777789961 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        9        |
|  0.506330625896 | 0.0312785843009 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        19       |
|  0.553245739767 |  0.083624219372 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        2        |
|  0.54710072951  |  0.07727843714  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.549959087611 | 0.0882384087826 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.509500398153 | 0.0422455533433 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.508189113624 | 0.0524454423756 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.533144946417 |  0.104510192921 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
|  0.50138238573  | 0.0184757933599 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        21       |
|  0.506330625896 | 0.0312785843009 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        19       |
|  0.506374104157 | 0.0317778821385 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        18       |
|  0.533431134083 | 0.0837083650693 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.547344853214 |  0.102585418032 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.564564975409 | 0.0746754931473 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.533953757524 | 0.0935845274865 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        6        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.93      0.74        30
          1       0.60      0.14      0.23        21

avg / total       0.61      0.61      0.53        51


Accuracy on test set (using best parameters): 0.61

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.441987878788 | 0.0161973128145 |        {'C': 0.001}        |        6        |
|  0.441987878788 | 0.0161973128145 |        {'C': 0.01}         |        6        |
|  0.441987878788 | 0.0161973128145 | {'C': 0.10000000000000001} |        6        |
|  0.452222222222 |  0.03382605416  |         {'C': 1.0}         |        5        |
|  0.481219710453 | 0.0410163901173 |        {'C': 10.0}         |        1        |
|  0.459628950341 | 0.0971252985261 |        {'C': 100.0}        |        2        |
|  0.456569576966 | 0.0975300000938 |       {'C': 1000.0}        |        4        |
|  0.457727670334 |  0.111631974175 |       {'C': 10000.0}       |        3        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.76      1.00      0.86        38
          1       1.00      0.08      0.14        13

avg / total       0.82      0.76      0.68        51


Accuracy on test set (using best parameters): 0.76

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.001}               |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 0.01}                |        14       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        14       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.001, 'gamma': 1.0}                |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 10.0}                |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.001, 'gamma': 100.0}               |        14       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 1000.0}               |        14       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.001, 'gamma': 10000.0}              |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 0.001}                |        14       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 0.01}                |        14       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        14       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 1.0}                 |        14       |
|  0.516477146042 | 0.0218143560652 |                {'C': 0.01, 'gamma': 10.0}                |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 100.0}                |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 0.01, 'gamma': 1000.0}               |        14       |
|  0.516477146042 | 0.0218143560652 |              {'C': 0.01, 'gamma': 10000.0}               |        14       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        14       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        14       |
|  0.516477146042 | 0.0218143560652 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        14       |
|  0.516477146042 | 0.0218143560652 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        14       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        14       |
|  0.516477146042 | 0.0218143560652 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        14       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        14       |
|  0.516477146042 | 0.0218143560652 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        14       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.001}                |        14       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 0.01}                 |        14       |
|  0.516477146042 | 0.0218143560652 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        14       |
|  0.516477146042 | 0.0218143560652 |                 {'C': 1.0, 'gamma': 1.0}                 |        14       |
|  0.509520624303 | 0.0260169947582 |                {'C': 1.0, 'gamma': 10.0}                 |        60       |
|  0.516477146042 | 0.0218143560652 |                {'C': 1.0, 'gamma': 100.0}                |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 1.0, 'gamma': 1000.0}                |        14       |
|  0.513143812709 | 0.0215288538618 |               {'C': 1.0, 'gamma': 10000.0}               |        51       |
|  0.516477146042 | 0.0218143560652 |               {'C': 10.0, 'gamma': 0.001}                |        14       |
|  0.516477146042 | 0.0218143560652 |                {'C': 10.0, 'gamma': 0.01}                |        14       |
|  0.516477146042 | 0.0218143560652 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        14       |
|  0.550058159232 | 0.0803538291152 |                {'C': 10.0, 'gamma': 1.0}                 |        4        |
|  0.466589204676 | 0.0847961960642 |                {'C': 10.0, 'gamma': 10.0}                |        64       |
|  0.526424908425 | 0.0791095208274 |               {'C': 10.0, 'gamma': 100.0}                |        8        |
|  0.513143812709 | 0.0215288538618 |               {'C': 10.0, 'gamma': 1000.0}               |        51       |
|  0.513143812709 | 0.0215288538618 |              {'C': 10.0, 'gamma': 10000.0}               |        51       |
|  0.516477146042 | 0.0218143560652 |               {'C': 100.0, 'gamma': 0.001}               |        14       |
|  0.516477146042 | 0.0218143560652 |               {'C': 100.0, 'gamma': 0.01}                |        14       |
|  0.514491749796 | 0.0612585437724 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        50       |
|  0.549485074838 | 0.0842142470464 |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.492757282975 | 0.0967819830811 |               {'C': 100.0, 'gamma': 10.0}                |        61       |
|  0.536217869087 |  0.066281262253 |               {'C': 100.0, 'gamma': 100.0}               |        7        |
|  0.509823654606 | 0.0252434835611 |              {'C': 100.0, 'gamma': 1000.0}               |        57       |
|  0.513143812709 | 0.0215288538618 |              {'C': 100.0, 'gamma': 10000.0}              |        51       |
|  0.516477146042 | 0.0218143560652 |              {'C': 1000.0, 'gamma': 0.001}               |        14       |
|  0.52296267018  |  0.10204403136  |               {'C': 1000.0, 'gamma': 0.01}               |        11       |
|  0.596532823055 |  0.117218844768 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        1        |
|  0.540438227761 | 0.0756395462695 |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.468998990669 | 0.0805853578572 |               {'C': 1000.0, 'gamma': 10.0}               |        63       |
|  0.524261825131 |  0.06766168146  |              {'C': 1000.0, 'gamma': 100.0}               |        9        |
|  0.509823654606 | 0.0252434835611 |              {'C': 1000.0, 'gamma': 1000.0}              |        57       |
|  0.513143812709 | 0.0215288538618 |             {'C': 1000.0, 'gamma': 10000.0}              |        51       |
|  0.52296267018  |  0.10204403136  |              {'C': 10000.0, 'gamma': 0.001}              |        11       |
|  0.575951268586 |  0.119412262238 |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.551383583737 | 0.0795060627304 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.51822277917  | 0.0993113839075 |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.490685027849 |  0.136741103763 |              {'C': 10000.0, 'gamma': 10.0}               |        62       |
|  0.524261825131 |  0.06766168146  |              {'C': 10000.0, 'gamma': 100.0}              |        9        |
|  0.509823654606 | 0.0252434835611 |             {'C': 10000.0, 'gamma': 1000.0}              |        57       |
|  0.513143812709 | 0.0215288538618 |             {'C': 10000.0, 'gamma': 10000.0}             |        51       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.50      0.52      0.51        29
          1       0.33      0.32      0.33        22

avg / total       0.43      0.43      0.43        51


Accuracy on test set (using best parameters): 0.43


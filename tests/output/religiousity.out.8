Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.499620958751 | 0.0195823941617 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        31
          1       0.00      0.00      0.00        20

avg / total       0.37      0.61      0.46        51


Accuracy on test set (using best parameters): 0.61

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.524552774118 |  0.098823750934 |  {'n_neighbors': 3} |        3        |
|  0.524756726933 |  0.121753328073 |  {'n_neighbors': 5} |        2        |
|  0.558563523433 |  0.101693068349 | {'n_neighbors': 11} |        1        |
|  0.490481475047 | 0.0362799241623 | {'n_neighbors': 21} |        5        |
|  0.499620958751 | 0.0195823941617 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.94      0.81        31
          1       0.80      0.40      0.53        20

avg / total       0.74      0.73      0.70        51


Accuracy on test set (using best parameters): 0.73

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.574577775136 |  0.113263891986 | {'n_estimators': 2}  |        2        |
|  0.522764499518 |  0.142839270777 | {'n_estimators': 3}  |        5        |
|  0.518364934859 |  0.146192532073 | {'n_estimators': 5}  |        6        |
|  0.506048096831 | 0.0775555288728 | {'n_estimators': 10} |        7        |
|  0.587416267943 |  0.128796239063 | {'n_estimators': 20} |        1        |
|  0.545229437229 |  0.105938302369 | {'n_estimators': 40} |        4        |
|  0.570176856282 |  0.099503104805 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.67      0.66        36
          1       0.14      0.13      0.14        15

avg / total       0.50      0.51      0.50        51


Accuracy on test set (using best parameters): 0.51

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.512866457214 | 0.0466914036707 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        12       |
|  0.499620958751 | 0.0195823941617 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        14       |
|  0.496300800649 | 0.0216198068567 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.496300800649 | 0.0216198068567 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        19       |
|  0.499620958751 | 0.0195823941617 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|  0.499620958751 | 0.0195823941617 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|  0.499620958751 | 0.0195823941617 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
|  0.532620857403 | 0.0766433932865 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        5        |
|  0.542184700967 |  0.136207331509 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        3        |
|  0.526336401119 | 0.0782596778457 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.528530016471 | 0.0943143164608 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.499100525883 | 0.0490062343339 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        18       |
|  0.503054022001 | 0.0478984344948 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        13       |
|  0.484946679729 | 0.0271851858066 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.513010945576 | 0.0558715449425 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        11       |
|  0.523630958414 | 0.0880471640061 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
|  0.545314182724 |  0.121270172739 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.530516979927 |  0.114215310206 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.531831867937 |  0.134988477609 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.541688533011 |  0.137162458878 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.547373662696 |  0.121958584718 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.87      0.71        31
          1       0.33      0.10      0.15        20

avg / total       0.50      0.57      0.49        51


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.441987878788 | 0.0161973128145 |        {'C': 0.001}        |        6        |
|  0.441987878788 | 0.0161973128145 |        {'C': 0.01}         |        6        |
|  0.441987878788 | 0.0161973128145 | {'C': 0.10000000000000001} |        6        |
|  0.45211210239  | 0.0471171512988 |         {'C': 1.0}         |        5        |
|  0.561480268524 |  0.102748283522 |        {'C': 10.0}         |        1        |
|  0.48917057796  |  0.144192771126 |        {'C': 100.0}        |        3        |
|  0.495269914296 |  0.145380774124 |       {'C': 1000.0}        |        2        |
|  0.488898370463 |  0.127450791822 |       {'C': 10000.0}       |        4        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.75      0.95      0.84        38
          1       0.33      0.08      0.12        13

avg / total       0.64      0.73      0.66        51


Accuracy on test set (using best parameters): 0.73

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.466477146042 | 0.0213755483698 |               {'C': 0.001, 'gamma': 0.001}               |        12       |
|  0.466477146042 | 0.0213755483698 |               {'C': 0.001, 'gamma': 0.01}                |        12       |
|  0.466477146042 | 0.0213755483698 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        12       |
|  0.466477146042 | 0.0213755483698 |                {'C': 0.001, 'gamma': 1.0}                |        12       |
|  0.466477146042 | 0.0213755483698 |               {'C': 0.001, 'gamma': 10.0}                |        12       |
|  0.466477146042 | 0.0213755483698 |               {'C': 0.001, 'gamma': 100.0}               |        12       |
|  0.466477146042 | 0.0213755483698 |              {'C': 0.001, 'gamma': 1000.0}               |        12       |
|  0.466477146042 | 0.0213755483698 |              {'C': 0.001, 'gamma': 10000.0}              |        12       |
|  0.466477146042 | 0.0213755483698 |               {'C': 0.01, 'gamma': 0.001}                |        12       |
|  0.466477146042 | 0.0213755483698 |                {'C': 0.01, 'gamma': 0.01}                |        12       |
|  0.466477146042 | 0.0213755483698 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        12       |
|  0.466477146042 | 0.0213755483698 |                {'C': 0.01, 'gamma': 1.0}                 |        12       |
|  0.466477146042 | 0.0213755483698 |                {'C': 0.01, 'gamma': 10.0}                |        12       |
|  0.466477146042 | 0.0213755483698 |               {'C': 0.01, 'gamma': 100.0}                |        12       |
|  0.466477146042 | 0.0213755483698 |               {'C': 0.01, 'gamma': 1000.0}               |        12       |
|  0.466477146042 | 0.0213755483698 |              {'C': 0.01, 'gamma': 10000.0}               |        12       |
|  0.466477146042 | 0.0213755483698 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        12       |
|  0.466477146042 | 0.0213755483698 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        12       |
|  0.466477146042 | 0.0213755483698 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        12       |
|  0.466477146042 | 0.0213755483698 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        12       |
|  0.466477146042 | 0.0213755483698 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        12       |
|  0.466477146042 | 0.0213755483698 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        12       |
|  0.466477146042 | 0.0213755483698 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        12       |
|  0.466477146042 | 0.0213755483698 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        12       |
|  0.466477146042 | 0.0213755483698 |                {'C': 1.0, 'gamma': 0.001}                |        12       |
|  0.466477146042 | 0.0213755483698 |                {'C': 1.0, 'gamma': 0.01}                 |        12       |
|  0.466477146042 | 0.0213755483698 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        12       |
|  0.463823114084 | 0.0263422285438 |                 {'C': 1.0, 'gamma': 1.0}                 |        42       |
|  0.457592986723 | 0.0479239882279 |                {'C': 1.0, 'gamma': 10.0}                 |        48       |
|  0.449231884058 | 0.0338876791948 |                {'C': 1.0, 'gamma': 100.0}                |        55       |
|  0.455774804905 | 0.0333207131031 |               {'C': 1.0, 'gamma': 1000.0}                |        49       |
|  0.459934225195 | 0.0252005573253 |               {'C': 1.0, 'gamma': 10000.0}               |        43       |
|  0.466477146042 | 0.0213755483698 |               {'C': 10.0, 'gamma': 0.001}                |        12       |
|  0.466477146042 | 0.0213755483698 |                {'C': 10.0, 'gamma': 0.01}                |        12       |
|  0.473319318363 |  0.044514868324 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        9        |
|  0.484982056591 |  0.103535625546 |                {'C': 10.0, 'gamma': 1.0}                 |        8        |
|  0.414215850481 | 0.0784666372882 |                {'C': 10.0, 'gamma': 10.0}                |        61       |
|  0.494377313508 |  0.104979594646 |               {'C': 10.0, 'gamma': 100.0}                |        7        |
|  0.45251393534  | 0.0352651545539 |               {'C': 10.0, 'gamma': 1000.0}               |        50       |
|  0.459934225195 | 0.0252005573253 |              {'C': 10.0, 'gamma': 10000.0}               |        43       |
|  0.466477146042 | 0.0213755483698 |               {'C': 100.0, 'gamma': 0.001}               |        12       |
|  0.473319318363 |  0.044514868324 |               {'C': 100.0, 'gamma': 0.01}                |        9        |
|  0.500163367356 | 0.0865271577737 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        6        |
|   0.3920215311  | 0.0752177884892 |                {'C': 100.0, 'gamma': 1.0}                |        62       |
|  0.429786027982 |  0.107400100429 |               {'C': 100.0, 'gamma': 10.0}                |        60       |
|  0.510598531903 |  0.100656509157 |               {'C': 100.0, 'gamma': 100.0}               |        4        |
|  0.45251393534  | 0.0352651545539 |              {'C': 100.0, 'gamma': 1000.0}               |        50       |
|  0.459934225195 | 0.0252005573253 |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.473319318363 |  0.044514868324 |              {'C': 1000.0, 'gamma': 0.001}               |        9        |
|  0.510910923554 | 0.0796835592125 |               {'C': 1000.0, 'gamma': 0.01}               |        3        |
|  0.385793688767 | 0.0884947191335 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        64       |
|  0.444406441684 | 0.0920431813333 |               {'C': 1000.0, 'gamma': 1.0}                |        59       |
|  0.448053652514 |  0.116821752348 |               {'C': 1000.0, 'gamma': 10.0}               |        56       |
|  0.521304347826 |  0.11283490906  |              {'C': 1000.0, 'gamma': 100.0}               |        1        |
|  0.45251393534  | 0.0352651545539 |              {'C': 1000.0, 'gamma': 1000.0}              |        50       |
|  0.459934225195 | 0.0252005573253 |             {'C': 1000.0, 'gamma': 10000.0}              |        43       |
|  0.501482352125 | 0.0614984872495 |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.449925339822 |  0.119042202427 |              {'C': 10000.0, 'gamma': 0.01}               |        54       |
|  0.390494589289 | 0.0952583770538 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.447598754187 |  0.122646297448 |               {'C': 10000.0, 'gamma': 1.0}               |        57       |
|  0.444975616791 |  0.12620187591  |              {'C': 10000.0, 'gamma': 10.0}               |        58       |
|  0.521304347826 |  0.11283490906  |              {'C': 10000.0, 'gamma': 100.0}              |        1        |
|  0.45251393534  | 0.0352651545539 |             {'C': 10000.0, 'gamma': 1000.0}              |        50       |
|  0.459934225195 | 0.0252005573253 |             {'C': 10000.0, 'gamma': 10000.0}             |        43       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.97      0.81        35
          1       0.50      0.06      0.11        16

avg / total       0.63      0.69      0.59        51


Accuracy on test set (using best parameters): 0.69


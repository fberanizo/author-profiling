Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+-----------------+--------+-----------------+
| test_mean_score |  test_std_score | params | test_rank_score |
+-----------------+-----------------+--------+-----------------+
|  0.491192865106 | 0.0111433338322 |   {}   |        1        |
+-----------------+-----------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      1.00      0.77        32
          1       0.00      0.00      0.00        19

avg / total       0.39      0.63      0.48        51


Accuracy on test set (using best parameters): 0.63

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.514868992387 |  0.100923158036 |  {'n_neighbors': 3} |        1        |
|  0.455273982057 |  0.110530549235 |  {'n_neighbors': 5} |        5        |
|  0.513788484878 |  0.082024626149 | {'n_neighbors': 11} |        2        |
|  0.464721090504 | 0.0239761768681 | {'n_neighbors': 21} |        4        |
|  0.479634133982 | 0.0185501860766 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.70      0.71        33
          1       0.47      0.50      0.49        18

avg / total       0.63      0.63      0.63        51


Accuracy on test set (using best parameters): 0.63

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.531445887446 |  0.10326559511  | {'n_estimators': 2}  |        6        |
|  0.52159073125  |  0.171605304775 | {'n_estimators': 3}  |        7        |
|  0.537942275818 | 0.0908154621607 | {'n_estimators': 5}  |        5        |
|  0.546655248134 |  0.140163693849 | {'n_estimators': 10} |        2        |
|  0.582278119541 |  0.136049868397 | {'n_estimators': 20} |        1        |
|  0.543541052896 |  0.123050527202 | {'n_estimators': 40} |        3        |
|  0.542993088783 |  0.168001850301 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.77      0.71        35
          1       0.20      0.12      0.15        16

avg / total       0.51      0.57      0.54        51


Accuracy on test set (using best parameters): 0.57

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.491192865106 | 0.0111433338322 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|  0.491192865106 | 0.0111433338322 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|  0.487910813824 | 0.0168169565157 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        19       |
|  0.504438363569 | 0.0463039901886 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        10       |
|  0.487910813824 | 0.0168169565157 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        19       |
|  0.501390667304 | 0.0401505486571 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        12       |
|  0.491192865106 | 0.0111433338322 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.520064824065 |  0.071112132575 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.512851283982 |  0.073140002818 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        7        |
|  0.461394817743 | 0.0642445163164 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        21       |
|  0.497320893616 |  0.11704417424  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        14       |
|  0.507588148101 |  0.053584190336 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
|  0.523761120056 |  0.132523661788 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.503977459273 | 0.0465556737989 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.533279454845 | 0.0700372883069 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        1        |
|  0.519837708186 |  0.067556641286 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.516989522555 | 0.0647685688285 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.525663592446 | 0.0724096173871 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.508610013175 | 0.0699314235749 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        8        |
|  0.500003952569 | 0.0730566088476 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        13       |
|  0.490366702879 | 0.0691961967614 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        18       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      1.00      0.78        32
          1       1.00      0.05      0.10        19

avg / total       0.77      0.65      0.53        51


Accuracy on test set (using best parameters): 0.65

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.474715719064 | 0.0219487777767 |        {'C': 0.001}        |        5        |
|  0.474715719064 | 0.0219487777767 |        {'C': 0.01}         |        5        |
|  0.474715719064 | 0.0219487777767 | {'C': 0.10000000000000001} |        5        |
|  0.474715719064 | 0.0219487777767 |         {'C': 1.0}         |        5        |
|  0.504843127887 | 0.0668348859597 |        {'C': 10.0}         |        4        |
|  0.565956001114 | 0.0978019448216 |        {'C': 100.0}        |        1        |
|  0.536819777641 |  0.106396230726 |       {'C': 1000.0}        |        2        |
|  0.522799613709 |  0.125002720467 |       {'C': 10000.0}       |        3        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.65      0.65        34
          1       0.29      0.29      0.29        17

avg / total       0.53      0.53      0.53        51


Accuracy on test set (using best parameters): 0.53

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.491192865106 | 0.0111433338322 |               {'C': 0.001, 'gamma': 0.001}               |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 0.001, 'gamma': 0.01}                |        18       |
|  0.491192865106 | 0.0111433338322 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 0.001, 'gamma': 1.0}                |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 0.001, 'gamma': 10.0}                |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 0.001, 'gamma': 100.0}               |        18       |
|  0.491192865106 | 0.0111433338322 |              {'C': 0.001, 'gamma': 1000.0}               |        18       |
|  0.491192865106 | 0.0111433338322 |              {'C': 0.001, 'gamma': 10000.0}              |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 0.01, 'gamma': 0.001}                |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 0.01, 'gamma': 0.01}                |        18       |
|  0.491192865106 | 0.0111433338322 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 0.01, 'gamma': 1.0}                 |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 0.01, 'gamma': 10.0}                |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 0.01, 'gamma': 100.0}                |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 0.01, 'gamma': 1000.0}               |        18       |
|  0.491192865106 | 0.0111433338322 |              {'C': 0.01, 'gamma': 10000.0}               |        18       |
|  0.491192865106 | 0.0111433338322 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        18       |
|  0.491192865106 | 0.0111433338322 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        18       |
|  0.491192865106 | 0.0111433338322 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        18       |
|  0.491192865106 | 0.0111433338322 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        18       |
|  0.491192865106 | 0.0111433338322 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        18       |
|  0.491192865106 | 0.0111433338322 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        18       |
|  0.491192865106 | 0.0111433338322 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        18       |
|  0.491192865106 | 0.0111433338322 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 1.0, 'gamma': 0.001}                |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 1.0, 'gamma': 0.01}                 |        18       |
|  0.491192865106 | 0.0111433338322 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        18       |
|  0.491192865106 | 0.0111433338322 |                 {'C': 1.0, 'gamma': 1.0}                 |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 1.0, 'gamma': 1000.0}                |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 1.0, 'gamma': 10000.0}               |        18       |
|  0.491192865106 | 0.0111433338322 |               {'C': 10.0, 'gamma': 0.001}                |        18       |
|  0.491192865106 | 0.0111433338322 |                {'C': 10.0, 'gamma': 0.01}                |        18       |
|  0.484590655721 | 0.0169999073155 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        57       |
|  0.509350074792 |  0.109074454091 |                {'C': 10.0, 'gamma': 1.0}                 |        12       |
|  0.513570173788 | 0.0606674645628 |                {'C': 10.0, 'gamma': 10.0}                |        9        |
|  0.491310158441 | 0.0547459676312 |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.484590655721 | 0.0169999073155 |               {'C': 10.0, 'gamma': 1000.0}               |        57       |
|  0.487910813824 | 0.0168169565157 |              {'C': 10.0, 'gamma': 10000.0}               |        53       |
|  0.491192865106 | 0.0111433338322 |               {'C': 100.0, 'gamma': 0.001}               |        18       |
|  0.484590655721 | 0.0169999073155 |               {'C': 100.0, 'gamma': 0.01}                |        57       |
|  0.538908461097 |   0.1096023453  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.52522526918  |  0.116087143133 |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.516464646465 |  0.064953745452 |               {'C': 100.0, 'gamma': 10.0}                |        8        |
|  0.511547853113 |  0.070117726682 |               {'C': 100.0, 'gamma': 100.0}               |        10       |
|  0.484590655721 | 0.0169999073155 |              {'C': 100.0, 'gamma': 1000.0}               |        57       |
|  0.487910813824 | 0.0168169565157 |              {'C': 100.0, 'gamma': 10000.0}              |        53       |
|  0.523152094283 | 0.0552204214774 |              {'C': 1000.0, 'gamma': 0.001}               |        6        |
|  0.547065716638 |   0.1177585536  |               {'C': 1000.0, 'gamma': 0.01}               |        2        |
|  0.523060210067 |  0.125553376704 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.509580298462 |  0.127631597332 |               {'C': 1000.0, 'gamma': 1.0}                |        11       |
|  0.502556141714 | 0.0837271804218 |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.507683118814 |  0.075993204829 |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.484590655721 | 0.0169999073155 |              {'C': 1000.0, 'gamma': 1000.0}              |        57       |
|  0.487910813824 | 0.0168169565157 |             {'C': 1000.0, 'gamma': 10000.0}              |        53       |
|  0.569312723043 |  0.11826366456  |              {'C': 10000.0, 'gamma': 0.001}              |        1        |
|  0.534950548173 |  0.106376353148 |              {'C': 10000.0, 'gamma': 0.01}               |        4        |
|  0.491789011814 | 0.0990677178197 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        16       |
|  0.471580603398 |  0.141731395365 |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.483946420729 | 0.0652567346003 |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.507683118814 |  0.075993204829 |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
|  0.484590655721 | 0.0169999073155 |             {'C': 10000.0, 'gamma': 1000.0}              |        57       |
|  0.487910813824 | 0.0168169565157 |             {'C': 10000.0, 'gamma': 10000.0}             |        53       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.88      0.73        32
          1       0.33      0.11      0.16        19

avg / total       0.51      0.59      0.52        51


Accuracy on test set (using best parameters): 0.59


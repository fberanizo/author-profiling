Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.539866075173 | 0.0208463295075 |  {'n_neighbors': 3} |        1        |
|  0.52668636421  |  0.033883542443 |  {'n_neighbors': 5} |        2        |
|  0.511755117837 | 0.0510245987383 | {'n_neighbors': 11} |        4        |
|  0.521759736312 | 0.0421861115889 | {'n_neighbors': 21} |        3        |
|  0.503559686114 | 0.0419482742647 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.69      0.65        74
          1       0.41      0.33      0.37        48

avg / total       0.53      0.55      0.54       122

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.561715902874 | 0.0727698212126 |  {'n_neighbors': 3} |        1        |
|  0.55775535032  | 0.0374325020175 |  {'n_neighbors': 5} |        2        |
|  0.537573675645 | 0.0252194460169 | {'n_neighbors': 11} |        3        |
|  0.514525871318 | 0.0396226851088 | {'n_neighbors': 21} |        5        |
|  0.515994404716 | 0.0323467767322 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.54      0.59      0.57        73
          1       0.29      0.25      0.27        48

avg / total       0.44      0.45      0.45       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.541729608783 | 0.0261970531839 |  {'n_neighbors': 3} |        1        |
|  0.514553259679 | 0.0312028583684 |  {'n_neighbors': 5} |        4        |
|  0.532057466524 | 0.0375309952314 | {'n_neighbors': 11} |        3        |
|  0.536600074205 | 0.0373890792505 | {'n_neighbors': 21} |        2        |
|  0.460673741211 | 0.0293407966835 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.70      0.65        73
          1       0.42      0.33      0.37        48

avg / total       0.54      0.55      0.54       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.54020027226  | 0.0317407204658 |  {'n_neighbors': 3} |        1        |
|  0.535851866652 |  0.047550860378 |  {'n_neighbors': 5} |        2        |
|  0.534833536092 | 0.0519724686862 | {'n_neighbors': 11} |        3        |
|  0.526399029625 |  0.03057740374  | {'n_neighbors': 21} |        4        |
|  0.485918979476 | 0.0243659807431 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.64      0.61        73
          1       0.35      0.30      0.32        47

avg / total       0.49      0.51      0.50       120

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 5 candidates, totalling 25 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.526360235922 | 0.0520449022978 |  {'n_neighbors': 3} |        4        |
|  0.546414491737 |  0.039346266981 |  {'n_neighbors': 5} |        1        |
|  0.539028400553 | 0.0200841040101 | {'n_neighbors': 11} |        2        |
|  0.533138921363 | 0.0366665533335 | {'n_neighbors': 21} |        3        |
|  0.514987036278 | 0.0199059484842 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.68      0.62        73
          1       0.30      0.21      0.25        47

avg / total       0.47      0.50      0.48       120

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.541936333823 | 0.0233682202796 | {'n_estimators': 2}  |        2        |
|  0.535635473239 | 0.0327953398101 | {'n_estimators': 3}  |        4        |
|  0.557644714999 | 0.0347054689089 | {'n_estimators': 5}  |        1        |
|  0.518025222003 | 0.0628824211066 | {'n_estimators': 10} |        7        |
|  0.527534133578 | 0.0397597986547 | {'n_estimators': 20} |        6        |
|  0.530452349934 | 0.0272308965445 | {'n_estimators': 40} |        5        |
|  0.536194882379 | 0.0236647995996 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.65      0.61        74
          1       0.32      0.25      0.28        48

avg / total       0.47      0.49      0.48       122

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.521203012139 | 0.0402526896957 | {'n_estimators': 2}  |        5        |
|  0.55627753332  | 0.0191027476814 | {'n_estimators': 3}  |        1        |
|  0.525411694156 | 0.0163618298662 | {'n_estimators': 5}  |        4        |
|  0.534308105144 | 0.0359657194216 | {'n_estimators': 10} |        3        |
|  0.515673349902 | 0.0567824484835 | {'n_estimators': 20} |        6        |
|  0.503412558693 | 0.0255612148314 | {'n_estimators': 40} |        7        |
|  0.553054078675 | 0.0310221893781 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.64      0.66        73
          1       0.49      0.52      0.51        48

avg / total       0.60      0.60      0.60       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.524905598869 | 0.0343592196763 | {'n_estimators': 2}  |        1        |
|  0.497876555292 | 0.0570949547989 | {'n_estimators': 3}  |        5        |
|  0.490175825243 | 0.0431867978376 | {'n_estimators': 5}  |        6        |
|  0.487462451458 | 0.0567379732619 | {'n_estimators': 10} |        7        |
|  0.511255004577 | 0.0460890012191 | {'n_estimators': 20} |        2        |
|  0.508626061816 | 0.0295747341518 | {'n_estimators': 40} |        3        |
|  0.501216891328 | 0.0240243940406 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.88      0.72        73
          1       0.47      0.17      0.25        48

avg / total       0.56      0.60      0.53       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.519279362158 |  0.038577836176 | {'n_estimators': 2}  |        5        |
|  0.539248390374 | 0.0548814011223 | {'n_estimators': 3}  |        2        |
|  0.519318224357 | 0.0512843832975 | {'n_estimators': 5}  |        4        |
|  0.546669431524 | 0.0350533372061 | {'n_estimators': 10} |        1        |
|  0.493124159042 | 0.0168010544481 | {'n_estimators': 20} |        7        |
|  0.531374339752 | 0.0251409396165 | {'n_estimators': 40} |        3        |
|  0.500095909659 | 0.0331540660912 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.84      0.73        73
          1       0.54      0.30      0.38        47

avg / total       0.61      0.62      0.59       120

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 7 candidates, totalling 35 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.498638484137 | 0.0257713526293 | {'n_estimators': 2}  |        7        |
|  0.521348901657 | 0.0355927915194 | {'n_estimators': 3}  |        4        |
|  0.57641895566  | 0.0519011593804 | {'n_estimators': 5}  |        1        |
|  0.518759855037 | 0.0357131789424 | {'n_estimators': 10} |        6        |
|  0.549619475327 | 0.0481008244095 | {'n_estimators': 20} |        3        |
|  0.519705826822 | 0.0206627260984 | {'n_estimators': 40} |        5        |
|  0.549893267836 | 0.0377625082472 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.77      0.70        73
          1       0.47      0.32      0.38        47

avg / total       0.57      0.59      0.57       120

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.457098226808 | 0.00245102134076 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|  0.457098226808 | 0.00245102134076 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|  0.457098226808 | 0.00245102134076 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|  0.457098226808 | 0.00245102134076 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|  0.457098226808 | 0.00245102134076 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.457098226808 | 0.00245102134076 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.456116138803 | 0.0019924663947  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        21       |
|  0.488275129586 | 0.0395966507648  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.484505623167 | 0.0135639119115  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.511312360661 |  0.042500251022  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.509623640684 | 0.0514195678883  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.48554124547  | 0.0434226818198  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.492320419407 | 0.0439276356761  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        8        |
|  0.542241382655 | 0.0431375514353  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.459463634567 | 0.0112985400209  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.492271204374 |  0.020026961021  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.501984076945 |  0.03043180888   |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
|  0.488907640455 | 0.0263185566328  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        10       |
|  0.502869821153 | 0.0206963367512  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.503581262272 | 0.0191183442264  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.531562660975 | 0.0253591905646  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.89      0.73        74
          1       0.43      0.12      0.19        48

avg / total       0.54      0.59      0.52       122

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.458097802818 | 0.00244594676241 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        14       |
|  0.458097802818 | 0.00244594676241 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        14       |
|  0.458097802818 | 0.00244594676241 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        14       |
|  0.458097802818 | 0.00244594676241 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|  0.458097802818 | 0.00244594676241 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|  0.458097802818 | 0.00244594676241 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|  0.458097802818 | 0.00244594676241 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
|  0.478191624795 | 0.0204016845163  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.492004959791 | 0.0314906238589  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.525294483779 | 0.0406174934909  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        2        |
|  0.496088492704 | 0.0344555752257  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.498892276778 | 0.0373413374753  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.495923405943 | 0.0397366070761  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        8        |
|  0.481534838326 | 0.0385927194056  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.455394972965 | 0.00567800851101 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        21       |
|  0.480514665802 | 0.0197714509536  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|   0.4957621189  |  0.021553652942  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.49691223972  | 0.0328580690353  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.504106353271 | 0.0442388222301  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.514053911775 |  0.027072512532  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.525667550341 | 0.0327995938733  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.90      0.73        73
          1       0.42      0.10      0.17        48

avg / total       0.53      0.59      0.50       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.458097802818 | 0.00244594676241 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        13       |
|  0.458097802818 | 0.00244594676241 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        13       |
|  0.457117748122 | 0.00243116473443 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        18       |
|  0.458097802818 | 0.00244594676241 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        13       |
|  0.457117748122 | 0.00243116473443 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        18       |
|  0.458097802818 | 0.00244594676241 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        13       |
|  0.458097802818 | 0.00244594676241 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        13       |
|  0.458583865218 | 0.00877086258875 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.447372424615 | 0.0253761602003  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        21       |
|   0.4955636059  | 0.0135334902006  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.496334832988 | 0.0509619265434  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        2        |
|  0.476625825011 | 0.0478066140863  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
|  0.490771369203 | 0.0298746874839  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.488416303011 | 0.0470374094394  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.455160707071 | 0.00443458891345 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        20       |
|  0.463247425904 | 0.00765387829401 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
|  0.463759336329 |  0.020321634278  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.481763438555 | 0.0183473332932  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.485248837892 | 0.0500946727072  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.482001300743 | 0.0188444149196  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.498831157091 | 0.0324587378835  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.97      0.75        73
          1       0.60      0.06      0.11        48

avg / total       0.61      0.61      0.50       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.456564013797 | 0.00303245687689 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|  0.456564013797 | 0.00303245687689 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|  0.456564013797 | 0.00303245687689 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|  0.460202215584 | 0.0078402239622  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|  0.456564013797 | 0.00303245687689 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.456564013797 | 0.00303245687689 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.456564013797 | 0.00303245687689 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.465271847364 | 0.0225427264913  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.471992942685 | 0.0208171826602  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.485675877195 | 0.0264384601798  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        7        |
|  0.500111206613 |  0.047217882781  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.46899792657  | 0.0141479138285  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.482274898712 | 0.0217277011844  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        8        |
|  0.519410601047 | 0.0597589498236  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.453869272943 | 0.00647432091772 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        21       |
|  0.464052884695 |  0.018551948505  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|  0.475660488028 | 0.0156474106116  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.508339897806 | 0.0461211465622  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.497688401935 | 0.0373269344505  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.489916768028 | 0.0370454794141  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.498680419532 | 0.0365295114066  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        4        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.90      0.74        73
          1       0.50      0.15      0.23        47

avg / total       0.57      0.61      0.54       120

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 21 candidates, totalling 105 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.456564013797 | 0.00303245687689 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|  0.456564013797 | 0.00303245687689 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|  0.456564013797 | 0.00303245687689 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|  0.456564013797 | 0.00303245687689 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|  0.456564013797 | 0.00303245687689 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|  0.456564013797 | 0.00303245687689 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|  0.456564013797 | 0.00303245687689 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.472807697096 | 0.0119736965932  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.484503878612 | 0.0224159137055  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.497379266891 | 0.0369522350968  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        8        |
|  0.510526144873 | 0.0317390167957  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.509681480669 | 0.00857781815856 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.525855025721 | 0.0453681764991  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.508287700457 | 0.0528184559968  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|  0.461509135217 |  0.019276444524  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.48456496434  | 0.0140892805686  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
|  0.496202798813 | 0.0335727584708  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.45792403354  | 0.0298755726378  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        14       |
|  0.521222871757 | 0.0290549921941  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.529943862002 | 0.0344329473631  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.524195237694 | 0.0632420517039  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.86      0.71        73
          1       0.33      0.11      0.16        47

avg / total       0.50      0.57      0.49       120

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.457098226808 | 0.00245102134076 |        {'C': 0.001}        |        4        |
|  0.457098226808 | 0.00245102134076 |        {'C': 0.01}         |        4        |
|  0.457098226808 | 0.00245102134076 | {'C': 0.10000000000000001} |        4        |
|  0.457098226808 | 0.00245102134076 |         {'C': 1.0}         |        4        |
|  0.456117676157 | 0.00371732400507 |        {'C': 10.0}         |        8        |
|  0.52801464429  | 0.0222779751304  |        {'C': 100.0}        |        2        |
|  0.556469707635 | 0.0430261759409  |       {'C': 1000.0}        |        1        |
|  0.518809817576 | 0.0279355315604  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.73      0.66        74
          1       0.39      0.27      0.32        48

avg / total       0.52      0.55      0.53       122

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.458097802818 | 0.00244594676241 |        {'C': 0.001}        |        5        |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.01}         |        5        |
|  0.458097802818 | 0.00244594676241 | {'C': 0.10000000000000001} |        5        |
|  0.458097802818 | 0.00244594676241 |         {'C': 1.0}         |        5        |
|  0.465386422389 | 0.0146544502502  |        {'C': 10.0}         |        4        |
|  0.51530214778  | 0.0202078045914  |        {'C': 100.0}        |        3        |
|  0.583973458632 | 0.0742577229912  |       {'C': 1000.0}        |        1        |
|  0.570080089501 | 0.0366996948853  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.73      0.66        73
          1       0.41      0.29      0.34        48

avg / total       0.53      0.55      0.54       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.458097802818 | 0.00244594676241 |        {'C': 0.001}        |        5        |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.01}         |        5        |
|  0.458097802818 | 0.00244594676241 | {'C': 0.10000000000000001} |        5        |
|  0.458097802818 | 0.00244594676241 |         {'C': 1.0}         |        5        |
|  0.458798652864 | 0.0127917985251  |        {'C': 10.0}         |        4        |
|   0.5506957584  | 0.0418786840812  |        {'C': 100.0}        |        1        |
|  0.541679726597 | 0.0526835902647  |       {'C': 1000.0}        |        2        |
|  0.537444233046 | 0.0461259215515  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.85      0.72        73
          1       0.48      0.21      0.29        48

avg / total       0.56      0.60      0.55       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.456564013797 | 0.00303245687689 |        {'C': 0.001}        |        4        |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.01}         |        4        |
|  0.456564013797 | 0.00303245687689 | {'C': 0.10000000000000001} |        4        |
|  0.456564013797 | 0.00303245687689 |         {'C': 1.0}         |        4        |
|  0.455064835244 | 0.00810874365797 |        {'C': 10.0}         |        8        |
|  0.526686949405 | 0.0474743675668  |        {'C': 100.0}        |        2        |
|  0.560363934234 | 0.0227261207281  |       {'C': 1000.0}        |        1        |
|  0.525838573166 |  0.033965870683  |       {'C': 10000.0}       |        3        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.71      0.67        73
          1       0.45      0.36      0.40        47

avg / total       0.56      0.57      0.56       120

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 8 candidates, totalling 40 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.456564013797 | 0.00303245687689 |        {'C': 0.001}        |        5        |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.01}         |        5        |
|  0.456564013797 | 0.00303245687689 | {'C': 0.10000000000000001} |        5        |
|  0.456564013797 | 0.00303245687689 |         {'C': 1.0}         |        5        |
|  0.457513488948 | 0.0134259985999  |        {'C': 10.0}         |        4        |
|  0.503629260155 | 0.0393824962005  |        {'C': 100.0}        |        3        |
|  0.531141200051 | 0.0477190654626  |       {'C': 1000.0}        |        1        |
|  0.507603979052 | 0.0293522049739  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.84      0.73        73
          1       0.52      0.28      0.36        47

avg / total       0.59      0.62      0.58       120

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.457098226808 | 0.00245102134076 |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|  0.457098226808 | 0.00245102134076 |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|  0.457098226808 | 0.00245102134076 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|  0.457098226808 | 0.00245102134076 |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|  0.457098226808 | 0.00245102134076 |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|  0.457098226808 | 0.00245102134076 |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|  0.457098226808 | 0.00245102134076 |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|  0.457098226808 | 0.00245102134076 |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|  0.457098226808 | 0.00245102134076 |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|  0.457098226808 | 0.00245102134076 |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|  0.457098226808 | 0.00245102134076 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|  0.457098226808 | 0.00245102134076 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.457098226808 | 0.00245102134076 |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|  0.457098226808 | 0.00245102134076 |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|  0.457098226808 | 0.00245102134076 |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|  0.457098226808 | 0.00245102134076 |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|  0.457098226808 | 0.00245102134076 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|  0.457098226808 | 0.00245102134076 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|  0.457098226808 | 0.00245102134076 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|  0.457098226808 | 0.00245102134076 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.457098226808 | 0.00245102134076 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|  0.457098226808 | 0.00245102134076 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|  0.457098226808 | 0.00245102134076 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|  0.457098226808 | 0.00245102134076 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.457098226808 | 0.00245102134076 |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|  0.457098226808 | 0.00245102134076 |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|  0.457098226808 | 0.00245102134076 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.457098226808 | 0.00245102134076 |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
|  0.486044606452 | 0.0152316313888  |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.477635893739 | 0.0128447061074  |                {'C': 1.0, 'gamma': 100.0}                |        21       |
|  0.459759622838 | 0.0107547107711  |               {'C': 1.0, 'gamma': 1000.0}                |        28       |
|  0.458456204929 | 0.00282113422239 |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|  0.457098226808 | 0.00245102134076 |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|  0.457098226808 | 0.00245102134076 |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|  0.456116138803 | 0.0019924663947  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        64       |
|  0.49922385174  | 0.0180818432633  |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.538310798165 | 0.0583283477594  |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.512920192105 | 0.0473988979931  |               {'C': 10.0, 'gamma': 100.0}                |        11       |
|  0.464551949941 | 0.00996341292296 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
|  0.465769301382 | 0.0128942052094  |              {'C': 10.0, 'gamma': 10000.0}               |        24       |
|  0.457098226808 | 0.00245102134076 |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|  0.456117676157 | 0.00371732400507 |               {'C': 100.0, 'gamma': 0.01}                |        63       |
|   0.4909626469  | 0.0361309702352  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.572041450898 | 0.0511768140246  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.526311881297 | 0.0639178622972  |               {'C': 100.0, 'gamma': 10.0}                |        8        |
|  0.50748789168  | 0.0383738402543  |               {'C': 100.0, 'gamma': 100.0}               |        14       |
|  0.471466864443 | 0.0141760703892  |              {'C': 100.0, 'gamma': 1000.0}               |        22       |
|  0.46191750489  | 0.00937340654326 |              {'C': 100.0, 'gamma': 10000.0}              |        26       |
|  0.457098226808 | 0.00245102134076 |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
|  0.488767509349 | 0.0259490150716  |               {'C': 1000.0, 'gamma': 0.01}               |        17       |
|  0.532538327933 | 0.0206378513374  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.56751960335  | 0.0303656549807  |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.508807661619 | 0.0480032832478  |               {'C': 1000.0, 'gamma': 10.0}               |        12       |
|  0.522158287151 |  0.017490918331  |              {'C': 1000.0, 'gamma': 100.0}               |        10       |
|  0.482251435639 |  0.029159598866  |              {'C': 1000.0, 'gamma': 1000.0}              |        20       |
|  0.458065195189 | 0.0194484852613  |             {'C': 1000.0, 'gamma': 10000.0}              |        30       |
|  0.483945132036 | 0.0261700645335  |              {'C': 10000.0, 'gamma': 0.001}              |        19       |
|  0.534507945402 | 0.0439812356263  |              {'C': 10000.0, 'gamma': 0.01}               |        6        |
|  0.537261870027 |  0.046952894732  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.523256950506 | 0.0397063465526  |               {'C': 10000.0, 'gamma': 1.0}               |        9        |
|  0.536409941568 | 0.0261005539684  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.508783110889 | 0.0321066833813  |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
|  0.468122113433 | 0.0148876327115  |             {'C': 10000.0, 'gamma': 1000.0}              |        23       |
|  0.461353141225 | 0.0143823937384  |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.73      0.65        74
          1       0.31      0.19      0.23        48

avg / total       0.47      0.52      0.48       122

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|  0.458097802818 | 0.00244594676241 |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|  0.458097802818 | 0.00244594676241 |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|  0.458097802818 | 0.00244594676241 |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|  0.458097802818 | 0.00244594676241 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|  0.458097802818 | 0.00244594676241 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|  0.458097802818 | 0.00244594676241 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|  0.458097802818 | 0.00244594676241 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|  0.458097802818 | 0.00244594676241 |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|  0.458097802818 | 0.00244594676241 |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|  0.458097802818 | 0.00244594676241 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.458097802818 | 0.00244594676241 |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.480670016454 | 0.0324936137132  |                {'C': 1.0, 'gamma': 10.0}                 |        20       |
|  0.474551769966 | 0.0140011035575  |                {'C': 1.0, 'gamma': 100.0}                |        22       |
|  0.458097802818 | 0.00244594676241 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.463000284739 | 0.00773175104234 |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.458097802818 | 0.00244594676241 |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|  0.458097802818 | 0.00244594676241 |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|  0.457117748122 | 0.00243116473443 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        63       |
|  0.495994594542 | 0.0278524994054  |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.56371260518  | 0.0207305022384  |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.490245556206 | 0.0415361274294  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.478703299444 | 0.0240294364212  |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|  0.467540094188 | 0.0125969065676  |              {'C': 10.0, 'gamma': 10000.0}               |        24       |
|  0.458097802818 | 0.00244594676241 |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|  0.458097802818 | 0.00244594676241 |               {'C': 100.0, 'gamma': 0.01}                |        29       |
|  0.491060256333 | 0.0345167770734  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.560337735008 | 0.0352489687171  |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.549566296286 | 0.0250046507697  |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.518553790228 | 0.0260011196412  |               {'C': 100.0, 'gamma': 100.0}               |        12       |
|  0.481368934938 | 0.0249321616435  |              {'C': 100.0, 'gamma': 1000.0}               |        19       |
|  0.467601535636 |  0.010929653108  |              {'C': 100.0, 'gamma': 10000.0}              |        23       |
|  0.458097802818 | 0.00244594676241 |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
|  0.466979365319 | 0.0193714406384  |               {'C': 1000.0, 'gamma': 0.01}               |        25       |
|  0.551592214453 | 0.0125894752949  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.564861897011 | 0.0243387225438  |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.537903719279 | 0.0367264687499  |               {'C': 1000.0, 'gamma': 10.0}               |        9        |
|  0.532477369052 | 0.0537339180181  |              {'C': 1000.0, 'gamma': 100.0}               |        10       |
|  0.485689004443 | 0.00604499638312 |              {'C': 1000.0, 'gamma': 1000.0}              |        18       |
|  0.464317271418 |  0.013447294171  |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
|  0.455767013304 | 0.0244773623234  |              {'C': 10000.0, 'gamma': 0.001}              |        64       |
|  0.571785954904 | 0.0496921831747  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.579184222541 | 0.0304036552509  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.508071925176 | 0.0397619526823  |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.548032168922 | 0.0361877400044  |              {'C': 10000.0, 'gamma': 10.0}               |        8        |
|  0.520426390072 | 0.0392300345876  |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
|  0.502781413387 | 0.0226572163391  |             {'C': 10000.0, 'gamma': 1000.0}              |        14       |
|  0.464302483111 | 0.0128799760233  |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.74      0.68        73
          1       0.47      0.35      0.40        48

avg / total       0.57      0.59      0.57       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|  0.458097802818 | 0.00244594676241 |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|  0.458097802818 | 0.00244594676241 |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|  0.458097802818 | 0.00244594676241 |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|  0.458097802818 | 0.00244594676241 |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|  0.458097802818 | 0.00244594676241 |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|  0.458097802818 | 0.00244594676241 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|  0.458097802818 | 0.00244594676241 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|  0.458097802818 | 0.00244594676241 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|  0.458097802818 | 0.00244594676241 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|  0.458097802818 | 0.00244594676241 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|  0.458097802818 | 0.00244594676241 |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|  0.458097802818 | 0.00244594676241 |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|  0.458097802818 | 0.00244594676241 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|  0.457119282293 | 0.00396682161052 |                 {'C': 1.0, 'gamma': 1.0}                 |        62       |
|  0.457117748122 | 0.00243116473443 |                {'C': 1.0, 'gamma': 10.0}                 |        64       |
|  0.473391178934 | 0.0215082936436  |                {'C': 1.0, 'gamma': 100.0}                |        23       |
|  0.481582068155 | 0.0203999692248  |               {'C': 1.0, 'gamma': 1000.0}                |        16       |
|  0.47505659039  | 0.0165986860957  |               {'C': 1.0, 'gamma': 10000.0}               |        21       |
|  0.458097802818 | 0.00244594676241 |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|  0.458097802818 | 0.00244594676241 |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|  0.457119282293 | 0.00396682161052 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        62       |
|  0.461409916075 | 0.00798944185738 |                {'C': 10.0, 'gamma': 1.0}                 |        29       |
|  0.504785992121 |  0.017879172713  |                {'C': 10.0, 'gamma': 10.0}                |        14       |
|  0.506983445186 | 0.0214405721496  |               {'C': 10.0, 'gamma': 100.0}                |        13       |
|  0.482218801943 | 0.00973418629168 |               {'C': 10.0, 'gamma': 1000.0}               |        15       |
|  0.477529228895 |  0.030756409751  |              {'C': 10.0, 'gamma': 10000.0}               |        18       |
|  0.458097802818 | 0.00244594676241 |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|  0.458097802818 | 0.00244594676241 |               {'C': 100.0, 'gamma': 0.01}                |        30       |
|  0.463210773009 | 0.0221039579281  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        28       |
|  0.507562352309 | 0.0491366137001  |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.507675054308 | 0.0252353514184  |               {'C': 100.0, 'gamma': 10.0}                |        10       |
|  0.511692742686 | 0.0371683940493  |               {'C': 100.0, 'gamma': 100.0}               |        9        |
|  0.467425339238 | 0.0247310285971  |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
|  0.475635468097 |  0.014695621707  |              {'C': 100.0, 'gamma': 10000.0}              |        19       |
|  0.458097802818 | 0.00244594676241 |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
|  0.477700867276 | 0.0144169164813  |               {'C': 1000.0, 'gamma': 0.01}               |        17       |
|  0.515432144241 | 0.0402777179064  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.514259363329 |  0.030355567809  |               {'C': 1000.0, 'gamma': 1.0}                |        8        |
|  0.539951449024 | 0.0695468331906  |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.523060925032 | 0.0399052778037  |              {'C': 1000.0, 'gamma': 100.0}               |        4        |
|  0.473013443252 | 0.0318659063107  |              {'C': 1000.0, 'gamma': 1000.0}              |        24       |
|  0.474245633004 | 0.0188065245826  |             {'C': 1000.0, 'gamma': 10000.0}              |        22       |
|  0.472375464226 | 0.0194091852095  |              {'C': 10000.0, 'gamma': 0.001}              |        25       |
|  0.517835889706 | 0.0387408100877  |              {'C': 10000.0, 'gamma': 0.01}               |        6        |
|  0.540953115661 | 0.0292599588137  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.507320794356 | 0.0265187092479  |               {'C': 10000.0, 'gamma': 1.0}               |        12       |
|  0.53190508936  | 0.0162572837587  |              {'C': 10000.0, 'gamma': 10.0}               |        3        |
|  0.520193325793 | 0.0310608455819  |              {'C': 10000.0, 'gamma': 100.0}              |        5        |
|  0.475632001593 | 0.0177942025506  |             {'C': 10000.0, 'gamma': 1000.0}              |        20       |
|  0.464097649679 | 0.00718491579804 |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.85      0.76        73
          1       0.63      0.40      0.49        48

avg / total       0.66      0.67      0.65       121

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|  0.456564013797 | 0.00303245687689 |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|  0.456564013797 | 0.00303245687689 |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|  0.456564013797 | 0.00303245687689 |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|  0.456564013797 | 0.00303245687689 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|  0.456564013797 | 0.00303245687689 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|  0.456564013797 | 0.00303245687689 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|  0.456564013797 | 0.00303245687689 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|  0.456564013797 | 0.00303245687689 |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|  0.456564013797 | 0.00303245687689 |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|  0.456564013797 | 0.00303245687689 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.455588488646 | 0.00457101150888 |                 {'C': 1.0, 'gamma': 1.0}                 |        62       |
|  0.469930285249 | 0.0116582097039  |                {'C': 1.0, 'gamma': 10.0}                 |        23       |
|  0.457391560014 | 0.0175026980432  |                {'C': 1.0, 'gamma': 100.0}                |        27       |
|  0.472486982786 | 0.0130273767073  |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.455950534192 | 0.00627189367895 |               {'C': 1.0, 'gamma': 10000.0}               |        61       |
|  0.456564013797 | 0.00303245687689 |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|  0.456564013797 | 0.00303245687689 |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|  0.456564013797 | 0.00303245687689 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.485522885578 | 0.0185968539447  |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.535118571629 | 0.0410586040549  |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.51886631725  | 0.0204797376781  |               {'C': 10.0, 'gamma': 100.0}                |        10       |
|  0.474373369907 | 0.0236856921634  |               {'C': 10.0, 'gamma': 1000.0}               |        20       |
|  0.452481799052 | 0.00855400480118 |              {'C': 10.0, 'gamma': 10000.0}               |        64       |
|  0.456564013797 | 0.00303245687689 |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|  0.456564013797 | 0.00303245687689 |               {'C': 100.0, 'gamma': 0.01}                |        29       |
|  0.469001198423 | 0.0121773950559  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        24       |
|  0.538618689946 | 0.0266885509429  |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.48312739414  | 0.0502522944193  |               {'C': 100.0, 'gamma': 10.0}                |        17       |
|  0.529473868238 | 0.0328782542892  |               {'C': 100.0, 'gamma': 100.0}               |        8        |
|  0.487316174397 | 0.0265270235365  |              {'C': 100.0, 'gamma': 1000.0}               |        14       |
|  0.465219371458 | 0.0116185369659  |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|  0.455585984006 | 0.00247500460074 |              {'C': 1000.0, 'gamma': 0.001}               |        63       |
|  0.477236574146 | 0.0220158788333  |               {'C': 1000.0, 'gamma': 0.01}               |        19       |
|  0.549554115595 | 0.0485438519469  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.56097535252  | 0.0365091884662  |               {'C': 1000.0, 'gamma': 1.0}                |        1        |
|  0.511777861671 | 0.0218443532458  |               {'C': 1000.0, 'gamma': 10.0}               |        11       |
|  0.495126818198 | 0.0347881751001  |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.474120284091 | 0.0156752705156  |              {'C': 1000.0, 'gamma': 1000.0}              |        21       |
|  0.460124940264 |  0.014398812476  |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
|  0.482147414438 | 0.0200279647317  |              {'C': 10000.0, 'gamma': 0.001}              |        18       |
|  0.540711425149 | 0.0306229026078  |              {'C': 10000.0, 'gamma': 0.01}               |        5        |
|  0.547472213839 |  0.031438881447  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.542694581105 | 0.0260593593625  |               {'C': 10000.0, 'gamma': 1.0}               |        4        |
|  0.519377316876 | 0.0312520601967  |              {'C': 10000.0, 'gamma': 10.0}               |        9        |
|  0.500936196945 | 0.0244005172609  |              {'C': 10000.0, 'gamma': 100.0}              |        12       |
|  0.485223791644 | 0.0112581947876  |             {'C': 10000.0, 'gamma': 1000.0}              |        16       |
|  0.457257942362 | 0.0108868980049  |             {'C': 10000.0, 'gamma': 10000.0}             |        28       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.60      0.59        73
          1       0.36      0.34      0.35        47

avg / total       0.50      0.50      0.50       120

# Tuning hyper-parameters for f1_weighted

Fitting 5 folds for each of 64 candidates, totalling 320 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 0.001}               |        28       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 0.01}                |        28       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        28       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.001, 'gamma': 1.0}                |        28       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 10.0}                |        28       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.001, 'gamma': 100.0}               |        28       |
|  0.456564013797 | 0.00303245687689 |              {'C': 0.001, 'gamma': 1000.0}               |        28       |
|  0.456564013797 | 0.00303245687689 |              {'C': 0.001, 'gamma': 10000.0}              |        28       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.01, 'gamma': 0.001}                |        28       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.01, 'gamma': 0.01}                |        28       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        28       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.01, 'gamma': 1.0}                 |        28       |
|  0.456564013797 | 0.00303245687689 |                {'C': 0.01, 'gamma': 10.0}                |        28       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.01, 'gamma': 100.0}                |        28       |
|  0.456564013797 | 0.00303245687689 |               {'C': 0.01, 'gamma': 1000.0}               |        28       |
|  0.456564013797 | 0.00303245687689 |              {'C': 0.01, 'gamma': 10000.0}               |        28       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        28       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        28       |
|  0.456564013797 | 0.00303245687689 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        28       |
|  0.456564013797 | 0.00303245687689 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        28       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        28       |
|  0.456564013797 | 0.00303245687689 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        28       |
|  0.456564013797 | 0.00303245687689 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        28       |
|  0.456564013797 | 0.00303245687689 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        28       |
|  0.456564013797 | 0.00303245687689 |                {'C': 1.0, 'gamma': 0.001}                |        28       |
|  0.456564013797 | 0.00303245687689 |                {'C': 1.0, 'gamma': 0.01}                 |        28       |
|  0.456564013797 | 0.00303245687689 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        28       |
|  0.454598167551 | 0.00553388096768 |                 {'C': 1.0, 'gamma': 1.0}                 |        64       |
|  0.490004095084 | 0.0247051255246  |                {'C': 1.0, 'gamma': 10.0}                 |        17       |
|  0.485174023689 | 0.0232954925634  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.455585984006 | 0.00247500460074 |               {'C': 1.0, 'gamma': 1000.0}                |        61       |
|  0.456564013797 | 0.00303245687689 |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.456564013797 | 0.00303245687689 |               {'C': 10.0, 'gamma': 0.001}                |        28       |
|  0.456564013797 | 0.00303245687689 |                {'C': 10.0, 'gamma': 0.01}                |        28       |
|  0.455588488646 | 0.00457101150888 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        60       |
|  0.490122979323 | 0.0245003897422  |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.565223131069 | 0.0251938118393  |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.527640778782 | 0.0270917936142  |               {'C': 10.0, 'gamma': 100.0}                |        11       |
|  0.457993428025 | 0.00897370430037 |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
|  0.455244433526 | 0.0149297308356  |              {'C': 10.0, 'gamma': 10000.0}               |        63       |
|  0.456564013797 | 0.00303245687689 |               {'C': 100.0, 'gamma': 0.001}               |        28       |
|  0.455585984006 | 0.00247500460074 |               {'C': 100.0, 'gamma': 0.01}                |        61       |
|  0.475260642894 | 0.0135517262005  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        19       |
|  0.585947352271 | 0.0274768591709  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.541697143364 | 0.0289767809276  |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|   0.5098402714  | 0.0321958593751  |               {'C': 100.0, 'gamma': 100.0}               |        13       |
|  0.467956492409 |  0.016396935893  |              {'C': 100.0, 'gamma': 1000.0}               |        23       |
|  0.460682244396 | 0.00928549803816 |              {'C': 100.0, 'gamma': 10000.0}              |        26       |
|  0.456564013797 | 0.00303245687689 |              {'C': 1000.0, 'gamma': 0.001}               |        28       |
|  0.492194286453 | 0.0248756370607  |               {'C': 1000.0, 'gamma': 0.01}               |        15       |
|  0.580208743369 | 0.0462761301021  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.564558335705 | 0.0127690160894  |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.546677183392 |  0.038866341711  |               {'C': 1000.0, 'gamma': 10.0}               |        7        |
|  0.513572332617 | 0.0457777140643  |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
|  0.470189331032 | 0.0217098890171  |              {'C': 1000.0, 'gamma': 1000.0}              |        22       |
|  0.461493005991 | 0.0190498125604  |             {'C': 1000.0, 'gamma': 10000.0}              |        24       |
|  0.475004015165 | 0.0217892468613  |              {'C': 10000.0, 'gamma': 0.001}              |        20       |
|  0.585860478242 | 0.0358852423398  |              {'C': 10000.0, 'gamma': 0.01}               |        2        |
|  0.566772013919 | 0.0303070195982  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.501787106155 | 0.0423464563674  |               {'C': 10000.0, 'gamma': 1.0}               |        14       |
|  0.529853946696 | 0.0296673049121  |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.544970357037 | 0.0291388868553  |              {'C': 10000.0, 'gamma': 100.0}              |        8        |
|  0.473059077696 |  0.019069820006  |             {'C': 10000.0, 'gamma': 1000.0}              |        21       |
|  0.461307945417 |  0.016670270613  |             {'C': 10000.0, 'gamma': 10000.0}             |        25       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.67      0.64        73
          1       0.40      0.34      0.37        47

avg / total       0.53      0.54      0.53       120


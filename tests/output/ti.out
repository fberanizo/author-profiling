Evaluating KNeighborsClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.546961325967 | 0.0741951761234 |  {'n_neighbors': 3} |        5        |
|  0.585635359116 | 0.0405118134935 |  {'n_neighbors': 5} |        2        |
|  0.572744014733 | 0.0449026981682 | {'n_neighbors': 11} |        4        |
|  0.596685082873 | 0.0312262580406 | {'n_neighbors': 21} |        1        |
|  0.578268876611 | 0.0383087312606 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.62      0.60        37
          1       0.33      0.29      0.31        24

avg / total       0.48      0.49      0.48        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.424027117572 |  0.111563181946 |  {'n_neighbors': 3} |        4        |
|  0.442242588463 | 0.0608376075299 |  {'n_neighbors': 5} |        2        |
|  0.432252924184 |  0.105724801522 | {'n_neighbors': 11} |        3        |
|  0.443591698357 |  0.186716105172 | {'n_neighbors': 21} |        1        |
|  0.399871215341 | 0.0716093161656 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.62      0.60        37
          1       0.33      0.29      0.31        24

avg / total       0.48      0.49      0.48        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.336665789704 |  0.103024240604 |  {'n_neighbors': 3} |        2        |
|  0.350477944401 | 0.0682825908742 |  {'n_neighbors': 5} |        1        |
|  0.186047531351 | 0.0856003099904 | {'n_neighbors': 11} |        4        |
|  0.243093922652 | 0.0608542638367 | {'n_neighbors': 21} |        3        |
|  0.163158817855 |  0.061857883333 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.65      0.63        37
          1       0.41      0.38      0.39        24

avg / total       0.53      0.54      0.54        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.539594843462 | 0.0660273769538 |  {'n_neighbors': 3} |        5        |
|  0.570902394107 | 0.0543021159132 |  {'n_neighbors': 5} |        3        |
|  0.558011049724 | 0.0367598933487 | {'n_neighbors': 11} |        4        |
|  0.598526703499 | 0.0391729910677 | {'n_neighbors': 21} |        1        |
|  0.589318600368 | 0.0360789003175 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.92      0.74        37
          1       0.50      0.12      0.20        24

avg / total       0.57      0.61      0.53        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.41882538536  | 0.0813432430611 |  {'n_neighbors': 3} |        4        |
|  0.457295432955 |  0.106118986351 |  {'n_neighbors': 5} |        2        |
|  0.389670182488 |  0.148798143877 | {'n_neighbors': 11} |        5        |
|  0.491005756061 |  0.205350458974 | {'n_neighbors': 21} |        1        |
|  0.424435090181 |   0.1733254381  | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.92      0.74        37
          1       0.50      0.12      0.20        24

avg / total       0.57      0.61      0.53        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.304086643866 |  0.07950955633  |  {'n_neighbors': 3} |        2        |
|  0.312900114005 | 0.0670928033991 |  {'n_neighbors': 5} |        1        |
|  0.205428396036 | 0.0849173954065 | {'n_neighbors': 11} |        3        |
|  0.173463123739 |  0.112746640511 | {'n_neighbors': 21} |        4        |
|  0.121415416996 | 0.0673018642028 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.65      0.62        37
          1       0.38      0.33      0.36        24

avg / total       0.51      0.52      0.52        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.546961325967 | 0.0537149653125 |  {'n_neighbors': 3} |        5        |
|  0.565377532228 | 0.0697475428147 |  {'n_neighbors': 5} |        4        |
|  0.574585635359 | 0.0742941676035 | {'n_neighbors': 11} |        2        |
|  0.572744014733 | 0.0585937482963 | {'n_neighbors': 21} |        3        |
|  0.594843462247 |  0.042459145218 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.89      0.72        37
          1       0.33      0.08      0.13        24

avg / total       0.50      0.57      0.49        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.438024872743 | 0.0685066565464 |  {'n_neighbors': 3} |        1        |
|  0.428720926366 | 0.0766812914235 |  {'n_neighbors': 5} |        3        |
|  0.408945489747 |  0.153825043589 | {'n_neighbors': 11} |        4        |
|  0.428813768593 |  0.13248416573  | {'n_neighbors': 21} |        2        |
|  0.350261064902 |  0.212608424595 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.68      0.62        37
          1       0.29      0.21      0.24        24

avg / total       0.46      0.49      0.47        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.373717442778 |  0.129860040669 |  {'n_neighbors': 3} |        1        |
|  0.364640883978 |  0.094961970504 |  {'n_neighbors': 5} |        2        |
|  0.201262825572 | 0.0488916527573 | {'n_neighbors': 11} |        4        |
|  0.229237919846 |  0.111087504496 | {'n_neighbors': 21} |        3        |
|  0.14062088924  | 0.0568763478504 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.68      0.62        37
          1       0.29      0.21      0.24        24

avg / total       0.46      0.49      0.47        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.546961325967 | 0.0427504720696 |  {'n_neighbors': 3} |        5        |
|  0.55985267035  | 0.0697791094184 |  {'n_neighbors': 5} |        4        |
|  0.574585635359 | 0.0388167046299 | {'n_neighbors': 11} |        2        |
|  0.58379373849  | 0.0586564469735 | {'n_neighbors': 21} |        1        |
|  0.572744014733 | 0.0484459418936 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.86      0.74        37
          1       0.55      0.25      0.34        24

avg / total       0.60      0.62      0.58        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.395227867319 |  0.115604933062 |  {'n_neighbors': 3} |        5        |
|  0.423395962981 | 0.0923687192164 |  {'n_neighbors': 5} |        3        |
|  0.443363476098 | 0.0912092784096 | {'n_neighbors': 11} |        2        |
|  0.475942637269 |  0.174559586959 | {'n_neighbors': 21} |        1        |
|  0.42114547004  |  0.204724656385 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.86      0.74        37
          1       0.55      0.25      0.34        24

avg / total       0.60      0.62      0.58        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.30838375866  |  0.113011494212 |  {'n_neighbors': 3} |        2        |
|  0.344865386302 |  0.103575870043 |  {'n_neighbors': 5} |        1        |
|  0.219766728054 |  0.11813264879  | {'n_neighbors': 11} |        3        |
|  0.158905551171 | 0.0986212490317 | {'n_neighbors': 21} |        4        |
|  0.112689643076 | 0.0647724819541 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.73      0.67        37
          1       0.41      0.29      0.34        24

avg / total       0.53      0.56      0.54        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.521178637201 | 0.0421025422349 |  {'n_neighbors': 3} |        5        |
|  0.561694290976 | 0.0587173746333 |  {'n_neighbors': 5} |        3        |
|  0.550644567219 |  0.038982622695 | {'n_neighbors': 11} |        4        |
|  0.567219152855 | 0.0335816972211 | {'n_neighbors': 21} |        2        |
|  0.585635359116 | 0.0416523726354 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.86      0.72        37
          1       0.44      0.17      0.24        24

avg / total       0.55      0.59      0.53        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|   0.3710941571  | 0.0873312575096 |  {'n_neighbors': 3} |        3        |
|  0.431666036784 | 0.0863253866486 |  {'n_neighbors': 5} |        2        |
|  0.446145219626 |  0.137002955709 | {'n_neighbors': 11} |        1        |
|  0.336493095609 |  0.124575017121 | {'n_neighbors': 21} |        5        |
|  0.366903446461 |  0.117031896938 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.86      0.74        37
          1       0.55      0.25      0.34        24

avg / total       0.60      0.62      0.58        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.298868718758 | 0.0911818663799 |  {'n_neighbors': 3} |        1        |
|  0.294133122862 |  0.104027290115 |  {'n_neighbors': 5} |        2        |
|  0.238709111637 | 0.0694239753845 | {'n_neighbors': 11} |        3        |
|  0.172323072876 |  0.064520558859 | {'n_neighbors': 21} |        4        |
|   0.1166798211  | 0.0563605671224 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.62      0.63        37
          1       0.44      0.46      0.45        24

avg / total       0.56      0.56      0.56        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.546961325967 | 0.0591562636451 |  {'n_neighbors': 3} |        5        |
|  0.558011049724 | 0.0781038073128 |  {'n_neighbors': 5} |        4        |
|  0.580110497238 | 0.0505228104649 | {'n_neighbors': 11} |        3        |
|  0.587476979742 |  0.04152358264  | {'n_neighbors': 21} |        1        |
|  0.585635359116 | 0.0390475986915 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.86      0.74        37
          1       0.55      0.25      0.34        24

avg / total       0.60      0.62      0.58        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.396233635937 | 0.0868850620468 |  {'n_neighbors': 3} |        3        |
|  0.407560166786 |  0.129174236828 |  {'n_neighbors': 5} |        2        |
|  0.391718287851 |  0.124122162516 | {'n_neighbors': 11} |        4        |
|  0.422745675646 |  0.148719417139 | {'n_neighbors': 21} |        1        |
|  0.373324802883 |  0.253873301018 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.86      0.74        37
          1       0.55      0.25      0.34        24

avg / total       0.60      0.62      0.58        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.340480575287 |  0.115561174935 |  {'n_neighbors': 3} |        1        |
|  0.32346750855  |  0.149570736495 |  {'n_neighbors': 5} |        2        |
|  0.206261510129 |  0.117959029823 | {'n_neighbors': 11} |        3        |
|  0.19148469701  | 0.0912398707289 | {'n_neighbors': 21} |        4        |
|  0.10769095852  | 0.0373977528346 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.78      0.70        37
          1       0.47      0.29      0.36        24

avg / total       0.57      0.59      0.57        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.568014705882 | 0.0739765783676 |  {'n_neighbors': 3} |        4        |
|  0.582720588235 | 0.0722733093046 |  {'n_neighbors': 5} |        3        |
|  0.568014705882 | 0.0752087606359 | {'n_neighbors': 11} |        4        |
|  0.595588235294 | 0.0363969525417 | {'n_neighbors': 21} |        1        |
|  0.595588235294 | 0.0549038175562 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.86      0.74        36
          1       0.58      0.29      0.39        24

avg / total       0.62      0.63      0.60        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.421463234697 |  0.118075106163 |  {'n_neighbors': 3} |        3        |
|  0.467920974988 |  0.112929283128 |  {'n_neighbors': 5} |        1        |
|  0.407418166644 |  0.117174379693 | {'n_neighbors': 11} |        4        |
|  0.444178921569 | 0.0892396499746 | {'n_neighbors': 21} |        2        |
|  0.390384278711 |  0.194897390553 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.69      0.64        36
          1       0.39      0.29      0.33        24

avg / total       0.51      0.53      0.52        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.350052521008 | 0.0802166285086 |  {'n_neighbors': 3} |        1        |
|  0.318277310924 | 0.0777736653799 |  {'n_neighbors': 5} |        2        |
|  0.252363445378 | 0.0764863747174 | {'n_neighbors': 11} |        3        |
|  0.243040966387 |  0.136325321351 | {'n_neighbors': 21} |        4        |
|  0.107536764706 | 0.0599538531112 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.72      0.67        36
          1       0.44      0.33      0.38        24

avg / total       0.55      0.57      0.55        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.507352941176 | 0.0898197751615 |  {'n_neighbors': 3} |        5        |
|  0.547794117647 | 0.0686992319408 |  {'n_neighbors': 5} |        4        |
|  0.553308823529 | 0.0440741712816 | {'n_neighbors': 11} |        3        |
|      0.5625     | 0.0336433702482 | {'n_neighbors': 21} |        2        |
|  0.595588235294 | 0.0469230035195 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.89      0.70        36
          1       0.00      0.00      0.00        24

avg / total       0.34      0.53      0.42        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.351577281132 | 0.0893872993897 |  {'n_neighbors': 3} |        4        |
|  0.409239246912 |  0.148337079967 |  {'n_neighbors': 5} |        2        |
|  0.350359291444 |  0.159520423428 | {'n_neighbors': 11} |        5        |
|  0.379628413866 |  0.116160657298 | {'n_neighbors': 21} |        3        |
|  0.507072829132 |  0.235961940037 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.89      0.70        36
          1       0.00      0.00      0.00        24

avg / total       0.34      0.53      0.42        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.289522058824 |  0.105167015545 |  {'n_neighbors': 3} |        2        |
|  0.313287815126 | 0.0602832635206 |  {'n_neighbors': 5} |        1        |
|  0.163340336134 | 0.0747982375886 | {'n_neighbors': 11} |        4        |
|  0.172794117647 |  0.041365087424 | {'n_neighbors': 21} |        3        |
| 0.0890231092437 | 0.0451878415551 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.83      0.76        36
          1       0.65      0.46      0.54        24

avg / total       0.68      0.68      0.67        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.550458715596 | 0.0798915197675 |  {'n_neighbors': 3} |        5        |
|  0.566972477064 | 0.0477417541534 |  {'n_neighbors': 5} |        4        |
|  0.596330275229 | 0.0697339150903 | {'n_neighbors': 11} |        1        |
|  0.594495412844 | 0.0453227604396 | {'n_neighbors': 21} |        2        |
|  0.579816513761 | 0.0519689576595 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.53      0.69      0.60        36
          1       0.08      0.04      0.06        23

avg / total       0.36      0.44      0.39        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.421404091043 |  0.114342036866 |  {'n_neighbors': 3} |        5        |
|   0.4348353098  | 0.0911405322636 |  {'n_neighbors': 5} |        3        |
|  0.466367592652 |  0.154310849154 | {'n_neighbors': 11} |        2        |
|  0.426073976991 |  0.158292056896 | {'n_neighbors': 21} |        4        |
|  0.491817387505 |  0.142623245469 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.81      0.67        36
          1       0.12      0.04      0.06        23

avg / total       0.40      0.51      0.43        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.335386631717 | 0.0743179677596 |  {'n_neighbors': 3} |        1        |
|  0.320838794233 |  0.129167572504 |  {'n_neighbors': 5} |        2        |
|  0.209174311927 | 0.0592451144786 | {'n_neighbors': 11} |        3        |
|  0.190956749672 | 0.0677694123443 | {'n_neighbors': 21} |        4        |
|  0.10747051114  | 0.0991127764543 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.56      0.61      0.59        36
          1       0.30      0.26      0.28        23

avg / total       0.46      0.47      0.47        59

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.533944954128 | 0.0443265591776 |  {'n_neighbors': 3} |        5        |
|  0.557798165138 |  0.067542173778 |  {'n_neighbors': 5} |        4        |
|  0.570642201835 | 0.0438678948428 | {'n_neighbors': 11} |        3        |
|  0.590825688073 | 0.0580565482513 | {'n_neighbors': 21} |        1        |
|  0.585321100917 | 0.0362689303101 | {'n_neighbors': 31} |        2        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.69      0.66        36
          1       0.42      0.35      0.38        23

avg / total       0.55      0.56      0.55        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.426579338992 |  0.113507775181 |  {'n_neighbors': 3} |        4        |
|  0.420126616928 | 0.0993676852655 |  {'n_neighbors': 5} |        5        |
|  0.45955668185  |  0.125877851224 | {'n_neighbors': 11} |        2        |
|  0.505804236538 |  0.117174599135 | {'n_neighbors': 21} |        1        |
|  0.428363186253 |  0.146337369099 | {'n_neighbors': 31} |        3        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 21}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.69      0.66        36
          1       0.42      0.35      0.38        23

avg / total       0.55      0.56      0.55        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.324901703801 | 0.0968543039682 |  {'n_neighbors': 3} |        1        |
|  0.303014416776 |  0.141354912645 |  {'n_neighbors': 5} |        2        |
|  0.227129750983 | 0.0719932274455 | {'n_neighbors': 11} |        4        |
|  0.242070773263 |  0.098502313788 | {'n_neighbors': 21} |        3        |
|  0.148885976409 | 0.0500828384189 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.58      0.59        36
          1       0.38      0.39      0.38        23

avg / total       0.51      0.51      0.51        59

Evaluating RandomForestClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.576427255985 | 0.0592261799017 | {'n_estimators': 2}  |        1        |
|  0.513812154696 |  0.059045046701 | {'n_estimators': 3}  |        7        |
|  0.539594843462 | 0.0763451516983 | {'n_estimators': 5}  |        6        |
|  0.55985267035  | 0.0503793378485 | {'n_estimators': 10} |        3        |
|  0.558011049724 | 0.0590581649987 | {'n_estimators': 20} |        4        |
|  0.541436464088 | 0.0405441477622 | {'n_estimators': 40} |        5        |
|  0.570902394107 | 0.0540732542136 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.86      0.73        37
          1       0.50      0.21      0.29        24

avg / total       0.58      0.61      0.56        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.419708488769 |  0.187245134325 | {'n_estimators': 2}  |        3        |
|  0.393480076232 | 0.0915303674664 | {'n_estimators': 3}  |        5        |
|  0.434338423836 | 0.0807163554334 | {'n_estimators': 5}  |        1        |
|  0.331211759389 |  0.122706123799 | {'n_estimators': 10} |        6        |
|  0.412861191217 |  0.103524314728 | {'n_estimators': 20} |        4        |
|  0.433050906532 |  0.123766091503 | {'n_estimators': 40} |        2        |
|  0.326793474584 |  0.143108243204 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.81      0.74        37
          1       0.59      0.42      0.49        24

avg / total       0.64      0.66      0.64        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.159124791721 | 0.0763156720758 | {'n_estimators': 2}  |        7        |
|  0.373585898448 |  0.145471496282 | {'n_estimators': 3}  |        1        |
|  0.368981846882 |  0.115397801058 | {'n_estimators': 5}  |        2        |
|  0.247697974217 |  0.127800199142 | {'n_estimators': 10} |        3        |
|  0.228930983075 | 0.0982953240492 | {'n_estimators': 20} |        4        |
|  0.205340699816 | 0.0623306399495 | {'n_estimators': 40} |        5        |
|  0.196220292905 | 0.0575375186287 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.76      0.71        37
          1       0.53      0.42      0.47        24

avg / total       0.61      0.62      0.61        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.578268876611 | 0.0693648262096 | {'n_estimators': 2}  |        2        |
|  0.576427255985 | 0.0750794471636 | {'n_estimators': 3}  |        3        |
|  0.563535911602 | 0.0504920523262 | {'n_estimators': 5}  |        6        |
|  0.576427255985 | 0.0301749895552 | {'n_estimators': 10} |        3        |
|  0.548802946593 | 0.0485290893589 | {'n_estimators': 20} |        7        |
|  0.567219152855 | 0.0269945686418 | {'n_estimators': 40} |        5        |
|  0.580110497238 | 0.0388901544312 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.81      0.70        37
          1       0.42      0.21      0.28        24

avg / total       0.54      0.57      0.53        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.461793347843 |  0.18102475803  | {'n_estimators': 2}  |        1        |
|  0.407170483622 |  0.110073669703 | {'n_estimators': 3}  |        3        |
|  0.39909208619  |  0.13192310834  | {'n_estimators': 5}  |        5        |
|  0.405828138027 | 0.0790230235526 | {'n_estimators': 10} |        4        |
|  0.378839820723 |  0.158191032166 | {'n_estimators': 20} |        6        |
|  0.423974981434 |  0.110219138411 | {'n_estimators': 40} |        2        |
|  0.346069073141 |  0.112744635899 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.56      0.73      0.64        37
          1       0.23      0.12      0.16        24

avg / total       0.43      0.49      0.45        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.205954573358 | 0.0686573555417 | {'n_estimators': 2}  |        4        |
|  0.401385600281 | 0.0509402165341 | {'n_estimators': 3}  |        1        |
|  0.377970709462 | 0.0988912959029 | {'n_estimators': 5}  |        2        |
|  0.210427080593 | 0.0862799220911 | {'n_estimators': 10} |        3        |
|  0.205209155485 | 0.0939098885531 | {'n_estimators': 20} |        5        |
|  0.186836797334 | 0.0545972474549 | {'n_estimators': 40} |        6        |
|  0.18253968254  |  0.080553631655 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.57      0.58        37
          1       0.38      0.42      0.40        24

avg / total       0.52      0.51      0.51        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.587476979742 |  0.038691883325 | {'n_estimators': 2}  |        1        |
|  0.548802946593 | 0.0679464305268 | {'n_estimators': 3}  |        6        |
|  0.534069981584 | 0.0639630471267 | {'n_estimators': 5}  |        7        |
|  0.578268876611 | 0.0500216991357 | {'n_estimators': 10} |        4        |
|  0.55985267035  | 0.0267147663606 | {'n_estimators': 20} |        5        |
|  0.58379373849  | 0.0499183504999 | {'n_estimators': 40} |        2        |
|  0.580110497238 | 0.0438380546594 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.54      0.70      0.61        37
          1       0.15      0.08      0.11        24

avg / total       0.39      0.46      0.41        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.381448263216 | 0.0893607962331 | {'n_estimators': 2}  |        5        |
|  0.393948335815 |  0.107017114285 | {'n_estimators': 3}  |        3        |
|   0.3896474035  |  0.102702618505 | {'n_estimators': 5}  |        4        |
|  0.356436227983 | 0.0985720313431 | {'n_estimators': 10} |        6        |
|   0.402381351   |  0.135189047596 | {'n_estimators': 20} |        2        |
|  0.339116505553 |  0.16094504835  | {'n_estimators': 40} |        7        |
|  0.418734835862 |  0.138403071254 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.76      0.67        37
          1       0.36      0.21      0.26        24

avg / total       0.50      0.54      0.51        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.191177760239 | 0.0544400217968 | {'n_estimators': 2}  |        6        |
|  0.34131368938  | 0.0743836490688 | {'n_estimators': 3}  |        1        |
|  0.317854950452 |  0.075133766106 | {'n_estimators': 5}  |        2        |
|  0.210470928703 | 0.0681042396792 | {'n_estimators': 10} |        3        |
|  0.201218977462 | 0.0824193405685 | {'n_estimators': 20} |        5        |
|  0.177540997983 | 0.0533154795152 | {'n_estimators': 40} |        7        |
|  0.201394369903 | 0.0759406021387 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.65      0.63        37
          1       0.41      0.38      0.39        24

avg / total       0.53      0.54      0.54        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.552486187845 | 0.0572867305132 | {'n_estimators': 2}  |        4        |
|  0.528545119705 | 0.0693655819427 | {'n_estimators': 3}  |        7        |
|  0.546961325967 | 0.0774845143821 | {'n_estimators': 5}  |        5        |
|  0.567219152855 | 0.0498219832583 | {'n_estimators': 10} |        2        |
|  0.539594843462 | 0.0622887437837 | {'n_estimators': 20} |        6        |
|  0.563535911602 | 0.0446214780607 | {'n_estimators': 40} |        3        |
|  0.578268876611 | 0.0450334592079 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.84      0.68        37
          1       0.14      0.04      0.06        24

avg / total       0.40      0.52      0.44        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.400984274683 |  0.165840301974 | {'n_estimators': 2}  |        3        |
|  0.438088393028 | 0.0471024563991 | {'n_estimators': 3}  |        2        |
|  0.373754598282 | 0.0805750058311 | {'n_estimators': 5}  |        6        |
|  0.378980626494 | 0.0613353814767 | {'n_estimators': 10} |        5        |
|  0.357781414411 |  0.167869081144 | {'n_estimators': 20} |        7        |
|  0.396752050896 |  0.14210396178  | {'n_estimators': 40} |        4        |
|  0.441855957569 |  0.111603811556 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.84      0.70        37
          1       0.40      0.17      0.24        24

avg / total       0.53      0.57      0.52        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.173419275629 | 0.0885675720491 | {'n_estimators': 2}  |        7        |
|  0.377619924581 |  0.123139668441 | {'n_estimators': 3}  |        1        |
|  0.368981846882 | 0.0929745460146 | {'n_estimators': 5}  |        2        |
|  0.219196702622 | 0.0903196315152 | {'n_estimators': 10} |        6        |
|  0.243532403753 | 0.0755945742682 | {'n_estimators': 20} |        3        |
|  0.238270630536 |  0.094484552029 | {'n_estimators': 40} |        4        |
|  0.23349118653  | 0.0945427855865 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.65      0.62        37
          1       0.35      0.29      0.32        24

avg / total       0.49      0.51      0.50        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.570902394107 | 0.0380030575776 | {'n_estimators': 2}  |        2        |
|  0.48802946593  | 0.0898749405526 | {'n_estimators': 3}  |        7        |
|  0.53591160221  |  0.070160869799 | {'n_estimators': 5}  |        5        |
|  0.534069981584 | 0.0533673051088 | {'n_estimators': 10} |        6        |
|  0.563535911602 | 0.0477886112666 | {'n_estimators': 20} |        4        |
|  0.567219152855 |  0.03140496067  | {'n_estimators': 40} |        3        |
|  0.574585635359 |  0.057723793719 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.84      0.73        37
          1       0.54      0.29      0.38        24

avg / total       0.60      0.62      0.59        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.407357712883 |  0.231092100659 | {'n_estimators': 2}  |        4        |
|  0.395369082983 | 0.0701577310158 | {'n_estimators': 3}  |        5        |
|  0.434274638355 | 0.0972211658307 | {'n_estimators': 5}  |        1        |
|  0.432587184659 |  0.175862891498 | {'n_estimators': 10} |        2        |
|  0.324146663649 |  0.137925756328 | {'n_estimators': 20} |        7        |
|  0.417464671608 |  0.162344308094 | {'n_estimators': 40} |        3        |
|  0.336456608426 |  0.177746060192 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.62      0.62        37
          1       0.42      0.42      0.42        24

avg / total       0.54      0.54      0.54        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.206129965798 | 0.0802962681278 | {'n_estimators': 2}  |        6        |
|  0.387354205034 |  0.115302760207 | {'n_estimators': 3}  |        1        |
|  0.319214241866 |  0.134240065576 | {'n_estimators': 5}  |        2        |
|  0.224370779619 | 0.0788899145592 | {'n_estimators': 10} |        4        |
|  0.233841971411 |  0.104580155279 | {'n_estimators': 20} |        3        |
|  0.215294220819 | 0.0658703409468 | {'n_estimators': 40} |        5        |
|  0.139612382706 | 0.0630784454489 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.76      0.71        37
          1       0.53      0.42      0.47        24

avg / total       0.61      0.62      0.61        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.574585635359 | 0.0541827813491 | {'n_estimators': 2}  |        2        |
|  0.484346224678 | 0.0487409466902 | {'n_estimators': 3}  |        7        |
|  0.517495395948 | 0.0699373114489 | {'n_estimators': 5}  |        6        |
|  0.572744014733 | 0.0466757953208 | {'n_estimators': 10} |        3        |
|  0.556169429098 | 0.0670950709936 | {'n_estimators': 20} |        5        |
|  0.570902394107 | 0.0475551289846 | {'n_estimators': 40} |        4        |
|  0.58379373849  | 0.0601437988801 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.89      0.73        37
          1       0.43      0.12      0.19        24

avg / total       0.54      0.59      0.52        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.413575374901 |  0.128647683782 | {'n_estimators': 2}  |        6        |
|  0.42316289738  | 0.0849959686305 | {'n_estimators': 3}  |        4        |
|  0.377969589537 | 0.0649216173394 | {'n_estimators': 5}  |        7        |
|  0.416528115838 |  0.137995903276 | {'n_estimators': 10} |        5        |
|  0.450510593596 |  0.162964287433 | {'n_estimators': 20} |        3        |
|  0.50203475162  |  0.134851936541 | {'n_estimators': 40} |        1        |
|  0.465009208103 |  0.200593336467 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.81      0.70        37
          1       0.42      0.21      0.28        24

avg / total       0.54      0.57      0.53        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.242962378321 | 0.0915177680178 | {'n_estimators': 2}  |        3        |
|  0.397395422257 |  0.110161288828 | {'n_estimators': 3}  |        1        |
|  0.355345084627 | 0.0947480008427 | {'n_estimators': 5}  |        2        |
|  0.223932298518 |  0.102045168185 | {'n_estimators': 10} |        4        |
|  0.214548802947 | 0.0574648239253 | {'n_estimators': 20} |        5        |
|  0.205077611155 | 0.0708627022691 | {'n_estimators': 40} |        6        |
|  0.186924493554 | 0.0509040558198 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.65      0.63        37
          1       0.41      0.38      0.39        24

avg / total       0.53      0.54      0.54        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.569852941176 | 0.0424422546639 | {'n_estimators': 2}  |        6        |
|  0.474264705882 | 0.0847178746483 | {'n_estimators': 3}  |        7        |
|  0.571691176471 | 0.0755419246909 | {'n_estimators': 5}  |        5        |
|  0.579044117647 | 0.0593352321206 | {'n_estimators': 10} |        4        |
|  0.586397058824 | 0.0728551946077 | {'n_estimators': 20} |        2        |
|  0.588235294118 |  0.040423955173 | {'n_estimators': 40} |        1        |
|  0.586397058824 | 0.0349878540347 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.92      0.72        36
          1       0.25      0.04      0.07        24

avg / total       0.45      0.57      0.46        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+----------------+----------------------+-----------------+
| test_mean_score | test_std_score |        params        | test_rank_score |
+-----------------+----------------+----------------------+-----------------+
|  0.348549836601 | 0.118649045657 | {'n_estimators': 2}  |        7        |
|  0.389174107143 | 0.132645451636 | {'n_estimators': 3}  |        6        |
|  0.473134333663 | 0.112371843459 | {'n_estimators': 5}  |        1        |
|  0.431283279629 | 0.069130072038 | {'n_estimators': 10} |        4        |
|  0.45908528617  | 0.14088989884  | {'n_estimators': 20} |        2        |
|  0.426142403348 | 0.184973447671 | {'n_estimators': 40} |        5        |
|  0.434963713778 | 0.147938238877 | {'n_estimators': 60} |        3        |
+-----------------+----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.51      0.67      0.58        36
          1       0.08      0.04      0.05        24

avg / total       0.34      0.42      0.37        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.178046218487 | 0.0710556325479 | {'n_estimators': 2}  |        7        |
|  0.387342436975 |  0.11178635681  | {'n_estimators': 3}  |        2        |
|  0.40099789916  | 0.0915501247817 | {'n_estimators': 5}  |        1        |
|  0.27993697479  |  0.138107557094 | {'n_estimators': 10} |        3        |
|  0.238182773109 | 0.0704321569838 | {'n_estimators': 20} |        4        |
|  0.228860294118 |  0.105643725502 | {'n_estimators': 40} |        6        |
|  0.233718487395 | 0.0728064218048 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.81      0.67        36
          1       0.30      0.12      0.18        24

avg / total       0.47      0.53      0.48        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.601102941176 | 0.0267582651285 | {'n_estimators': 2}  |        1        |
|  0.538602941176 | 0.0704604870334 | {'n_estimators': 3}  |        5        |
|  0.525735294118 | 0.0506806908629 | {'n_estimators': 5}  |        7        |
|  0.534926470588 | 0.0656388916142 | {'n_estimators': 10} |        6        |
|  0.566176470588 | 0.0291025286298 | {'n_estimators': 20} |        4        |
|  0.575367647059 | 0.0678203504245 | {'n_estimators': 40} |        2        |
|  0.573529411765 | 0.0294334194396 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.81      0.67        36
          1       0.30      0.12      0.18        24

avg / total       0.47      0.53      0.48        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.404777055053 |  0.145319006984 | {'n_estimators': 2}  |        4        |
|   0.4548403815  | 0.0949763273774 | {'n_estimators': 3}  |        2        |
|  0.393292378871 | 0.0946166901814 | {'n_estimators': 5}  |        5        |
|  0.467027710207 |  0.164897051623 | {'n_estimators': 10} |        1        |
|  0.353486983029 | 0.0870413290986 | {'n_estimators': 20} |        7        |
|  0.362280089732 | 0.0804221619379 | {'n_estimators': 40} |        6        |
|  0.425265987077 |  0.103134316325 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 10}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.81      0.71        36
          1       0.50      0.29      0.37        24

avg / total       0.58      0.60      0.57        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.209952731092 | 0.0715536754137 | {'n_estimators': 2}  |        5        |
|  0.346244747899 | 0.0981283062074 | {'n_estimators': 3}  |        1        |
|  0.313287815126 | 0.0823731289007 | {'n_estimators': 5}  |        2        |
|  0.225052521008 |  0.10419796125  | {'n_estimators': 10} |        3        |
|  0.181985294118 | 0.0753797074594 | {'n_estimators': 20} |        7        |
|  0.191964285714 |  0.108147288477 | {'n_estimators': 40} |        6        |
|  0.210871848739 | 0.0594577061179 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.69      0.65        36
          1       0.42      0.33      0.37        24

avg / total       0.53      0.55      0.54        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.590825688073 | 0.0512757667454 | {'n_estimators': 2}  |        1        |
|  0.530275229358 | 0.0498963333027 | {'n_estimators': 3}  |        6        |
|  0.522935779817 | 0.0533150810575 | {'n_estimators': 5}  |        7        |
|  0.565137614679 |  0.061673425414 | {'n_estimators': 10} |        3        |
|  0.563302752294 | 0.0351614664403 | {'n_estimators': 20} |        4        |
|  0.550458715596 | 0.0750962249043 | {'n_estimators': 40} |        5        |
|  0.57247706422  | 0.0576940998405 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.83      0.71        36
          1       0.45      0.22      0.29        23

avg / total       0.56      0.59      0.55        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.361050845179 |  0.105458875968 | {'n_estimators': 2}  |        7        |
|  0.407931180037 | 0.0839313910794 | {'n_estimators': 3}  |        4        |
|  0.415161392704 |  0.108227416634 | {'n_estimators': 5}  |        3        |
|  0.363477781138 |  0.13586516068  | {'n_estimators': 10} |        6        |
|  0.394652686763 |  0.092817931097 | {'n_estimators': 20} |        5        |
|  0.438701916899 |  0.148446165641 | {'n_estimators': 40} |        2        |
|  0.46976376295  |  0.157907724998 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.83      0.72        36
          1       0.50      0.26      0.34        23

avg / total       0.58      0.61      0.57        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.167627785059 | 0.0753200955115 | {'n_estimators': 2}  |        7        |
|  0.325425950197 |  0.106118156109 | {'n_estimators': 3}  |        2        |
|  0.340366972477 |  0.106795033982 | {'n_estimators': 5}  |        1        |
|  0.223984272608 | 0.0978199990617 | {'n_estimators': 10} |        3        |
|  0.200131061599 | 0.0696769611115 | {'n_estimators': 20} |        4        |
|  0.186107470511 | 0.0616782472396 | {'n_estimators': 40} |        5        |
|  0.172083879423 |  0.102849130796 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.61      0.60        36
          1       0.36      0.35      0.36        23

avg / total       0.50      0.51      0.51        59

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.561467889908 | 0.0293858752774 | {'n_estimators': 2}  |        4        |
|  0.552293577982 | 0.0662581781072 | {'n_estimators': 3}  |        6        |
|  0.559633027523 | 0.0486840513286 | {'n_estimators': 5}  |        5        |
|  0.577981651376 | 0.0434955657721 | {'n_estimators': 10} |        2        |
|  0.550458715596 | 0.0365493730856 | {'n_estimators': 20} |        7        |
|  0.576146788991 | 0.0573298048912 | {'n_estimators': 40} |        3        |
|  0.596330275229 | 0.0418888199508 | {'n_estimators': 60} |        1        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 60}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.78      0.67        36
          1       0.33      0.17      0.23        23

avg / total       0.49      0.54      0.50        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.373464226905 |  0.168296555312 | {'n_estimators': 2}  |        7        |
|  0.389138990795 | 0.0969145574373 | {'n_estimators': 3}  |        6        |
|  0.462001558316 | 0.0770912088581 | {'n_estimators': 5}  |        2        |
|  0.404050167468 |  0.136013219102 | {'n_estimators': 10} |        4        |
|  0.394154988742 |  0.149468574882 | {'n_estimators': 20} |        5        |
|  0.472775159122 |  0.154185187647 | {'n_estimators': 40} |        1        |
|  0.422027926202 |  0.11902554108  | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.83      0.71        36
          1       0.45      0.22      0.29        23

avg / total       0.56      0.59      0.55        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.205242463958 |  0.101237876353 | {'n_estimators': 2}  |        5        |
|  0.366579292267 |  0.109711917052 | {'n_estimators': 3}  |        1        |
|  0.353473132372 |  0.103009869084 | {'n_estimators': 5}  |        2        |
|  0.251638269987 | 0.0688476673704 | {'n_estimators': 10} |        3        |
|  0.190956749672 | 0.0851849616758 | {'n_estimators': 20} |        6        |
|  0.227916120577 |  0.097568328578 | {'n_estimators': 40} |        4        |
|  0.190563564875 | 0.0561434770318 | {'n_estimators': 60} |        7        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.64      0.63        36
          1       0.41      0.39      0.40        23

avg / total       0.54      0.54      0.54        59

Evaluating MLPClassifier
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.604051565378 | 0.00628818395263 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        7        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.602209944751 | 0.00848063199395 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        9        |
|  0.602209944751 | 0.0106047130009  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.587476979742 | 0.0343270105427  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        16       |
|  0.596685082873 | 0.0187921441955  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.598526703499 | 0.0118996804583  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.591160220994 |  0.030843660189  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        15       |
|  0.585635359116 | 0.0242719624937  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        17       |
|  0.604051565378 | 0.00893566371013 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        7        |
|  0.593001841621 | 0.0406757863317  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        14       |
|  0.596685082873 |  0.03023759103   |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        12       |
|  0.574585635359 | 0.0423951943762  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        20       |
|  0.585635359116 | 0.0277746287654  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        17       |
|  0.569060773481 | 0.0429761379147  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        21       |
|  0.58379373849  | 0.0403917627257  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        19       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        13       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        13       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        13       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        13       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        13       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        13       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        13       |
|       0.0       |      0.0       |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
| 0.0500306936771 | 0.106584429045 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
| 0.0584714548803 | 0.118158299004 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
|  0.16758747698  | 0.34264043402  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
|  0.174585635359 | 0.251823119571 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        8        |
|  0.342848373235 | 0.387250794642 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
| 0.0755064456722 | 0.160737456384 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        10       |
|       0.0       |      0.0       |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.448434622468 | 0.471188633384 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        1        |
|  0.247158642463 | 0.189646825689 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
|  0.376561723523 | 0.262344121685 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.348057528721 | 0.116812396737 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.360673810536 | 0.272647174576 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|   0.3585986144  | 0.256804973521 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        4        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.97      0.75        37
          1       0.50      0.04      0.08        24

avg / total       0.57      0.61      0.49        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+------------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                         params                        | test_rank_score |
+------------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.00473559589582 | 0.0142505683388 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
| 0.00920810313076 | 0.0274282905291 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
| 0.00460405156538 | 0.0137141452645 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        13       |
|  0.042225730071  | 0.0644945389685 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        7        |
|  0.037139349294  | 0.0983617966899 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
| 0.0561694290976  | 0.0512039196024 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
| 0.0374901341752  | 0.0656623416416 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
| 0.00460405156538 | 0.0137141452645 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
| 0.00933964746119 | 0.0186427096454 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
| 0.0425326668421  | 0.0396152084158 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
| 0.0748925721301  | 0.0644135888192 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.11685521354   | 0.0563137563522 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.135490660353  | 0.0804362608014 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.102999210734  |  0.069735190013 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+------------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.84      0.73        37
          1       0.54      0.29      0.38        24

avg / total       0.60      0.62      0.59        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.600368324125 | 0.0157099858854  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.594843462247 | 0.0244195279639  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.593001841621 |  0.018935795158  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        15       |
|  0.604051565378 | 0.00813661180546 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.594843462247 | 0.0135331068305  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.585635359116 |  0.031834853006  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        16       |
|  0.563535911602 | 0.0553567195009  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.604051565378 | 0.00628818395263 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.594843462247 | 0.0210806818244  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.58379373849  | 0.0321571480604  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        17       |
|  0.58379373849  | 0.0395554265425  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        17       |
|  0.578268876611 | 0.0447844054992  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        19       |
|  0.576427255985 | 0.0470311123033  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        20       |
|  0.596685082873 | 0.0483527741698  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        11       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        14       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        14       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        14       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
| 0.0331491712707 | 0.0997539783716 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|       0.0       |       0.0       |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        14       |
|  0.244444444444 |  0.336828412868 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
| 0.0950276243094 |  0.162516890102 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.232658072437 |  0.218535769319 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.30531748611  |  0.220275301574 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.197163027274 |  0.201861319189 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
| 0.0994475138122 |  0.299261935115 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        10       |
| 0.0586249232658 |  0.118460694985 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.147110409541 |  0.185628684008 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.362169046423 |  0.24046247934  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|  0.285845830045 |   0.2207110189  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.373048759098 |  0.155173203725 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.397410375587 |  0.162896117303 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.89      0.73        37
          1       0.50      0.17      0.25        24

avg / total       0.57      0.61      0.54        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+------------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                         params                        | test_rank_score |
+------------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.00473559589582 | 0.0142505683388 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
| 0.0235464351486  | 0.0437022439655 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
| 0.0325791458388  | 0.0420987779153 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
| 0.0330614750504  | 0.0706497427569 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
| 0.0418310970797  | 0.0756363157835 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        8        |
| 0.0559063404367  | 0.0815303613991 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
| 0.0606419363325  | 0.0803157196177 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
| 0.00473559589582 | 0.0142505683388 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
| 0.0277997018329  | 0.0304903284235 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
| 0.0419626414102  | 0.0528791846878 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
| 0.0791896869245  | 0.0624549127517 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.102209944751  | 0.0855928322386 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.117118302201  |  0.118576227772 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.14965359993   | 0.0588753559659 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+------------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.86      0.73        37
          1       0.50      0.21      0.29        24

avg / total       0.58      0.61      0.56        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.604051565378 | 0.00819820772769 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        7        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.604051565378 | 0.0103802422304  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        7        |
|  0.598526703499 | 0.0177785617912  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.591160220994 | 0.0265134376113  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.598526703499 |  0.016726436109  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
|  0.593001841621 | 0.0332621996545  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.581952117864 | 0.0347584263035  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        20       |
|  0.596685082873 | 0.0250566875639  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
|  0.593001841621 | 0.0208675238012  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.58379373849  | 0.0328092382494  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        19       |
|  0.589318600368 | 0.0279371681256  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        15       |
|  0.585635359116 | 0.0367234784118  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.587476979742 | 0.0426624593657  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        17       |
|  0.589318600368 | 0.0368494208605  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        15       |
|  0.574585635359 | 0.0633423859028  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        14       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        14       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        14       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
|  0.169060773481 | 0.315762169501 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.218232044199 | 0.322825642586 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.197263877927 | 0.271073225233 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
|  0.172928176796 | 0.227012360422 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.293429161385 | 0.217583478399 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.298299030619 | 0.212195879173 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
|  0.213597298956 | 0.301839463103 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        10       |
|       0.0       |      0.0       |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.223384197141 | 0.211565595631 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.336086263849 | 0.147214593784 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        5        |
|  0.339676693268 | 0.261051793853 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|  0.455296851706 | 0.15571484586  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        1        |
|  0.336458972785 | 0.175288219004 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.345653655737 | 0.207900236084 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      1.00      0.78        37
          1       1.00      0.12      0.22        24

avg / total       0.78      0.66      0.56        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+------------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                         params                        | test_rank_score |
+------------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.0231518021573  | 0.0307432765049 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
| 0.0471805665176  | 0.0601698332163 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        7        |
| 0.0329737788301  | 0.0602629385569 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
| 0.0327106901693  | 0.0421894310167 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
| 0.0656406208892  | 0.0737223532274 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
| 0.0368762606332  | 0.0570635299637 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
|  0.149960536701  |  0.111317498238 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        2        |
| 0.00473559589582 | 0.0142505683388 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
| 0.0186792949224  | 0.0228176075969 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        13       |
|   0.0419187933   | 0.0484603191906 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
| 0.0891870560379  | 0.0581290105559 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.145400333246  |  0.113430437519 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.139743927037  | 0.0806711004083 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.172586161536  | 0.0843490609684 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+------------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.95      0.75        37
          1       0.60      0.12      0.21        24

avg / total       0.62      0.62      0.54        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.605893186004 |  0.005295999933 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.605893186004 |  0.005295999933 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.605893186004 |  0.005295999933 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.605893186004 |  0.005295999933 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.605893186004 |  0.005295999933 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.605893186004 |  0.005295999933 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.596685082873 |  0.019488660234 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        10       |
|  0.600368324125 | 0.0188498449961 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.576427255985 | 0.0296952468554 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        17       |
|  0.596685082873 | 0.0272549467572 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.591160220994 | 0.0291692344973 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        13       |
|  0.596685082873 | 0.0234720404063 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.574585635359 | 0.0328631260859 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        18       |
|  0.600368324125 | 0.0148047661938 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.585635359116 | 0.0339285934826 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        15       |
|  0.591160220994 |  0.025065367969 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        13       |
|  0.572744014733 | 0.0401920828819 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        19       |
|  0.580110497238 | 0.0500360230965 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        16       |
|  0.567219152855 | 0.0312031421285 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        20       |
|  0.563535911602 | 0.0482010635246 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        21       |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.116942909761 | 0.198168990658 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.240791896869 | 0.307828967259 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
|  0.260728835314 | 0.304223253393 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.187845303867 | 0.308682756579 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        13       |
|  0.207313864772 | 0.184860156009 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.341278610892 | 0.313848545635 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.294935543278 | 0.34046759295  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        6        |
|  0.198895027624 | 0.399168881065 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.308041743401 | 0.350110029618 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.513167587477 | 0.322854447103 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.283872665088 | 0.194770127935 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.287327896168 | 0.180170617058 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        7        |
|  0.324365735554 | 0.144059619123 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.407959275224 | 0.102369045616 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.97      0.77        37
          1       0.75      0.12      0.21        24

avg / total       0.68      0.64      0.55        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+------------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                         params                        | test_rank_score |
+------------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.00473559589582 | 0.0142505683388 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
| 0.0421380338507  | 0.0492305736206 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.027843549943  | 0.0471065935653 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
| 0.0416995527493  | 0.0476427606574 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        9        |
| 0.0374462860651  | 0.0464401301766 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
| 0.0837498903797  |  0.097304161319 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
| 0.0564325177585  | 0.0658518089464 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
| 0.00933964746119 | 0.0186427096454 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
| 0.0374901341752  | 0.0460588257171 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
| 0.0743225466982  | 0.0467275182145 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
| 0.0935718670525  | 0.0659426781053 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.107164781198  | 0.0497510165327 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.121415416996  | 0.0779352650081 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.139743927037  | 0.0800652825462 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+------------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.89      0.73        37
          1       0.50      0.17      0.25        24

avg / total       0.57      0.61      0.54        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.604051565378 | 0.00628818395263 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.602209944751 | 0.0138502507666  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        7        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.593001841621 | 0.0188639882005  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        9        |
|  0.596685082873 | 0.0252784281316  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.585635359116 | 0.0190961062041  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.587476979742 | 0.0264039013731  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        13       |
|  0.580110497238 | 0.0303113119431  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        16       |
|  0.581952117864 | 0.0259052498882  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        15       |
|  0.569060773481 |  0.048300582556  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        19       |
|  0.593001841621 | 0.0219958937944  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.593001841621 | 0.0144826278655  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.580110497238 | 0.0317367919562  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        16       |
|  0.570902394107 | 0.0232238048524  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        18       |
|  0.565377532228 | 0.0306007963895  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        21       |
|  0.591160220994 |  0.044414549628  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        12       |
|  0.567219152855 | 0.0574810763043  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        20       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.162764184864 | 0.220190627561 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
|  0.129702709813 | 0.30427702164  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.109760589319 | 0.157549541313 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.252543190388 | 0.239211034947 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.268067414476 | 0.221984954281 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        10       |
|  0.34445995993  | 0.276138970149 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.326182105188 | 0.326937571096 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
|  0.303867403315 | 0.459926085929 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        7        |
|  0.396804934374 | 0.320725219179 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        1        |
|  0.28993247391  | 0.190924740516 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        9        |
|  0.318427633345 | 0.151024657465 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.290971474811 | 0.19271917961  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        8        |
|  0.349372972025 | 0.222105963172 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.349088756547 | 0.228901692849 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.95      0.73        37
          1       0.00      0.00      0.00        24

avg / total       0.36      0.57      0.44        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+------------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                         params                        | test_rank_score |
+------------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        16       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
| 0.00464789967552 | 0.0141324302434 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
| 0.00938349557134 | 0.0189415715638 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
| 0.0463036043147  | 0.0709665176541 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        10       |
| 0.0234148908182  | 0.0310701926609 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
| 0.0701569762343  | 0.0812625240796 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
| 0.0278873980531  | 0.0470856879235 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
| 0.0651144435675  | 0.0583748085018 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        8        |
| 0.0844076120319  | 0.0882452498781 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
| 0.0232833464878  | 0.0309074467569 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
| 0.0519600105235  | 0.0449391111049 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
| 0.0653775322284  | 0.0552459422766 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
| 0.0935718670525  | 0.0652001520229 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.140182408138  | 0.0408515561597 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.14960975182   | 0.0631975723171 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.177584846093  | 0.0940442191052 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+------------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.68      0.63        37
          1       0.37      0.29      0.33        24

avg / total       0.51      0.52      0.51        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.604051565378 | 0.00628818395263 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        8        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.605893186004 |  0.005295999933  |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.605893186004 |  0.005295999933  | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.605893186004 | 0.0424289985922  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        1        |
|  0.596685082873 | 0.0139345497321  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.591160220994 | 0.0227586894677  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        14       |
|  0.594843462247 | 0.0166738221795  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.585635359116 | 0.0386475012481  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        18       |
|  0.594843462247 | 0.0278848028397  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.598526703499 | 0.0403350256928  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        9        |
|  0.591160220994 | 0.0223171922874  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.591160220994 | 0.0218301022301  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        14       |
|  0.58379373849  | 0.0299333342212  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        19       |
|  0.580110497238 | 0.0322489426904  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        20       |
|  0.591160220994 |  0.064820719502  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        14       |
|  0.578268876611 |  0.072439849058  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        21       |
|  0.598526703499 | 0.0219808559969  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        9        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.127685696746 | 0.172102351537 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|  0.192072660305 | 0.241879036863 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.278161448742 | 0.277718037388 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.239391593673 | 0.305339929077 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        11       |
|  0.499079189687 | 0.37009415853  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        1        |
|  0.224094536525 | 0.208939446518 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.301677021567 | 0.182660118119 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        7        |
|  0.283609576427 | 0.324914283158 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.296378146102 | 0.345129191205 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.470776696191 | 0.348686877062 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.380593557251 | 0.20728514162  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.393516550975 | 0.159552880166 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.410434777009 | 0.195812332018 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.445609209698 | 0.102772548213 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.78      0.67        37
          1       0.27      0.12      0.17        24

avg / total       0.46      0.52      0.47        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.0188108392528 | 0.0313520370964 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
| 0.0610365693239 | 0.0637951413483 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        7        |
| 0.0282820310445 |  0.043473578439 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
| 0.0602911514514 | 0.0689348937728 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
| 0.0564763658686 | 0.0728731749843 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        10       |
|   0.176751732   |  0.101531797836 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
| 0.0565640620889 | 0.0896557366205 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        9        |
| 0.0139436990266 | 0.0294648622691 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
| 0.0374901341752 | 0.0589444045287 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        11       |
| 0.0611242655442 | 0.0604674443194 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        6        |
|  0.163334210296 | 0.0506319565133 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|  0.131018153118 | 0.0715654353688 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.140050863808 | 0.0926861382071 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.182320441989 | 0.0668435614171 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.86      0.71        37
          1       0.38      0.12      0.19        24

avg / total       0.51      0.57      0.51        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.606617647059 | 0.00545308712286 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.606617647059 | 0.00545308712286 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.604779411765 | 0.00917110107027 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        7        |
|  0.606617647059 | 0.00545308712286 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.606617647059 | 0.00545308712286 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.606617647059 | 0.00545308712286 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.606617647059 | 0.00545308712286 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.591911764706 | 0.0188502542109  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        14       |
|     0.59375     | 0.0137774982062  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
|  0.599264705882 | 0.0263044330254  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
|  0.586397058824 | 0.0245255352813  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        17       |
|  0.573529411765 | 0.0524202907756  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        21       |
|  0.595588235294 | 0.0336856836132  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        12       |
|  0.588235294118 |  0.020532987582  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        15       |
|  0.602941176471 | 0.0231893252764  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        8        |
|  0.601102941176 | 0.0229884235349  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.597426470588 | 0.0315877153273  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        11       |
|  0.586397058824 | 0.0317219956214  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        17       |
|  0.588235294118 | 0.0414146901931  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        15       |
|  0.584558823529 | 0.0608253741436  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        19       |
|  0.577205882353 |  0.049963706347  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        20       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        36
          1       0.00      0.00      0.00        24

avg / total       0.36      0.60      0.45        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.167331932773 | 0.213583640416 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.226225490196 | 0.258401575055 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.36162464986  | 0.372360106691 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        7        |
|  0.246844362745 | 0.197067318611 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.230025106634 | 0.211043364447 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.364837184874 | 0.31374443458  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
|  0.291544117647 | 0.315299527705 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
|  0.119719251337 | 0.19953779585  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.267463235294 | 0.300804644422 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.442629551821 | 0.241120940843 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        3        |
|  0.382593662465 | 0.188222965327 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.470303746499 | 0.210849453948 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        1        |
|  0.457506127451 | 0.218772467142 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.380974825828 |  0.145080566   |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        5        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.86      0.69        36
          1       0.17      0.04      0.07        24

avg / total       0.41      0.53      0.44        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.0378151260504 | 0.0593464155119 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        12       |
| 0.0376838235294 | 0.0592934277542 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        13       |
| 0.0656512605042 |  0.05287338817  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        7        |
| 0.0749737394958 | 0.0638146093679 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        6        |
|  0.046743697479 | 0.0363217476469 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
| 0.0797006302521 |  0.055238454336 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
| 0.0513392857143 | 0.0489443726646 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        9        |
| 0.0235031512605 | 0.0235977202122 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|     0.046875    | 0.0363754950869 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
| 0.0563287815126 |  0.05097461134  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.112394957983 | 0.0439513581885 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.140756302521 | 0.0612830580817 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.182773109244 | 0.0917781141126 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.149422268908 |  0.057110682917 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.86      0.69        36
          1       0.17      0.04      0.07        24

avg / total       0.41      0.53      0.44        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.606617647059 | 0.00545308712286 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        2        |
|  0.606617647059 | 0.00545308712286 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.606617647059 | 0.00545308712286 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.606617647059 | 0.00545308712286 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.608455882353 | 0.00877032114213 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.606617647059 | 0.00545308712286 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.606617647059 | 0.00545308712286 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.604779411765 | 0.00662407397913 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        8        |
|     0.59375     |  0.019773041006  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        11       |
|  0.579044117647 | 0.0298258186123  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        16       |
|  0.586397058824 | 0.0309916740022  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        14       |
|  0.577205882353 | 0.0402256631776  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.584558823529 | 0.0197712571755  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        15       |
|  0.579044117647 | 0.0233813980499  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        16       |
|  0.601102941176 | 0.0126570779944  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.595588235294 | 0.0179806069535  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        10       |
|  0.591911764706 | 0.0254089027179  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        12       |
|  0.575367647059 |  0.041011498021  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        21       |
|  0.579044117647 | 0.0386478909093  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        16       |
|  0.577205882353 | 0.0567442183413  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        19       |
|  0.588235294118 | 0.0396900161224  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        13       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        36
          1       0.00      0.00      0.00        24

avg / total       0.36      0.60      0.45        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.0496323529412 | 0.149508548291 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
|  0.100183823529 | 0.200137735741 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.265931372549 | 0.31724577882  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        6        |
|  0.227718360071 | 0.244643578832 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        8        |
|  0.17718837535  | 0.265041229504 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
|  0.14693627451  | 0.180918839975 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        10       |
|  0.123161764706 | 0.191971973314 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        11       |
| 0.0496323529412 | 0.149508548291 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
|  0.259191176471 | 0.40956855913  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        7        |
|  0.274772408964 | 0.329207899398 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        5        |
|  0.282453606443 | 0.218812926444 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.345127273666 | 0.291565545088 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.43232303338  | 0.233093551301 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.427726715686 | 0.149638622658 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.83      0.73        36
          1       0.57      0.33      0.42        24

avg / total       0.62      0.63      0.61        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+------------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                         params                        | test_rank_score |
+------------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        14       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        14       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        14       |
|       0.0        |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        14       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        14       |
|       0.0        |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        14       |
| 0.00459558823529 | 0.0137029538094 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
| 0.0139180672269  | 0.0294438268234 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
| 0.0325630252101  |  0.029466281462 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        10       |
| 0.0325630252101  | 0.0358614346041 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
| 0.0375525210084  | 0.0461134480972 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        9        |
| 0.0512079831933  |  0.056245706675 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
| 0.0797006302521  | 0.0670747718864 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|       0.0        |       0.0       |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
| 0.0422794117647  | 0.0390384840166 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        7        |
| 0.0421481092437  | 0.0447377750271 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.112657563025  | 0.0647172385594 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
| 0.0655199579832  | 0.0605357699815 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.131171218487  |  0.106427587338 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.149422268908  | 0.0748981203602 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+------------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.83      0.73        36
          1       0.57      0.33      0.42        24

avg / total       0.62      0.63      0.61        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        2        |
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.607339449541 | 0.00637618179008 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.603669724771 | 0.00639526488944 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        7        |
|  0.605504587156 | 0.00555532175064 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.594495412844 | 0.0262099963226  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        9        |
|  0.592660550459 | 0.0299074173448  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.592660550459 | 0.0339240343585  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        12       |
|  0.592660550459 | 0.0311618462438  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        12       |
|  0.592660550459 | 0.0472831340966  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        12       |
|  0.590825688073 | 0.0455322451751  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        17       |
|  0.581651376147 | 0.0387543182202  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.594495412844 | 0.0204655621823  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        9        |
|  0.594495412844 | 0.0335959824537  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
|  0.592660550459 |  0.029164874398  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        12       |
|  0.596330275229 | 0.0248704900445  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        8        |
|  0.585321100917 | 0.0350210262713  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        18       |
|  0.585321100917 | 0.0577068205414  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        18       |
|  0.585321100917 | 0.0449069807989  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        18       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 100}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        36
          1       0.00      0.00      0.00        23

avg / total       0.37      0.61      0.46        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
|  0.333333333333 | 0.325285101954 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        8        |
|  0.223394495413 | 0.324077293373 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
|  0.332874617737 | 0.327046670285 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        9        |
|  0.287811271298 | 0.328402291005 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.246636085627 | 0.174092276461 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        11       |
|  0.157232801377 | 0.246327777268 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        13       |
|  0.432372214941 | 0.258697169517 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
| 0.0504587155963 | 0.150609680361 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
|  0.424923547401 | 0.361935164735 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.429877675841 | 0.271118770444 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.50381170817  | 0.167081458179 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        1        |
|  0.436766979198 | 0.166132186608 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.369646133683 | 0.217586959834 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        7        |
|  0.417506418149 | 0.134344874572 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        6        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.94      0.73        36
          1       0.00      0.00      0.00        23

avg / total       0.36      0.58      0.45        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.0280471821756 | 0.0373556701133 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
| 0.0281782437746 | 0.0379023338066 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        12       |
| 0.0463958060288 | 0.0408073098771 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
|  0.125950196592 | 0.0561234475873 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
| 0.0791612057667 | 0.0757297916834 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        7        |
|  0.115727391874 |  0.115260637476 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        6        |
| 0.0741808650066 |  0.101242889239 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        8        |
| 0.0184796854522 | 0.0304255435213 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        14       |
| 0.0694626474443 | 0.0627211324582 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        9        |
| 0.0465268676278 | 0.0294540218112 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.11625163827  | 0.0478402745114 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.143643512451 | 0.0925345347456 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.185845347313 |  0.101722914699 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.190432503277 |  0.10090331826  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.94      0.76        36
          1       0.67      0.17      0.28        23

avg / total       0.65      0.64      0.57        59

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        1        |
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        1        |
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        1        |
|  0.605504587156 | 0.00555532175064 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        1        |
|  0.605504587156 | 0.00555532175064 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        1        |
|  0.605504587156 | 0.00555532175064 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        1        |
|  0.605504587156 | 0.00555532175064 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        1        |
|  0.585321100917 | 0.0250441103186  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        16       |
|  0.583486238532 | 0.0278846483423  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        17       |
|  0.590825688073 | 0.0137889325293  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        13       |
|  0.601834862385 | 0.0361265982662  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
|  0.583486238532 | 0.0382047571584  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        17       |
|  0.588990825688 | 0.0362313269998  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        14       |
|  0.576146788991 | 0.0384982633881  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        20       |
|  0.592660550459 | 0.0159697173394  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        12       |
|  0.603669724771 |  0.027377264601  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        8        |
|  0.603669724771 | 0.0288710105731  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        8        |
|  0.596330275229 | 0.0308769852059  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        11       |
|  0.588990825688 | 0.0458301484223  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        14       |
|  0.576146788991 | 0.0320244123023  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        20       |
|  0.577981651376 | 0.0316287938129  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        19       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'logistic', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        36
          1       0.00      0.00      0.00        23

avg / total       0.37      0.61      0.46        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+----------------+-------------------------------------------------------+-----------------+
| test_mean_score | test_std_score |                         params                        | test_rank_score |
+-----------------+----------------+-------------------------------------------------------+-----------------+
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        16       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        16       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        16       |
|       0.0       |      0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
|  0.100917431193 | 0.301219360723 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        14       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        16       |
|       0.0       |      0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        16       |
|  0.182568807339 | 0.319358312095 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        11       |
|  0.233027522936 | 0.325958022251 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.11376146789  | 0.174244313299 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        13       |
|   0.3274472113  | 0.302142745068 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        5        |
|  0.319204892966 | 0.290842531275 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.277438131216 | 0.229383005844 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        8        |
|  0.36496286588  | 0.268757617852 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
| 0.0403669724771 | 0.120487744289 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        15       |
|  0.16880733945  | 0.223277195435 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
|  0.224921363041 | 0.247882708738 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        10       |
|  0.305490024756 | 0.246058599944 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.385125170446 | 0.162700050414 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.460384447357 | 0.24458630658  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        1        |
|  0.397441549276 | 0.164221646966 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 120}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.75      0.67        36
          1       0.36      0.22      0.27        23

avg / total       0.51      0.54      0.51        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+-----------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                         params                        | test_rank_score |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        15       |
|       0.0       |       0.0       |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        15       |
|       0.0       |       0.0       | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        15       |
| 0.0229357798165 | 0.0367493375094 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        13       |
| 0.0604193971166 | 0.0545427868179 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        8        |
|  0.037745740498 | 0.0664594746472 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        11       |
| 0.0559633027523 | 0.0412045358104 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        10       |
| 0.0834862385321 | 0.0766814320316 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
| 0.0598951507208 | 0.0763395691044 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        9        |
| 0.0888597640891 | 0.0899163328026 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        5        |
| 0.0229357798165 | 0.0420419788528 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        13       |
| 0.0370904325033 | 0.0403019696015 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        12       |
| 0.0792922673657 | 0.0792261181627 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        7        |
| 0.0979030144168 | 0.0612240952409 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
| 0.0930537352556 | 0.0911922834852 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.162778505898 | 0.0838719390799 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.223328964613 | 0.0911054587333 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        1        |
+-----------------+-----------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.72      0.65        36
          1       0.33      0.22      0.26        23

avg / total       0.49      0.53      0.50        59

Evaluating SVC
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |        {'C': 0.001}        |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.01}         |        1        |
|  0.605893186004 |  0.005295999933 | {'C': 0.10000000000000001} |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 1.0}         |        1        |
|  0.596685082873 | 0.0192646525463 |        {'C': 10.0}         |        5        |
|  0.578268876611 | 0.0516035048994 |        {'C': 100.0}        |        7        |
|  0.567219152855 | 0.0640074234111 |       {'C': 1000.0}        |        8        |
|  0.581952117864 | 0.0717049996487 |       {'C': 10000.0}       |        6        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|  0.126151012891 |  0.302639267112 |        {'C': 10.0}         |        4        |
|  0.461486411072 |  0.158115265862 |        {'C': 100.0}        |        1        |
|  0.385796128906 | 0.0992152462457 |       {'C': 1000.0}        |        3        |
|  0.453457064796 | 0.0901948856404 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.86      0.70        37
          1       0.29      0.08      0.13        24

avg / total       0.47      0.56      0.48        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0185477505919 | 0.0304608087584 |        {'C': 10.0}         |        4        |
|  0.158160133298 | 0.0701065926089 |        {'C': 100.0}        |        3        |
|  0.27558537227  | 0.0581517110768 |       {'C': 1000.0}        |        2        |
|  0.336008068052 |  0.100886274935 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.70      0.70      0.70        37
          1       0.54      0.54      0.54        24

avg / total       0.64      0.64      0.64        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |        {'C': 0.001}        |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.01}         |        1        |
|  0.605893186004 |  0.005295999933 | {'C': 0.10000000000000001} |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 1.0}         |        1        |
|  0.604051565378 | 0.0159789583067 |        {'C': 10.0}         |        5        |
|  0.587476979742 |  0.040431505376 |        {'C': 100.0}        |        6        |
|  0.552486187845 | 0.0635125924789 |       {'C': 1000.0}        |        8        |
|  0.58379373849  | 0.0476918392341 |       {'C': 10000.0}       |        7        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0253222836096 |  0.075427798955 |        {'C': 10.0}         |        4        |
|  0.398394627676 |  0.187185944615 |        {'C': 100.0}        |        3        |
|  0.515410031416 |  0.12836841847  |       {'C': 1000.0}        |        1        |
|  0.435344662802 | 0.0849747532062 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.70      0.68        37
          1       0.50      0.46      0.48        24

avg / total       0.60      0.61      0.60        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0092519512409 | 0.0185743108988 |        {'C': 10.0}         |        4        |
|  0.130360431465 | 0.0863648206302 |        {'C': 100.0}        |        3        |
|  0.294703148294 | 0.0752593326041 |       {'C': 1000.0}        |        2        |
|  0.30851530299  | 0.0887178538842 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.70      0.69        37
          1       0.52      0.50      0.51        24

avg / total       0.62      0.62      0.62        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |        {'C': 0.001}        |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.01}         |        1        |
|  0.605893186004 |  0.005295999933 | {'C': 0.10000000000000001} |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 1.0}         |        1        |
|  0.605893186004 | 0.0156637927515 |        {'C': 10.0}         |        1        |
|  0.569060773481 | 0.0628239408597 |        {'C': 100.0}        |        6        |
|  0.567219152855 | 0.0437765117618 |       {'C': 1000.0}        |        7        |
|  0.55985267035  | 0.0553241828289 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|  0.16758747698  |  0.34264043402  |        {'C': 10.0}         |        4        |
|  0.375942734368 |  0.115673637471 |        {'C': 100.0}        |        3        |
|  0.428323895338 | 0.0919353103398 |       {'C': 1000.0}        |        1        |
|  0.389592800385 |  0.121847618671 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.68      0.66        37
          1       0.45      0.42      0.43        24

avg / total       0.57      0.57      0.57        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------+-----------------+
| test_mean_score  |  test_std_score |           params           | test_rank_score |
+------------------+-----------------+----------------------------+-----------------+
|       0.0        |       0.0       |        {'C': 0.001}        |        5        |
|       0.0        |       0.0       |        {'C': 0.01}         |        5        |
|       0.0        |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0        |       0.0       |         {'C': 1.0}         |        5        |
| 0.00920810313076 | 0.0274282905291 |        {'C': 10.0}         |        4        |
|  0.112163465755  | 0.0592091968806 |        {'C': 100.0}        |        3        |
|  0.285363500833  | 0.0821307653815 |       {'C': 1000.0}        |        2        |
|  0.360299921073  | 0.0725400328955 |       {'C': 10000.0}       |        1        |
+------------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.62      0.61        37
          1       0.36      0.33      0.35        24

avg / total       0.50      0.51      0.50        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |        {'C': 0.001}        |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.01}         |        1        |
|  0.605893186004 |  0.005295999933 | {'C': 0.10000000000000001} |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 1.0}         |        1        |
|  0.596685082873 | 0.0161214003869 |        {'C': 10.0}         |        5        |
|  0.581952117864 | 0.0412936676408 |        {'C': 100.0}        |        6        |
|  0.576427255985 | 0.0451811343267 |       {'C': 1000.0}        |        7        |
|  0.569060773481 | 0.0687361236084 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|  0.184162062615 |  0.321379948568 |        {'C': 10.0}         |        4        |
|  0.387925758506 |  0.215618435399 |        {'C': 100.0}        |        3        |
|  0.435570261988 |  0.097072487381 |       {'C': 1000.0}        |        2        |
|  0.453877116418 | 0.0692976821394 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.89      0.74        37
          1       0.56      0.21      0.30        24

avg / total       0.60      0.62      0.57        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0184162062615 | 0.0302736481755 |        {'C': 10.0}         |        4        |
|  0.154389195826 | 0.0774569433197 |        {'C': 100.0}        |        3        |
|  0.326975357362 |  0.103348964815 |       {'C': 1000.0}        |        2        |
|  0.387704989915 |  0.123902874887 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.89      0.74        37
          1       0.56      0.21      0.30        24

avg / total       0.60      0.62      0.57        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |        {'C': 0.001}        |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.01}         |        1        |
|  0.605893186004 |  0.005295999933 | {'C': 0.10000000000000001} |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 1.0}         |        1        |
|  0.604051565378 | 0.0172381226939 |        {'C': 10.0}         |        5        |
|  0.550644567219 | 0.0519003312633 |        {'C': 100.0}        |        8        |
|  0.561694290976 | 0.0461579019077 |       {'C': 1000.0}        |        7        |
|  0.581952117864 | 0.0423070109316 |       {'C': 10000.0}       |        6        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|  0.199815837937 |  0.331217914347 |        {'C': 10.0}         |        4        |
|  0.223429506855 |  0.164041372859 |        {'C': 100.0}        |        3        |
|  0.398199304277 |  0.128598687495 |       {'C': 1000.0}        |        2        |
|  0.403141064503 | 0.0766980888795 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.78      0.70        37
          1       0.47      0.29      0.36        24

avg / total       0.57      0.59      0.57        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------+-----------------+
| test_mean_score  |  test_std_score |           params           | test_rank_score |
+------------------+-----------------+----------------------------+-----------------+
|       0.0        |       0.0       |        {'C': 0.001}        |        5        |
|       0.0        |       0.0       |        {'C': 0.01}         |        5        |
|       0.0        |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0        |       0.0       |         {'C': 1.0}         |        5        |
| 0.00933964746119 | 0.0186427096454 |        {'C': 10.0}         |        4        |
| 0.0985705516092  |  0.068867359624 |        {'C': 100.0}        |        3        |
|  0.257125317899  | 0.0837372755326 |       {'C': 1000.0}        |        2        |
|  0.360519161624  | 0.0714431137979 |       {'C': 10000.0}       |        1        |
+------------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.78      0.70        37
          1       0.47      0.29      0.36        24

avg / total       0.57      0.59      0.57        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |        {'C': 0.001}        |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.01}         |        1        |
|  0.605893186004 |  0.005295999933 | {'C': 0.10000000000000001} |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 1.0}         |        1        |
|  0.604051565378 | 0.0208304705328 |        {'C': 10.0}         |        6        |
|  0.591160220994 | 0.0512366339366 |        {'C': 100.0}        |        7        |
|  0.605893186004 | 0.0471695962108 |       {'C': 1000.0}        |        1        |
|  0.589318600368 | 0.0661770089414 |       {'C': 10000.0}       |        8        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|  0.198895027624 |  0.399168881065 |        {'C': 10.0}         |        4        |
|  0.453675871908 |  0.162055907966 |        {'C': 100.0}        |        3        |
|  0.523403267575 |  0.147854093981 |       {'C': 1000.0}        |        1        |
|  0.501819855441 | 0.0832008981614 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.53      0.57      0.55        37
          1       0.24      0.21      0.22        24

avg / total       0.41      0.43      0.42        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0139875471367 | 0.0214582552575 |        {'C': 10.0}         |        4        |
|  0.195869508024 | 0.0976396517896 |        {'C': 100.0}        |        3        |
|  0.365693238621 |  0.141153079156 |       {'C': 1000.0}        |        2        |
|  0.369157239323 | 0.0552742067416 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.54      0.57      0.55        37
          1       0.27      0.25      0.26        24

avg / total       0.43      0.44      0.44        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.606617647059 | 0.00545308712286 |        {'C': 0.001}        |        1        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.01}         |        1        |
|  0.606617647059 | 0.00545308712286 | {'C': 0.10000000000000001} |        1        |
|  0.606617647059 | 0.00545308712286 |         {'C': 1.0}         |        1        |
|  0.601102941176 | 0.00886015106816 |        {'C': 10.0}         |        5        |
|  0.577205882353 | 0.0472384166813  |        {'C': 100.0}        |        6        |
|      0.5625     |  0.064811675857  |       {'C': 1000.0}        |        7        |
|  0.538602941176 | 0.0452440412785  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        36
          1       0.00      0.00      0.00        24

avg / total       0.36      0.60      0.45        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|  0.150735294118 |  0.321244437702 |        {'C': 10.0}         |        4        |
|  0.384633059955 | 0.0773848563693 |        {'C': 100.0}        |        3        |
|  0.430825826513 |  0.142491121134 |       {'C': 1000.0}        |        1        |
|  0.426085892752 | 0.0722999306186 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.81      0.69        36
          1       0.42      0.21      0.28        24

avg / total       0.53      0.57      0.53        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0093224789916 | 0.0186298630107 |        {'C': 10.0}         |        4        |
|  0.136160714286 | 0.0787544218286 |        {'C': 100.0}        |        3        |
|  0.316964285714 | 0.0851537457035 |       {'C': 1000.0}        |        2        |
|  0.373818277311 | 0.0612554949875 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.68      0.83      0.75        36
          1       0.62      0.42      0.50        24

avg / total       0.66      0.67      0.65        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.606617647059 | 0.00545308712286 |        {'C': 0.001}        |        1        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.01}         |        1        |
|  0.606617647059 | 0.00545308712286 | {'C': 0.10000000000000001} |        1        |
|  0.606617647059 | 0.00545308712286 |         {'C': 1.0}         |        1        |
|  0.602941176471 | 0.00715977199353 |        {'C': 10.0}         |        5        |
|  0.582720588235 | 0.0425950739963  |        {'C': 100.0}        |        6        |
|  0.556985294118 | 0.0605795970876  |       {'C': 1000.0}        |        8        |
|  0.564338235294 |  0.058715329131  |       {'C': 10000.0}       |        7        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        36
          1       0.00      0.00      0.00        24

avg / total       0.36      0.60      0.45        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0330882352941 | 0.0996723655274 |        {'C': 10.0}         |        4        |
|  0.466125408497 |  0.154970159638 |        {'C': 100.0}        |        1        |
|  0.40352777989  | 0.0607141299409 |       {'C': 1000.0}        |        3        |
|  0.40783928661  | 0.0868276777095 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.86      0.72        36
          1       0.50      0.21      0.29        24

avg / total       0.57      0.60      0.55        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
| 0.0047268907563 | 0.0142389093611 |        {'C': 10.0}         |        4        |
|  0.11200105042  | 0.0661891283239 |        {'C': 100.0}        |        3        |
|  0.295036764706 | 0.0673432301549 |       {'C': 1000.0}        |        2        |
|  0.322610294118 | 0.0649278927093 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.72      0.68        36
          1       0.47      0.38      0.42        24

avg / total       0.57      0.58      0.57        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.605504587156 | 0.00555532175064 |        {'C': 0.001}        |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.01}         |        1        |
|  0.605504587156 | 0.00555532175064 | {'C': 0.10000000000000001} |        1        |
|  0.605504587156 | 0.00555532175064 |         {'C': 1.0}         |        1        |
|  0.603669724771 | 0.0122071372574  |        {'C': 10.0}         |        5        |
|  0.57247706422  | 0.0393539180103  |        {'C': 100.0}        |        7        |
|  0.585321100917 | 0.0366080217597  |       {'C': 1000.0}        |        6        |
|  0.557798165138 | 0.0522805971768  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        36
          1       0.00      0.00      0.00        23

avg / total       0.37      0.61      0.46        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|       0.2       |  0.332353299361 |        {'C': 10.0}         |        4        |
|  0.362908895386 |  0.201155589536 |        {'C': 100.0}        |        3        |
|  0.425254778879 |  0.103136921912 |       {'C': 1000.0}        |        1        |
|  0.413331819476 | 0.0612604331994 |       {'C': 10000.0}       |        2        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.78      0.72        36
          1       0.53      0.39      0.45        23

avg / total       0.61      0.63      0.61        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------+-----------------+
| test_mean_score  |  test_std_score |           params           | test_rank_score |
+------------------+-----------------+----------------------------+-----------------+
|       0.0        |       0.0       |        {'C': 0.001}        |        5        |
|       0.0        |       0.0       |        {'C': 0.01}         |        5        |
|       0.0        |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0        |       0.0       |         {'C': 1.0}         |        5        |
| 0.00930537352556 |  0.018617038958 |        {'C': 10.0}         |        4        |
|  0.130799475754  | 0.0788806938017 |        {'C': 100.0}        |        3        |
|  0.315858453473  |  0.081810157617 |       {'C': 1000.0}        |        2        |
|  0.316644823067  | 0.0999559934084 |       {'C': 10000.0}       |        1        |
+------------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.67      0.65        36
          1       0.43      0.39      0.41        23

avg / total       0.55      0.56      0.56        59

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.605504587156 | 0.00555532175064 |        {'C': 0.001}        |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.01}         |        1        |
|  0.605504587156 | 0.00555532175064 | {'C': 0.10000000000000001} |        1        |
|  0.605504587156 | 0.00555532175064 |         {'C': 1.0}         |        1        |
|       0.6       | 0.0159540934738  |        {'C': 10.0}         |        5        |
|  0.56880733945  |  0.048248490391  |        {'C': 100.0}        |        6        |
|  0.546788990826 | 0.0366055444576  |       {'C': 1000.0}        |        7        |
|  0.54128440367  | 0.0534173055736  |       {'C': 10000.0}       |        8        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        36
          1       0.00      0.00      0.00        23

avg / total       0.37      0.61      0.46        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------+-----------------+
| test_mean_score |  test_std_score |           params           | test_rank_score |
+-----------------+-----------------+----------------------------+-----------------+
|       0.0       |       0.0       |        {'C': 0.001}        |        5        |
|       0.0       |       0.0       |        {'C': 0.01}         |        5        |
|       0.0       |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0       |       0.0       |         {'C': 1.0}         |        5        |
|  0.100917431193 |  0.301219360723 |        {'C': 10.0}         |        4        |
|  0.348591143821 |  0.150895480031 |        {'C': 100.0}        |        3        |
|  0.392349022627 |  0.129688453105 |       {'C': 1000.0}        |        2        |
|  0.417251368222 | 0.0711614690251 |       {'C': 10000.0}       |        1        |
+-----------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.89      0.74        36
          1       0.56      0.22      0.31        23

avg / total       0.61      0.63      0.58        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------+-----------------+
| test_mean_score  |  test_std_score |           params           | test_rank_score |
+------------------+-----------------+----------------------------+-----------------+
|       0.0        |       0.0       |        {'C': 0.001}        |        5        |
|       0.0        |       0.0       |        {'C': 0.01}         |        5        |
|       0.0        |       0.0       | {'C': 0.10000000000000001} |        5        |
|       0.0        |       0.0       |         {'C': 1.0}         |        5        |
| 0.00930537352556 |  0.018617038958 |        {'C': 10.0}         |        4        |
|  0.107208387942  | 0.0557401479882 |        {'C': 100.0}        |        3        |
|  0.27378768021   | 0.0911939444786 |       {'C': 1000.0}        |        2        |
|  0.353342070773  | 0.0742847616088 |       {'C': 10000.0}       |        1        |
+------------------+-----------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.89      0.74        36
          1       0.56      0.22      0.31        23

avg / total       0.61      0.63      0.58        59

Evaluating SVC
# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.001}               |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.605893186004 |  0.005295999933  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.604051565378 | 0.00628818395263 |                 {'C': 1.0, 'gamma': 1.0}                 |        34       |
|  0.596685082873 |  0.017837783865  |                {'C': 1.0, 'gamma': 10.0}                 |        45       |
|  0.613259668508 | 0.0238415621703  |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.598526703499 | 0.0119095081891  |               {'C': 1.0, 'gamma': 1000.0}                |        42       |
|  0.596685082873 | 0.0143376080174  |               {'C': 1.0, 'gamma': 10000.0}               |        45       |
|  0.605893186004 |  0.005295999933  |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.604051565378 | 0.00893566371013 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        34       |
|  0.600368324125 |  0.016598974829  |                {'C': 10.0, 'gamma': 1.0}                 |        37       |
|  0.589318600368 | 0.0638133516947  |                {'C': 10.0, 'gamma': 10.0}                |        49       |
|  0.589318600368 | 0.0423165649434  |               {'C': 10.0, 'gamma': 100.0}                |        49       |
|  0.589318600368 | 0.0191487212124  |               {'C': 10.0, 'gamma': 1000.0}               |        49       |
|  0.600368324125 | 0.00908206865312 |              {'C': 10.0, 'gamma': 10000.0}               |        37       |
|  0.605893186004 |  0.005295999933  |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 100.0, 'gamma': 0.01}                |        2        |
|  0.600368324125 | 0.0321443111844  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        37       |
|  0.581952117864 | 0.0356091928633  |                {'C': 100.0, 'gamma': 1.0}                |        56       |
|  0.541436464088 | 0.0663683758962  |               {'C': 100.0, 'gamma': 10.0}                |        64       |
|  0.570902394107 | 0.0429316589788  |               {'C': 100.0, 'gamma': 100.0}               |        59       |
|  0.598526703499 | 0.0265153184162  |              {'C': 100.0, 'gamma': 1000.0}               |        42       |
|  0.600368324125 | 0.0105065367196  |              {'C': 100.0, 'gamma': 10000.0}              |        37       |
|  0.605893186004 |  0.005295999933  |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.596685082873 | 0.0339116298213  |               {'C': 1000.0, 'gamma': 0.01}               |        45       |
|  0.581952117864 | 0.0427188462132  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        56       |
|  0.570902394107 | 0.0452372237486  |               {'C': 1000.0, 'gamma': 1.0}                |        59       |
|  0.546961325967 | 0.0411095264992  |               {'C': 1000.0, 'gamma': 10.0}               |        63       |
|  0.585635359116 | 0.0445590849755  |              {'C': 1000.0, 'gamma': 100.0}               |        52       |
|  0.58379373849  |  0.032944109439  |              {'C': 1000.0, 'gamma': 1000.0}              |        53       |
|  0.600368324125 | 0.0191698761545  |             {'C': 1000.0, 'gamma': 10000.0}              |        37       |
|  0.596685082873 | 0.0199388074288  |              {'C': 10000.0, 'gamma': 0.001}              |        45       |
|  0.58379373849  | 0.0422240987851  |              {'C': 10000.0, 'gamma': 0.01}               |        53       |
|  0.572744014733 | 0.0854772684202  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        58       |
|  0.561694290976 | 0.0517734256365  |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.58379373849  | 0.0473558006384  |              {'C': 10000.0, 'gamma': 10.0}               |        53       |
|  0.563535911602 | 0.0744067777659  |              {'C': 10000.0, 'gamma': 100.0}              |        61       |
|  0.602209944751 | 0.0271068354769  |             {'C': 10000.0, 'gamma': 1000.0}              |        36       |
|  0.598526703499 | 0.0178068362613  |             {'C': 10000.0, 'gamma': 10000.0}             |        42       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.89      0.71        37
          1       0.20      0.04      0.07        24

avg / total       0.44      0.56      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
|  0.250460405157 |  0.403569216061 |                {'C': 1.0, 'gamma': 10.0}                 |        24       |
|  0.707366482505 |  0.257371297908 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
| 0.0492633517495 | 0.0994432507101 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.100368324125 |  0.200275713892 |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.499758835394 |  0.280268883323 |                {'C': 10.0, 'gamma': 1.0}                 |        2        |
|  0.42361699375  |  0.087772289566 |                {'C': 10.0, 'gamma': 10.0}                |        11       |
|  0.467164511363 |  0.142948424981 |               {'C': 10.0, 'gamma': 100.0}                |        5        |
|  0.302578268877 |  0.329712536654 |               {'C': 10.0, 'gamma': 1000.0}               |        22       |
| 0.0331491712707 | 0.0997539783716 |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        31       |
|  0.38336402701  |  0.381031065245 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.481162189802 | 0.0843836000799 |                {'C': 100.0, 'gamma': 1.0}                |        4        |
|  0.41918743524  | 0.0703289720444 |               {'C': 100.0, 'gamma': 10.0}                |        13       |
|  0.44527463533  |  0.153153260532 |               {'C': 100.0, 'gamma': 100.0}               |        8        |
|  0.36525475752  |   0.3708258603  |              {'C': 100.0, 'gamma': 1000.0}               |        17       |
|  0.149171270718 |  0.319464120454 |              {'C': 100.0, 'gamma': 10000.0}              |        27       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
|  0.302025782689 |  0.40717172814  |               {'C': 1000.0, 'gamma': 0.01}               |        23       |
|   0.4609148576  |  0.124324551287 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.413191050062 | 0.0632411449929 |               {'C': 1000.0, 'gamma': 1.0}                |        14       |
|  0.410935221161 | 0.0939679491411 |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.364131218689 |  0.134198207715 |              {'C': 1000.0, 'gamma': 100.0}               |        18       |
|  0.336709637815 |  0.388128070375 |              {'C': 1000.0, 'gamma': 1000.0}              |        20       |
|  0.202578268877 |  0.401920780572 |             {'C': 1000.0, 'gamma': 10000.0}              |        25       |
|  0.499079189687 |  0.323440002009 |              {'C': 10000.0, 'gamma': 0.001}              |        3        |
|  0.42070649322  |  0.094406846227 |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.451747693548 |  0.095377744005 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        7        |
|  0.430845425954 |  0.071971460681 |               {'C': 10000.0, 'gamma': 1.0}               |        10       |
|  0.433603100643 | 0.0725155539975 |              {'C': 10000.0, 'gamma': 10.0}               |        9        |
|  0.340149522056 | 0.0906465489614 |              {'C': 10000.0, 'gamma': 100.0}              |        19       |
|  0.331623257038 |  0.312231224155 |             {'C': 10000.0, 'gamma': 1000.0}              |        21       |
|  0.184162062615 |  0.321379948568 |             {'C': 10000.0, 'gamma': 10000.0}             |        26       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.89      0.71        37
          1       0.20      0.04      0.07        24

avg / total       0.44      0.56      0.46        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|       0.0        |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        30       |
| 0.00947119179163 | 0.0190080419555 |                {'C': 1.0, 'gamma': 10.0}                 |        27       |
| 0.0698938875734  | 0.0471988268554 |                {'C': 1.0, 'gamma': 100.0}                |        15       |
|       0.0        |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
| 0.00933964746119 | 0.0186427096454 |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        30       |
| 0.0659037095501  | 0.0610004251677 |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.261378584583  | 0.0792121110448 |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.135139875471  | 0.0653831236192 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
| 0.0375339822854  | 0.0284536612294 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
| 0.0185039024818  | 0.0371486217977 |              {'C': 10.0, 'gamma': 10000.0}               |        24       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        30       |
|  0.032622993949  |  0.036316849052 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        23       |
|  0.270016662282  | 0.0912780347142 |                {'C': 100.0, 'gamma': 1.0}                |        7        |
|  0.332017890029  |  0.058071475496 |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.172586161536  | 0.0641871880428 |               {'C': 100.0, 'gamma': 100.0}               |        12       |
| 0.0419626414102  | 0.0320098521105 |              {'C': 100.0, 'gamma': 1000.0}               |        19       |
| 0.0138121546961  | 0.0292506365472 |              {'C': 100.0, 'gamma': 10000.0}              |        26       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
| 0.0467420854161  |  0.029507429558 |               {'C': 1000.0, 'gamma': 0.01}               |        18       |
|  0.247566429887  |  0.134753527875 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.360168376743  | 0.0680435106314 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.392747522582  | 0.0839754118098 |               {'C': 1000.0, 'gamma': 10.0}               |        3        |
|  0.205691484697  |  0.056364648191 |              {'C': 1000.0, 'gamma': 100.0}               |        10       |
| 0.0468297816364  | 0.0367440693733 |              {'C': 1000.0, 'gamma': 1000.0}              |        17       |
|  0.014075243357  | 0.0214981796562 |             {'C': 1000.0, 'gamma': 10000.0}              |        25       |
| 0.0374901341752  | 0.0463546040138 |              {'C': 10000.0, 'gamma': 0.001}              |        22       |
|  0.196483381566  |  0.047709429314 |              {'C': 10000.0, 'gamma': 0.01}               |        11       |
|  0.359554503201  | 0.0659548908914 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.402525651144  | 0.0780395489999 |               {'C': 10000.0, 'gamma': 1.0}               |        2        |
|  0.406384284837  | 0.0965304531614 |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.159387880382  | 0.0539241199069 |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
| 0.0419626414102  |  0.037989219187 |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
| 0.0092519512409  | 0.0185743108988 |             {'C': 10000.0, 'gamma': 10000.0}             |        29       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.56      0.49      0.52        37
          1       0.34      0.42      0.38        24

avg / total       0.48      0.46      0.46        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.001}               |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.605893186004 |  0.005295999933  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.604051565378 | 0.00893566371013 |                 {'C': 1.0, 'gamma': 1.0}                 |        34       |
|  0.589318600368 | 0.0246917829687  |                {'C': 1.0, 'gamma': 10.0}                 |        51       |
|  0.615101289134 | 0.0206465297529  |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.605893186004 |  0.005295999933  |               {'C': 1.0, 'gamma': 1000.0}                |        2        |
|  0.602209944751 | 0.0138502507666  |               {'C': 1.0, 'gamma': 10000.0}               |        40       |
|  0.605893186004 |  0.005295999933  |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.604051565378 | 0.00893566371013 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        34       |
|  0.600368324125 | 0.0305588933731  |                {'C': 10.0, 'gamma': 1.0}                 |        44       |
|  0.604051565378 |  0.052495213245  |                {'C': 10.0, 'gamma': 10.0}                |        34       |
|  0.580110497238 | 0.0539456981409  |               {'C': 10.0, 'gamma': 100.0}                |        55       |
|  0.600368324125 | 0.0244492474684  |               {'C': 10.0, 'gamma': 1000.0}               |        44       |
|  0.602209944751 | 0.0165517382852  |              {'C': 10.0, 'gamma': 10000.0}               |        40       |
|  0.605893186004 |  0.005295999933  |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.604051565378 | 0.00893566371013 |               {'C': 100.0, 'gamma': 0.01}                |        34       |
|  0.602209944751 | 0.0165619843675  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        40       |
|  0.587476979742 | 0.0505582536717  |                {'C': 100.0, 'gamma': 1.0}                |        52       |
|  0.550644567219 | 0.0927086368934  |               {'C': 100.0, 'gamma': 10.0}                |        62       |
|  0.574585635359 | 0.0737594246397  |               {'C': 100.0, 'gamma': 100.0}               |        57       |
|  0.587476979742 | 0.0201735282582  |              {'C': 100.0, 'gamma': 1000.0}               |        52       |
|  0.605893186004 | 0.0173539934598  |              {'C': 100.0, 'gamma': 10000.0}              |        2        |
|  0.604051565378 | 0.00628818395263 |              {'C': 1000.0, 'gamma': 0.001}               |        34       |
|  0.602209944751 | 0.0389079403426  |               {'C': 1000.0, 'gamma': 0.01}               |        40       |
|  0.58379373849  | 0.0574927323839  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        54       |
|  0.55985267035  | 0.0612094965126  |               {'C': 1000.0, 'gamma': 1.0}                |        59       |
|  0.558011049724 | 0.0567005491248  |               {'C': 1000.0, 'gamma': 10.0}               |        60       |
|  0.591160220994 | 0.0378019505447  |              {'C': 1000.0, 'gamma': 100.0}               |        50       |
|  0.596685082873 |  0.023024913529  |              {'C': 1000.0, 'gamma': 1000.0}              |        46       |
|  0.604051565378 | 0.0183700218435  |             {'C': 1000.0, 'gamma': 10000.0}              |        34       |
|  0.594843462247 |  0.035647654568  |              {'C': 10000.0, 'gamma': 0.001}              |        48       |
|  0.567219152855 | 0.0467345127174  |              {'C': 10000.0, 'gamma': 0.01}               |        58       |
|  0.545119705341 | 0.0868341270216  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        63       |
|  0.530386740331 | 0.0416705082531  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.552486187845 | 0.0490503018823  |              {'C': 10000.0, 'gamma': 10.0}               |        61       |
|  0.580110497238 | 0.0474732942874  |              {'C': 10000.0, 'gamma': 100.0}              |        55       |
|  0.593001841621 | 0.0222760146685  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.596685082873 | 0.0139429432521  |             {'C': 10000.0, 'gamma': 10000.0}             |        46       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.97      0.75        37
          1       0.50      0.04      0.08        24

avg / total       0.57      0.61      0.49        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.538152240638 |  0.296526516834 |                {'C': 1.0, 'gamma': 10.0}                 |        2        |
|  0.484346224678 |  0.397210574214 |                {'C': 1.0, 'gamma': 100.0}                |        5        |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.607581338244 |  0.354023790967 |                {'C': 10.0, 'gamma': 1.0}                 |        1        |
|  0.47382206859  |  0.118171552861 |                {'C': 10.0, 'gamma': 10.0}                |        9        |
|  0.489749707015 |  0.207631106782 |               {'C': 10.0, 'gamma': 100.0}                |        4        |
|  0.182934315531 |  0.319528992014 |               {'C': 10.0, 'gamma': 1000.0}               |        24       |
|  0.150092081031 |  0.321189935936 |              {'C': 10.0, 'gamma': 10000.0}               |        25       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        29       |
|  0.482197667281 |  0.318565178061 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.466469457207 | 0.0960949795706 |                {'C': 100.0, 'gamma': 1.0}                |        11       |
|  0.439393364581 |  0.112874162121 |               {'C': 100.0, 'gamma': 10.0}                |        14       |
|  0.446902131018 |  0.118443790899 |               {'C': 100.0, 'gamma': 100.0}               |        13       |
|  0.134131368938 |  0.208440126176 |              {'C': 100.0, 'gamma': 1000.0}               |        27       |
|  0.202578268877 |  0.401920780572 |              {'C': 100.0, 'gamma': 10000.0}              |        22       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
|   0.4671577655  |  0.393048564956 |               {'C': 1000.0, 'gamma': 0.01}               |        10       |
|  0.426910770833 |  0.120991352992 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.480538560983 |  0.10569966126  |               {'C': 1000.0, 'gamma': 1.0}                |        7        |
|  0.389358514737 | 0.0926862602471 |               {'C': 1000.0, 'gamma': 10.0}               |        19       |
|  0.460458673718 |  0.129439422635 |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
|  0.144076120319 |  0.227199930472 |              {'C': 1000.0, 'gamma': 1000.0}              |        26       |
|  0.121178637201 |  0.300969720864 |             {'C': 1000.0, 'gamma': 10000.0}              |        28       |
|  0.268262737876 |  0.327233178684 |              {'C': 10000.0, 'gamma': 0.001}              |        21       |
|  0.475758240123 | 0.0972184129163 |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|  0.437486581775 | 0.0982049426884 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        15       |
|  0.432888433885 | 0.0570041323714 |               {'C': 10000.0, 'gamma': 1.0}               |        16       |
|  0.420625046399 | 0.0742283493595 |              {'C': 10000.0, 'gamma': 10.0}               |        18       |
|  0.368555845628 |  0.148751712343 |              {'C': 10000.0, 'gamma': 100.0}              |        20       |
|  0.510128913444 |  0.43657441628  |             {'C': 10000.0, 'gamma': 1000.0}              |        3        |
|  0.198895027624 |  0.399168881065 |             {'C': 10000.0, 'gamma': 10000.0}             |        23       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.97      0.74        37
          1       0.00      0.00      0.00        24

avg / total       0.36      0.59      0.45        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|       0.0        |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.055994036657  | 0.0348136422745 |                {'C': 1.0, 'gamma': 10.0}                 |        17       |
| 0.0513461369815  | 0.0382813338458 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|       0.0        |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|       0.0        |       0.0       |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        29       |
| 0.0751118126809  | 0.0486083688414 |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.335657283171  |  0.115841439743 |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.140357800579  | 0.0638828893789 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
| 0.00947119179163 | 0.0190080419555 |               {'C': 10.0, 'gamma': 1000.0}               |        24       |
| 0.00933964746119 | 0.0186427096454 |              {'C': 10.0, 'gamma': 10000.0}               |        25       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        29       |
| 0.0560378847672  | 0.0410596501058 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.30829606244   | 0.0994663234139 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.372928176796  | 0.0971719863838 |               {'C': 100.0, 'gamma': 10.0}                |        3        |
|  0.181925808998  | 0.0669538909398 |               {'C': 100.0, 'gamma': 100.0}               |        12       |
| 0.0184162062615  | 0.0302736481755 |              {'C': 100.0, 'gamma': 1000.0}               |        23       |
| 0.00473559589582 | 0.0142505683388 |              {'C': 100.0, 'gamma': 10000.0}              |        28       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
| 0.0370955011839  | 0.0609216175167 |               {'C': 1000.0, 'gamma': 0.01}               |        20       |
|  0.252521266333  | 0.0527555403867 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.369025694993  |  0.089260163092 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.35043409629   | 0.0929671857408 |               {'C': 1000.0, 'gamma': 10.0}               |        6        |
|  0.18271507498   | 0.0827946479547 |              {'C': 1000.0, 'gamma': 100.0}               |        11       |
| 0.0324476015084  | 0.0362439287833 |              {'C': 1000.0, 'gamma': 1000.0}              |        21       |
| 0.00933964746119 | 0.0186427096454 |             {'C': 1000.0, 'gamma': 10000.0}              |        25       |
| 0.0376216785057  | 0.0726968246843 |              {'C': 10000.0, 'gamma': 0.001}              |        19       |
|  0.224765412611  | 0.0897345158527 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.360563009734  | 0.0945523690758 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.434710163992  | 0.0590706054115 |               {'C': 10000.0, 'gamma': 1.0}               |        1        |
|  0.397176181707  | 0.0493617166533 |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.172717705867  | 0.0504622356957 |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
| 0.0231956502675  |  0.030905829335 |             {'C': 10000.0, 'gamma': 1000.0}              |        22       |
| 0.00933964746119 | 0.0186427096454 |             {'C': 10000.0, 'gamma': 10000.0}             |        25       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.52      0.59      0.56        37
          1       0.21      0.17      0.19        24

avg / total       0.40      0.43      0.41        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.001}               |        3        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.01}                |        3        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        3        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.001, 'gamma': 1.0}                |        3        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 10.0}                |        3        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 100.0}               |        3        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 1000.0}               |        3        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 10000.0}              |        3        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 0.001}                |        3        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 0.01}                |        3        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        3        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 1.0}                 |        3        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 10.0}                |        3        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 100.0}                |        3        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 1000.0}               |        3        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.01, 'gamma': 10000.0}               |        3        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        3        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        3        |
|  0.605893186004 |  0.005295999933  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        3        |
|  0.605893186004 |  0.005295999933  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        3        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        3        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        3        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        3        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        3        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.001}                |        3        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.01}                 |        3        |
|  0.605893186004 |  0.005295999933  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        3        |
|  0.605893186004 |  0.005295999933  |                 {'C': 1.0, 'gamma': 1.0}                 |        3        |
|  0.593001841621 | 0.0381148010855  |                {'C': 1.0, 'gamma': 10.0}                 |        50       |
|  0.591160220994 | 0.0264847397012  |                {'C': 1.0, 'gamma': 100.0}                |        52       |
|  0.602209944751 | 0.0245226275649  |               {'C': 1.0, 'gamma': 1000.0}                |        41       |
|  0.604051565378 | 0.0190745932702  |               {'C': 1.0, 'gamma': 10000.0}               |        35       |
|  0.605893186004 |  0.005295999933  |               {'C': 10.0, 'gamma': 0.001}                |        3        |
|  0.605893186004 |  0.005295999933  |                {'C': 10.0, 'gamma': 0.01}                |        3        |
|  0.604051565378 | 0.00819820772769 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.598526703499 | 0.0253668382301  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.561694290976 | 0.0531115334159  |                {'C': 10.0, 'gamma': 10.0}                |        59       |
|  0.587476979742 | 0.0528900520956  |               {'C': 10.0, 'gamma': 100.0}                |        54       |
|  0.604051565378 | 0.0208546076657  |               {'C': 10.0, 'gamma': 1000.0}               |        35       |
|  0.602209944751 | 0.0178002938614  |              {'C': 10.0, 'gamma': 10000.0}               |        41       |
|  0.605893186004 |  0.005295999933  |               {'C': 100.0, 'gamma': 0.001}               |        3        |
|  0.604051565378 | 0.00628818395263 |               {'C': 100.0, 'gamma': 0.01}                |        35       |
|  0.602209944751 | 0.0203168595869  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        41       |
|  0.598526703499 | 0.0409384741255  |                {'C': 100.0, 'gamma': 1.0}                |        47       |
|  0.519337016575 | 0.0409022939731  |               {'C': 100.0, 'gamma': 10.0}                |        63       |
|  0.593001841621 | 0.0338163168368  |               {'C': 100.0, 'gamma': 100.0}               |        50       |
|  0.600368324125 | 0.0241744670233  |              {'C': 100.0, 'gamma': 1000.0}               |        44       |
|  0.600368324125 | 0.0122250559831  |              {'C': 100.0, 'gamma': 10000.0}              |        44       |
|  0.605893186004 |  0.005295999933  |              {'C': 1000.0, 'gamma': 0.001}               |        3        |
|  0.60773480663  | 0.0208072653358  |               {'C': 1000.0, 'gamma': 0.01}               |        2        |
|  0.58379373849  | 0.0443192238056  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        55       |
|  0.55985267035  | 0.0438701518574  |               {'C': 1000.0, 'gamma': 1.0}                |        60       |
|  0.526703499079 | 0.0415728498002  |               {'C': 1000.0, 'gamma': 10.0}               |        62       |
|  0.581952117864 | 0.0364863055669  |              {'C': 1000.0, 'gamma': 100.0}               |        56       |
|  0.611418047882 | 0.0258900335681  |              {'C': 1000.0, 'gamma': 1000.0}              |        1        |
|  0.600368324125 | 0.0138750822629  |             {'C': 1000.0, 'gamma': 10000.0}              |        44       |
|  0.604051565378 | 0.0208798375766  |              {'C': 10000.0, 'gamma': 0.001}              |        35       |
|  0.581952117864 | 0.0618930249489  |              {'C': 10000.0, 'gamma': 0.01}               |        56       |
|  0.580110497238 | 0.0547666161715  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        58       |
|  0.517495395948 | 0.0388877302249  |               {'C': 10000.0, 'gamma': 1.0}               |        64       |
|  0.532228360958 | 0.0369934287648  |              {'C': 10000.0, 'gamma': 10.0}               |        61       |
|  0.591160220994 | 0.0436292113857  |              {'C': 10000.0, 'gamma': 100.0}              |        52       |
|  0.596685082873 | 0.0292367026176  |             {'C': 10000.0, 'gamma': 1000.0}              |        49       |
|  0.604051565378 | 0.0127311419573  |             {'C': 10000.0, 'gamma': 10000.0}             |        35       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.86      0.70        37
          1       0.17      0.04      0.07        24

avg / total       0.42      0.54      0.45        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        32       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        32       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        32       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        32       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        32       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        32       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        32       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        32       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        32       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        32       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        32       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        32       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        32       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        32       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        32       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        32       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        32       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        32       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        32       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        32       |
|  0.449355432781 |  0.349578210466 |                {'C': 1.0, 'gamma': 10.0}                 |        9        |
|  0.381829343155 |  0.434355984034 |                {'C': 1.0, 'gamma': 100.0}                |        23       |
|  0.385490660353 |  0.213917615036 |               {'C': 1.0, 'gamma': 1000.0}                |        22       |
|  0.249539594843 |  0.334997828251 |               {'C': 1.0, 'gamma': 10000.0}               |        27       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        32       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        32       |
| 0.0331491712707 | 0.0997539783716 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.581491712707 |  0.328878589365 |                {'C': 10.0, 'gamma': 1.0}                 |        1        |
|  0.428880691673 | 0.0719543459256 |                {'C': 10.0, 'gamma': 10.0}                |        12       |
|  0.423232190359 |  0.210914459245 |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|  0.476212400246 |  0.313538127609 |               {'C': 10.0, 'gamma': 1000.0}               |        5        |
| 0.0994475138122 |  0.299261935115 |              {'C': 10.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        32       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        32       |
|  0.326712268701 |  0.321147917152 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        24       |
|  0.460977992746 |  0.155835853755 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.40509727343  | 0.0800591335491 |               {'C': 100.0, 'gamma': 10.0}                |        18       |
|  0.473509629311 |  0.22275919537  |               {'C': 100.0, 'gamma': 100.0}               |        6        |
|  0.493677102517 |  0.330378128652 |              {'C': 100.0, 'gamma': 1000.0}               |        3        |
|  0.097605893186 |  0.296781035111 |              {'C': 100.0, 'gamma': 10000.0}              |        30       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        32       |
|  0.524094536525 |  0.338314642431 |               {'C': 1000.0, 'gamma': 0.01}               |        2        |
|  0.446415583087 |  0.227206113261 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.426533381023 | 0.0844816664489 |               {'C': 1000.0, 'gamma': 1.0}                |        14       |
|  0.399324620189 | 0.0766613517608 |               {'C': 1000.0, 'gamma': 10.0}               |        20       |
|  0.414516760097 |  0.118589367115 |              {'C': 1000.0, 'gamma': 100.0}               |        17       |
|  0.303275453828 |  0.320142391143 |              {'C': 1000.0, 'gamma': 1000.0}              |        25       |
|  0.232658072437 |  0.394993160985 |             {'C': 1000.0, 'gamma': 10000.0}              |        28       |
|  0.466894676839 |  0.408694585129 |              {'C': 10000.0, 'gamma': 0.001}              |        7        |
|  0.428375143796 |  0.146823537275 |              {'C': 10000.0, 'gamma': 0.01}               |        13       |
|  0.477549493252 |  0.111840227699 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.399638310266 | 0.0708652641229 |               {'C': 10000.0, 'gamma': 1.0}               |        19       |
|  0.416224881763 | 0.0715822125375 |              {'C': 10000.0, 'gamma': 10.0}               |        16       |
|  0.437049292022 |  0.164682659477 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
|  0.385819521179 |  0.435363166945 |             {'C': 10000.0, 'gamma': 1000.0}              |        21       |
|  0.278084714549 |  0.395960747592 |             {'C': 10000.0, 'gamma': 10000.0}             |        26       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.86      0.70        37
          1       0.17      0.04      0.07        24

avg / total       0.42      0.54      0.45        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|       0.0        |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
|  0.03292993072   | 0.0427407711799 |                {'C': 1.0, 'gamma': 10.0}                 |        23       |
| 0.0186792949224  | 0.0228176075969 |                {'C': 1.0, 'gamma': 100.0}                |        27       |
|  0.060773480663  | 0.0554076950811 |               {'C': 1.0, 'gamma': 1000.0}                |        17       |
| 0.0235464351486  | 0.0235978543265 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        31       |
| 0.0610365693239  | 0.0429197889303 |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.256949925458  | 0.0965997741765 |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.177804086644  | 0.0414803037711 |               {'C': 10.0, 'gamma': 100.0}                |        12       |
| 0.0421818819609  | 0.0332127259605 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
| 0.0234587389284  | 0.0235967136361 |              {'C': 10.0, 'gamma': 10000.0}               |        26       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        31       |
| 0.0374901341752  | 0.0282992405951 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        22       |
|  0.266684205911  | 0.0730688680287 |                {'C': 100.0, 'gamma': 1.0}                |        7        |
|  0.345435411734  | 0.0836434456754 |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.164430413049  | 0.0815576777524 |               {'C': 100.0, 'gamma': 100.0}               |        13       |
| 0.0559501885469  | 0.0456372221167 |              {'C': 100.0, 'gamma': 1000.0}               |        18       |
| 0.0185915987021  |  0.022797713097 |              {'C': 100.0, 'gamma': 10000.0}              |        28       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
| 0.0655529246689  | 0.0432053290709 |               {'C': 1000.0, 'gamma': 0.01}               |        15       |
|  0.234368148733  | 0.0891938914874 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.326843813032  | 0.0673352385368 |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.402131018153  | 0.0722936985804 |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.149127422608  | 0.0780957391008 |              {'C': 1000.0, 'gamma': 100.0}               |        14       |
| 0.0468297816364  | 0.0471135427383 |              {'C': 1000.0, 'gamma': 1000.0}              |        19       |
| 0.0138121546961  | 0.0209057311786 |             {'C': 1000.0, 'gamma': 10000.0}              |        29       |
| 0.0328860826098  | 0.0369675102095 |              {'C': 10000.0, 'gamma': 0.001}              |        24       |
|  0.214855739718  | 0.0628361179372 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.351047969833  |  0.102423043721 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.40129790406   | 0.0782825635731 |               {'C': 10000.0, 'gamma': 1.0}               |        3        |
|  0.405901955626  |  0.103890845428 |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.182276593879  | 0.0749300581573 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
| 0.0467859335263  |  0.047495002111 |             {'C': 10000.0, 'gamma': 1000.0}              |        20       |
| 0.00920810313076 | 0.0182691263896 |             {'C': 10000.0, 'gamma': 10000.0}             |        30       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.68      0.68        37
          1       0.52      0.54      0.53        24

avg / total       0.63      0.62      0.62        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.001}               |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.605893186004 |  0.005295999933  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.604051565378 | 0.00628818395263 |                 {'C': 1.0, 'gamma': 1.0}                 |        35       |
|  0.591160220994 | 0.0307631399499  |                {'C': 1.0, 'gamma': 10.0}                 |        49       |
|  0.596685082873 | 0.0169647544414  |                {'C': 1.0, 'gamma': 100.0}                |        46       |
|  0.605893186004 |  0.005295999933  |               {'C': 1.0, 'gamma': 1000.0}                |        2        |
|  0.598526703499 | 0.0119095081891  |               {'C': 1.0, 'gamma': 10000.0}               |        44       |
|  0.605893186004 |  0.005295999933  |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.604051565378 | 0.00893566371013 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        35       |
|  0.604051565378 | 0.0314311251372  |                {'C': 10.0, 'gamma': 1.0}                 |        35       |
|  0.576427255985 | 0.0571397589636  |                {'C': 10.0, 'gamma': 10.0}                |        53       |
|  0.580110497238 |  0.041756193867  |               {'C': 10.0, 'gamma': 100.0}                |        52       |
|  0.600368324125 |  0.032097324915  |               {'C': 10.0, 'gamma': 1000.0}               |        41       |
|  0.594843462247 | 0.0140859095309  |              {'C': 10.0, 'gamma': 10000.0}               |        47       |
|  0.605893186004 |  0.005295999933  |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.604051565378 | 0.00628818395263 |               {'C': 100.0, 'gamma': 0.01}                |        35       |
|  0.604051565378 | 0.0103802422304  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        35       |
|  0.570902394107 |  0.063726193705  |                {'C': 100.0, 'gamma': 1.0}                |        54       |
|  0.570902394107 | 0.0362893684857  |               {'C': 100.0, 'gamma': 10.0}                |        54       |
|  0.567219152855 | 0.0355286716339  |               {'C': 100.0, 'gamma': 100.0}               |        59       |
|  0.589318600368 | 0.0233952437849  |              {'C': 100.0, 'gamma': 1000.0}               |        50       |
|  0.600368324125 | 0.0147533103108  |              {'C': 100.0, 'gamma': 10000.0}              |        41       |
|  0.605893186004 |  0.005295999933  |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.605893186004 |  0.016446782685  |               {'C': 1000.0, 'gamma': 0.01}               |        2        |
|  0.569060773481 | 0.0407637904648  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        57       |
|  0.581952117864 | 0.0438047785661  |               {'C': 1000.0, 'gamma': 1.0}                |        51       |
|  0.554327808471 | 0.0544205260388  |               {'C': 1000.0, 'gamma': 10.0}               |        62       |
|  0.563535911602 | 0.0337996582686  |              {'C': 1000.0, 'gamma': 100.0}               |        61       |
|  0.611418047882 | 0.0257172861685  |              {'C': 1000.0, 'gamma': 1000.0}              |        1        |
|  0.600368324125 | 0.0226789872275  |             {'C': 1000.0, 'gamma': 10000.0}              |        41       |
|  0.594843462247 | 0.0287332636019  |              {'C': 10000.0, 'gamma': 0.001}              |        47       |
|  0.567219152855 | 0.0568866263065  |              {'C': 10000.0, 'gamma': 0.01}               |        59       |
|  0.569060773481 | 0.0665217792124  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        57       |
|  0.543278084715 | 0.0790009698149  |               {'C': 10000.0, 'gamma': 1.0}               |        63       |
|  0.53591160221  |  0.059044432556  |              {'C': 10000.0, 'gamma': 10.0}               |        64       |
|  0.570902394107 | 0.0356262689981  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.598526703499 | 0.0304403751569  |             {'C': 10000.0, 'gamma': 1000.0}              |        44       |
|  0.602209944751 | 0.0161727720123  |             {'C': 10000.0, 'gamma': 10000.0}             |        40       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.97      0.77        37
          1       0.75      0.12      0.21        24

avg / total       0.68      0.64      0.55        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        30       |
|  0.151012891344 |  0.321474912768 |                {'C': 1.0, 'gamma': 10.0}                 |        27       |
|  0.249539594843 |  0.402426765809 |                {'C': 1.0, 'gamma': 100.0}                |        23       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
|  0.024861878453 | 0.0748154837787 |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        30       |
|  0.454511970534 |  0.330472069369 |                {'C': 10.0, 'gamma': 1.0}                 |        4        |
|  0.443789103685 |  0.121620695597 |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.44496404455  |  0.179931286603 |               {'C': 10.0, 'gamma': 100.0}                |        5        |
|  0.274094536525 |  0.247030809942 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
| 0.0497237569061 |  0.149630967557 |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        30       |
|  0.199508901166 |  0.208023438694 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        26       |
|  0.439843218987 | 0.0736558431404 |                {'C': 100.0, 'gamma': 1.0}                |        7        |
|  0.41834682989  |  0.125490933149 |               {'C': 100.0, 'gamma': 10.0}                |        11       |
|  0.377625939643 |  0.152386127104 |               {'C': 100.0, 'gamma': 100.0}               |        16       |
|  0.348987108656 |  0.390062900225 |              {'C': 100.0, 'gamma': 1000.0}               |        18       |
|  0.215162676489 |  0.268573007083 |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
|  0.317679558011 |  0.352590601443 |               {'C': 1000.0, 'gamma': 0.01}               |        20       |
|  0.36580007217  | 0.0894258419852 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.476025022915 | 0.0822669736815 |               {'C': 1000.0, 'gamma': 1.0}                |        1        |
|  0.39856733073  | 0.0685575327191 |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.424961267503 |  0.161284349252 |              {'C': 1000.0, 'gamma': 100.0}               |        10       |
|  0.383057090239 |  0.373683386015 |              {'C': 1000.0, 'gamma': 1000.0}              |        15       |
|  0.25138121547  |  0.334995297206 |             {'C': 1000.0, 'gamma': 10000.0}              |        22       |
|  0.434622467772 |  0.464443066558 |              {'C': 10000.0, 'gamma': 0.001}              |        8        |
|  0.412499517058 |  0.173246581721 |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.471160402224 | 0.0776027244601 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.430543605179 | 0.0920664016164 |               {'C': 10000.0, 'gamma': 1.0}               |        9        |
|  0.464332771176 |  0.111841270886 |              {'C': 10000.0, 'gamma': 10.0}               |        3        |
|  0.40529180764  |  0.113661130087 |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
|  0.340085942296 |  0.366072447772 |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
|  0.224217311234 |  0.393639677713 |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.70      0.65        37
          1       0.39      0.29      0.33        24

avg / total       0.52      0.54      0.53        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        32       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        32       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        32       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        32       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        32       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        32       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        32       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        32       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        32       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        32       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        32       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        32       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        32       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        32       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        32       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        32       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        32       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        32       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        32       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        32       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        32       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        32       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        32       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        32       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        32       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        32       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        32       |
| 0.00460405156538 | 0.0137141452645 |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
|  0.018854687363  | 0.0232882592699 |                {'C': 1.0, 'gamma': 10.0}                 |        27       |
| 0.0232833464878  | 0.0314281602335 |                {'C': 1.0, 'gamma': 100.0}                |        26       |
| 0.00473559589582 | 0.0142505683388 |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
| 0.0092519512409  | 0.0185743108988 |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        32       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        32       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        32       |
| 0.0372708936245  | 0.0404219302604 |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.285144260282  |  0.106539832685 |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.149434359379  | 0.0877345730235 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
| 0.0234148908182  | 0.0310701926609 |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.014075243357  | 0.0214981796562 |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        32       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        32       |
| 0.0281943348242  | 0.0314437674231 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        19       |
|  0.247215645006  | 0.0662304924702 |                {'C': 100.0, 'gamma': 1.0}                |        9        |
|  0.331228624046  |  0.104803591114 |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.186705253004  | 0.0703151692854 |               {'C': 100.0, 'gamma': 100.0}               |        10       |
|  0.032622993949  |  0.036316849052 |              {'C': 100.0, 'gamma': 1000.0}               |        18       |
| 0.0234148908182  | 0.0315882234799 |              {'C': 100.0, 'gamma': 10000.0}              |        23       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        32       |
| 0.0516969218627  | 0.0333514229671 |               {'C': 1000.0, 'gamma': 0.01}               |        15       |
|  0.247697974217  | 0.0867933621001 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        8        |
|  0.359598351311  |   0.0700015244  |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.392966763133  | 0.0875737407362 |               {'C': 1000.0, 'gamma': 10.0}               |        3        |
|  0.168639831623  | 0.0802411789776 |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
| 0.0374462860651  | 0.0409049821814 |              {'C': 1000.0, 'gamma': 1000.0}              |        16       |
| 0.0235902832588  | 0.0238085143933 |             {'C': 1000.0, 'gamma': 10000.0}              |        22       |
|  0.028150486714  | 0.0373855290344 |              {'C': 10000.0, 'gamma': 0.001}              |        21       |
|  0.177628694203  | 0.0510137527849 |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.336490397264  | 0.0804213570733 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.439489607998  |  0.071717646082 |               {'C': 10000.0, 'gamma': 1.0}               |        1        |
|  0.429448390774  |  0.136433088053 |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.186310620012  | 0.0777091848971 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
| 0.0281943348242  | 0.0314437674231 |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
| 0.0233271945979  | 0.0315870061314 |             {'C': 10000.0, 'gamma': 10000.0}             |        25       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.68      0.64        37
          1       0.40      0.33      0.36        24

avg / total       0.53      0.54      0.53        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933 |               {'C': 0.001, 'gamma': 0.001}               |        1        |
|  0.605893186004 |  0.005295999933 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        1        |
|  0.605893186004 |  0.005295999933 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.605893186004 |  0.005295999933 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.605893186004 |  0.005295999933 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.605893186004 |  0.005295999933 |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.605893186004 |  0.005295999933 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.605893186004 |  0.005295999933 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.605893186004 |  0.005295999933 |                {'C': 0.01, 'gamma': 0.01}                |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.605893186004 |  0.005295999933 |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.605893186004 |  0.005295999933 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.605893186004 |  0.005295999933 |               {'C': 0.01, 'gamma': 100.0}                |        1        |
|  0.605893186004 |  0.005295999933 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.605893186004 |  0.005295999933 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.605893186004 |  0.005295999933 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        1        |
|  0.605893186004 |  0.005295999933 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.605893186004 |  0.005295999933 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.605893186004 |  0.005295999933 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.605893186004 |  0.005295999933 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.605893186004 |  0.005295999933 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.605893186004 |  0.005295999933 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.593001841621 | 0.0303168516145 |                {'C': 1.0, 'gamma': 10.0}                 |        47       |
|  0.602209944751 | 0.0313481251098 |                {'C': 1.0, 'gamma': 100.0}                |        36       |
|  0.596685082873 | 0.0189400462521 |               {'C': 1.0, 'gamma': 1000.0}                |        39       |
|  0.589318600368 |  0.018655101124 |               {'C': 1.0, 'gamma': 10000.0}               |        49       |
|  0.605893186004 |  0.005295999933 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.605893186004 |  0.005295999933 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.605893186004 |  0.005295999933 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.602209944751 | 0.0206243414782 |                {'C': 10.0, 'gamma': 1.0}                 |        36       |
|  0.570902394107 | 0.0461104511413 |                {'C': 10.0, 'gamma': 10.0}                |        52       |
|  0.567219152855 | 0.0435832603435 |               {'C': 10.0, 'gamma': 100.0}                |        54       |
|  0.589318600368 | 0.0318624030559 |               {'C': 10.0, 'gamma': 1000.0}               |        49       |
|  0.591160220994 | 0.0178912199648 |              {'C': 10.0, 'gamma': 10000.0}               |        48       |
|  0.605893186004 |  0.005295999933 |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.605893186004 |  0.005295999933 |               {'C': 100.0, 'gamma': 0.01}                |        1        |
|  0.604051565378 | 0.0186804262689 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        35       |
|  0.570902394107 | 0.0374498133027 |                {'C': 100.0, 'gamma': 1.0}                |        52       |
|  0.530386740331 |  0.04706925419  |               {'C': 100.0, 'gamma': 10.0}                |        61       |
|  0.550644567219 | 0.0591638490119 |               {'C': 100.0, 'gamma': 100.0}               |        58       |
|  0.594843462247 | 0.0201121804059 |              {'C': 100.0, 'gamma': 1000.0}               |        41       |
|  0.594843462247 |  0.015846739776 |              {'C': 100.0, 'gamma': 10000.0}              |        41       |
|  0.605893186004 |  0.005295999933 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.594843462247 | 0.0182708246042 |               {'C': 1000.0, 'gamma': 0.01}               |        41       |
|  0.581952117864 | 0.0650774159722 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        51       |
|  0.55985267035  | 0.0751223974743 |               {'C': 1000.0, 'gamma': 1.0}                |        57       |
|  0.508287292818 | 0.0770310722989 |               {'C': 1000.0, 'gamma': 10.0}               |        63       |
|  0.546961325967 | 0.0586814830132 |              {'C': 1000.0, 'gamma': 100.0}               |        60       |
|  0.594843462247 | 0.0196603495882 |              {'C': 1000.0, 'gamma': 1000.0}              |        41       |
|  0.598526703499 | 0.0148729920922 |             {'C': 1000.0, 'gamma': 10000.0}              |        38       |
|  0.596685082873 | 0.0303156480268 |              {'C': 10000.0, 'gamma': 0.001}              |        39       |
|  0.561694290976 |  0.026566173906 |              {'C': 10000.0, 'gamma': 0.01}               |        56       |
|  0.565377532228 | 0.0505648419388 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        55       |
|  0.510128913444 | 0.0437638330068 |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.506445672192 | 0.0831399601815 |              {'C': 10000.0, 'gamma': 10.0}               |        64       |
|  0.548802946593 | 0.0469179506303 |              {'C': 10000.0, 'gamma': 100.0}              |        59       |
|  0.594843462247 | 0.0190191055136 |             {'C': 10000.0, 'gamma': 1000.0}              |        41       |
|  0.594843462247 |  0.021584690278 |             {'C': 10000.0, 'gamma': 10000.0}             |        41       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        37
          1       0.00      0.00      0.00        24

avg / total       0.37      0.61      0.46        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
| 0.0469613259669 | 0.0944515315551 |                {'C': 1.0, 'gamma': 10.0}                 |        30       |
|  0.476453564851 |  0.451566645151 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.103130755064 |  0.171251904945 |               {'C': 1.0, 'gamma': 1000.0}                |        28       |
| 0.0497237569061 |  0.149630967557 |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.28453038674  |  0.261617912838 |                {'C': 10.0, 'gamma': 1.0}                 |        20       |
|  0.427223284507 |  0.101287779816 |                {'C': 10.0, 'gamma': 10.0}                |        6        |
|  0.33057798555  |  0.161384797489 |               {'C': 10.0, 'gamma': 100.0}                |        18       |
|  0.316022099448 |  0.313994075482 |               {'C': 10.0, 'gamma': 1000.0}               |        19       |
|  0.132596685083 |  0.304820203848 |              {'C': 10.0, 'gamma': 10000.0}               |        27       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        31       |
|  0.349907918969 |  0.389828066639 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        14       |
|  0.431288282097 |  0.105967706955 |                {'C': 100.0, 'gamma': 1.0}                |        5        |
|  0.402638882441 | 0.0532708229507 |               {'C': 100.0, 'gamma': 10.0}                |        10       |
|  0.349881906512 |  0.111678921053 |               {'C': 100.0, 'gamma': 100.0}               |        15       |
|  0.344076120319 |  0.304588067175 |              {'C': 100.0, 'gamma': 1000.0}               |        16       |
|  0.201657458564 |  0.33287770413  |              {'C': 100.0, 'gamma': 10000.0}              |        23       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
|  0.156537753223 |  0.204998724229 |               {'C': 1000.0, 'gamma': 0.01}               |        25       |
|  0.442678898756 | 0.0875793050395 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        3        |
|  0.433089297264 | 0.0815341712557 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.405805210174 |  0.105208676291 |               {'C': 1000.0, 'gamma': 10.0}               |        9        |
|  0.378579354961 |  0.213530567777 |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
|  0.240484960098 |  0.211959564774 |              {'C': 1000.0, 'gamma': 1000.0}              |        22       |
|  0.151012891344 |  0.321474912768 |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
|  0.334868017188 |  0.387348124622 |              {'C': 10000.0, 'gamma': 0.001}              |        17       |
|  0.412764442794 |  0.109302515718 |              {'C': 10000.0, 'gamma': 0.01}               |        7        |
|  0.444323656661 |  0.084977705261 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.409675950395 | 0.0746303466743 |               {'C': 10000.0, 'gamma': 1.0}               |        8        |
|  0.39644372846  | 0.0692142591414 |              {'C': 10000.0, 'gamma': 10.0}               |        11       |
|  0.370628849358 |  0.188504352304 |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
|  0.245023239498 |  0.307970091355 |             {'C': 10000.0, 'gamma': 1000.0}              |        21       |
|  0.198895027624 |  0.331077088764 |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.95      0.74        37
          1       0.33      0.04      0.07        24

avg / total       0.50      0.59      0.48        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|       0.0        |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
| 0.00460405156538 | 0.0137141452645 |                {'C': 1.0, 'gamma': 10.0}                 |        30       |
| 0.0420064895203  | 0.0436183620107 |                {'C': 1.0, 'gamma': 100.0}                |        17       |
| 0.0279312461633  | 0.0228036924672 |               {'C': 1.0, 'gamma': 1000.0}                |        21       |
| 0.00947119179163 | 0.0190080419555 |               {'C': 1.0, 'gamma': 10000.0}               |        26       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        31       |
| 0.0374901341752  | 0.0353815792637 |                {'C': 10.0, 'gamma': 1.0}                 |        19       |
|  0.27554152416   | 0.0842476431438 |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.14982899237   | 0.0588032183315 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
| 0.0374462860651  | 0.0283488675615 |               {'C': 10.0, 'gamma': 1000.0}               |        20       |
| 0.00933964746119 | 0.0186427096454 |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        31       |
| 0.0186792949224  | 0.0306462617419 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        24       |
|  0.270630535824  |  0.107087709398 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.336095764273  | 0.0805791143443 |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.182057353328  | 0.0756452167965 |               {'C': 100.0, 'gamma': 100.0}               |        11       |
| 0.0468736297466  | 0.0295736923273 |              {'C': 100.0, 'gamma': 1000.0}               |        15       |
| 0.00933964746119 | 0.0186427096454 |              {'C': 100.0, 'gamma': 10000.0}              |        28       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
| 0.0235464351486  | 0.0317469346827 |               {'C': 1000.0, 'gamma': 0.01}               |        22       |
|  0.22454617206   | 0.0838689011283 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.397483118478  |  0.106908977962 |               {'C': 1000.0, 'gamma': 1.0}                |        1        |
|  0.359861439972  | 0.0993488945444 |               {'C': 1000.0, 'gamma': 10.0}               |        4        |
|  0.163334210296  | 0.0741177847518 |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
| 0.0424011225116  | 0.0448922814512 |              {'C': 1000.0, 'gamma': 1000.0}              |        16       |
| 0.00947119179163 | 0.0190080419555 |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
| 0.0231518021573  | 0.0307432765049 |              {'C': 10000.0, 'gamma': 0.001}              |        23       |
|  0.182408138209  |  0.078177973263 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.313601683767  | 0.0744874450254 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        6        |
|  0.364597035868  |  0.088799262301 |               {'C': 10000.0, 'gamma': 1.0}               |        3        |
|  0.388099622906  |  0.126989397292 |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.163728843287  |  0.103904436728 |              {'C': 10000.0, 'gamma': 100.0}              |        12       |
| 0.0376216785057  | 0.0507816258264 |             {'C': 10000.0, 'gamma': 1000.0}              |        18       |
| 0.0139436990266  | 0.0294648622691 |             {'C': 10000.0, 'gamma': 10000.0}             |        25       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.84      0.75        37
          1       0.60      0.38      0.46        24

avg / total       0.64      0.66      0.63        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.001}               |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.605893186004 |  0.005295999933  | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.605893186004 |  0.005295999933  |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.605893186004 |  0.005295999933  |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.605893186004 |  0.005295999933  |                 {'C': 1.0, 'gamma': 1.0}                 |        2        |
|  0.585635359116 | 0.0197407759182  |                {'C': 1.0, 'gamma': 10.0}                 |        53       |
|  0.611418047882 | 0.0178698571036  |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.600368324125 | 0.0190787236566  |               {'C': 1.0, 'gamma': 1000.0}                |        39       |
|  0.594843462247 | 0.0196918636625  |               {'C': 1.0, 'gamma': 10000.0}               |        49       |
|  0.605893186004 |  0.005295999933  |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.605893186004 |  0.005295999933  |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.605893186004 |  0.005295999933  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.589318600368 | 0.0241213453383  |                {'C': 10.0, 'gamma': 1.0}                 |        51       |
|  0.598526703499 | 0.0573041402205  |                {'C': 10.0, 'gamma': 10.0}                |        43       |
|  0.567219152855 | 0.0458258318743  |               {'C': 10.0, 'gamma': 100.0}                |        55       |
|  0.600368324125 | 0.0235771380526  |               {'C': 10.0, 'gamma': 1000.0}               |        39       |
|  0.600368324125 | 0.0133552047863  |              {'C': 10.0, 'gamma': 10000.0}               |        39       |
|  0.605893186004 |  0.005295999933  |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.605893186004 |  0.005295999933  |               {'C': 100.0, 'gamma': 0.01}                |        2        |
|  0.596685082873 | 0.0356316499274  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        48       |
|  0.554327808471 | 0.0569367810297  |                {'C': 100.0, 'gamma': 1.0}                |        60       |
|  0.567219152855 | 0.0656118063116  |               {'C': 100.0, 'gamma': 10.0}                |        55       |
|  0.572744014733 | 0.0482678733752  |               {'C': 100.0, 'gamma': 100.0}               |        54       |
|  0.591160220994 | 0.0203649975969  |              {'C': 100.0, 'gamma': 1000.0}               |        50       |
|  0.598526703499 | 0.0158224329723  |              {'C': 100.0, 'gamma': 10000.0}              |        43       |
|  0.605893186004 |  0.005295999933  |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.605893186004 | 0.00902075405893 |               {'C': 1000.0, 'gamma': 0.01}               |        2        |
|  0.561694290976 |  0.042645000242  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        58       |
|  0.589318600368 | 0.0612901235554  |               {'C': 1000.0, 'gamma': 1.0}                |        51       |
|  0.53591160221  | 0.0591225501229  |               {'C': 1000.0, 'gamma': 10.0}               |        63       |
|  0.55985267035  | 0.0559750712494  |              {'C': 1000.0, 'gamma': 100.0}               |        59       |
|  0.602209944751 | 0.0244915970439  |              {'C': 1000.0, 'gamma': 1000.0}              |        38       |
|  0.598526703499 | 0.0100646692192  |             {'C': 1000.0, 'gamma': 10000.0}              |        43       |
|  0.605893186004 | 0.0194753805842  |              {'C': 10000.0, 'gamma': 0.001}              |        2        |
|  0.565377532228 | 0.0796215778801  |              {'C': 10000.0, 'gamma': 0.01}               |        57       |
|  0.598526703499 | 0.0726604288433  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        43       |
|  0.539594843462 | 0.0483611839436  |               {'C': 10000.0, 'gamma': 1.0}               |        62       |
|  0.523020257827 | 0.0814193587967  |              {'C': 10000.0, 'gamma': 10.0}               |        64       |
|  0.552486187845 | 0.0405081786912  |              {'C': 10000.0, 'gamma': 100.0}              |        61       |
|  0.600368324125 | 0.0325438315159  |             {'C': 10000.0, 'gamma': 1000.0}              |        39       |
|  0.598526703499 | 0.0134499466637  |             {'C': 10000.0, 'gamma': 10000.0}             |        43       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.97      0.75        37
          1       0.50      0.04      0.08        24

avg / total       0.57      0.61      0.49        61

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.308011049724 |  0.234788441622 |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.348987108656 |  0.449302596296 |                {'C': 1.0, 'gamma': 100.0}                |        17       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.24684732088  |  0.176404223217 |                {'C': 10.0, 'gamma': 1.0}                 |        22       |
|  0.461910097269 | 0.0921642459384 |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.423870911164 |  0.146359053499 |               {'C': 10.0, 'gamma': 100.0}                |        6        |
|  0.52394106814  |  0.480396103665 |               {'C': 10.0, 'gamma': 1000.0}               |        1        |
| 0.0994475138122 |  0.299261935115 |              {'C': 10.0, 'gamma': 10000.0}               |        27       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        29       |
|  0.24861878453  |  0.334995297206 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        20       |
|  0.41115063307  |  0.125241087009 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.418685984135 |  0.088208099607 |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.392710251688 |  0.12252746168  |               {'C': 100.0, 'gamma': 100.0}               |        10       |
|  0.242019643953 |  0.307530732855 |              {'C': 100.0, 'gamma': 1000.0}               |        23       |
|  0.24861878453  |  0.402424658857 |              {'C': 100.0, 'gamma': 10000.0}              |        20       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
|  0.215776550031 |  0.349723977801 |               {'C': 1000.0, 'gamma': 0.01}               |        24       |
|  0.432766742159 | 0.0794606475361 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        4        |
|  0.407975122781 | 0.0675787899579 |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.382002280465 |  0.097788087008 |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.363358633386 |  0.102819553674 |              {'C': 1000.0, 'gamma': 100.0}               |        16       |
|  0.302639656231 |  0.379383782086 |              {'C': 1000.0, 'gamma': 1000.0}              |        19       |
| 0.0822590546347 |  0.170118857351 |             {'C': 1000.0, 'gamma': 10000.0}              |        28       |
|  0.430939226519 |  0.472367613255 |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.376653916985 |   0.1176872972  |              {'C': 10000.0, 'gamma': 0.01}               |        15       |
|  0.472298653332 | 0.0903544913527 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.385101230905 | 0.0570742840411 |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.390177209855 | 0.0779899659088 |              {'C': 10000.0, 'gamma': 10.0}               |        11       |
|   0.3874297587  |  0.112422453679 |              {'C': 10000.0, 'gamma': 100.0}              |        12       |
|  0.179404542664 |  0.302198755505 |             {'C': 10000.0, 'gamma': 1000.0}              |        25       |
|  0.151933701657 |  0.321757002019 |             {'C': 10000.0, 'gamma': 10000.0}             |        26       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.76        37
          1       1.00      0.04      0.08        24

avg / total       0.77      0.62      0.49        61

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|       0.0        |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
| 0.0516092256424  | 0.0497013919414 |                {'C': 1.0, 'gamma': 10.0}                 |        15       |
| 0.0279750942734  | 0.0311812058706 |                {'C': 1.0, 'gamma': 100.0}                |        20       |
|       0.0        |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|       0.0        |       0.0       |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        29       |
| 0.0513899850916  | 0.0391097837033 |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.261992458125  | 0.0498507591549 |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.135709900903  | 0.0570799484749 |               {'C': 10.0, 'gamma': 100.0}                |        13       |
| 0.0142067876875  |  0.030425154329 |               {'C': 10.0, 'gamma': 1000.0}               |        25       |
| 0.00920810313076 | 0.0182691263896 |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        29       |
| 0.0283258791546  |  0.043583521625 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        18       |
|  0.256818381128  | 0.0896348059212 |                {'C': 100.0, 'gamma': 1.0}                |        9        |
|  0.369727264755  |  0.114854185984 |               {'C': 100.0, 'gamma': 10.0}                |        4        |
|  0.135227571692  | 0.0634546874483 |               {'C': 100.0, 'gamma': 100.0}               |        14       |
| 0.0235464351486  | 0.0317469346827 |              {'C': 100.0, 'gamma': 1000.0}               |        22       |
| 0.00933964746119 | 0.0186427096454 |              {'C': 100.0, 'gamma': 10000.0}              |        27       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
| 0.0374462860651  | 0.0283488675615 |               {'C': 1000.0, 'gamma': 0.01}               |        17       |
|  0.262036306235  | 0.0966137688195 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        7        |
|  0.364114706656  |  0.125877695921 |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.392791370692  | 0.0983470093249 |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.181531176006  | 0.0809471461373 |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
| 0.0279312461633  | 0.0306359026707 |              {'C': 1000.0, 'gamma': 1000.0}              |        21       |
| 0.0138121546961  | 0.0292506365472 |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
| 0.0234148908182  | 0.0310701926609 |              {'C': 10000.0, 'gamma': 0.001}              |        23       |
|  0.252915899325  | 0.0661430921047 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.359861439972  | 0.0554311001383 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        6        |
|  0.425370516531  | 0.0784306236809 |               {'C': 10000.0, 'gamma': 1.0}               |        1        |
|  0.378584583004  |  0.107467319407 |              {'C': 10000.0, 'gamma': 10.0}               |        3        |
|   0.2005174077   | 0.0845439776976 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
| 0.0280189423836  | 0.0311494287829 |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
| 0.0188108392528  |  0.023063848273 |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.62      0.63        37
          1       0.44      0.46      0.45        24

avg / total       0.56      0.56      0.56        61

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 0.001}               |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.606617647059 | 0.00545308712286 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.606617647059 | 0.00545308712286 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.606617647059 | 0.00545308712286 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.606617647059 | 0.00545308712286 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.606617647059 | 0.00545308712286 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.604779411765 | 0.00662407397913 |                 {'C': 1.0, 'gamma': 1.0}                 |        34       |
|  0.599264705882 | 0.0138946765404  |                {'C': 1.0, 'gamma': 10.0}                 |        40       |
|  0.610294117647 | 0.0182239660953  |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.595588235294 | 0.0190989746861  |               {'C': 1.0, 'gamma': 1000.0}                |        46       |
|  0.599264705882 | 0.0112346391298  |               {'C': 1.0, 'gamma': 10000.0}               |        40       |
|  0.606617647059 | 0.00545308712286 |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.604779411765 | 0.00662407397913 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        34       |
|  0.599264705882 | 0.0227732639931  |                {'C': 10.0, 'gamma': 1.0}                 |        40       |
|  0.590073529412 | 0.0467197361903  |                {'C': 10.0, 'gamma': 10.0}                |        51       |
|  0.558823529412 | 0.0581346446726  |               {'C': 10.0, 'gamma': 100.0}                |        57       |
|     0.59375     | 0.0290096091793  |               {'C': 10.0, 'gamma': 1000.0}               |        49       |
|  0.601102941176 | 0.0102526317586  |              {'C': 10.0, 'gamma': 10000.0}               |        37       |
|  0.606617647059 | 0.00545308712286 |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 100.0, 'gamma': 0.01}                |        2        |
|  0.599264705882 | 0.0234296679571  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        40       |
|  0.560661764706 | 0.0638291547645  |                {'C': 100.0, 'gamma': 1.0}                |        56       |
|  0.534926470588 | 0.0751644532286  |               {'C': 100.0, 'gamma': 10.0}                |        61       |
|  0.555147058824 | 0.0423108043056  |               {'C': 100.0, 'gamma': 100.0}               |        58       |
|     0.59375     | 0.0373812861479  |              {'C': 100.0, 'gamma': 1000.0}               |        49       |
|  0.595588235294 | 0.0168614755149  |              {'C': 100.0, 'gamma': 10000.0}              |        46       |
|  0.606617647059 | 0.00545308712286 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.601102941176 | 0.0225672472603  |               {'C': 1000.0, 'gamma': 0.01}               |        37       |
|  0.569852941176 | 0.0580599924823  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        54       |
|  0.525735294118 | 0.0709052816527  |               {'C': 1000.0, 'gamma': 1.0}                |        63       |
|  0.511029411765 | 0.0758666826859  |               {'C': 1000.0, 'gamma': 10.0}               |        64       |
|  0.584558823529 | 0.0397865598725  |              {'C': 1000.0, 'gamma': 100.0}               |        52       |
|  0.597426470588 | 0.0250160780235  |              {'C': 1000.0, 'gamma': 1000.0}              |        45       |
|  0.601102941176 | 0.0197753424849  |             {'C': 1000.0, 'gamma': 10000.0}              |        37       |
|  0.599264705882 | 0.0156936419679  |              {'C': 10000.0, 'gamma': 0.001}              |        40       |
|  0.582720588235 | 0.0324507467482  |              {'C': 10000.0, 'gamma': 0.01}               |        53       |
|  0.569852941176 | 0.0668131794815  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        54       |
|  0.540441176471 | 0.0607897491245  |               {'C': 10000.0, 'gamma': 1.0}               |        60       |
|  0.555147058824 | 0.0707019116483  |              {'C': 10000.0, 'gamma': 10.0}               |        58       |
|  0.534926470588 |  0.046384022684  |              {'C': 10000.0, 'gamma': 100.0}              |        61       |
|  0.595588235294 | 0.0204450286406  |             {'C': 10000.0, 'gamma': 1000.0}              |        46       |
|  0.602941176471 | 0.0234547115869  |             {'C': 10000.0, 'gamma': 10000.0}             |        36       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        36
          1       0.00      0.00      0.00        24

avg / total       0.36      0.60      0.45        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        30       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 10.0}                 |        30       |
|  0.467218137255 |  0.419959661692 |                {'C': 1.0, 'gamma': 100.0}                |        1        |
| 0.0404411764706 |  0.120585993523 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.267463235294 |  0.318931174764 |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        30       |
|  0.338235294118 |  0.296935035361 |                {'C': 10.0, 'gamma': 1.0}                 |        19       |
|  0.414885665805 |  0.114352605026 |                {'C': 10.0, 'gamma': 10.0}                |        4        |
|  0.33005004085  |  0.103058281831 |               {'C': 10.0, 'gamma': 100.0}                |        20       |
|  0.315134803922 |  0.308508333694 |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.318014705882 |  0.384639479507 |              {'C': 10.0, 'gamma': 10000.0}               |        21       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        30       |
|     0.234375    |  0.32755552824  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        26       |
|  0.397636323572 |  0.117512503652 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.396347441606 | 0.0745102457658 |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|  0.37446315939  |  0.174146736537 |               {'C': 100.0, 'gamma': 100.0}               |        14       |
|  0.289093137255 |  0.25043979842  |              {'C': 100.0, 'gamma': 1000.0}               |        24       |
|  0.200367647059 |  0.400275471483 |              {'C': 100.0, 'gamma': 10000.0}              |        28       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
|  0.364583333333 |  0.370815088227 |               {'C': 1000.0, 'gamma': 0.01}               |        15       |
|  0.357200791501 |  0.115679286564 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        16       |
|  0.40296254231  | 0.0892765518767 |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.399009920181 | 0.0932530299781 |               {'C': 1000.0, 'gamma': 10.0}               |        7        |
|  0.375717113769 |  0.10588941326  |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.394730392157 |  0.385369709412 |              {'C': 1000.0, 'gamma': 1000.0}              |        11       |
|  0.350183823529 |  0.390700684709 |             {'C': 1000.0, 'gamma': 10000.0}              |        17       |
|  0.31556372549  |  0.41073076816  |              {'C': 10000.0, 'gamma': 0.001}              |        22       |
|  0.382836740465 | 0.0705119004226 |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.427170065412 |  0.107089833889 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.39577072838  |  0.126996012466 |               {'C': 10000.0, 'gamma': 1.0}               |        10       |
|  0.417983672053 | 0.0905336205362 |              {'C': 10000.0, 'gamma': 10.0}               |        3        |
|  0.413267859591 |  0.103661008982 |              {'C': 10000.0, 'gamma': 100.0}              |        5        |
|  0.342218137255 |  0.399010344106 |             {'C': 10000.0, 'gamma': 1000.0}              |        18       |
|  0.233149509804 |  0.325931869961 |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        36
          1       0.00      0.00      0.00        24

avg / total       0.36      0.60      0.45        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|       0.0        |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
| 0.0093224789916  | 0.0186298630107 |                {'C': 1.0, 'gamma': 10.0}                 |        28       |
| 0.0139180672269  | 0.0211933524801 |                {'C': 1.0, 'gamma': 100.0}                |        27       |
| 0.00459558823529 | 0.0137029538094 |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
| 0.0140493697479  | 0.0214868717138 |               {'C': 1.0, 'gamma': 10000.0}               |        24       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        31       |
| 0.0420168067227  | 0.0380649691477 |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|     0.265625     |  0.105989367317 |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.126181722689  | 0.0556238962459 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
| 0.0376838235294  |  0.041412441207 |               {'C': 10.0, 'gamma': 1000.0}               |        18       |
| 0.0233718487395  | 0.0376134067042 |              {'C': 10.0, 'gamma': 10000.0}               |        21       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        31       |
| 0.0140493697479  | 0.0301971145654 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        24       |
|  0.228466386555  | 0.0792171872263 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.326680672269  |  0.138079137687 |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.15887605042   | 0.0817432901429 |               {'C': 100.0, 'gamma': 100.0}               |        12       |
| 0.0325630252101  |  0.036310354105 |              {'C': 100.0, 'gamma': 1000.0}               |        19       |
| 0.0093224789916  | 0.0186298630107 |              {'C': 100.0, 'gamma': 10000.0}              |        28       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
| 0.0187762605042  | 0.0313335697916 |               {'C': 1000.0, 'gamma': 0.01}               |        22       |
|  0.177258403361  | 0.0820812720714 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.355829831933  |  0.112378362663 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.369353991597  | 0.0915959340242 |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.130777310924  | 0.0586529725487 |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
| 0.0605304621849  | 0.0585136004773 |              {'C': 1000.0, 'gamma': 1000.0}              |        16       |
| 0.0235031512605  | 0.0235977202122 |             {'C': 1000.0, 'gamma': 10000.0}              |        20       |
| 0.0186449579832  | 0.0228106633507 |              {'C': 10000.0, 'gamma': 0.001}              |        23       |
|  0.173056722689  | 0.0697761188189 |              {'C': 10000.0, 'gamma': 0.01}               |        11       |
|  0.322478991597  |  0.104127030975 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        6        |
|     0.359375     | 0.0648805627066 |               {'C': 10000.0, 'gamma': 1.0}               |        3        |
|  0.388130252101  |  0.127571611876 |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.181328781513  |  0.106147828692 |              {'C': 10000.0, 'gamma': 100.0}              |        9        |
| 0.0607930672269  |  0.03698481004  |             {'C': 10000.0, 'gamma': 1000.0}              |        15       |
| 0.0140493697479  | 0.0214868717138 |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.67      0.65        36
          1       0.45      0.42      0.43        24

avg / total       0.56      0.57      0.56        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 0.001}               |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 0.01}                |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.001, 'gamma': 1.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 10.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.001, 'gamma': 100.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |              {'C': 0.001, 'gamma': 1000.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |              {'C': 0.001, 'gamma': 10000.0}              |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.01, 'gamma': 0.001}                |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.01, 'gamma': 0.01}                |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.01, 'gamma': 1.0}                 |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 0.01, 'gamma': 10.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.01, 'gamma': 100.0}                |        2        |
|  0.606617647059 | 0.00545308712286 |               {'C': 0.01, 'gamma': 1000.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |              {'C': 0.01, 'gamma': 10000.0}               |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        2        |
|  0.606617647059 | 0.00545308712286 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        2        |
|  0.606617647059 | 0.00545308712286 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        2        |
|  0.606617647059 | 0.00545308712286 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        2        |
|  0.606617647059 | 0.00545308712286 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        2        |
|  0.606617647059 | 0.00545308712286 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 1.0, 'gamma': 0.001}                |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 1.0, 'gamma': 0.01}                 |        2        |
|  0.606617647059 | 0.00545308712286 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        2        |
|  0.610294117647 | 0.00871057294696 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.599264705882 | 0.0296452592907  |                {'C': 1.0, 'gamma': 10.0}                 |        43       |
|  0.602941176471 | 0.0231358827151  |                {'C': 1.0, 'gamma': 100.0}                |        38       |
|  0.597426470588 | 0.0219452143891  |               {'C': 1.0, 'gamma': 1000.0}                |        44       |
|  0.601102941176 | 0.0115043284656  |               {'C': 1.0, 'gamma': 10000.0}               |        41       |
|  0.606617647059 | 0.00545308712286 |               {'C': 10.0, 'gamma': 0.001}                |        2        |
|  0.606617647059 | 0.00545308712286 |                {'C': 10.0, 'gamma': 0.01}                |        2        |
|  0.604779411765 | 0.00917110107027 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        34       |
|  0.595588235294 | 0.0289205615301  |                {'C': 10.0, 'gamma': 1.0}                 |        47       |
|  0.564338235294 |  0.070958133571  |                {'C': 10.0, 'gamma': 10.0}                |        56       |
|  0.580882352941 | 0.0397688262341  |               {'C': 10.0, 'gamma': 100.0}                |        52       |
|  0.591911764706 | 0.0182496696925  |               {'C': 10.0, 'gamma': 1000.0}               |        49       |
|  0.604779411765 | 0.0198543509215  |              {'C': 10.0, 'gamma': 10000.0}               |        34       |
|  0.606617647059 | 0.00545308712286 |               {'C': 100.0, 'gamma': 0.001}               |        2        |
|  0.604779411765 | 0.00917110107027 |               {'C': 100.0, 'gamma': 0.01}                |        34       |
|  0.601102941176 | 0.0163864319114  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        41       |
|  0.551470588235 | 0.0763353505019  |                {'C': 100.0, 'gamma': 1.0}                |        60       |
|  0.542279411765 | 0.0560006681266  |               {'C': 100.0, 'gamma': 10.0}                |        63       |
|  0.555147058824 | 0.0528418302421  |               {'C': 100.0, 'gamma': 100.0}               |        57       |
|  0.602941176471 | 0.0271028773284  |              {'C': 100.0, 'gamma': 1000.0}               |        38       |
|  0.597426470588 |  0.02339229543   |              {'C': 100.0, 'gamma': 10000.0}              |        44       |
|  0.606617647059 | 0.00545308712286 |              {'C': 1000.0, 'gamma': 0.001}               |        2        |
|  0.584558823529 | 0.0150215549849  |               {'C': 1000.0, 'gamma': 0.01}               |        50       |
|  0.582720588235 | 0.0693227992018  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        51       |
|  0.545955882353 | 0.0548272357674  |               {'C': 1000.0, 'gamma': 1.0}                |        62       |
|  0.523897058824 | 0.0597306051898  |               {'C': 1000.0, 'gamma': 10.0}               |        64       |
|  0.566176470588 | 0.0411465740433  |              {'C': 1000.0, 'gamma': 100.0}               |        55       |
|     0.59375     | 0.0423348642181  |              {'C': 1000.0, 'gamma': 1000.0}              |        48       |
|  0.604779411765 | 0.0117718021466  |             {'C': 1000.0, 'gamma': 10000.0}              |        34       |
|  0.597426470588 | 0.0227891955885  |              {'C': 10000.0, 'gamma': 0.001}              |        44       |
|  0.568014705882 | 0.0278244998919  |              {'C': 10000.0, 'gamma': 0.01}               |        53       |
|  0.551470588235 |  0.039420329089  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        60       |
|  0.568014705882 | 0.0354712493189  |               {'C': 10000.0, 'gamma': 1.0}               |        53       |
|  0.555147058824 | 0.0612705732544  |              {'C': 10000.0, 'gamma': 10.0}               |        57       |
|  0.555147058824 |  0.079175840928  |              {'C': 10000.0, 'gamma': 100.0}              |        57       |
|  0.606617647059 | 0.0264349066855  |             {'C': 10000.0, 'gamma': 1000.0}              |        2        |
|  0.602941176471 | 0.0158681156524  |             {'C': 10000.0, 'gamma': 10000.0}             |        38       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.97      0.74        36
          1       0.00      0.00      0.00        24

avg / total       0.36      0.58      0.44        60

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        32       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        32       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        32       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        32       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        32       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        32       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        32       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        32       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        32       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        32       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        32       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        32       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        32       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        32       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        32       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        32       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        32       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        32       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        32       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        32       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        32       |
| 0.0992647058824 |  0.299017096582 |                 {'C': 1.0, 'gamma': 1.0}                 |        28       |
|  0.370812908497 |  0.375403815548 |                {'C': 1.0, 'gamma': 10.0}                 |        19       |
|  0.416360294118 |  0.44234583843  |                {'C': 1.0, 'gamma': 100.0}                |        8        |
| 0.0283613445378 | 0.0854334561663 |               {'C': 1.0, 'gamma': 1000.0}                |        31       |
| 0.0397058823529 |  0.119606838633 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        32       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        32       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        32       |
|  0.599264705882 |  0.359072809987 |                {'C': 10.0, 'gamma': 1.0}                 |        1        |
|  0.462443165065 |  0.144850258725 |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.346803513072 |  0.149156980706 |               {'C': 10.0, 'gamma': 100.0}                |        20       |
|  0.322150735294 |  0.385005809829 |               {'C': 10.0, 'gamma': 1000.0}               |        22       |
| 0.0827205882353 |  0.170302356171 |              {'C': 10.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        32       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        32       |
|  0.183823529412 |  0.321181318645 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        27       |
|  0.410324418229 |  0.169525864692 |                {'C': 100.0, 'gamma': 1.0}                |        13       |
|  0.378649952628 | 0.0847004719505 |               {'C': 100.0, 'gamma': 10.0}                |        18       |
|  0.380619747899 |  0.162790937636 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.51862745098  |  0.298430390223 |              {'C': 100.0, 'gamma': 1000.0}               |        2        |
|  0.250919117647 |  0.403339780771 |              {'C': 100.0, 'gamma': 10000.0}              |        26       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        32       |
|  0.306678921569 |  0.383055259133 |               {'C': 1000.0, 'gamma': 0.01}               |        23       |
|  0.410656483559 |  0.134855862555 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        12       |
|  0.421675398498 | 0.0624605582271 |               {'C': 1000.0, 'gamma': 1.0}                |        7        |
|  0.391759018201 | 0.0949876646709 |               {'C': 1000.0, 'gamma': 10.0}               |        15       |
|  0.432536672886 |  0.152674441284 |              {'C': 1000.0, 'gamma': 100.0}               |        6        |
|  0.506893382353 |  0.402569070198 |              {'C': 1000.0, 'gamma': 1000.0}              |        3        |
|  0.415441176471 |  0.442690417067 |             {'C': 1000.0, 'gamma': 10000.0}              |        9        |
|  0.282781862745 |  0.324716603134 |              {'C': 10000.0, 'gamma': 0.001}              |        25       |
|  0.411899179192 | 0.0809856531203 |              {'C': 10000.0, 'gamma': 0.01}               |        11       |
|  0.401843487888 | 0.0941166777079 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        14       |
|  0.414455429076 |  0.103440485601 |               {'C': 10000.0, 'gamma': 1.0}               |        10       |
|  0.389397140726 | 0.0697781663024 |              {'C': 10000.0, 'gamma': 10.0}               |        16       |
|  0.334089164512 |  0.178063600626 |              {'C': 10000.0, 'gamma': 100.0}              |        21       |
|  0.475490196078 |  0.333695827263 |             {'C': 10000.0, 'gamma': 1000.0}              |        4        |
|  0.299632352941 |  0.400275471483 |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.97      0.74        36
          1       0.50      0.04      0.08        24

avg / total       0.56      0.60      0.48        60

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
| 0.0093224789916 | 0.0186298630107 |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
| 0.0187762605042 | 0.0230567240486 |                {'C': 1.0, 'gamma': 10.0}                 |        25       |
| 0.0372899159664 | 0.0452648442682 |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        31       |
| 0.0047268907563 | 0.0142389093611 |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        31       |
| 0.0559348739496 |  0.027584667982 |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.247505252101 | 0.0613100208247 |                {'C': 10.0, 'gamma': 10.0}                |        8        |
|  0.130908613445 | 0.0759612345815 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
| 0.0186449579832 |  0.030628534264 |               {'C': 10.0, 'gamma': 1000.0}               |        26       |
| 0.0140493697479 | 0.0214868717138 |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        31       |
| 0.0279674369748 | 0.0311439203076 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        22       |
|  0.257221638655 | 0.0930858267839 |                {'C': 100.0, 'gamma': 1.0}                |        7        |
|  0.32155987395  | 0.0984937676524 |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.145351890756 | 0.0839897070201 |               {'C': 100.0, 'gamma': 100.0}               |        13       |
| 0.0374212184874 | 0.0349246980041 |              {'C': 100.0, 'gamma': 1000.0}               |        17       |
| 0.0186449579832 | 0.0228106633507 |              {'C': 100.0, 'gamma': 10000.0}              |        26       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
| 0.0283613445378 | 0.0315650823557 |               {'C': 1000.0, 'gamma': 0.01}               |        20       |
|  0.201418067227 | 0.0873149648531 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.327205882353 |  0.101549191023 |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.429753151261 | 0.0948035365265 |               {'C': 1000.0, 'gamma': 10.0}               |        1        |
|  0.163602941176 |  0.114159464454 |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
| 0.0421481092437 | 0.0248702427597 |              {'C': 1000.0, 'gamma': 1000.0}              |        16       |
| 0.0232405462185 | 0.0308951283401 |             {'C': 1000.0, 'gamma': 10000.0}              |        23       |
| 0.0189075630252 |  0.031512605042 |              {'C': 10000.0, 'gamma': 0.001}              |        24       |
|  0.201024159664 | 0.0562781464877 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.331538865546 |  0.127586040598 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.369879201681 | 0.0912818522273 |               {'C': 10000.0, 'gamma': 1.0}               |        3        |
|  0.425288865546 | 0.0975997429738 |              {'C': 10000.0, 'gamma': 10.0}               |        2        |
|  0.167673319328 | 0.0712415210302 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
| 0.0325630252101 |  0.029466281462 |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
| 0.0282300420168 | 0.0379178773956 |             {'C': 10000.0, 'gamma': 10000.0}             |        21       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.69      0.65        36
          1       0.42      0.33      0.37        24

avg / total       0.53      0.55      0.54        60

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 0.001}               |        1        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 0.01}                |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        1        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.001, 'gamma': 1.0}                |        1        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 10.0}                |        1        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 100.0}               |        1        |
|  0.605504587156 | 0.00555532175064 |              {'C': 0.001, 'gamma': 1000.0}               |        1        |
|  0.605504587156 | 0.00555532175064 |              {'C': 0.001, 'gamma': 10000.0}              |        1        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.01, 'gamma': 0.001}                |        1        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.01, 'gamma': 0.01}                |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        1        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.01, 'gamma': 1.0}                 |        1        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.01, 'gamma': 10.0}                |        1        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.01, 'gamma': 100.0}                |        1        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.01, 'gamma': 1000.0}               |        1        |
|  0.605504587156 | 0.00555532175064 |              {'C': 0.01, 'gamma': 10000.0}               |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        1        |
|  0.605504587156 | 0.00555532175064 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        1        |
|  0.605504587156 | 0.00555532175064 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        1        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        1        |
|  0.605504587156 | 0.00555532175064 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        1        |
|  0.605504587156 | 0.00555532175064 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        1        |
|  0.605504587156 | 0.00555532175064 |                {'C': 1.0, 'gamma': 0.001}                |        1        |
|  0.605504587156 | 0.00555532175064 |                {'C': 1.0, 'gamma': 0.01}                 |        1        |
|  0.605504587156 | 0.00555532175064 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        1        |
|  0.605504587156 | 0.00555532175064 |                 {'C': 1.0, 'gamma': 1.0}                 |        1        |
|  0.603669724771 | 0.0251668123894  |                {'C': 1.0, 'gamma': 10.0}                 |        38       |
|  0.605504587156 | 0.0214817911604  |                {'C': 1.0, 'gamma': 100.0}                |        1        |
|  0.603669724771 | 0.00900312911698 |               {'C': 1.0, 'gamma': 1000.0}                |        38       |
|  0.605504587156 | 0.00555532175064 |               {'C': 1.0, 'gamma': 10000.0}               |        1        |
|  0.605504587156 | 0.00555532175064 |               {'C': 10.0, 'gamma': 0.001}                |        1        |
|  0.605504587156 | 0.00555532175064 |                {'C': 10.0, 'gamma': 0.01}                |        1        |
|  0.603669724771 | 0.00639526488944 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        38       |
|  0.588990825688 | 0.0238641387922  |                {'C': 10.0, 'gamma': 1.0}                 |        50       |
|  0.579816513761 | 0.0565135027139  |                {'C': 10.0, 'gamma': 10.0}                |        51       |
|  0.56880733945  | 0.0434018375196  |               {'C': 10.0, 'gamma': 100.0}                |        54       |
|  0.596330275229 | 0.0286346586899  |               {'C': 10.0, 'gamma': 1000.0}               |        47       |
|  0.603669724771 | 0.0146879701994  |              {'C': 10.0, 'gamma': 10000.0}               |        38       |
|  0.605504587156 | 0.00555532175064 |               {'C': 100.0, 'gamma': 0.001}               |        1        |
|  0.603669724771 | 0.00639526488944 |               {'C': 100.0, 'gamma': 0.01}                |        38       |
|  0.601834862385 | 0.0195009313683  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        44       |
|  0.566972477064 | 0.0428233834155  |                {'C': 100.0, 'gamma': 1.0}                |        56       |
|  0.555963302752 | 0.0564230166122  |               {'C': 100.0, 'gamma': 10.0}                |        59       |
|  0.555963302752 | 0.0718925885832  |               {'C': 100.0, 'gamma': 100.0}               |        59       |
|  0.605504587156 | 0.0156600695219  |              {'C': 100.0, 'gamma': 1000.0}               |        1        |
|  0.603669724771 | 0.0198253554641  |              {'C': 100.0, 'gamma': 10000.0}              |        38       |
|  0.605504587156 | 0.00555532175064 |              {'C': 1000.0, 'gamma': 0.001}               |        1        |
|  0.596330275229 | 0.0271961364261  |               {'C': 1000.0, 'gamma': 0.01}               |        47       |
|  0.57247706422  | 0.0407119570711  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        52       |
|  0.546788990826 | 0.0551095195204  |               {'C': 1000.0, 'gamma': 1.0}                |        61       |
|  0.54495412844  | 0.0689508280533  |               {'C': 1000.0, 'gamma': 10.0}               |        62       |
|  0.570642201835 | 0.0480421194593  |              {'C': 1000.0, 'gamma': 100.0}               |        53       |
|  0.601834862385 | 0.0286815315632  |              {'C': 1000.0, 'gamma': 1000.0}              |        44       |
|  0.605504587156 | 0.0123268066103  |             {'C': 1000.0, 'gamma': 10000.0}              |        1        |
|  0.594495412844 | 0.0337976568752  |              {'C': 10000.0, 'gamma': 0.001}              |        49       |
|  0.561467889908 | 0.0576185528001  |              {'C': 10000.0, 'gamma': 0.01}               |        57       |
|  0.557798165138 | 0.0633558025613  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        58       |
|  0.539449541284 | 0.0695176222708  |               {'C': 10000.0, 'gamma': 1.0}               |        63       |
|  0.539449541284 | 0.0439771294726  |              {'C': 10000.0, 'gamma': 10.0}               |        63       |
|  0.56880733945  | 0.0504701435797  |              {'C': 10000.0, 'gamma': 100.0}              |        54       |
|  0.601834862385 | 0.0195009313683  |             {'C': 10000.0, 'gamma': 1000.0}              |        44       |
|  0.605504587156 | 0.0128663022828  |             {'C': 10000.0, 'gamma': 10000.0}             |        1        |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 0.001, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        36
          1       0.00      0.00      0.00        23

avg / total       0.37      0.61      0.46        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.174311926606 |  0.316417350028 |                {'C': 1.0, 'gamma': 10.0}                 |        27       |
|  0.399388379205 |  0.351376546019 |                {'C': 1.0, 'gamma': 100.0}                |        14       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 10000.0}               |        29       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|       0.0       |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.449418960245 |  0.396772361227 |                {'C': 10.0, 'gamma': 1.0}                 |        4        |
|  0.458381641294 |  0.146532130214 |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.400184677708 |  0.125732539344 |               {'C': 10.0, 'gamma': 100.0}                |        13       |
|  0.300917431193 |  0.458656876976 |               {'C': 10.0, 'gamma': 1000.0}               |        22       |
| 0.0990825688073 |  0.298772845764 |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        29       |
|  0.284097859327 |  0.325867346677 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        23       |
|  0.432738637509 |  0.123811086149 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.433011703408 | 0.0843915525662 |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.381719819426 | 0.0824165377364 |               {'C': 100.0, 'gamma': 100.0}               |        18       |
|  0.346657929227 |  0.398770072221 |              {'C': 100.0, 'gamma': 1000.0}               |        20       |
|  0.249541284404 |  0.403112626421 |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
|  0.334556574924 |  0.316547590859 |               {'C': 1000.0, 'gamma': 0.01}               |        21       |
|  0.387112276103 |  0.149938517086 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.431466020015 | 0.0901748736021 |               {'C': 1000.0, 'gamma': 1.0}                |        9        |
|  0.402514866399 | 0.0704296571033 |               {'C': 1000.0, 'gamma': 10.0}               |        12       |
|  0.390657889511 |  0.172804685796 |              {'C': 1000.0, 'gamma': 100.0}               |        16       |
|  0.464220183486 |  0.355951479989 |              {'C': 1000.0, 'gamma': 1000.0}              |        2        |
|  0.198165137615 |  0.330687815689 |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
|  0.467278287462 |  0.400050497612 |              {'C': 10000.0, 'gamma': 0.001}              |        1        |
|  0.35914797441  |  0.153612219573 |              {'C': 10000.0, 'gamma': 0.01}               |        19       |
|  0.436597551276 |  0.100457944195 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        5        |
|  0.426404974807 | 0.0963344980931 |               {'C': 10000.0, 'gamma': 1.0}               |        10       |
|  0.434328498193 | 0.0560930284531 |              {'C': 10000.0, 'gamma': 10.0}               |        6        |
|  0.414033856052 |  0.045473002463 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
|  0.39877675841  |   0.3817959226  |             {'C': 10000.0, 'gamma': 1000.0}              |        15       |
|  0.266055045872 |  0.416234801301 |             {'C': 10000.0, 'gamma': 10000.0}             |        24       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.97      0.75        36
          1       0.50      0.04      0.08        23

avg / total       0.57      0.61      0.49        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
| 0.00471821756225 | 0.0142272783697 |                 {'C': 1.0, 'gamma': 1.0}                 |        28       |
| 0.00943643512451 | 0.0189817740396 |                {'C': 1.0, 'gamma': 10.0}                 |        27       |
| 0.0507208387942  | 0.0516953926197 |                {'C': 1.0, 'gamma': 100.0}                |        16       |
|       0.0        |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
| 0.00471821756225 | 0.0142272783697 |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        30       |
| 0.0511140235911  |  0.038238473435 |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.260550458716  | 0.0797860364633 |                {'C': 10.0, 'gamma': 10.0}                |        7        |
|  0.116644823067  | 0.0851657482163 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.032372214941  | 0.0293418366509 |               {'C': 10.0, 'gamma': 1000.0}               |        21       |
|       0.0        |       0.0       |              {'C': 10.0, 'gamma': 10000.0}               |        30       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        30       |
|  0.032372214941  |  0.035748532229 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        21       |
|  0.237090432503  | 0.0990367591547 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.371821756225  |  0.080660508549 |               {'C': 100.0, 'gamma': 10.0}                |        3        |
|  0.167627785059  | 0.0563119145205 |               {'C': 100.0, 'gamma': 100.0}               |        10       |
| 0.0372214941022  | 0.0348376961478 |              {'C': 100.0, 'gamma': 1000.0}               |        20       |
| 0.0140235910878  | 0.0214755683462 |              {'C': 100.0, 'gamma': 10000.0}              |        24       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
| 0.0467889908257  | 0.0471538035086 |               {'C': 1000.0, 'gamma': 0.01}               |        17       |
|  0.17627785059   |  0.10566243124  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.334338138925  | 0.0923211522603 |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.404849279161  |  0.101568811107 |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.153866317169  |  0.060547234958 |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
| 0.0373525557012  | 0.0353892793269 |              {'C': 1000.0, 'gamma': 1000.0}              |        19       |
| 0.0138925294889  | 0.0211822763096 |             {'C': 1000.0, 'gamma': 10000.0}              |        25       |
| 0.0419397116645  | 0.0326319216162 |              {'C': 10000.0, 'gamma': 0.001}              |        18       |
|  0.166972477064  | 0.0791042551522 |              {'C': 10000.0, 'gamma': 0.01}               |        12       |
|  0.319790301442  |  0.126084329717 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        6        |
|  0.408912188729  |  0.159390764172 |               {'C': 10000.0, 'gamma': 1.0}               |        1        |
|   0.3625163827   | 0.0969969659162 |              {'C': 10000.0, 'gamma': 10.0}               |        4        |
|  0.16749672346   |  0.105154045925 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
| 0.0277850589777  | 0.0226135558486 |             {'C': 10000.0, 'gamma': 1000.0}              |        23       |
| 0.0138925294889  | 0.0211822763096 |             {'C': 10000.0, 'gamma': 10000.0}             |        25       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.64      0.64        36
          1       0.43      0.43      0.43        23

avg / total       0.56      0.56      0.56        59

# Tuning hyper-parameters for accuracy

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 0.001}               |        7        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 0.01}                |        7        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        7        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.001, 'gamma': 1.0}                |        7        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 10.0}                |        7        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.001, 'gamma': 100.0}               |        7        |
|  0.605504587156 | 0.00555532175064 |              {'C': 0.001, 'gamma': 1000.0}               |        7        |
|  0.605504587156 | 0.00555532175064 |              {'C': 0.001, 'gamma': 10000.0}              |        7        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.01, 'gamma': 0.001}                |        7        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.01, 'gamma': 0.01}                |        7        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        7        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.01, 'gamma': 1.0}                 |        7        |
|  0.605504587156 | 0.00555532175064 |                {'C': 0.01, 'gamma': 10.0}                |        7        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.01, 'gamma': 100.0}                |        7        |
|  0.605504587156 | 0.00555532175064 |               {'C': 0.01, 'gamma': 1000.0}               |        7        |
|  0.605504587156 | 0.00555532175064 |              {'C': 0.01, 'gamma': 10000.0}               |        7        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        7        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        7        |
|  0.605504587156 | 0.00555532175064 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        7        |
|  0.605504587156 | 0.00555532175064 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        7        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        7        |
|  0.605504587156 | 0.00555532175064 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        7        |
|  0.605504587156 | 0.00555532175064 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        7        |
|  0.605504587156 | 0.00555532175064 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        7        |
|  0.605504587156 | 0.00555532175064 |                {'C': 1.0, 'gamma': 0.001}                |        7        |
|  0.605504587156 | 0.00555532175064 |                {'C': 1.0, 'gamma': 0.01}                 |        7        |
|  0.605504587156 | 0.00555532175064 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        7        |
|  0.605504587156 | 0.0075780569686  |                 {'C': 1.0, 'gamma': 1.0}                 |        7        |
|  0.609174311927 | 0.0224218831605  |                {'C': 1.0, 'gamma': 10.0}                 |        2        |
|  0.609174311927 | 0.0218497389999  |                {'C': 1.0, 'gamma': 100.0}                |        2        |
|  0.598165137615 |  0.014758226327  |               {'C': 1.0, 'gamma': 1000.0}                |        46       |
|  0.594495412844 | 0.0194597614206  |               {'C': 1.0, 'gamma': 10000.0}               |        49       |
|  0.605504587156 | 0.00555532175064 |               {'C': 10.0, 'gamma': 0.001}                |        7        |
|  0.605504587156 | 0.00555532175064 |                {'C': 10.0, 'gamma': 0.01}                |        7        |
|  0.603669724771 | 0.00900312911698 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        40       |
|  0.607339449541 | 0.0374883075869  |                {'C': 10.0, 'gamma': 1.0}                 |        5        |
|  0.590825688073 | 0.0370069255265  |                {'C': 10.0, 'gamma': 10.0}                |        51       |
|  0.565137614679 | 0.0498582650951  |               {'C': 10.0, 'gamma': 100.0}                |        57       |
|  0.588990825688 | 0.0285007375692  |               {'C': 10.0, 'gamma': 1000.0}               |        52       |
|  0.598165137615 | 0.0122915814996  |              {'C': 10.0, 'gamma': 10000.0}               |        46       |
|  0.605504587156 | 0.00555532175064 |               {'C': 100.0, 'gamma': 0.001}               |        7        |
|  0.605504587156 | 0.00555532175064 |               {'C': 100.0, 'gamma': 0.01}                |        7        |
|  0.609174311927 | 0.0233134202582  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.552293577982 | 0.0471542769463  |                {'C': 100.0, 'gamma': 1.0}                |        60       |
|  0.535779816514 | 0.0584412900264  |               {'C': 100.0, 'gamma': 10.0}                |        62       |
|  0.557798165138 |  0.028742233703  |               {'C': 100.0, 'gamma': 100.0}               |        59       |
|  0.592660550459 | 0.0227099748634  |              {'C': 100.0, 'gamma': 1000.0}               |        50       |
|       0.6       | 0.0167659907621  |              {'C': 100.0, 'gamma': 10000.0}              |        42       |
|  0.605504587156 | 0.00555532175064 |              {'C': 1000.0, 'gamma': 0.001}               |        7        |
|  0.611009174312 | 0.0375130946465  |               {'C': 1000.0, 'gamma': 0.01}               |        1        |
|       0.6       | 0.0463607804705  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        42       |
|  0.57247706422  | 0.0606946740381  |               {'C': 1000.0, 'gamma': 1.0}                |        54       |
|  0.530275229358 | 0.0682458790432  |               {'C': 1000.0, 'gamma': 10.0}               |        63       |
|  0.57247706422  | 0.0694126935226  |              {'C': 1000.0, 'gamma': 100.0}               |        54       |
|       0.6       | 0.0223285381929  |              {'C': 1000.0, 'gamma': 1000.0}              |        42       |
|       0.6       | 0.0207510421836  |             {'C': 1000.0, 'gamma': 10000.0}              |        42       |
|  0.607339449541 | 0.0395493045823  |              {'C': 10000.0, 'gamma': 0.001}              |        5        |
|  0.574311926606 | 0.0480355122771  |              {'C': 10000.0, 'gamma': 0.01}               |        53       |
|  0.566972477064 | 0.0823703928217  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        56       |
|  0.546788990826 | 0.0589707526999  |               {'C': 10000.0, 'gamma': 1.0}               |        61       |
|  0.526605504587 | 0.0267787232426  |              {'C': 10000.0, 'gamma': 10.0}               |        64       |
|  0.561467889908 | 0.0587861663916  |              {'C': 10000.0, 'gamma': 100.0}              |        58       |
|  0.596330275229 | 0.0311161595669  |             {'C': 10000.0, 'gamma': 1000.0}              |        48       |
|  0.601834862385 | 0.0138289513938  |             {'C': 10000.0, 'gamma': 10000.0}             |        41       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 0.01}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.92      0.73        36
          1       0.25      0.04      0.07        23

avg / total       0.46      0.58      0.47        59

# Tuning hyper-parameters for precision

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score |                          params                          | test_rank_score |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|       0.0       |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|       0.0       |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|       0.0       |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|       0.0       |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|       0.0       |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|       0.0       |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|       0.0       |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|       0.0       |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|       0.0       |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|       0.0       |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|       0.0       |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        30       |
|  0.399694189602 |  0.351391450283 |                {'C': 1.0, 'gamma': 10.0}                 |        13       |
|  0.352293577982 |  0.391092642601 |                {'C': 1.0, 'gamma': 100.0}                |        19       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
|       0.0       |       0.0       |               {'C': 1.0, 'gamma': 10000.0}               |        30       |
|       0.0       |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|       0.0       |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        30       |
| 0.0990825688073 |  0.298772845764 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.485657492355 |  0.307206513463 |                {'C': 10.0, 'gamma': 1.0}                 |        3        |
|  0.458900085793 |  0.104560355285 |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.358453473132 |  0.175981801212 |               {'C': 10.0, 'gamma': 100.0}                |        18       |
|  0.182568807339 |  0.319358312095 |               {'C': 10.0, 'gamma': 1000.0}               |        28       |
|  0.224770642202 |  0.394551414843 |              {'C': 10.0, 'gamma': 10000.0}               |        24       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|       0.0       |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        30       |
|  0.501039755352 |  0.291129368712 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        2        |
|  0.42219981853  |  0.170830506115 |                {'C': 100.0, 'gamma': 1.0}                |        10       |
|  0.40136033658  |  0.106439992094 |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.369619921363 |  0.164020492239 |               {'C': 100.0, 'gamma': 100.0}               |        17       |
|  0.280733944954 |  0.393869783404 |              {'C': 100.0, 'gamma': 1000.0}               |        23       |
|  0.217737003058 |  0.317340143559 |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|       0.0       |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
|  0.341437308869 |  0.369757715249 |               {'C': 1000.0, 'gamma': 0.01}               |        20       |
|  0.454190992494 |  0.094036958716 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.464816121697 | 0.0743709527004 |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.40144384166  |  0.100879241431 |               {'C': 1000.0, 'gamma': 10.0}               |        11       |
|  0.376605504587 |  0.185559101645 |              {'C': 1000.0, 'gamma': 100.0}               |        15       |
|  0.433639143731 |  0.472408870508 |              {'C': 1000.0, 'gamma': 1000.0}              |        9        |
|       0.2       |  0.339334360711 |             {'C': 1000.0, 'gamma': 10000.0}              |        26       |
|  0.548165137615 |  0.327551845151 |              {'C': 10000.0, 'gamma': 0.001}              |        1        |
|  0.37058256728  |  0.101829056838 |              {'C': 10000.0, 'gamma': 0.01}               |        16       |
|  0.442119977223 |  0.069057464914 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        8        |
|  0.445804995697 |  0.089316242443 |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.379676146654 | 0.0799604698733 |              {'C': 10000.0, 'gamma': 10.0}               |        14       |
|  0.329002256663 |  0.117758537381 |              {'C': 10000.0, 'gamma': 100.0}              |        21       |
|  0.199388379205 |  0.304568733093 |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.283180428135 |  0.32596203894  |             {'C': 10000.0, 'gamma': 10000.0}             |        22       |
+-----------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.86      0.70        36
          1       0.17      0.04      0.07        23

avg / total       0.42      0.54      0.45        59

# Tuning hyper-parameters for recall

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+------------------+-----------------+----------------------------------------------------------+-----------------+
| test_mean_score  |  test_std_score |                          params                          | test_rank_score |
+------------------+-----------------+----------------------------------------------------------+-----------------+
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|       0.0        |       0.0       |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|       0.0        |       0.0       |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|       0.0        |       0.0       |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|       0.0        |       0.0       |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|       0.0        |       0.0       | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|       0.0        |       0.0       |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|       0.0        |       0.0       |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|       0.0        |       0.0       |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|       0.0        |       0.0       |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|       0.0        |       0.0       |                 {'C': 1.0, 'gamma': 1.0}                 |        30       |
| 0.0650065530799  | 0.0550008042322 |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
| 0.00930537352556 |  0.018617038958 |                {'C': 1.0, 'gamma': 100.0}                |        26       |
|       0.0        |       0.0       |               {'C': 1.0, 'gamma': 1000.0}                |        30       |
| 0.00471821756225 | 0.0142272783697 |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|       0.0        |       0.0       |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|       0.0        |       0.0       |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|       0.0        |       0.0       |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        30       |
| 0.0927916120577  |  0.045538886617 |                {'C': 10.0, 'gamma': 1.0}                 |        15       |
|  0.358584534731  | 0.0662841717657 |                {'C': 10.0, 'gamma': 10.0}                |        5        |
|  0.111664482307  | 0.0781629744011 |               {'C': 10.0, 'gamma': 100.0}                |        14       |
| 0.0187418086501  | 0.0313151214533 |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
| 0.0045871559633  | 0.0136917891238 |              {'C': 10.0, 'gamma': 10000.0}               |        29       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|       0.0        |       0.0       |               {'C': 100.0, 'gamma': 0.01}                |        30       |
| 0.0698558322412  | 0.0373262295892 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.250720838794  | 0.0663713046592 |                {'C': 100.0, 'gamma': 1.0}                |        8        |
|  0.33001310616   | 0.0455894372819 |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.130275229358  | 0.0549501019344 |               {'C': 100.0, 'gamma': 100.0}               |        13       |
| 0.0277850589777  | 0.0226135558486 |              {'C': 100.0, 'gamma': 1000.0}               |        21       |
| 0.0137614678899  | 0.0292088590623 |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|       0.0        |       0.0       |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
| 0.0557011795544  | 0.0499643095557 |               {'C': 1000.0, 'gamma': 0.01}               |        19       |
|  0.241546526868  | 0.0789217607642 |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.390170380079  | 0.0702710202039 |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.385976408912  | 0.0898460045168 |               {'C': 1000.0, 'gamma': 10.0}               |        3        |
|  0.143905635649  | 0.0595632137034 |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
| 0.0322411533421  | 0.0458724787571 |              {'C': 1000.0, 'gamma': 1000.0}              |        20       |
| 0.0186107470511  | 0.0228036910659 |             {'C': 1000.0, 'gamma': 10000.0}              |        24       |
| 0.0790301441678  | 0.0551673807684 |              {'C': 10000.0, 'gamma': 0.001}              |        16       |
|  0.232110091743  |  0.106177133279 |              {'C': 10000.0, 'gamma': 0.01}               |        10       |
|  0.339711664482  | 0.0905388613693 |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        6        |
|  0.377064220183  | 0.0829947087342 |               {'C': 10000.0, 'gamma': 1.0}               |        4        |
|       0.4        |  0.117956074505 |              {'C': 10000.0, 'gamma': 10.0}               |        1        |
|  0.172608125819  | 0.0612972526582 |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
| 0.0277850589777  | 0.0470294535064 |             {'C': 10000.0, 'gamma': 1000.0}              |        21       |
| 0.00917431192661 | 0.0182440724389 |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+------------------+-----------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.78      0.71        36
          1       0.50      0.35      0.41        23

avg / total       0.59      0.61      0.59        59


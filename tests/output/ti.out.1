Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.485932108285 | 0.00626096416842 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.54      1.00      0.70        81
          1       0.00      0.00      0.00        70

avg / total       0.29      0.54      0.37       151


Accuracy on test set (using best parameters): 0.54

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.525163641554 | 0.0671344785381 |  {'n_neighbors': 3} |        3        |
|  0.542996322445 | 0.0599086775422 |  {'n_neighbors': 5} |        1        |
|  0.528851972377 | 0.0543286561293 | {'n_neighbors': 11} |        2        |
|  0.517255602415 | 0.0643664175155 | {'n_neighbors': 21} |        4        |
|  0.47533912275  | 0.0591978005762 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.71      0.68        96
          1       0.42      0.36      0.39        55

avg / total       0.57      0.58      0.58       151


Accuracy on test set (using best parameters): 0.58

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.502565038038 | 0.0448033948501 | {'n_estimators': 2}  |        7        |
|  0.54873270251  | 0.0866406910697 | {'n_estimators': 3}  |        1        |
|  0.531541471445 | 0.0579893697803 | {'n_estimators': 5}  |        4        |
|  0.540246404962 | 0.0532847088474 | {'n_estimators': 10} |        3        |
|  0.546011812362 | 0.0432672276515 | {'n_estimators': 20} |        2        |
|  0.51357517714  | 0.0452312006545 | {'n_estimators': 40} |        6        |
|  0.520905722949 |  0.028387562359 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.55      0.74      0.63        84
          1       0.44      0.25      0.32        67

avg / total       0.50      0.52      0.49       151


Accuracy on test set (using best parameters): 0.52

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.453239663505 | 0.00489458232085 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        10       |
|  0.453239663505 | 0.00489458232085 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        10       |
|  0.453239663505 | 0.00489458232085 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        10       |
|  0.453239663505 | 0.00489458232085 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        10       |
|  0.453239663505 | 0.00489458232085 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        10       |
|  0.453239663505 | 0.00489458232085 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        10       |
|  0.453239663505 | 0.00489458232085 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        10       |
|  0.458051910987 | 0.0142386864533  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.45422241663  | 0.00513283328086 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        9        |
|  0.457770193356 |  0.010512144717  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        5        |
|  0.453169744617 | 0.00475927247307 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        18       |
|  0.456795537259 | 0.0137266712937  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        6        |
|  0.463913147365 | 0.0446632831132  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        2        |
|  0.460058442485 | 0.0311857722508  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.453239663505 | 0.00489458232085 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        10       |
|  0.466536113671 | 0.0392524081194  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        1        |
|  0.452190321092 | 0.0063827464445  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        19       |
|  0.456677029556 | 0.0153343458712  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        7        |
|  0.454823788015 | 0.0211781181021  |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        8        |
|  0.452190321092 | 0.0063827464445  |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        19       |
|  0.452190321092 | 0.0063827464445  |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        19       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.76        93
          1       0.00      0.00      0.00        58

avg / total       0.38      0.62      0.47       151


Accuracy on test set (using best parameters): 0.62

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.453239663505 | 0.00489458232085 |        {'C': 0.001}        |        5        |
|  0.453239663505 | 0.00489458232085 |        {'C': 0.01}         |        5        |
|  0.453239663505 | 0.00489458232085 | {'C': 0.10000000000000001} |        5        |
|  0.453239663505 | 0.00489458232085 |         {'C': 1.0}         |        5        |
|  0.458656800018 | 0.0200601224515  |        {'C': 10.0}         |        4        |
|  0.498694183254 |  0.05752946269   |        {'C': 100.0}        |        3        |
|  0.537177862888 |  0.059947881241  |       {'C': 1000.0}        |        2        |
|  0.565242433715 | 0.0704173061625  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.70      0.67        93
          1       0.44      0.38      0.41        58

avg / total       0.57      0.58      0.57       151


Accuracy on test set (using best parameters): 0.58

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.485932108285 | 0.00626096416842 |               {'C': 0.001, 'gamma': 0.001}               |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 0.001, 'gamma': 0.01}                |        28       |
|  0.485932108285 | 0.00626096416842 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        28       |
|  0.485932108285 | 0.00626096416842 |                {'C': 0.001, 'gamma': 1.0}                |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 0.001, 'gamma': 10.0}                |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 0.001, 'gamma': 100.0}               |        28       |
|  0.485932108285 | 0.00626096416842 |              {'C': 0.001, 'gamma': 1000.0}               |        28       |
|  0.485932108285 | 0.00626096416842 |              {'C': 0.001, 'gamma': 10000.0}              |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 0.01, 'gamma': 0.001}                |        28       |
|  0.485932108285 | 0.00626096416842 |                {'C': 0.01, 'gamma': 0.01}                |        28       |
|  0.485932108285 | 0.00626096416842 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        28       |
|  0.485932108285 | 0.00626096416842 |                {'C': 0.01, 'gamma': 1.0}                 |        28       |
|  0.485932108285 | 0.00626096416842 |                {'C': 0.01, 'gamma': 10.0}                |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 0.01, 'gamma': 100.0}                |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 0.01, 'gamma': 1000.0}               |        28       |
|  0.485932108285 | 0.00626096416842 |              {'C': 0.01, 'gamma': 10000.0}               |        28       |
|  0.485932108285 | 0.00626096416842 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        28       |
|  0.485932108285 | 0.00626096416842 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        28       |
|  0.485932108285 | 0.00626096416842 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        28       |
|  0.485932108285 | 0.00626096416842 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        28       |
|  0.485932108285 | 0.00626096416842 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        28       |
|  0.485932108285 | 0.00626096416842 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        28       |
|  0.485932108285 | 0.00626096416842 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        28       |
|  0.485932108285 | 0.00626096416842 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        28       |
|  0.485932108285 | 0.00626096416842 |                {'C': 1.0, 'gamma': 0.001}                |        28       |
|  0.485932108285 | 0.00626096416842 |                {'C': 1.0, 'gamma': 0.01}                 |        28       |
|  0.485932108285 | 0.00626096416842 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        28       |
|  0.485932108285 | 0.00626096416842 |                 {'C': 1.0, 'gamma': 1.0}                 |        28       |
|  0.483780647199 | 0.00855873450214 |                {'C': 1.0, 'gamma': 10.0}                 |        64       |
|  0.495738334497 | 0.0182453831342  |                {'C': 1.0, 'gamma': 100.0}                |        20       |
|  0.485932108285 | 0.00626096416842 |               {'C': 1.0, 'gamma': 1000.0}                |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 10.0, 'gamma': 0.001}                |        28       |
|  0.485932108285 | 0.00626096416842 |                {'C': 10.0, 'gamma': 0.01}                |        28       |
|  0.485932108285 | 0.00626096416842 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        28       |
|  0.489268989286 |  0.029308411701  |                {'C': 10.0, 'gamma': 1.0}                 |        22       |
|  0.588060296701 | 0.0444179004691  |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.547370906447 | 0.0504740067722  |               {'C': 10.0, 'gamma': 100.0}                |        10       |
|  0.504206275154 | 0.0258652410061  |               {'C': 10.0, 'gamma': 1000.0}               |        15       |
|  0.488645636103 | 0.0166758497543  |              {'C': 10.0, 'gamma': 10000.0}               |        23       |
|  0.485932108285 | 0.00626096416842 |               {'C': 100.0, 'gamma': 0.001}               |        28       |
|  0.485932108285 | 0.00626096416842 |               {'C': 100.0, 'gamma': 0.01}                |        28       |
|  0.487180974069 | 0.0311986237873  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        24       |
|  0.566661258497 | 0.0427208038854  |                {'C': 100.0, 'gamma': 1.0}                |        7        |
|  0.571404613679 | 0.0629824537471  |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.53344772209  | 0.0494206871557  |               {'C': 100.0, 'gamma': 100.0}               |        14       |
|  0.502818377732 | 0.0297633664041  |              {'C': 100.0, 'gamma': 1000.0}               |        16       |
|  0.486515591698 | 0.0150906005825  |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|  0.485932108285 | 0.00626096416842 |              {'C': 1000.0, 'gamma': 0.001}               |        28       |
|  0.495891308591 | 0.0443006871512  |               {'C': 1000.0, 'gamma': 0.01}               |        19       |
|  0.561693590194 | 0.0654818314488  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.575882630077 | 0.0687988732333  |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.588223383981 | 0.0554818942826  |               {'C': 1000.0, 'gamma': 10.0}               |        2        |
|  0.534499268812 | 0.0556155056551  |              {'C': 1000.0, 'gamma': 100.0}               |        12       |
|  0.498594474459 | 0.0242713546147  |              {'C': 1000.0, 'gamma': 1000.0}              |        17       |
|  0.486515591698 | 0.0150906005825  |             {'C': 1000.0, 'gamma': 10000.0}              |        25       |
|  0.489991368916 | 0.0425070432917  |              {'C': 10000.0, 'gamma': 0.001}              |        21       |
|  0.546377398901 |  0.069756928566  |              {'C': 10000.0, 'gamma': 0.01}               |        11       |
|  0.599798856414 | 0.0605630433872  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.581777306254 | 0.0814934917277  |               {'C': 10000.0, 'gamma': 1.0}               |        4        |
|  0.565925413748 | 0.0621812287262  |              {'C': 10000.0, 'gamma': 10.0}               |        8        |
|  0.533582979405 | 0.0466152169947  |              {'C': 10000.0, 'gamma': 100.0}              |        13       |
|  0.498594474459 | 0.0242713546147  |             {'C': 10000.0, 'gamma': 1000.0}              |        17       |
|  0.486515591698 | 0.0150906005825  |             {'C': 10000.0, 'gamma': 10000.0}             |        25       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.51      0.65      0.57        81
          1       0.40      0.27      0.32        70

avg / total       0.46      0.48      0.46       151


Accuracy on test set (using best parameters): 0.48


Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.474958906346 | 0.00519544539189 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.56      1.00      0.72        85
          1       0.00      0.00      0.00        66

avg / total       0.32      0.56      0.41       151


Accuracy on test set (using best parameters): 0.56

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.529814612081 |  0.052175053729 |  {'n_neighbors': 3} |        4        |
|  0.529664263413 | 0.0541297204398 |  {'n_neighbors': 5} |        5        |
|  0.546860994136 |  0.108898838137 | {'n_neighbors': 11} |        3        |
|  0.547414142487 | 0.0499183506688 | {'n_neighbors': 21} |        2        |
|  0.548268924199 | 0.0602491805629 | {'n_neighbors': 31} |        1        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 31}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.73      0.66        98
          1       0.19      0.11      0.14        53

avg / total       0.46      0.52      0.48       151


Accuracy on test set (using best parameters): 0.52

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.545133546645 |  0.07701712519  | {'n_estimators': 2}  |        1        |
|  0.48817845586  |  0.047155735869 | {'n_estimators': 3}  |        6        |
|  0.534184419583 | 0.0453752904259 | {'n_estimators': 5}  |        3        |
|  0.539893525157 | 0.0362642027926 | {'n_estimators': 10} |        2        |
|  0.487791266711 |  0.074656847415 | {'n_estimators': 20} |        7        |
|  0.53177095627  | 0.0518399441987 | {'n_estimators': 40} |        4        |
|  0.513843215943 | 0.0922234264322 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 2}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      0.83      0.72        90
          1       0.55      0.30      0.38        61

avg / total       0.60      0.62      0.58       151


Accuracy on test set (using best parameters): 0.62

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.477690644707 | 0.00384159090605 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        4        |
|  0.477690644707 | 0.00384159090605 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        4        |
|  0.477690644707 | 0.00384159090605 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        4        |
|  0.477690644707 | 0.00384159090605 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        4        |
|  0.477690644707 | 0.00384159090605 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        4        |
|  0.477690644707 | 0.00384159090605 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        4        |
|  0.477690644707 | 0.00384159090605 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        4        |
|  0.477690644707 | 0.00384159090605 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.477690644707 | 0.00384159090605 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        4        |
|  0.485480686405 | 0.0265533613874  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        2        |
|  0.477690644707 | 0.00384159090605 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.477690644707 | 0.00384159090605 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        4        |
|  0.477690644707 | 0.00384159090605 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.47663225165  | 0.00506916069074 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.493005567985 | 0.0461519099847  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        1        |
|  0.477690644707 | 0.00384159090605 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        4        |
|  0.482529390738 | 0.0178100157912  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        3        |
|  0.477690644707 | 0.00384159090605 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.477690644707 | 0.00384159090605 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.477690644707 | 0.00384159090605 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.477690644707 | 0.00384159090605 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        4        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.56      1.00      0.71        84
          1       0.00      0.00      0.00        67

avg / total       0.31      0.56      0.40       151


Accuracy on test set (using best parameters): 0.56

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.496982545459 | 0.00833160714513 |        {'C': 0.001}        |        5        |
|  0.496982545459 | 0.00833160714513 |        {'C': 0.01}         |        5        |
|  0.496982545459 | 0.00833160714513 | {'C': 0.10000000000000001} |        5        |
|  0.496982545459 | 0.00833160714513 |         {'C': 1.0}         |        5        |
|  0.513349979071 | 0.0313133504113  |        {'C': 10.0}         |        4        |
|  0.545704105102 | 0.0459463804728  |        {'C': 100.0}        |        3        |
|  0.564539332955 | 0.0486028177301  |       {'C': 1000.0}        |        2        |
|  0.592464632558 | 0.0703015829056  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.48      0.61      0.54        77
          1       0.43      0.31      0.36        74

avg / total       0.46      0.46      0.45       151


Accuracy on test set (using best parameters): 0.46

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.442504849168 | 0.00756469597889 |               {'C': 0.001, 'gamma': 0.001}               |        28       |
|  0.442504849168 | 0.00756469597889 |               {'C': 0.001, 'gamma': 0.01}                |        28       |
|  0.442504849168 | 0.00756469597889 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        28       |
|  0.442504849168 | 0.00756469597889 |                {'C': 0.001, 'gamma': 1.0}                |        28       |
|  0.442504849168 | 0.00756469597889 |               {'C': 0.001, 'gamma': 10.0}                |        28       |
|  0.442504849168 | 0.00756469597889 |               {'C': 0.001, 'gamma': 100.0}               |        28       |
|  0.442504849168 | 0.00756469597889 |              {'C': 0.001, 'gamma': 1000.0}               |        28       |
|  0.442504849168 | 0.00756469597889 |              {'C': 0.001, 'gamma': 10000.0}              |        28       |
|  0.442504849168 | 0.00756469597889 |               {'C': 0.01, 'gamma': 0.001}                |        28       |
|  0.442504849168 | 0.00756469597889 |                {'C': 0.01, 'gamma': 0.01}                |        28       |
|  0.442504849168 | 0.00756469597889 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        28       |
|  0.442504849168 | 0.00756469597889 |                {'C': 0.01, 'gamma': 1.0}                 |        28       |
|  0.442504849168 | 0.00756469597889 |                {'C': 0.01, 'gamma': 10.0}                |        28       |
|  0.442504849168 | 0.00756469597889 |               {'C': 0.01, 'gamma': 100.0}                |        28       |
|  0.442504849168 | 0.00756469597889 |               {'C': 0.01, 'gamma': 1000.0}               |        28       |
|  0.442504849168 | 0.00756469597889 |              {'C': 0.01, 'gamma': 10000.0}               |        28       |
|  0.442504849168 | 0.00756469597889 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        28       |
|  0.442504849168 | 0.00756469597889 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        28       |
|  0.442504849168 | 0.00756469597889 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        28       |
|  0.442504849168 | 0.00756469597889 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        28       |
|  0.442504849168 | 0.00756469597889 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        28       |
|  0.442504849168 | 0.00756469597889 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        28       |
|  0.442504849168 | 0.00756469597889 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        28       |
|  0.442504849168 | 0.00756469597889 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        28       |
|  0.442504849168 | 0.00756469597889 |                {'C': 1.0, 'gamma': 0.001}                |        28       |
|  0.442504849168 | 0.00756469597889 |                {'C': 1.0, 'gamma': 0.01}                 |        28       |
|  0.442504849168 | 0.00756469597889 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        28       |
|  0.441461576012 | 0.00917661757686 |                 {'C': 1.0, 'gamma': 1.0}                 |        61       |
|  0.467402814626 | 0.0326276573091  |                {'C': 1.0, 'gamma': 10.0}                 |        18       |
|  0.49936537093  | 0.0459169032078  |                {'C': 1.0, 'gamma': 100.0}                |        9        |
|  0.452858335347 | 0.0328574078803  |               {'C': 1.0, 'gamma': 1000.0}                |        24       |
|  0.447517557693 | 0.0173455472202  |               {'C': 1.0, 'gamma': 10000.0}               |        26       |
|  0.442504849168 | 0.00756469597889 |               {'C': 10.0, 'gamma': 0.001}                |        28       |
|  0.442504849168 | 0.00756469597889 |                {'C': 10.0, 'gamma': 0.01}                |        28       |
|  0.442504849168 | 0.00756469597889 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        28       |
|  0.473077900297 | 0.0279229783587  |                {'C': 10.0, 'gamma': 1.0}                 |        16       |
|  0.527361189261 | 0.0651584339753  |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.489238922564 | 0.0561221388676  |               {'C': 10.0, 'gamma': 100.0}                |        12       |
|  0.46656554952  | 0.0352903757772  |               {'C': 10.0, 'gamma': 1000.0}               |        19       |
|  0.443969780967 | 0.0119983613432  |              {'C': 10.0, 'gamma': 10000.0}               |        27       |
|  0.442504849168 | 0.00756469597889 |               {'C': 100.0, 'gamma': 0.001}               |        28       |
|  0.442504849168 | 0.00756469597889 |               {'C': 100.0, 'gamma': 0.01}                |        28       |
|  0.472240046801 | 0.0365908112697  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.50880784513  | 0.0715458868431  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.50398557528  | 0.0596118942647  |               {'C': 100.0, 'gamma': 10.0}                |        6        |
|  0.490642664285 | 0.0509000116622  |               {'C': 100.0, 'gamma': 100.0}               |        11       |
|  0.452710729617 | 0.0302136985674  |              {'C': 100.0, 'gamma': 1000.0}               |        25       |
|  0.439368960444 | 0.00994453007211 |              {'C': 100.0, 'gamma': 10000.0}              |        62       |
|  0.442504849168 | 0.00756469597889 |              {'C': 1000.0, 'gamma': 0.001}               |        28       |
|  0.461860714779 |  0.023444084304  |               {'C': 1000.0, 'gamma': 0.01}               |        20       |
|  0.476698699447 |  0.060735276048  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        15       |
|  0.504560435305 | 0.0630255859694  |               {'C': 1000.0, 'gamma': 1.0}                |        5        |
|  0.501973366421 | 0.0585204687662  |               {'C': 1000.0, 'gamma': 10.0}               |        7        |
|  0.499592345133 | 0.0603650786547  |              {'C': 1000.0, 'gamma': 100.0}               |        8        |
|  0.455069677366 | 0.0300243112224  |              {'C': 1000.0, 'gamma': 1000.0}              |        22       |
|  0.439368960444 | 0.00994453007211 |             {'C': 1000.0, 'gamma': 10000.0}              |        62       |
|  0.460896993118 |  0.029946703448  |              {'C': 10000.0, 'gamma': 0.001}              |        21       |
|  0.48389391951  | 0.0646920343952  |              {'C': 10000.0, 'gamma': 0.01}               |        13       |
|  0.529784669507 | 0.0746217775714  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.480463938591 | 0.0843436014271  |               {'C': 10000.0, 'gamma': 1.0}               |        14       |
|  0.495047180581 |  0.051721158539  |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.50516056725  | 0.0443227563129  |              {'C': 10000.0, 'gamma': 100.0}              |        4        |
|  0.455069677366 | 0.0300243112224  |             {'C': 10000.0, 'gamma': 1000.0}              |        22       |
|  0.439368960444 | 0.00994453007211 |             {'C': 10000.0, 'gamma': 10000.0}             |        62       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.69      0.81      0.75        97
          1       0.51      0.35      0.42        54

avg / total       0.63      0.65      0.63       151


Accuracy on test set (using best parameters): 0.65


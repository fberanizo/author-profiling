Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.453239663505 | 0.00489458232085 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.76        93
          1       0.00      0.00      0.00        58

avg / total       0.38      0.62      0.47       151


Accuracy on test set (using best parameters): 0.62

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.554351579953 | 0.0723279821161 |  {'n_neighbors': 3} |        2        |
|  0.577527355851 | 0.0845987515366 |  {'n_neighbors': 5} |        1        |
|  0.545791297006 | 0.0664460959048 | {'n_neighbors': 11} |        3        |
|  0.536975711552 |  0.063837018073 | {'n_neighbors': 21} |        4        |
|  0.514379558357 | 0.0773094368809 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.77      0.70        92
          1       0.49      0.34      0.40        59

avg / total       0.58      0.60      0.58       151


Accuracy on test set (using best parameters): 0.60

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.522168321575 | 0.0573158877959 | {'n_estimators': 2}  |        7        |
|  0.569895612766 | 0.0762612213896 | {'n_estimators': 3}  |        2        |
|  0.575601678966 | 0.0954504044328 | {'n_estimators': 5}  |        1        |
|  0.555056021041 | 0.0409558373825 | {'n_estimators': 10} |        4        |
|  0.530257862099 | 0.0546839542523 | {'n_estimators': 20} |        6        |
|  0.555432358537 | 0.0461115724566 | {'n_estimators': 40} |        3        |
|  0.550789608092 | 0.0421492448791 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.53      0.65      0.59        86
          1       0.35      0.25      0.29        65

avg / total       0.45      0.48      0.46       151


Accuracy on test set (using best parameters): 0.48

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.472237818877 | 0.00768006176082 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        3        |
|  0.472237818877 | 0.00768006176082 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        3        |
|  0.472237818877 | 0.00768006176082 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        3        |
|  0.472237818877 | 0.00768006176082 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        3        |
|  0.472237818877 | 0.00768006176082 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        3        |
|  0.472237818877 | 0.00768006176082 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        3        |
|  0.472237818877 | 0.00768006176082 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        3        |
|  0.472237818877 | 0.00768006176082 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.472237818877 | 0.00768006176082 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        3        |
|  0.472237818877 | 0.00768006176082 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.472237818877 | 0.00768006176082 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.471185146863 | 0.00965487779022 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        20       |
|  0.472237818877 | 0.00768006176082 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.470103233961 |  0.012199769916  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.472237818877 | 0.00768006176082 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        3        |
|  0.472237818877 | 0.00768006176082 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        3        |
|  0.47860324511  | 0.0164245484639  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.472237818877 | 0.00768006176082 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        3        |
|  0.473185833527 | 0.00876184955937 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.472237818877 | 0.00768006176082 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.472237818877 | 0.00768006176082 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      1.00      0.73        86
          1       0.00      0.00      0.00        65

avg / total       0.32      0.57      0.41       151


Accuracy on test set (using best parameters): 0.57

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.472237818877 | 0.00768006176082 |        {'C': 0.001}        |        4        |
|  0.472237818877 | 0.00768006176082 |        {'C': 0.01}         |        4        |
|  0.472237818877 | 0.00768006176082 | {'C': 0.10000000000000001} |        4        |
|  0.472237818877 | 0.00768006176082 |         {'C': 1.0}         |        4        |
|  0.471326947014 |  0.014260061626  |        {'C': 10.0}         |        8        |
|  0.524825737491 | 0.0497066273285  |        {'C': 100.0}        |        3        |
|  0.587200680796 | 0.0576336567027  |       {'C': 1000.0}        |        1        |
|  0.542595877088 | 0.0756682742582  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.70      0.62        86
          1       0.42      0.29      0.35        65

avg / total       0.50      0.52      0.50       151


Accuracy on test set (using best parameters): 0.52

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|  0.464062297997 | 0.00516368736714 |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|  0.464062297997 | 0.00516368736714 |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|  0.464062297997 | 0.00516368736714 |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|  0.464062297997 | 0.00516368736714 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|  0.464062297997 | 0.00516368736714 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|  0.464062297997 | 0.00516368736714 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|  0.464062297997 | 0.00516368736714 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|  0.464062297997 | 0.00516368736714 |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|  0.464062297997 | 0.00516368736714 |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|  0.464062297997 | 0.00516368736714 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.473703023731 | 0.0198542428947  |                 {'C': 1.0, 'gamma': 1.0}                 |        17       |
|  0.490526708312 | 0.0340505506171  |                {'C': 1.0, 'gamma': 10.0}                 |        16       |
|  0.495371971227 | 0.0284369362663  |                {'C': 1.0, 'gamma': 100.0}                |        14       |
|  0.464062297997 | 0.00516368736714 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.459793128165 | 0.0112892631383  |               {'C': 1.0, 'gamma': 10000.0}               |        63       |
|  0.464062297997 | 0.00516368736714 |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|  0.464062297997 | 0.00516368736714 |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|  0.463006959343 | 0.00560618564699 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        61       |
|  0.471973531921 | 0.0423717542053  |                {'C': 10.0, 'gamma': 1.0}                 |        18       |
|  0.607125844364 | 0.0879522685332  |                {'C': 10.0, 'gamma': 10.0}                |        1        |
|  0.53158621324  | 0.0367141711216  |               {'C': 10.0, 'gamma': 100.0}                |        9        |
|  0.466129642572 | 0.0288954825919  |               {'C': 10.0, 'gamma': 1000.0}               |        20       |
|  0.457675769052 | 0.00843221179851 |              {'C': 10.0, 'gamma': 10000.0}               |        64       |
|  0.464062297997 | 0.00516368736714 |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|  0.463006959343 | 0.00560618564699 |               {'C': 100.0, 'gamma': 0.01}                |        61       |
|  0.465678499659 | 0.0343982231028  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        24       |
|  0.540807056833 | 0.0861523490006  |                {'C': 100.0, 'gamma': 1.0}                |        7        |
|  0.570463229001 | 0.0877745471154  |               {'C': 100.0, 'gamma': 10.0}                |        4        |
|  0.515262781007 | 0.0255803877048  |               {'C': 100.0, 'gamma': 100.0}               |        12       |
|  0.46422721436  | 0.0258584035353  |              {'C': 100.0, 'gamma': 1000.0}               |        26       |
|  0.465843896343 | 0.0329379372318  |              {'C': 100.0, 'gamma': 10000.0}              |        21       |
|  0.464062297997 | 0.00516368736714 |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
|  0.465621448991 | 0.0352720629075  |               {'C': 1000.0, 'gamma': 0.01}               |        25       |
|  0.523677198579 | 0.0585766899556  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        10       |
|  0.575383335562 | 0.0766712481032  |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.561488148331 | 0.0635887156792  |               {'C': 1000.0, 'gamma': 10.0}               |        6        |
|  0.510060729579 | 0.0288430905416  |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.464217421485 | 0.0274407281165  |              {'C': 1000.0, 'gamma': 1000.0}              |        27       |
|  0.465843896343 | 0.0329379372318  |             {'C': 1000.0, 'gamma': 10000.0}              |        21       |
|  0.468900210629 | 0.0435838835781  |              {'C': 10000.0, 'gamma': 0.001}              |        19       |
|  0.521993900258 | 0.0445267970543  |              {'C': 10000.0, 'gamma': 0.01}               |        11       |
|  0.584552874321 |   0.0618939603   |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.56370968229  | 0.0507609670306  |               {'C': 10000.0, 'gamma': 1.0}               |        5        |
|  0.540349652209 | 0.0725807375015  |              {'C': 10000.0, 'gamma': 10.0}               |        8        |
|  0.494207144372 | 0.0444276672915  |              {'C': 10000.0, 'gamma': 100.0}              |        15       |
|  0.464217421485 | 0.0274407281165  |             {'C': 10000.0, 'gamma': 1000.0}              |        27       |
|  0.465843896343 | 0.0329379372318  |             {'C': 10000.0, 'gamma': 10000.0}             |        21       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.59      0.80      0.68        89
          1       0.42      0.21      0.28        62

avg / total       0.52      0.56      0.52       151


Accuracy on test set (using best parameters): 0.56


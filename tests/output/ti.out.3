Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.461348275801 | 0.00463446896902 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        90
          1       0.00      0.00      0.00        61

avg / total       0.36      0.60      0.45       151


Accuracy on test set (using best parameters): 0.60

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.551071684522 | 0.0782847395883 |  {'n_neighbors': 3} |        1        |
|  0.543679927802 | 0.0671730186432 |  {'n_neighbors': 5} |        3        |
|  0.545257512328 | 0.0653415467523 | {'n_neighbors': 11} |        2        |
|  0.497265188768 |  0.039698108626 | {'n_neighbors': 21} |        4        |
|  0.47671358577  | 0.0687404426724 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.72      0.66        92
          1       0.41      0.31      0.35        59

avg / total       0.54      0.56      0.54       151


Accuracy on test set (using best parameters): 0.56

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.503737257367 | 0.0552524930339 | {'n_estimators': 2}  |        7        |
|  0.612278686403 | 0.0853727532881 | {'n_estimators': 3}  |        1        |
|  0.523490396672 | 0.0457420987963 | {'n_estimators': 5}  |        5        |
|  0.52567886638  | 0.0492277666427 | {'n_estimators': 10} |        4        |
|  0.537266040941 | 0.0606933860047 | {'n_estimators': 20} |        2        |
|  0.526355503257 | 0.0293544918399 | {'n_estimators': 40} |        3        |
|  0.515061101913 | 0.0309448539922 | {'n_estimators': 60} |        6        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.53      0.70      0.60        77
          1       0.53      0.35      0.42        74

avg / total       0.53      0.53      0.51       151


Accuracy on test set (using best parameters): 0.53

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.447857106857 | 0.00485597425035 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        6        |
|  0.447857106857 | 0.00485597425035 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        6        |
|  0.447857106857 | 0.00485597425035 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        6        |
|  0.447857106857 | 0.00485597425035 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        6        |
|  0.447857106857 | 0.00485597425035 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        6        |
|  0.447857106857 | 0.00485597425035 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        6        |
|  0.446807764445 | 0.00539135530721 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        17       |
|  0.447857106857 | 0.00485597425035 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        6        |
|  0.447857106857 | 0.00485597425035 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        6        |
|  0.444691830157 | 0.0110494050521  |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        20       |
|  0.457914282621 |  0.025051156712  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        2        |
|  0.448086483249 | 0.0187063466049  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        5        |
|  0.448541612619 | 0.0214840878436  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.449491345892 | 0.0178250870918  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.443811157299 | 0.0124362009909  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        21       |
|  0.459884615772 | 0.0372386978783  |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        1        |
|  0.446807764445 | 0.00539135530721 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        17       |
|  0.447857106857 | 0.00485597425035 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        6        |
|  0.447857106857 | 0.00485597425035 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        6        |
|  0.447857106857 | 0.00485597425035 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        6        |
|  0.446201477718 | 0.00642942644415 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        19       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      1.00      0.77        95
          1       0.00      0.00      0.00        56

avg / total       0.40      0.63      0.49       151


Accuracy on test set (using best parameters): 0.63

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.450542728159 | 0.00373772714054 |        {'C': 0.001}        |        4        |
|  0.450542728159 | 0.00373772714054 |        {'C': 0.01}         |        4        |
|  0.450542728159 | 0.00373772714054 | {'C': 0.10000000000000001} |        4        |
|  0.450542728159 | 0.00373772714054 |         {'C': 1.0}         |        4        |
|  0.447397168645 | 0.0071458149877  |        {'C': 10.0}         |        8        |
|  0.511009798972 | 0.0530462210459  |        {'C': 100.0}        |        3        |
|  0.591600424101 | 0.0558961556116  |       {'C': 1000.0}        |        2        |
|  0.605595449447 | 0.0643497426395  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.66      0.65        94
          1       0.42      0.40      0.41        57

avg / total       0.56      0.56      0.56       151


Accuracy on test set (using best parameters): 0.56

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.450542728159 | 0.00373772714054 |               {'C': 0.001, 'gamma': 0.001}               |        29       |
|  0.450542728159 | 0.00373772714054 |               {'C': 0.001, 'gamma': 0.01}                |        29       |
|  0.450542728159 | 0.00373772714054 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        29       |
|  0.450542728159 | 0.00373772714054 |                {'C': 0.001, 'gamma': 1.0}                |        29       |
|  0.450542728159 | 0.00373772714054 |               {'C': 0.001, 'gamma': 10.0}                |        29       |
|  0.450542728159 | 0.00373772714054 |               {'C': 0.001, 'gamma': 100.0}               |        29       |
|  0.450542728159 | 0.00373772714054 |              {'C': 0.001, 'gamma': 1000.0}               |        29       |
|  0.450542728159 | 0.00373772714054 |              {'C': 0.001, 'gamma': 10000.0}              |        29       |
|  0.450542728159 | 0.00373772714054 |               {'C': 0.01, 'gamma': 0.001}                |        29       |
|  0.450542728159 | 0.00373772714054 |                {'C': 0.01, 'gamma': 0.01}                |        29       |
|  0.450542728159 | 0.00373772714054 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        29       |
|  0.450542728159 | 0.00373772714054 |                {'C': 0.01, 'gamma': 1.0}                 |        29       |
|  0.450542728159 | 0.00373772714054 |                {'C': 0.01, 'gamma': 10.0}                |        29       |
|  0.450542728159 | 0.00373772714054 |               {'C': 0.01, 'gamma': 100.0}                |        29       |
|  0.450542728159 | 0.00373772714054 |               {'C': 0.01, 'gamma': 1000.0}               |        29       |
|  0.450542728159 | 0.00373772714054 |              {'C': 0.01, 'gamma': 10000.0}               |        29       |
|  0.450542728159 | 0.00373772714054 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        29       |
|  0.450542728159 | 0.00373772714054 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        29       |
|  0.450542728159 | 0.00373772714054 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        29       |
|  0.450542728159 | 0.00373772714054 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        29       |
|  0.450542728159 | 0.00373772714054 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        29       |
|  0.450542728159 | 0.00373772714054 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        29       |
|  0.450542728159 | 0.00373772714054 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        29       |
|  0.450542728159 | 0.00373772714054 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        29       |
|  0.450542728159 | 0.00373772714054 |                {'C': 1.0, 'gamma': 0.001}                |        29       |
|  0.450542728159 | 0.00373772714054 |                {'C': 1.0, 'gamma': 0.01}                 |        29       |
|  0.450542728159 | 0.00373772714054 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        29       |
|  0.450542728159 | 0.00373772714054 |                 {'C': 1.0, 'gamma': 1.0}                 |        29       |
|  0.488308921939 | 0.0368960822987  |                {'C': 1.0, 'gamma': 10.0}                 |        16       |
|  0.488540243552 | 0.0360368844164  |                {'C': 1.0, 'gamma': 100.0}                |        15       |
|  0.446317845021 | 0.00887743244792 |               {'C': 1.0, 'gamma': 1000.0}                |        64       |
|  0.447364719711 | 0.00800120809447 |               {'C': 1.0, 'gamma': 10000.0}               |        63       |
|  0.450542728159 | 0.00373772714054 |               {'C': 10.0, 'gamma': 0.001}                |        29       |
|  0.450542728159 | 0.00373772714054 |                {'C': 10.0, 'gamma': 0.01}                |        29       |
|  0.449493385747 | 0.00500930164535 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        62       |
|  0.461045095188 | 0.0338934370771  |                {'C': 10.0, 'gamma': 1.0}                 |        26       |
|  0.542816067578 | 0.0764363151414  |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.489560928716 | 0.0480123894082  |               {'C': 10.0, 'gamma': 100.0}                |        14       |
|  0.45602783635  | 0.0269748533561  |               {'C': 10.0, 'gamma': 1000.0}               |        27       |
|  0.452206948405 | 0.0166063076073  |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|  0.450542728159 | 0.00373772714054 |               {'C': 100.0, 'gamma': 0.001}               |        29       |
|  0.450542728159 | 0.00373772714054 |               {'C': 100.0, 'gamma': 0.01}                |        29       |
|  0.461291134469 | 0.0318853483693  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        25       |
|  0.524012071232 | 0.0535675235265  |                {'C': 100.0, 'gamma': 1.0}                |        9        |
|  0.539733386959 | 0.0397361285065  |               {'C': 100.0, 'gamma': 10.0}                |        4        |
|  0.503501415487 | 0.0489162068577  |               {'C': 100.0, 'gamma': 100.0}               |        10       |
|  0.465729951503 | 0.0303294531267  |              {'C': 100.0, 'gamma': 1000.0}               |        21       |
|  0.46352704098  | 0.0285787916854  |              {'C': 100.0, 'gamma': 10000.0}              |        22       |
|  0.450542728159 | 0.00373772714054 |              {'C': 1000.0, 'gamma': 0.001}               |        29       |
|  0.480486469802 | 0.0377310780174  |               {'C': 1000.0, 'gamma': 0.01}               |        17       |
|  0.534567812091 | 0.0704312022877  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        5        |
|  0.544816390377 | 0.0628574260865  |               {'C': 1000.0, 'gamma': 1.0}                |        2        |
|  0.529994810287 | 0.0671642269622  |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.490428047278 | 0.0446114904139  |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.46611057845  | 0.0399629168063  |              {'C': 1000.0, 'gamma': 1000.0}              |        19       |
|  0.46352704098  | 0.0285787916854  |             {'C': 1000.0, 'gamma': 10000.0}              |        22       |
|  0.477850233027 | 0.0372403008576  |              {'C': 10000.0, 'gamma': 0.001}              |        18       |
|  0.533792275474 | 0.0513699697915  |              {'C': 10000.0, 'gamma': 0.01}               |        6        |
|  0.573278436725 | 0.0720933226788  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        1        |
|  0.530173550402 | 0.0582595129805  |               {'C': 10000.0, 'gamma': 1.0}               |        7        |
|  0.50088681545  |  0.095706205818  |              {'C': 10000.0, 'gamma': 10.0}               |        11       |
|  0.500387718966 | 0.0537473108576  |              {'C': 10000.0, 'gamma': 100.0}              |        12       |
|  0.46611057845  | 0.0399629168063  |             {'C': 10000.0, 'gamma': 1000.0}              |        19       |
|  0.46352704098  | 0.0285787916854  |             {'C': 10000.0, 'gamma': 10000.0}             |        22       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 0.10000000000000001}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.66      0.65        94
          1       0.40      0.37      0.38        57

avg / total       0.54      0.55      0.55       151


Accuracy on test set (using best parameters): 0.55


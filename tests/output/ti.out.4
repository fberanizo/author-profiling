Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.45594253427  | 0.00614343110071 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      1.00      0.76        92
          1       0.00      0.00      0.00        59

avg / total       0.37      0.61      0.46       151


Accuracy on test set (using best parameters): 0.61

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.53974003654  | 0.0699016197825 |  {'n_neighbors': 3} |        2        |
|  0.570481402153 | 0.0675543337466 |  {'n_neighbors': 5} |        1        |
|  0.516032531668 | 0.0491832360192 | {'n_neighbors': 11} |        4        |
|  0.531594566205 | 0.0396481469638 | {'n_neighbors': 21} |        3        |
|  0.514597679559 | 0.0525916467088 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.71      0.69       100
          1       0.34      0.29      0.32        51

avg / total       0.55      0.57      0.56       151


Accuracy on test set (using best parameters): 0.57

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.494168856558 | 0.0325509868727 | {'n_estimators': 2}  |        7        |
|  0.556002108138 | 0.0728048651856 | {'n_estimators': 3}  |        1        |
|  0.514925004594 | 0.0427551930762 | {'n_estimators': 5}  |        5        |
|  0.524251494181 | 0.0518733440847 | {'n_estimators': 10} |        3        |
|  0.513136375086 | 0.0481975193761 | {'n_estimators': 20} |        6        |
|  0.517638570056 | 0.0408380931691 | {'n_estimators': 40} |        4        |
|  0.531516076873 | 0.0825291864547 | {'n_estimators': 60} |        2        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.63      0.61        87
          1       0.46      0.42      0.44        64

avg / total       0.54      0.54      0.54       151


Accuracy on test set (using best parameters): 0.54

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.461348275801 | 0.00463446896902 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        3        |
|  0.461348275801 | 0.00463446896902 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        3        |
|  0.460292937147 | 0.00452940700785 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        20       |
|  0.461348275801 | 0.00463446896902 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        3        |
|  0.461348275801 | 0.00463446896902 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        3        |
|  0.461348275801 | 0.00463446896902 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        3        |
|  0.458158352231 | 0.00770531222386 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        21       |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        3        |
|  0.466273442834 | 0.0151351230684  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        1        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        3        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        3        |
|  0.460295603788 | 0.00572585230779 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        19       |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        3        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        3        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        3        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        3        |
|  0.46382955636  | 0.0134968460467  |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        2        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        3        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        3        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        90
          1       0.00      0.00      0.00        61

avg / total       0.36      0.60      0.45       151


Accuracy on test set (using best parameters): 0.60

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.46951264525  | 0.00794123819674 |        {'C': 0.001}        |        5        |
|  0.46951264525  | 0.00794123819674 |        {'C': 0.01}         |        5        |
|  0.46951264525  | 0.00794123819674 | {'C': 0.10000000000000001} |        5        |
|  0.46951264525  | 0.00794123819674 |         {'C': 1.0}         |        5        |
|  0.473277651107 | 0.0136785192591  |        {'C': 10.0}         |        4        |
|  0.505004458013 | 0.0306695909872  |        {'C': 100.0}        |        3        |
|  0.558507133528 | 0.0694178185104  |       {'C': 1000.0}        |        2        |
|  0.570348006119 | 0.0841118230216  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.69      0.63        87
          1       0.44      0.33      0.38        64

avg / total       0.52      0.54      0.52       151


Accuracy on test set (using best parameters): 0.54

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.466787471624 | 0.00723118503124 |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|  0.466787471624 | 0.00723118503124 |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|  0.466787471624 | 0.00723118503124 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|  0.466787471624 | 0.00723118503124 |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|  0.466787471624 | 0.00723118503124 |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|  0.466787471624 | 0.00723118503124 |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|  0.466787471624 | 0.00723118503124 |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|  0.466787471624 | 0.00723118503124 |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|  0.466787471624 | 0.00723118503124 |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|  0.466787471624 | 0.00723118503124 |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|  0.466787471624 | 0.00723118503124 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|  0.466787471624 | 0.00723118503124 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.466787471624 | 0.00723118503124 |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|  0.466787471624 | 0.00723118503124 |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|  0.466787471624 | 0.00723118503124 |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|  0.466787471624 | 0.00723118503124 |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|  0.466787471624 | 0.00723118503124 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|  0.466787471624 | 0.00723118503124 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|  0.466787471624 | 0.00723118503124 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|  0.466787471624 | 0.00723118503124 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.466787471624 | 0.00723118503124 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|  0.466787471624 | 0.00723118503124 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|  0.466787471624 | 0.00723118503124 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|  0.466787471624 | 0.00723118503124 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.466787471624 | 0.00723118503124 |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|  0.466787471624 | 0.00723118503124 |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|  0.466787471624 | 0.00723118503124 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.466787471624 | 0.00723118503124 |                 {'C': 1.0, 'gamma': 1.0}                 |        31       |
|  0.483870484042 | 0.0391398380152  |                {'C': 1.0, 'gamma': 10.0}                 |        22       |
|  0.472193508877 | 0.0247629172371  |                {'C': 1.0, 'gamma': 100.0}                |        30       |
|  0.474129661135 | 0.0185291480804  |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.477549074019 | 0.0210927919311  |               {'C': 1.0, 'gamma': 10000.0}               |        28       |
|  0.466787471624 | 0.00723118503124 |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|  0.466787471624 | 0.00723118503124 |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|  0.46573479961  | 0.00866305358503 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        63       |
|  0.501081074918 | 0.0632871956935  |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.553039597112 | 0.0593499302862  |                {'C': 10.0, 'gamma': 10.0}                |        2        |
|  0.509754021931 | 0.0376401089793  |               {'C': 10.0, 'gamma': 100.0}                |        16       |
|  0.491844983316 | 0.0192095944366  |               {'C': 10.0, 'gamma': 1000.0}               |        18       |
|  0.479282264395 | 0.0261017699914  |              {'C': 10.0, 'gamma': 10000.0}               |        27       |
|  0.466787471624 | 0.00723118503124 |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|  0.46573479961  | 0.00866305358503 |               {'C': 100.0, 'gamma': 0.01}                |        63       |
|  0.480458528339 |  0.040786094751  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        26       |
|  0.547287662094 | 0.0348265203949  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.52547531229  | 0.0572861803199  |               {'C': 100.0, 'gamma': 10.0}                |        9        |
|  0.521601170417 | 0.0489109982978  |               {'C': 100.0, 'gamma': 100.0}               |        12       |
|  0.489190314903 | 0.0172186308782  |              {'C': 100.0, 'gamma': 1000.0}               |        19       |
|  0.480588394288 |  0.023845531308  |              {'C': 100.0, 'gamma': 10000.0}              |        23       |
|  0.466787471624 | 0.00723118503124 |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
|  0.484692642637 | 0.0371951058433  |               {'C': 1000.0, 'gamma': 0.01}               |        21       |
|  0.541002794357 | 0.0477797545715  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.560075545156 | 0.0677539698361  |               {'C': 1000.0, 'gamma': 1.0}                |        1        |
|  0.530988047858 | 0.0690312037604  |               {'C': 1000.0, 'gamma': 10.0}               |        7        |
|  0.527696112214 | 0.0403102788393  |              {'C': 1000.0, 'gamma': 100.0}               |        8        |
|  0.511868826204 | 0.0383732511298  |              {'C': 1000.0, 'gamma': 1000.0}              |        14       |
|  0.480588394288 |  0.023845531308  |             {'C': 1000.0, 'gamma': 10000.0}              |        23       |
|  0.48577455554  | 0.0360040169822  |              {'C': 10000.0, 'gamma': 0.001}              |        20       |
|  0.523089916541 | 0.0429535427531  |              {'C': 10000.0, 'gamma': 0.01}               |        11       |
|  0.546403678769 | 0.0544678365569  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        4        |
|  0.513718560462 | 0.0363545092606  |               {'C': 10000.0, 'gamma': 1.0}               |        13       |
|  0.541884398784 | 0.0877717224596  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.52441759405  | 0.0571787551893  |              {'C': 10000.0, 'gamma': 100.0}              |        10       |
|  0.511868826204 | 0.0383732511298  |             {'C': 10000.0, 'gamma': 1000.0}              |        14       |
|  0.480588394288 |  0.023845531308  |             {'C': 10000.0, 'gamma': 10000.0}             |        23       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 1000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.81      0.71        88
          1       0.56      0.35      0.43        63

avg / total       0.60      0.62      0.59       151


Accuracy on test set (using best parameters): 0.62


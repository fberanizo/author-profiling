Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.453239663505 | 0.00489458232085 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      1.00      0.76        93
          1       0.00      0.00      0.00        58

avg / total       0.38      0.62      0.47       151


Accuracy on test set (using best parameters): 0.62

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.553286353929 | 0.0879251812285 |  {'n_neighbors': 3} |        2        |
|  0.541235110803 | 0.0921114521327 |  {'n_neighbors': 5} |        3        |
|  0.559574900052 | 0.0842319016202 | {'n_neighbors': 11} |        1        |
|  0.521288073943 | 0.0620060791159 | {'n_neighbors': 21} |        5        |
|  0.539843799239 | 0.0726990812038 | {'n_neighbors': 31} |        4        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      0.67      0.67       100
          1       0.34      0.33      0.34        51

avg / total       0.55      0.56      0.56       151


Accuracy on test set (using best parameters): 0.56

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.504791882667 | 0.0432120836573 | {'n_estimators': 2}  |        6        |
|  0.518562073018 | 0.0559371073121 | {'n_estimators': 3}  |        3        |
|  0.537391994238 | 0.0557611350887 | {'n_estimators': 5}  |        1        |
|  0.535932177934 | 0.0514830101629 | {'n_estimators': 10} |        2        |
|  0.502482141927 |  0.061312343878 | {'n_estimators': 20} |        7        |
|  0.505670306699 | 0.0773395882894 | {'n_estimators': 40} |        5        |
|  0.508673768378 | 0.0614108685955 | {'n_estimators': 60} |        4        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.67      0.74      0.70        87
          1       0.59      0.52      0.55        64

avg / total       0.64      0.64      0.64       151


Accuracy on test set (using best parameters): 0.64

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.458645405036 | 0.00607581554462 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        4        |
|  0.458645405036 | 0.00607581554462 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        4        |
|  0.458645405036 | 0.00607581554462 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        4        |
|  0.458645405036 | 0.00607581554462 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        4        |
|  0.458645405036 | 0.00607581554462 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        4        |
|  0.458645405036 | 0.00607581554462 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        4        |
|  0.458645405036 | 0.00607581554462 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        4        |
|  0.458645405036 | 0.00607581554462 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        4        |
|  0.455398430797 | 0.0108295602466  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        21       |
|  0.458645405036 | 0.00607581554462 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        4        |
|  0.458645405036 | 0.00607581554462 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        4        |
|  0.458645405036 | 0.00607581554462 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        4        |
|  0.458645405036 | 0.00607581554462 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        4        |
|  0.458645405036 | 0.00607581554462 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        4        |
|  0.463457652518 | 0.0127934068255  |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        2        |
|  0.458645405036 | 0.00607581554462 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        4        |
|  0.466397827896 | 0.0268440512654  |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        1        |
|  0.458645405036 | 0.00607581554462 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.460923857086 | 0.00958707322394 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        3        |
|  0.458645405036 | 0.00607581554462 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.457590066381 | 0.00549980651992 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        20       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'relu', 'hidden_layer_sizes': 50}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        91
          1       0.00      0.00      0.00        60

avg / total       0.36      0.60      0.45       151


Accuracy on test set (using best parameters): 0.60

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.464062297997 | 0.00516368736714 |        {'C': 0.001}        |        5        |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.01}         |        5        |
|  0.464062297997 | 0.00516368736714 | {'C': 0.10000000000000001} |        5        |
|  0.464062297997 | 0.00516368736714 |         {'C': 1.0}         |        5        |
|  0.471197565352 | 0.0274888992918  |        {'C': 10.0}         |        4        |
|  0.528106227117 | 0.0772496072724  |        {'C': 100.0}        |        3        |
|  0.541250391321 | 0.0554938279841  |       {'C': 1000.0}        |        2        |
|  0.554468029707 |  0.061970197179  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.65      0.63        89
          1       0.44      0.39      0.41        62

avg / total       0.54      0.54      0.54       151


Accuracy on test set (using best parameters): 0.54

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.429174314081 | 0.00612114566145 |               {'C': 0.001, 'gamma': 0.001}               |        31       |
|  0.429174314081 | 0.00612114566145 |               {'C': 0.001, 'gamma': 0.01}                |        31       |
|  0.429174314081 | 0.00612114566145 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        31       |
|  0.429174314081 | 0.00612114566145 |                {'C': 0.001, 'gamma': 1.0}                |        31       |
|  0.429174314081 | 0.00612114566145 |               {'C': 0.001, 'gamma': 10.0}                |        31       |
|  0.429174314081 | 0.00612114566145 |               {'C': 0.001, 'gamma': 100.0}               |        31       |
|  0.429174314081 | 0.00612114566145 |              {'C': 0.001, 'gamma': 1000.0}               |        31       |
|  0.429174314081 | 0.00612114566145 |              {'C': 0.001, 'gamma': 10000.0}              |        31       |
|  0.429174314081 | 0.00612114566145 |               {'C': 0.01, 'gamma': 0.001}                |        31       |
|  0.429174314081 | 0.00612114566145 |                {'C': 0.01, 'gamma': 0.01}                |        31       |
|  0.429174314081 | 0.00612114566145 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        31       |
|  0.429174314081 | 0.00612114566145 |                {'C': 0.01, 'gamma': 1.0}                 |        31       |
|  0.429174314081 | 0.00612114566145 |                {'C': 0.01, 'gamma': 10.0}                |        31       |
|  0.429174314081 | 0.00612114566145 |               {'C': 0.01, 'gamma': 100.0}                |        31       |
|  0.429174314081 | 0.00612114566145 |               {'C': 0.01, 'gamma': 1000.0}               |        31       |
|  0.429174314081 | 0.00612114566145 |              {'C': 0.01, 'gamma': 10000.0}               |        31       |
|  0.429174314081 | 0.00612114566145 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        31       |
|  0.429174314081 | 0.00612114566145 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        31       |
|  0.429174314081 | 0.00612114566145 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        31       |
|  0.429174314081 | 0.00612114566145 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        31       |
|  0.429174314081 | 0.00612114566145 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        31       |
|  0.429174314081 | 0.00612114566145 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        31       |
|  0.429174314081 | 0.00612114566145 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        31       |
|  0.429174314081 | 0.00612114566145 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        31       |
|  0.429174314081 | 0.00612114566145 |                {'C': 1.0, 'gamma': 0.001}                |        31       |
|  0.429174314081 | 0.00612114566145 |                {'C': 1.0, 'gamma': 0.01}                 |        31       |
|  0.429174314081 | 0.00612114566145 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        31       |
|  0.428134965406 | 0.00773059622682 |                 {'C': 1.0, 'gamma': 1.0}                 |        62       |
|  0.479369553417 | 0.0414365838457  |                {'C': 1.0, 'gamma': 10.0}                 |        15       |
|  0.468928191017 | 0.0421008934237  |                {'C': 1.0, 'gamma': 100.0}                |        19       |
|  0.458149438293 | 0.0435535129692  |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.449605253355 | 0.0334583554141  |               {'C': 1.0, 'gamma': 10000.0}               |        26       |
|  0.429174314081 | 0.00612114566145 |               {'C': 10.0, 'gamma': 0.001}                |        31       |
|  0.429174314081 | 0.00612114566145 |                {'C': 10.0, 'gamma': 0.01}                |        31       |
|  0.428134965406 | 0.00773059622682 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        62       |
|  0.470594099281 | 0.0583255908154  |                {'C': 10.0, 'gamma': 1.0}                 |        18       |
|  0.517420897456 |  0.052383823936  |                {'C': 10.0, 'gamma': 10.0}                |        9        |
|  0.516566110861 | 0.0711924647287  |               {'C': 10.0, 'gamma': 100.0}                |        10       |
|  0.464049678678 | 0.0305101849171  |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.437711804812 | 0.0218494496694  |              {'C': 10.0, 'gamma': 10000.0}               |        27       |
|  0.429174314081 | 0.00612114566145 |               {'C': 100.0, 'gamma': 0.001}               |        31       |
|  0.428134965406 | 0.00773059622682 |               {'C': 100.0, 'gamma': 0.01}                |        62       |
|  0.464075867536 | 0.0556846826077  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        22       |
|  0.543352377621 | 0.0397117990467  |                {'C': 100.0, 'gamma': 1.0}                |        2        |
|  0.510901963965 | 0.0531160939536  |               {'C': 100.0, 'gamma': 10.0}                |        12       |
|  0.513935823339 |  0.07082538339   |               {'C': 100.0, 'gamma': 100.0}               |        11       |
|  0.462018548651 | 0.0406863905541  |              {'C': 100.0, 'gamma': 1000.0}               |        24       |
|  0.437711804812 | 0.0218494496694  |              {'C': 100.0, 'gamma': 10000.0}              |        27       |
|  0.429174314081 | 0.00612114566145 |              {'C': 1000.0, 'gamma': 0.001}               |        31       |
|  0.473265374479 |  0.05094783021   |               {'C': 1000.0, 'gamma': 0.01}               |        17       |
|  0.526037826056 | 0.0571834285635  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        6        |
|  0.53828027247  | 0.0553973770382  |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.537314378878 | 0.0486552761501  |               {'C': 1000.0, 'gamma': 10.0}               |        5        |
|  0.501778720273 | 0.0298743451037  |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.465861410859 | 0.0442545753544  |              {'C': 1000.0, 'gamma': 1000.0}              |        20       |
|  0.437711804812 | 0.0218494496694  |             {'C': 1000.0, 'gamma': 10000.0}              |        27       |
|  0.474680513561 | 0.0519041950006  |              {'C': 10000.0, 'gamma': 0.001}              |        16       |
|  0.523002545355 | 0.0615496487952  |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|  0.539352112068 | 0.0478987285759  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        3        |
|  0.551131864491 | 0.0553732390904  |               {'C': 10000.0, 'gamma': 1.0}               |        1        |
|  0.525455359704 | 0.0619613566813  |              {'C': 10000.0, 'gamma': 10.0}               |        7        |
|  0.49545972311  | 0.0535132187713  |              {'C': 10000.0, 'gamma': 100.0}              |        14       |
|  0.465861410859 | 0.0442545753544  |             {'C': 10000.0, 'gamma': 1000.0}              |        20       |
|  0.437711804812 | 0.0218494496694  |             {'C': 10000.0, 'gamma': 10000.0}             |        27       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.71      0.59      0.64       102
          1       0.36      0.49      0.42        49

avg / total       0.59      0.56      0.57       151


Accuracy on test set (using best parameters): 0.56


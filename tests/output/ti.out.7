Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.434482841286 | 0.00431625250189 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.66      1.00      0.80       100
          1       0.00      0.00      0.00        51

avg / total       0.44      0.66      0.53       151


Accuracy on test set (using best parameters): 0.66

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.528191467436 |  0.073264425419 |  {'n_neighbors': 3} |        4        |
|  0.547763935942 | 0.0347502819176 |  {'n_neighbors': 5} |        1        |
|  0.544227769059 | 0.0396587171976 | {'n_neighbors': 11} |        2        |
|  0.533204675081 | 0.0560080299846 | {'n_neighbors': 21} |        3        |
|  0.492074505342 | 0.0409093227443 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 5}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.72      0.66        90
          1       0.43      0.31      0.36        61

avg / total       0.54      0.56      0.54       151


Accuracy on test set (using best parameters): 0.56

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.482695754436 | 0.0578548355529 | {'n_estimators': 2}  |        7        |
|  0.565068122965 | 0.0449306608174 | {'n_estimators': 3}  |        1        |
|  0.523350086116 | 0.0718010829146 | {'n_estimators': 5}  |        5        |
|  0.558291511994 | 0.0538543539948 | {'n_estimators': 10} |        2        |
|  0.540959764949 | 0.0636634947692 | {'n_estimators': 20} |        4        |
|  0.523046039975 | 0.0505710421375 | {'n_estimators': 40} |        6        |
|  0.545704166003 | 0.0662318029418 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.61      0.62        96
          1       0.35      0.36      0.36        55

avg / total       0.53      0.52      0.52       151


Accuracy on test set (using best parameters): 0.52

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.45594253427  | 0.00614343110071 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        4        |
|  0.45594253427  | 0.00614343110071 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        4        |
|  0.45594253427  | 0.00614343110071 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        4        |
|  0.454887195616 | 0.00503678418435 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        16       |
|  0.454887195616 | 0.00503678418435 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        16       |
|  0.45594253427  | 0.00614343110071 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        4        |
|  0.45594253427  | 0.00614343110071 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        4        |
|  0.459490310997 | 0.0104735747522  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        2        |
|  0.477814019706 | 0.0619048822526  |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        1        |
|  0.454887195616 | 0.00503678418435 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        16       |
|  0.454893191858 | 0.00775865552952 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        15       |
|  0.458631348267 | 0.0181583727048  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        3        |
|  0.451841033132 |  0.021163246866  |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        20       |
|  0.451642888018 | 0.00967695310344 |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        21       |
|  0.45594253427  | 0.00614343110071 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        4        |
|  0.45594253427  | 0.00614343110071 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        4        |
|  0.45594253427  | 0.00614343110071 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        4        |
|  0.45594253427  | 0.00614343110071 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        4        |
|  0.45594253427  | 0.00614343110071 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        4        |
|  0.45594253427  | 0.00614343110071 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        4        |
|  0.454887195616 | 0.00503678418435 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        16       |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 30}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.98      0.75        92
          1       0.50      0.03      0.06        59

avg / total       0.57      0.61      0.48       151


Accuracy on test set (using best parameters): 0.61

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.464062297997 | 0.00516368736714 |        {'C': 0.001}        |        5        |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.01}         |        5        |
|  0.464062297997 | 0.00516368736714 | {'C': 0.10000000000000001} |        5        |
|  0.464062297997 | 0.00516368736714 |         {'C': 1.0}         |        5        |
|  0.487259947009 | 0.0288622866679  |        {'C': 10.0}         |        4        |
|  0.517231437554 | 0.0561372960861  |        {'C': 100.0}        |        3        |
|  0.566297524727 | 0.0809131172846  |       {'C': 1000.0}        |        2        |
|  0.57603935347  |  0.063308807058  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      0.70      0.64        89
          1       0.40      0.29      0.34        62

avg / total       0.51      0.53      0.51       151


Accuracy on test set (using best parameters): 0.53

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.453239663505 | 0.00489458232085 |               {'C': 0.001, 'gamma': 0.001}               |        30       |
|  0.453239663505 | 0.00489458232085 |               {'C': 0.001, 'gamma': 0.01}                |        30       |
|  0.453239663505 | 0.00489458232085 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        30       |
|  0.453239663505 | 0.00489458232085 |                {'C': 0.001, 'gamma': 1.0}                |        30       |
|  0.453239663505 | 0.00489458232085 |               {'C': 0.001, 'gamma': 10.0}                |        30       |
|  0.453239663505 | 0.00489458232085 |               {'C': 0.001, 'gamma': 100.0}               |        30       |
|  0.453239663505 | 0.00489458232085 |              {'C': 0.001, 'gamma': 1000.0}               |        30       |
|  0.453239663505 | 0.00489458232085 |              {'C': 0.001, 'gamma': 10000.0}              |        30       |
|  0.453239663505 | 0.00489458232085 |               {'C': 0.01, 'gamma': 0.001}                |        30       |
|  0.453239663505 | 0.00489458232085 |                {'C': 0.01, 'gamma': 0.01}                |        30       |
|  0.453239663505 | 0.00489458232085 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        30       |
|  0.453239663505 | 0.00489458232085 |                {'C': 0.01, 'gamma': 1.0}                 |        30       |
|  0.453239663505 | 0.00489458232085 |                {'C': 0.01, 'gamma': 10.0}                |        30       |
|  0.453239663505 | 0.00489458232085 |               {'C': 0.01, 'gamma': 100.0}                |        30       |
|  0.453239663505 | 0.00489458232085 |               {'C': 0.01, 'gamma': 1000.0}               |        30       |
|  0.453239663505 | 0.00489458232085 |              {'C': 0.01, 'gamma': 10000.0}               |        30       |
|  0.453239663505 | 0.00489458232085 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        30       |
|  0.453239663505 | 0.00489458232085 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        30       |
|  0.453239663505 | 0.00489458232085 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        30       |
|  0.453239663505 | 0.00489458232085 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        30       |
|  0.453239663505 | 0.00489458232085 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        30       |
|  0.453239663505 | 0.00489458232085 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        30       |
|  0.453239663505 | 0.00489458232085 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        30       |
|  0.453239663505 | 0.00489458232085 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        30       |
|  0.453239663505 | 0.00489458232085 |                {'C': 1.0, 'gamma': 0.001}                |        30       |
|  0.453239663505 | 0.00489458232085 |                {'C': 1.0, 'gamma': 0.01}                 |        30       |
|  0.453239663505 | 0.00489458232085 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        30       |
|  0.452190321092 | 0.0063827464445  |                 {'C': 1.0, 'gamma': 1.0}                 |        61       |
|  0.490742348807 | 0.0288802746616  |                {'C': 1.0, 'gamma': 10.0}                 |        16       |
|  0.463352633976 | 0.0266371416557  |                {'C': 1.0, 'gamma': 100.0}                |        24       |
|  0.453900758951 | 0.00481002948642 |               {'C': 1.0, 'gamma': 1000.0}                |        29       |
|  0.452186991491 | 0.00426527837979 |               {'C': 1.0, 'gamma': 10000.0}               |        64       |
|  0.453239663505 | 0.00489458232085 |               {'C': 10.0, 'gamma': 0.001}                |        30       |
|  0.453239663505 | 0.00489458232085 |                {'C': 10.0, 'gamma': 0.01}                |        30       |
|  0.452190321092 | 0.0063827464445  |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        61       |
|  0.495253150392 | 0.0509020131727  |                {'C': 10.0, 'gamma': 1.0}                 |        14       |
|  0.56140102157  | 0.0663858018461  |                {'C': 10.0, 'gamma': 10.0}                |        3        |
|  0.495090291494 | 0.0460147693064  |               {'C': 10.0, 'gamma': 100.0}                |        15       |
|   0.4680975277  | 0.0248520021913  |               {'C': 10.0, 'gamma': 1000.0}               |        23       |
|  0.459505770316 | 0.0194157165087  |              {'C': 10.0, 'gamma': 10000.0}               |        28       |
|  0.453239663505 | 0.00489458232085 |               {'C': 100.0, 'gamma': 0.001}               |        30       |
|  0.452190321092 | 0.0063827464445  |               {'C': 100.0, 'gamma': 0.01}                |        61       |
|  0.48659762976  | 0.0356917032474  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        17       |
|  0.576063488435 | 0.0571434927327  |                {'C': 100.0, 'gamma': 1.0}                |        1        |
|  0.544201583489 | 0.0462603089325  |               {'C': 100.0, 'gamma': 10.0}                |        7        |
|  0.528093572156 | 0.0393524254919  |               {'C': 100.0, 'gamma': 100.0}               |        10       |
|  0.470707192556 | 0.0178783265102  |              {'C': 100.0, 'gamma': 1000.0}               |        20       |
|  0.463040596095 |  0.020732324164  |              {'C': 100.0, 'gamma': 10000.0}              |        25       |
|  0.453239663505 | 0.00489458232085 |              {'C': 1000.0, 'gamma': 0.001}               |        30       |
|  0.477832227064 | 0.0320029443608  |               {'C': 1000.0, 'gamma': 0.01}               |        19       |
|  0.537082900343 | 0.0570648120309  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        9        |
|  0.559033429034 | 0.0714740109788  |               {'C': 1000.0, 'gamma': 1.0}                |        4        |
|  0.538461010538 | 0.0736231676219  |               {'C': 1000.0, 'gamma': 10.0}               |        8        |
|  0.504532254275 | 0.0342161047257  |              {'C': 1000.0, 'gamma': 100.0}               |        13       |
|  0.468329828952 | 0.0191753404908  |              {'C': 1000.0, 'gamma': 1000.0}              |        21       |
|  0.463040596095 |  0.020732324164  |             {'C': 1000.0, 'gamma': 10000.0}              |        25       |
|  0.485066820331 | 0.0314203042491  |              {'C': 10000.0, 'gamma': 0.001}              |        18       |
|  0.55213938197  | 0.0514763831745  |              {'C': 10000.0, 'gamma': 0.01}               |        6        |
|  0.574033423317 | 0.0610296949426  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.522969735343 | 0.0521914588131  |               {'C': 10000.0, 'gamma': 1.0}               |        11       |
|  0.556815399019 | 0.0434220104149  |              {'C': 10000.0, 'gamma': 10.0}               |        5        |
|  0.517572928566 | 0.0419815651568  |              {'C': 10000.0, 'gamma': 100.0}              |        12       |
|  0.468329828952 | 0.0191753404908  |             {'C': 10000.0, 'gamma': 1000.0}              |        21       |
|  0.463040596095 |  0.020732324164  |             {'C': 10000.0, 'gamma': 10000.0}             |        25       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0, 'gamma': 1.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.83      0.70        93
          1       0.36      0.16      0.22        58

avg / total       0.51      0.57      0.52       151


Accuracy on test set (using best parameters): 0.57


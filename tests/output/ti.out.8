Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.442504849168 | 0.00756469597889 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.64      1.00      0.78        97
          1       0.00      0.00      0.00        54

avg / total       0.41      0.64      0.50       151


Accuracy on test set (using best parameters): 0.64

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.53091164921  | 0.0678237021931 |  {'n_neighbors': 3} |        2        |
|  0.525505244905 | 0.0657618330403 |  {'n_neighbors': 5} |        3        |
|  0.55714172285  | 0.0509562102945 | {'n_neighbors': 11} |        1        |
|  0.502514384968 | 0.0646391374089 | {'n_neighbors': 21} |        4        |
|  0.495562661724 | 0.0638141571052 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 11}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.62      0.71      0.66        91
          1       0.43      0.33      0.38        60

avg / total       0.55      0.56      0.55       151


Accuracy on test set (using best parameters): 0.56

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|   0.5028270682  | 0.0787831901914 | {'n_estimators': 2}  |        4        |
|  0.528965177361 | 0.0725439989999 | {'n_estimators': 3}  |        2        |
|  0.510760674144 |  0.103449642149 | {'n_estimators': 5}  |        3        |
|  0.487257554205 | 0.0631371415334 | {'n_estimators': 10} |        7        |
|  0.492992317186 | 0.0483530276673 | {'n_estimators': 20} |        6        |
|  0.53275994781  | 0.0919652049332 | {'n_estimators': 40} |        1        |
|  0.502414986033 | 0.0711844856954 | {'n_estimators': 60} |        5        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 40}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.72      0.76      0.74       106
          1       0.36      0.31      0.33        45

avg / total       0.61      0.63      0.62       151


Accuracy on test set (using best parameters): 0.63

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.46951264525  | 0.00794123819674 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        2        |
|  0.46951264525  | 0.00794123819674 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        2        |
|  0.46951264525  | 0.00794123819674 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        2        |
|  0.46951264525  | 0.00794123819674 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        2        |
|  0.46951264525  | 0.00794123819674 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        2        |
|  0.46951264525  | 0.00794123819674 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        2        |
|  0.46951264525  | 0.00794123819674 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        2        |
|  0.46951264525  | 0.00794123819674 |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        2        |
|  0.46951264525  | 0.00794123819674 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        2        |
|  0.468454252193 | 0.00752932651878 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        19       |
|  0.46951264525  | 0.00794123819674 |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        2        |
|  0.46951264525  | 0.00794123819674 |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        2        |
|  0.467366045247 | 0.00844499729443 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        21       |
|  0.474368478209 | 0.0187797998852  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        1        |
|  0.46951264525  | 0.00794123819674 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        2        |
|  0.46951264525  | 0.00794123819674 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        2        |
|  0.46951264525  | 0.00794123819674 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        2        |
|  0.468454252193 | 0.00752932651878 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        19       |
|  0.46951264525  | 0.00794123819674 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        2        |
|  0.46951264525  | 0.00794123819674 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        2        |
|  0.46951264525  | 0.00794123819674 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        2        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 150}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.58      1.00      0.73        87
          1       1.00      0.02      0.03        64

avg / total       0.76      0.58      0.44       151


Accuracy on test set (using best parameters): 0.58

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.447857106857 | 0.00485597425035 |        {'C': 0.001}        |        5        |
|  0.447857106857 | 0.00485597425035 |        {'C': 0.01}         |        5        |
|  0.447857106857 | 0.00485597425035 | {'C': 0.10000000000000001} |        5        |
|  0.447857106857 | 0.00485597425035 |         {'C': 1.0}         |        5        |
|  0.448444471203 | 0.0183569013717  |        {'C': 10.0}         |        4        |
|  0.561803159319 |  0.079380731317  |        {'C': 100.0}        |        1        |
|  0.549657027946 | 0.0756758198568  |       {'C': 1000.0}        |        3        |
|  0.561541692725 | 0.0647717391799  |       {'C': 10000.0}       |        2        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 100.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.83      0.70        95
          1       0.24      0.09      0.13        56

avg / total       0.47      0.56      0.49       151


Accuracy on test set (using best parameters): 0.56

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.474958906346 | 0.00519544539189 |               {'C': 0.001, 'gamma': 0.001}               |        27       |
|  0.474958906346 | 0.00519544539189 |               {'C': 0.001, 'gamma': 0.01}                |        27       |
|  0.474958906346 | 0.00519544539189 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        27       |
|  0.474958906346 | 0.00519544539189 |                {'C': 0.001, 'gamma': 1.0}                |        27       |
|  0.474958906346 | 0.00519544539189 |               {'C': 0.001, 'gamma': 10.0}                |        27       |
|  0.474958906346 | 0.00519544539189 |               {'C': 0.001, 'gamma': 100.0}               |        27       |
|  0.474958906346 | 0.00519544539189 |              {'C': 0.001, 'gamma': 1000.0}               |        27       |
|  0.474958906346 | 0.00519544539189 |              {'C': 0.001, 'gamma': 10000.0}              |        27       |
|  0.474958906346 | 0.00519544539189 |               {'C': 0.01, 'gamma': 0.001}                |        27       |
|  0.474958906346 | 0.00519544539189 |                {'C': 0.01, 'gamma': 0.01}                |        27       |
|  0.474958906346 | 0.00519544539189 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        27       |
|  0.474958906346 | 0.00519544539189 |                {'C': 0.01, 'gamma': 1.0}                 |        27       |
|  0.474958906346 | 0.00519544539189 |                {'C': 0.01, 'gamma': 10.0}                |        27       |
|  0.474958906346 | 0.00519544539189 |               {'C': 0.01, 'gamma': 100.0}                |        27       |
|  0.474958906346 | 0.00519544539189 |               {'C': 0.01, 'gamma': 1000.0}               |        27       |
|  0.474958906346 | 0.00519544539189 |              {'C': 0.01, 'gamma': 10000.0}               |        27       |
|  0.474958906346 | 0.00519544539189 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        27       |
|  0.474958906346 | 0.00519544539189 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        27       |
|  0.474958906346 | 0.00519544539189 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        27       |
|  0.474958906346 | 0.00519544539189 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        27       |
|  0.474958906346 | 0.00519544539189 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        27       |
|  0.474958906346 | 0.00519544539189 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        27       |
|  0.474958906346 | 0.00519544539189 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        27       |
|  0.474958906346 | 0.00519544539189 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        27       |
|  0.474958906346 | 0.00519544539189 |                {'C': 1.0, 'gamma': 0.001}                |        27       |
|  0.474958906346 | 0.00519544539189 |                {'C': 1.0, 'gamma': 0.01}                 |        27       |
|  0.474958906346 | 0.00519544539189 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        27       |
|  0.474958906346 | 0.00519544539189 |                 {'C': 1.0, 'gamma': 1.0}                 |        27       |
|  0.472788192182 | 0.0146849686449  |                {'C': 1.0, 'gamma': 10.0}                 |        62       |
|  0.49531094205  | 0.0321843669117  |                {'C': 1.0, 'gamma': 100.0}                |        18       |
|  0.47995238116  | 0.0181737178483  |               {'C': 1.0, 'gamma': 1000.0}                |        23       |
|  0.479722823613 | 0.0141588376462  |               {'C': 1.0, 'gamma': 10000.0}               |        25       |
|  0.474958906346 | 0.00519544539189 |               {'C': 10.0, 'gamma': 0.001}                |        27       |
|  0.474958906346 | 0.00519544539189 |                {'C': 10.0, 'gamma': 0.01}                |        27       |
|  0.474958906346 | 0.00519544539189 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        27       |
|  0.479171268869 | 0.0281106005636  |                {'C': 10.0, 'gamma': 1.0}                 |        26       |
|  0.547872916972 | 0.0678198358677  |                {'C': 10.0, 'gamma': 10.0}                |        1        |
|  0.500591068511 | 0.0217411671543  |               {'C': 10.0, 'gamma': 100.0}                |        17       |
|  0.479736515714 | 0.0135111257658  |               {'C': 10.0, 'gamma': 1000.0}               |        24       |
|  0.490671339189 | 0.0239326281826  |              {'C': 10.0, 'gamma': 10000.0}               |        19       |
|  0.474958906346 | 0.00519544539189 |               {'C': 100.0, 'gamma': 0.001}               |        27       |
|  0.474958906346 | 0.00519544539189 |               {'C': 100.0, 'gamma': 0.01}                |        27       |
|  0.46858139734  | 0.00779348632993 |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        64       |
|  0.540611047512 | 0.0445725330516  |                {'C': 100.0, 'gamma': 1.0}                |        3        |
|  0.532336934136 | 0.0597940030282  |               {'C': 100.0, 'gamma': 10.0}                |        5        |
|  0.518741603319 | 0.0435557236372  |               {'C': 100.0, 'gamma': 100.0}               |        10       |
|  0.501985375882 | 0.0383971790229  |              {'C': 100.0, 'gamma': 1000.0}               |        16       |
|  0.490671339189 | 0.0239326281826  |              {'C': 100.0, 'gamma': 10000.0}              |        19       |
|  0.474958906346 | 0.00519544539189 |              {'C': 1000.0, 'gamma': 0.001}               |        27       |
|  0.472842120233 | 0.00592151908502 |               {'C': 1000.0, 'gamma': 0.01}               |        61       |
|  0.511894908721 | 0.0668254413223  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        13       |
|  0.529585751738 | 0.0699485283508  |               {'C': 1000.0, 'gamma': 1.0}                |        6        |
|  0.508329311582 | 0.0856732883708  |               {'C': 1000.0, 'gamma': 10.0}               |        14       |
|  0.521300193397 | 0.0498809678796  |              {'C': 1000.0, 'gamma': 100.0}               |        9        |
|  0.51204502233  | 0.0476954688818  |              {'C': 1000.0, 'gamma': 1000.0}              |        11       |
|  0.490671339189 | 0.0239326281826  |             {'C': 1000.0, 'gamma': 10000.0}              |        19       |
|  0.471783727176 | 0.00597826633835 |              {'C': 10000.0, 'gamma': 0.001}              |        63       |
|  0.507228763005 | 0.0706236216458  |              {'C': 10000.0, 'gamma': 0.01}               |        15       |
|  0.545493157122 | 0.0651045518474  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.536857205116 | 0.0842932160108  |               {'C': 10000.0, 'gamma': 1.0}               |        4        |
|  0.523669134925 | 0.0599696967315  |              {'C': 10000.0, 'gamma': 10.0}               |        8        |
|  0.528838092909 | 0.0384204761656  |              {'C': 10000.0, 'gamma': 100.0}              |        7        |
|  0.51204502233  | 0.0476954688818  |             {'C': 10000.0, 'gamma': 1000.0}              |        11       |
|  0.490671339189 | 0.0239326281826  |             {'C': 10000.0, 'gamma': 10000.0}             |        19       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.57      0.79      0.66        85
          1       0.47      0.24      0.32        66

avg / total       0.53      0.55      0.51       151


Accuracy on test set (using best parameters): 0.55


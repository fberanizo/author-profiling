Evaluating DummyClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 1 candidates, totalling 10 fits
Grid scores on validation set:

+-----------------+------------------+--------+-----------------+
| test_mean_score |  test_std_score  | params | test_rank_score |
+-----------------+------------------+--------+-----------------+
|  0.458645405036 | 0.00607581554462 |   {}   |        1        |
+-----------------+------------------+--------+-----------------+
Best parameters set found on validation set:

{}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        91
          1       0.00      0.00      0.00        60

avg / total       0.36      0.60      0.45       151


Accuracy on test set (using best parameters): 0.60

Evaluating KNeighborsClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 5 candidates, totalling 50 fits
Grid scores on validation set:

+-----------------+-----------------+---------------------+-----------------+
| test_mean_score |  test_std_score |        params       | test_rank_score |
+-----------------+-----------------+---------------------+-----------------+
|  0.553221693092 |   0.0705569089  |  {'n_neighbors': 3} |        1        |
|  0.528708672073 |  0.041497538036 |  {'n_neighbors': 5} |        2        |
|  0.479790780633 | 0.0482965244752 | {'n_neighbors': 11} |        3        |
|  0.47926543806  |  0.036605470544 | {'n_neighbors': 21} |        4        |
|  0.458629664857 | 0.0269534183517 | {'n_neighbors': 31} |        5        |
+-----------------+-----------------+---------------------+-----------------+
Best parameters set found on validation set:

{'n_neighbors': 3}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.63      0.74      0.68        91
          1       0.47      0.35      0.40        60

avg / total       0.57      0.58      0.57       151


Accuracy on test set (using best parameters): 0.58

Evaluating RandomForestClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 7 candidates, totalling 70 fits
Grid scores on validation set:

+-----------------+-----------------+----------------------+-----------------+
| test_mean_score |  test_std_score |        params        | test_rank_score |
+-----------------+-----------------+----------------------+-----------------+
|  0.502326027145 | 0.0490044600606 | {'n_estimators': 2}  |        7        |
|  0.540180392706 | 0.0923245721014 | {'n_estimators': 3}  |        2        |
|  0.515433952377 | 0.0500653824725 | {'n_estimators': 5}  |        6        |
|  0.537535115976 | 0.0746396892051 | {'n_estimators': 10} |        5        |
|  0.554225348492 | 0.0622052148066 | {'n_estimators': 20} |        1        |
|  0.538350455075 |  0.062735037863 | {'n_estimators': 40} |        4        |
|  0.538663731884 | 0.0824088966551 | {'n_estimators': 60} |        3        |
+-----------------+-----------------+----------------------+-----------------+
Best parameters set found on validation set:

{'n_estimators': 20}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      0.87      0.71        90
          1       0.40      0.13      0.20        61

avg / total       0.52      0.57      0.50       151


Accuracy on test set (using best parameters): 0.57

Evaluating MLPClassifier
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 21 candidates, totalling 210 fits
Grid scores on validation set:

+-----------------+------------------+-------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                         params                        | test_rank_score |
+-----------------+------------------+-------------------------------------------------------+-----------------+
|  0.461348275801 | 0.00463446896902 |  {'activation': 'logistic', 'hidden_layer_sizes': 20} |        5        |
|  0.461348275801 | 0.00463446896902 |  {'activation': 'logistic', 'hidden_layer_sizes': 30} |        5        |
|  0.461348275801 | 0.00463446896902 |  {'activation': 'logistic', 'hidden_layer_sizes': 50} |        5        |
|  0.461348275801 | 0.00463446896902 |  {'activation': 'logistic', 'hidden_layer_sizes': 75} |        5        |
|  0.461348275801 | 0.00463446896902 | {'activation': 'logistic', 'hidden_layer_sizes': 100} |        5        |
|  0.461348275801 | 0.00463446896902 | {'activation': 'logistic', 'hidden_layer_sizes': 120} |        5        |
|  0.461348275801 | 0.00463446896902 | {'activation': 'logistic', 'hidden_layer_sizes': 150} |        5        |
|  0.466171674714 | 0.0148472001244  |    {'activation': 'tanh', 'hidden_layer_sizes': 20}   |        2        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'tanh', 'hidden_layer_sizes': 30}   |        5        |
|  0.460295603788 | 0.00572585230779 |    {'activation': 'tanh', 'hidden_layer_sizes': 50}   |        21       |
|  0.467713702034 |  0.019258606194  |    {'activation': 'tanh', 'hidden_layer_sizes': 75}   |        1        |
|  0.464884895014 | 0.0132537906302  |   {'activation': 'tanh', 'hidden_layer_sizes': 100}   |        4        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'tanh', 'hidden_layer_sizes': 120}   |        5        |
|  0.465891289616 | 0.0113344078826  |   {'activation': 'tanh', 'hidden_layer_sizes': 150}   |        3        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'relu', 'hidden_layer_sizes': 20}   |        5        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'relu', 'hidden_layer_sizes': 30}   |        5        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'relu', 'hidden_layer_sizes': 50}   |        5        |
|  0.461348275801 | 0.00463446896902 |    {'activation': 'relu', 'hidden_layer_sizes': 75}   |        5        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'relu', 'hidden_layer_sizes': 100}   |        5        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'relu', 'hidden_layer_sizes': 120}   |        5        |
|  0.461348275801 | 0.00463446896902 |   {'activation': 'relu', 'hidden_layer_sizes': 150}   |        5        |
+-----------------+------------------+-------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'activation': 'tanh', 'hidden_layer_sizes': 75}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.60      1.00      0.75        90
          1       0.00      0.00      0.00        61

avg / total       0.36      0.60      0.45       151


Accuracy on test set (using best parameters): 0.60

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 8 candidates, totalling 80 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------+-----------------+
| test_mean_score |  test_std_score  |           params           | test_rank_score |
+-----------------+------------------+----------------------------+-----------------+
|  0.447857106857 | 0.00485597425035 |        {'C': 0.001}        |        5        |
|  0.447857106857 | 0.00485597425035 |        {'C': 0.01}         |        5        |
|  0.447857106857 | 0.00485597425035 | {'C': 0.10000000000000001} |        5        |
|  0.447857106857 | 0.00485597425035 |         {'C': 1.0}         |        5        |
|  0.452628174959 | 0.0145275275091  |        {'C': 10.0}         |        4        |
|  0.489808088571 | 0.0459709566165  |        {'C': 100.0}        |        2        |
|  0.484871394255 | 0.0547570618935  |       {'C': 1000.0}        |        3        |
|  0.503310903445 | 0.0631032961965  |       {'C': 10000.0}       |        1        |
+-----------------+------------------+----------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10000.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.65      0.62      0.63        95
          1       0.40      0.43      0.41        56

avg / total       0.56      0.55      0.55       151


Accuracy on test set (using best parameters): 0.55

Evaluating SVC
# Tuning hyper-parameters for f1_weighted

Fitting 10 folds for each of 64 candidates, totalling 640 fits
Grid scores on validation set:

+-----------------+------------------+----------------------------------------------------------+-----------------+
| test_mean_score |  test_std_score  |                          params                          | test_rank_score |
+-----------------+------------------+----------------------------------------------------------+-----------------+
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 0.001}               |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 0.01}                |        26       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.001, 'gamma': 0.10000000000000001}        |        26       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.001, 'gamma': 1.0}                |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 10.0}                |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.001, 'gamma': 100.0}               |        26       |
|  0.464062297997 | 0.00516368736714 |              {'C': 0.001, 'gamma': 1000.0}               |        26       |
|  0.464062297997 | 0.00516368736714 |              {'C': 0.001, 'gamma': 10000.0}              |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.01, 'gamma': 0.001}                |        26       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.01, 'gamma': 0.01}                |        26       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.01, 'gamma': 0.10000000000000001}         |        26       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.01, 'gamma': 1.0}                 |        26       |
|  0.464062297997 | 0.00516368736714 |                {'C': 0.01, 'gamma': 10.0}                |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.01, 'gamma': 100.0}                |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 0.01, 'gamma': 1000.0}               |        26       |
|  0.464062297997 | 0.00516368736714 |              {'C': 0.01, 'gamma': 10000.0}               |        26       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 0.001}        |        26       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 0.01}         |        26       |
|  0.464062297997 | 0.00516368736714 | {'C': 0.10000000000000001, 'gamma': 0.10000000000000001} |        26       |
|  0.464062297997 | 0.00516368736714 |         {'C': 0.10000000000000001, 'gamma': 1.0}         |        26       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 10.0}         |        26       |
|  0.464062297997 | 0.00516368736714 |        {'C': 0.10000000000000001, 'gamma': 100.0}        |        26       |
|  0.464062297997 | 0.00516368736714 |       {'C': 0.10000000000000001, 'gamma': 1000.0}        |        26       |
|  0.464062297997 | 0.00516368736714 |       {'C': 0.10000000000000001, 'gamma': 10000.0}       |        26       |
|  0.464062297997 | 0.00516368736714 |                {'C': 1.0, 'gamma': 0.001}                |        26       |
|  0.464062297997 | 0.00516368736714 |                {'C': 1.0, 'gamma': 0.01}                 |        26       |
|  0.464062297997 | 0.00516368736714 |         {'C': 1.0, 'gamma': 0.10000000000000001}         |        26       |
|  0.468885696911 |  0.014122432252  |                 {'C': 1.0, 'gamma': 1.0}                 |        24       |
|  0.461374230925 | 0.0185686480839  |                {'C': 1.0, 'gamma': 10.0}                 |        64       |
|  0.531273012656 | 0.0398340953848  |                {'C': 1.0, 'gamma': 100.0}                |        12       |
|  0.468879624818 | 0.0163671412696  |               {'C': 1.0, 'gamma': 1000.0}                |        25       |
|  0.464062297997 | 0.00516368736714 |               {'C': 1.0, 'gamma': 10000.0}               |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 10.0, 'gamma': 0.001}                |        26       |
|  0.464062297997 | 0.00516368736714 |                {'C': 10.0, 'gamma': 0.01}                |        26       |
|  0.463006959343 | 0.00560618564699 |        {'C': 10.0, 'gamma': 0.10000000000000001}         |        59       |
|  0.500818499354 |  0.037666764424  |                {'C': 10.0, 'gamma': 1.0}                 |        17       |
|  0.583854559313 | 0.0725494773439  |                {'C': 10.0, 'gamma': 10.0}                |        1        |
|  0.530543701855 |  0.027725998231  |               {'C': 10.0, 'gamma': 100.0}                |        13       |
|  0.478852121283 | 0.0262494049483  |               {'C': 10.0, 'gamma': 1000.0}               |        22       |
|  0.461954287329 | 0.00679915428718 |              {'C': 10.0, 'gamma': 10000.0}               |        60       |
|  0.464062297997 | 0.00516368736714 |               {'C': 100.0, 'gamma': 0.001}               |        26       |
|  0.464062297997 | 0.00516368736714 |               {'C': 100.0, 'gamma': 0.01}                |        26       |
|  0.496123346457 | 0.0373570326921  |        {'C': 100.0, 'gamma': 0.10000000000000001}        |        19       |
|  0.559805805716 | 0.0297143540936  |                {'C': 100.0, 'gamma': 1.0}                |        6        |
|  0.574065070441 |  0.073296984847  |               {'C': 100.0, 'gamma': 10.0}                |        4        |
|  0.512827291287 | 0.0285548314337  |               {'C': 100.0, 'gamma': 100.0}               |        15       |
|  0.476499487121 | 0.0369520898812  |              {'C': 100.0, 'gamma': 1000.0}               |        23       |
|  0.461954287329 | 0.00679915428718 |              {'C': 100.0, 'gamma': 10000.0}              |        60       |
|  0.464062297997 | 0.00516368736714 |              {'C': 1000.0, 'gamma': 0.001}               |        26       |
|  0.49787397106  | 0.0350317472571  |               {'C': 1000.0, 'gamma': 0.01}               |        18       |
|  0.56088174596  | 0.0385957881593  |       {'C': 1000.0, 'gamma': 0.10000000000000001}        |        5        |
|   0.5767250915  | 0.0681866907605  |               {'C': 1000.0, 'gamma': 1.0}                |        3        |
|  0.558131293844 |  0.055016174126  |               {'C': 1000.0, 'gamma': 10.0}               |        7        |
|  0.528735119003 | 0.0370172363019  |              {'C': 1000.0, 'gamma': 100.0}               |        14       |
|  0.481800163718 | 0.0404162941484  |              {'C': 1000.0, 'gamma': 1000.0}              |        20       |
|  0.461954287329 | 0.00679915428718 |             {'C': 1000.0, 'gamma': 10000.0}              |        60       |
|  0.502655492821 | 0.0400548046527  |              {'C': 10000.0, 'gamma': 0.001}              |        16       |
|  0.554658264531 | 0.0529855061591  |              {'C': 10000.0, 'gamma': 0.01}               |        8        |
|  0.579615701758 | 0.0527530728531  |       {'C': 10000.0, 'gamma': 0.10000000000000001}       |        2        |
|  0.547420247102 | 0.0503945541142  |               {'C': 10000.0, 'gamma': 1.0}               |        9        |
|  0.539861113891 | 0.0253916056424  |              {'C': 10000.0, 'gamma': 10.0}               |        10       |
|  0.534980026886 | 0.0222660277763  |              {'C': 10000.0, 'gamma': 100.0}              |        11       |
|  0.481800163718 | 0.0404162941484  |             {'C': 10000.0, 'gamma': 1000.0}              |        20       |
|  0.461954287329 | 0.00679915428718 |             {'C': 10000.0, 'gamma': 10000.0}             |        60       |
+-----------------+------------------+----------------------------------------------------------+-----------------+
Best parameters set found on validation set:

{'C': 10.0, 'gamma': 10.0}


Scores on test set (using best parameters):

             precision    recall  f1-score   support

          0       0.61      0.76      0.68        89
          1       0.46      0.29      0.36        62

avg / total       0.55      0.57      0.55       151


Accuracy on test set (using best parameters): 0.57

